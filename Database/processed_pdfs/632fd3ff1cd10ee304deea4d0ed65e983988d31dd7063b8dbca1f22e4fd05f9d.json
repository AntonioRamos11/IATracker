{
  "text": "MNRAS 000, 1â€“13 (0000)\nPreprint 25 February 2025\nCompiled using MNRAS LATEX style file v3.3\nConditional Diffusion-Flow models for generating 3D cosmic density fields:\napplications to ğ‘“(ğ‘…) cosmologies\nJulieth Katherine Riveros,1 Paola Saavedra,1 HÃ©ctor J. HortÃºa, 1,2â˜…\nJorge Enrique GarcÃ­a-Farieta,3 and Ivan Olier2\n1Grupo Signos, Departamento de MatemÃ¡ticas, Universidad El Bosque, BogotÃ¡, Colombia\n2 Data Science Research Centre, Liverpool John Moores University, 3 Byrom Street, Liverpool L3 3AF, UK\n3 Departamento de FÃ­sica, Universidad de CÃ³rdoba, E-14071, CÃ³rdoba, Spain\n25 February 2025\nABSTRACT\nNext-generation galaxy surveys promise unprecedented precision in testing gravity at cosmological scales. However, realising this\npotential requires accurately modelling the non-linear cosmic web. We address this challenge by exploring conditional generative\nmodelling to create 3D dark matter density fields via score-based (diffusion) and flow-based methods. Our results demonstrate\nthe power of diffusion models to accurately reproduce the matter power spectra and bispectra, even for unseen configurations.\nThey also offer a significant speed-up with slightly reduced accuracy, when flow-based reconstructing the probability distribution\nfunction, but they struggle with higher-order statistics. To improve conditional generation, we introduce a novel multi-output\nmodel to develop feature representations of the cosmological parameters. Our findings offer a powerful tool for exploring\ndeviations from standard gravity, combining high precision with reduced computational cost, thus paving the way for more\ncomprehensive and efficient cosmological analyses Â§.\nKey words: cosmology: large-scale structure of Universe, methods: statistical, methods: numerical, diffusion models\n1 INTRODUCTION\nThe advent of precision cosmology marks a new era in our under-\nstanding of the Universe driven by a variety of upcoming missions.\nAmong the key ongoing and forthcoming efforts are the Dark En-\nergy Spectroscopic Instrument (DESI) (DESI Collaboration et al.\n2016), the Euclid space mission (LaureÄ³s et al. 2011; Amendola\net al. 2018), the Legacy Survey of Space and Time (LSST) (Vera C.\nRubin Observatory LSST Solar System Science Collaboration et al.\n2020), the Wide-Field Infrared Survey Telescope (WFIRST) (Ake-\nson et al. 2019), and the Square Kilometre Array (SKA) (Square\nKilometre Array Cosmology Science Working Group et al. 2020).\nThese experiments aim to provide unprecedented measurements that\nwill constrain cosmological parameters with high precision, with\nN-body simulations being a crucial component of these efforts. N-\nbody simulations are, in fact, essential for accurately modelling the\nlarge-scale structure of the universe, understanding the evolution of\ncosmic fields, and interpreting the data from these surveys. N-body\nsimulations play a fundamental role in understanding the physics\nbehind galaxy survey data, as they enable the exploration of cos-\nmic structures across a range of scales. Although the non-linear\nregime of structure formation can, in principle, be approximated by\nperturbative-based methods (for different approaches, see e.g. Osato\net al. 2019; Blas et al. 2014; Konstandin et al. 2019; Cabass et al.\n2023; Bernardeau et al. 2002; Crocce & Scoccimarro 2006; Carl-\nson et al. 2009; Malik & Wands 2009; Baumann et al. 2012; Car-\nâ˜…E-mail: H.J.HortuaOrjuela@ljmu.ac.uk\nrasco et al. 2012), there is currently no single, universally adopted\nframework. Simulations not only offer insights into the small-scale\nbehaviour of galaxy clustering but also provide a reliable means of\ninvestigating the clustering in cosmologies beyond the Î›-Cold Dark\nMatter (Î›CDM) model. As a result, simulations have become in-\ncreasingly crucial in exploring modified gravity models, with ğ‘“(ğ‘…)\nmodels highlighting a minimal but significant modification of Ein-\nsteinâ€™s general relativity (GR). Since deviations from GR are likely to\nmanifest in summary statistics, accurately predicting these statistics\nis crucial for connecting to theoretical models of structure formation.\nDespite their advantages, simulations can be computationally expen-\nsive, depending on their complexity, such as the richness of physical\nphenomena included and the resolution of mass and scale. This has\nled to the rise of emulators based on deep learning algorithms that\nare designed to quickly and accurately predict cosmological observ-\nables. In particular, generative models have emerged as a promising\ntool in cosmology, especially for enhancing and accelerating the\nanalysis of simulations. Recent advancements in generative models\noffer a powerful approach to efficiently approximate and generate\nmaps where their summary statistics closely mirror the ones ob-\ntained from simulated data. By learning the underlying distribution\nof the complex, high-dimensional cosmic structures, generative mod-\nels can potentially provide faster and more scalable solutions while\nmaintaining accuracy, opening new avenues for both theoretical and\nobservational cosmology. Generative models have been widely used\nin astronomy such as autoencoders (Ullmo et al. 2024; Rothschild\net al. 2022; Arcelin et al. 2021; Jamieson et al. 2023a; Saadeh et al.\n2025), normalizing flows (Hassan et al. 2022; Kwon & Hahn 2024;\nÂ© 0000 The Authors\narXiv:2502.17087v1  [astro-ph.CO]  24 Feb 2025\n\n2\nRiveros et al.\nMootoovaloo et al. 2025; Rouhiainen et al. 2021; GarcÃ­a-Farieta\net al. 2024a), generative adversarial networks (GANs) (Bhambra\net al. 2025; Gondhalekar et al. 2025; Andrianomena et al. 2024b;\nDiao & Mao 2023; Andrianomena et al. 2022; Yiu et al. 2022; Per-\nraudin et al. 2020; Tamosiunas et al. 2021; RodrÃ­guez et al. 2018;\nPerraudin et al. 2019; Gondhalekar et al. 2025; Schaurecker et al.\n2021; Mustafa et al. 2019; Zhang et al. 2024; Kodi Ramanah et al.\n2020; Ullmo et al. 2021), where the authors have demonstrated them\nto be powerful tools for simulating samples from complex proba-\nbility distributions (see GM et al. 2020; Salakhutdinov 2015, for a\ncomprehensive review). Recently, the potential of diffusion models\nhas gained increasing attention, with several studies exploring their\napplication in cosmology for emulating satellite galaxy and subhalo\npopulations (Nguyen et al. 2024), field emulation and parameter in-\nference (Mudur et al. 2023b), emulators (Rouhiainen et al. 2024;\nHassan & Andrianomena 2023) and image generation (Mudur &\nFinkbeiner 2022; Mudur et al. 2023a; Zhao et al. 2023) among oth-\ners. Diffusion models have gained significant attention due to their\neffectiveness in generating high-quality samples (for a review, see\nCroitoru et al. 2023; Cao et al. 2024). These models define a forward\ndiffusion (noising) process that gradually transforms samples from\nthe target distribution into samples from a standard normal distribu-\ntion. The reverse diffusion process, which is learned during training,\nis equivalent to learning the data score, which is why diffusion models\nare also referred to as score-based generative models. This framework\nhas demonstrated remarkable success in photorealistic image gener-\nation, as exemplified by Stable Diffusion, and addresses some of the\nkey limitations of GANs, such as mode collapseâ€”where the model\nfails to capture all modes of the distribution (see e.g. Ho et al. 2020).\nIn this work, we apply diffusion models to generate cold-dark-matter\n3D-density fields of modified ğ‘“(ğ‘…) gravity conditioned on cosmo-\nlogical parameters. By leveraging conditional diffusion models, we\ndemonstrate their ability to emulate fast and accurate full 3D density\nfields while maintaining consistency with the summary statistics, all\nat a low computational cost, with an accuracy similar to state-of-the-\nart N-body simulations of modified gravity models.\nThe outline of this paper is as follows. In Section 2, we describe\nthree diffusion methods employed in this research and illustrate the\nalgorithms used for training and deploying the models. Section 3 in-\ntroduces the modified gravity simulations used for training and eval-\nuating the trained-models, and Section 4 we detail our methodology\nincluding the neural network, the use of representation learning for\nincluding the cosmological parameters as conditioned on the genera-\ntive models, and the n-point statistics for evaluating the performance\nof the models. In Section 5, we present the results of the predicted\nobservables for the different methods implemented and assess their\nperformance. Finally, in Sections 6 and 7, we discuss the results and\nprovide the main conclusions of this research.\n2 PRELIMINARIES\nThis section outlines the basis for conditional diffusion models as\nemulators for N-body simulations. Additionally, we introduce several\nstrategies developed to implement diffusion model flavours.\n2.1 Denoising Diffusion Models\nDiffusion Probabilistic Models (DPMs) have rapidly gained promi-\nnence as a highly promising generative technique in recent years.\nFunctioning as latent variable models for sequence modelling, DPMs\nutilise a latent space with the same dimensionality as the input data.\nForward step\nReverse step\nAdd noise\nDenoise\nFigure 1. The diagram illustrates the forward and reverse processes in DDPM.\nThe top panel shows the generative 3D density fields created at each time step\nğœ, with their corresponding 2D projections displayed below. The centre panel\npresents the power spectra (PS), followed by the evolution of one bispectrum\nconfiguration. The bottom panel depicts the probability distribution function\n(PDF) of the voxels (see Sec. 4.3 for definitions of these statistical moments).\nIn the plots, the blue curves represent the true statistical moments, while the\norange curves correspond to those computed from the generated simulation\nat each time step ğœ.\nIn contrast to Generative Adversarial Networks (GANs) (Goodfellow\net al. 2014), which are not probabilistic models, DPMs offer signif-\nicant advantages, including excellent parallelisation capabilities and\navoidance of adversarial training (Ho et al. 2020). This eliminates\nthe well-known challenges of debugging and convergence difficulties\nfrequently encountered with GAN training.\n2.2 Denoising diffusion probabilistic model (DDPM)\nGenerative models aim to learn and approximate complex, high-\ndimensional data distributions (Lamb 2021). Among these, proba-\nbilistic diffusion models have recently emerged as a powerful tech-\nnique, distinguished by their capacity to transform unstructured noise\ninto highly detailed and structured outputs that closely resemble the\ntraining data distribution (Ho et al. 2020). This is achieved through\na two-stage process: a forward diffusion process that progressively\nadds noise to the data, gradually corrupting its structure, and a re-\nverse diffusion process that learns to reverse this corruption, itera-\ntively building coherent structures from the noise. This bidirectional\napproach, involving both forward and reverse diffusion, has proven\nparticularly effective for challenging astrophysical scenarios, most\nMNRAS 000, 1â€“13 (0000)\n\nGeneration of 3D dark matter density fields\n3\nnotably in generating high-resolution fields (Schanz et al. 2023),re-\nconstruction (Sabti et al. 2024), and as emulators (Mudur et al. 2024;\nZhao et al. 2023; Mudur & Finkbeiner 2022), setting new bench-\nmarks for generative modelling performance. The learning aspect of\nthese models involves mastering the reversal of a complex noising\nprocess, where progressively more noise is actively added to an ini-\ntial image ğ‘¥0 âˆ¼ğ‘(ğ‘¥0) (Schanz et al. 2023). This noise sequence is\nexecuted through a Markov chain of ğ‘‡steps and systematically intro-\nduces Gaussian noise at each stage, generating a sequence of noise\nsamples ğ‘¥1, ..., ğ‘¥ğ‘¡. According to Ho et al. (2020), during the forward\ndiffusion step, noise is introduced to a sample ğ‘¥ğ‘¡from the preceding\none ğ‘¥ğ‘¡âˆ’1 and step sizes are regulated by a variance {ğ›½ğ‘¡âˆˆ(0, 1)}ğ‘‡\nğ‘¡=1\nas\nğ‘(xğ‘¡|xğ‘¡âˆ’1) = N\n\u0010\nxğ‘¡;\nâˆšï¸\n1 âˆ’ğ›½ğ‘¡xğ‘¡âˆ’1, ğ›½ğ‘¡I\n\u0011\n.\n(1)\nwhere ğ›½1 < ğ›½2 < Â· Â· Â· < ğ›½ğ‘¡regulates the reduction in noise between\nsteps. In Eq. (1) the process assumes that ğ‘¥ğ‘¡is conditionally Gaussian\nwith a mean\nâˆšï¸\n1 âˆ’ğ›½ğ‘¡ğ‘¥ğ‘¡âˆ’1 and variance ğ›½ğ‘¡I, where I is the identity\nmatrix. The mean term controls how much of ğ‘¥ğ‘¡âˆ’1 contributes to\nğ‘¥ğ‘¡, while the variance introduces isotropic Gaussian noise with a\nmagnitude determined by ğ›½ğ‘¡(Weng 2021). Therefore, by repeatedly\napplying the forward diffusion process, the image at a specific time\nğ‘¡, denoted ğ‘¥ğ‘¡, can be expressed as a function of the original field\nğ‘¥0. From conditional probabilities, the following joint probability is\ncalculated as\nğ‘(ğ‘¥1:ğ‘‡| ğ‘¥0) =\nğ‘‡\nÃ–\nğ‘¡=1\nğ‘(ğ‘¥ğ‘¡| ğ‘¥ğ‘¡âˆ’1).\n(2)\nThe term ğ‘(ğ‘¥1:ğ‘‡| ğ‘¥0) represents the overall probability of observing\nthe sequence ğ‘¥1 to ğ‘¥ğ‘‡. Each factor ğ‘(ğ‘¥ğ‘¡| ğ‘¥ğ‘¡âˆ’1) denotes the probability\nof transitioning to state ğ‘¥ğ‘¡from the previous state ğ‘¥ğ‘¡âˆ’1, capturing the\nMarkov property, where the next state is determined solely by the\ncurrent state (Weng 2021). A notable feature of this process is that\nsampling at any arbitrary time step can be achieved in closed form\nby leveraging the reparameterization trick (Ho et al. 2020). This\nproperty allows for direct access to any sample ğ‘¥ğ‘¡eliminating the\nneed to sequentially compute all ğ‘¡âˆ’1 previous noisy image\nğ‘¥ğ‘¡=\nâˆšï¸\nÂ¯ğ›¼ğ‘¡ğ‘¥0 +\nâˆšï¸\n1 âˆ’Â¯ğ›¼ğ‘¡ğœ–,\n(3)\nwhere ğ›¼ğ‘¡= 1âˆ’ğ›½ğ‘¡, with Â¯ğ›¼ğ‘¡= Î ğ‘¡\nğ‘–ğ›¼ğ‘–, and ğœ–âˆ¼N (0, I). The noise added\nat each step is systematically removed during the reverse diffusion\nphase (Ho et al. 2020). As a result, the process begins with a distribu-\ntion that contains only noise (the final state of the forward process).\nConsequently, the noise is removed from the samples step by step,\nmoving in the reverse direction. As stated in Ho et al. (2020), the\ninverse diffusion process considers ğ‘¥0, and the events are connected\nthrough the conditional probability distribution\nğ‘ğœƒ(x0:ğ‘‡) = ğ‘(xğ‘‡)\nğ‘‡\nÃ–\nğ‘¡=1\nğ‘ğœƒ(xğ‘¡âˆ’1 | xğ‘¡).\n(4)\nbeing the reverse process equals to\nğ‘ğœƒ(xğ‘¡âˆ’1 | xğ‘¡) = N (xğ‘¡âˆ’1; ğœ‡ğœƒ(xğ‘¡, ğ‘¡), Î£ğœƒ(xğ‘¡, ğ‘¡)).\n(5)\nHere, a neural network with parameters ğœƒis used to compute Eq (4).\nThis express the joint probability distribution ğ‘ğœƒ(x0:ğ‘‡) over a se-\nquence of variables ğ‘¥0, ğ‘¥1, ..., ğ‘¥ğ‘‡parameterized by ğœƒ(Weng 2021).\nWe can divide this joint probability into two parts: the marginal\nprobability of the final state ğ‘(ğ‘¥ğ‘‡), and the product of conditional\nprobabilities ğ‘ğœƒ(ğ‘¥ğ‘¡âˆ’1 | ğ‘¥ğ‘¡) over all timesteps ğ‘¡from 1 to ğ‘‡(Weng\n2021). This structure reflects a reverse process, where each state\nAlgorithm 1 DDPM Training\n1: Randomly select a simulation ğ‘¥0 and its cosmological parameters\nğ‘¦from the training dataset distribution ğ‘(ğ‘¥0).\n2: Drawn sample from Uniform distribution ğ›¾âˆ¼ğ‘ˆ(0, 1)\n3: if ğ›¾< 0.1 then\n4:\nDiscard conditioning from the dataset ğ‘(ğ‘¥0, ğ‘¦= âˆ…)\n5: else\n6:\nKeep conditioning from the dataset ğ‘(ğ‘¥0, ğ‘¦)\n7: end if\n8: Randomly select a time step ğ‘¡in the Markov chain from the\nuniform distribution {1, ...,ğ‘‡}.\n9: Drawn sample from a Gaussian noise ğœ–âˆ¼N (0, I).\n10: Compute the sample ğ‘¥ğ‘¡in the ğ‘¡-th step of the Markov chain as\nEq. 3.\n11: Make a gradient descent step with âˆ‡ğœƒLğ‘¡defined in Eq.7.\n12: Repeat steps 1-5 until converged.\nğ‘¥ğ‘¡âˆ’1 depends on the subsequent step ğ‘¥ğ‘¡. The variance is usually se-\nlected as Î£ğœƒ(xğ‘¡, ğ‘¡) = ğ›½ğ‘¡I as Ho et al. (2020) reported to be the best\nperformance in their results, while the mean ğœ‡ğœƒ(xğ‘¡, ğ‘¡) is given by\nğœ‡ğœƒ(xğ‘¡, ğ‘¡) =\n1\nâˆšğ›¼ğ‘¡\n\u0000ğ‘¥ğ‘¡âˆ’\nğ›½ğ‘¡\nâˆš1 âˆ’Â¯ğ›¼ğ‘¡\nğœ–ğœƒ(xğ‘¡, ğ‘¡)\u0001,\n(6)\nwhere ğœ–ğœƒ(xğ‘¡, ğ‘¡) is the neural network outcome of the noise ğœ–present\nin the sample ğ‘¥ğ‘¡. The loss function used for this optimisation is given\nby the expectation value (Ho et al. 2020)\nLğ‘¡= Eğ‘¡âˆ¼[1,ğ‘‡],ğ‘¥0,ğœ–\n\u0014\r\rğâˆ’ğğœƒ\n\u0000xğ‘¡, ğ‘¡\u0001\r\r2\n\u0015\n,\n(7)\nbeing ğğœƒ\n\u0000xğ‘¡, ğ‘¡\u0001 the neural network prediction of the noise ğœ–present\nin the sample ğ‘¥ğ‘¡, and ğ‘¡âˆ¼[1,ğ‘‡] the time step drawn from a uniform\ndistribution. By minimising this loss, the model learns to predict and\nremove the noise at each step, enabling it to reverse the diffusion\nprocess during inference and generate realistic data from random\nnoise. The training algorithm is listed in Algorithm 1. Once training\nis completed, we expect to generate ğ‘¥0 âˆ¼ğ‘(ğ‘¥0) image from noise.\nIn fact, the model learns to approximate the probability distribution\nof the training set. Hence, we can sample from this distribution and\nbe able to generate new samples that obey the same features as the\ntraining dataset. This can be done by sampling ğ‘‡times Eq. 5 crossing\nthe Markov chain until ğ‘¡= 0 as\nğ‘¥ğ‘¡âˆ’1 =\n1\nâˆšğ›¼ğ‘¡\n\u0000ğ‘¥ğ‘¡âˆ’\nğ›½ğ‘¡\nâˆš1 âˆ’Â¯ğ›¼ğ‘¡\nğœ–ğœƒ(xğ‘¡, ğ‘¡)\u0001 +\nâˆšï¸\nğ›½ğ‘¡ğ‘§,\n(8)\nwith ğ‘§âˆ¼N (0, I). Here, the first term is the mean estimate provided\nby the neural network Eq. 6 perturbed by the presence of a Gaussian\nnoise ğ›½ğ‘¡akin to a Langevin sampling step (Welling & Teh 2011).\nThe inference algorithm is listed in Algorithm 2.\n2.3 Denoising diffusion implicit models (DDIM)\nDDIMs are implicit probabilistic models associated with DDPMs,\nsince they are trained using the same loss function (Song et al. 2022).\nDDIMs present an optimised version of DDPM and offer a more effi-\ncient and faster solution to the image generation problem. Although\nit uses the same training objective as DDPM, DDIM introduces non-\nMarkov processes instead of strictly following the Markov approach.\nThis allows DDIM to balance between the quality of the generated\nsamples and processing time. Furthermore, it can create high-quality\nMNRAS 000, 1â€“13 (0000)\n\n4\nRiveros et al.\nAlgorithm 2 DDPM Sampling\n1: Drawn sample from a Gaussian noise ğœ–âˆ¼N (0, I).\n2: Choose ğœ”= [0, 1]: guidance strength.\n3: Loop through the backward Markov chain:\n4: for ğ‘¡= ğ‘‡, ..., 1 do\n5:\nif ğ‘¡> 1 then\n6:\nğœ–âˆ¼N (0, I)\n7:\nelse\n8:\nğœ–= 0\nâŠ²No additional noise in the last step\n9:\nend if\n10:\nCompute ğ‘¥ğ‘¡âˆ’1 Eq. 8 where the score estimation is given by\nEq. 12\n11: end for\n12: Return ğ‘¥0.\nAlgorithm 3 DDIM Sampling\n1: Create a time subset {ğ‘¡1, .., ğ‘¡ğ‘ } âˆˆ{ğ‘¡1, .., ğ‘¡ğ‘‡} with ğ‘ â‰ªğ‘‡\n2: Choose ğœ”= [0, 1]: guidance strength.\n3: Drawn sample from a Gaussian noise ğœ–âˆ¼N (0, I).\n4: Loop through a subset of timesteps:\n5: for ğ‘¡= ğ‘ , ..., 1 do\n6:\nif ğ‘ > 1 then\n7:\nğœ–âˆ¼N (0, I)\n8:\nelse\n9:\nğœ–= 0\nâŠ²No additional noise in the last step\n10:\nend if\n11:\nCompute ğ‘¥ğ‘¡âˆ’1 Eq. 11 with ğœğ‘¡= 0 and where the score\nestimation is given by Eq. 12\n12: end for\n13: Return ğ‘¥0.\nimages faster than DDPM and it performs direct interpolations in\nlatent space and reconstructs observations with minimal error, pro-\nviding greater flexibility in the generation process (Song et al. 2021).\nAccording to Song et al. (2021), the non-Markov inference process\nis employed in this case, which leads to the same function applied\nin the DDPM model mentioned above in equation (1). Therefore,\nthe DDIM model generalises the DDPM model and, in turn, allows\nmodifications to the design of the inverse Markov chains. The ex-\npression for the non-Markovian conditional probability distribution\nğ‘(ğ‘¥ğ‘¡âˆ’1 | ğ‘¥ğ‘¡, ğ‘¥0) is\nğ‘(ğ‘¥ğ‘¡âˆ’1 | ğ‘¥ğ‘¡, ğ‘¥0) = N (ğ‘¥ğ‘¡âˆ’1;\nâˆšï¸\nÂ¯ğ›¼ğ‘¡âˆ’1ğ‘¥0\n+\nâˆšï¸ƒ\n1 âˆ’Â¯ğ›¼ğ‘¡âˆ’1 âˆ’ğœ2\nğ‘¡\nğ‘¥ğ‘¡âˆ’âˆšÂ¯ğ›¼ğ‘¡ğ‘¥0\nâˆš1 âˆ’Â¯ğ›¼ğ‘¡\n, ğœ2I).\n(9)\nAccording to Song et al. (2021), the processes for the implicit DDIM\ndiffusion models are defined in two phases. In the first phase, the for-\nward diffusion process defines ğ‘¥0 and transforms it into ğ‘¥ğ‘¡. Initially,\nthe inference distribution, the non-Markovian forward process is as\nfollows\nğ‘(ğ‘¥1:ğ‘‡| ğ‘¥0) = ğ‘(ğ‘¥ğ‘‡| ğ‘¥0)\nğ‘‡\nÃ–\nğ‘¡=2\nğ‘(ğ‘¥ğ‘¡âˆ’1 | ğ‘¥ğ‘¡, ğ‘¥0),\n(10)\nwhere ğ‘(ğ‘¥1:ğ‘‡| ğ‘¥0) corresponds to the conditional probability of\nobserving the sequence of variables ğ‘¥1:ğ‘‡evolves from an initial state\nğ‘¥0. It shows that the likelihood of a sequence of observations given\nthe initial conditions can be decomposed in terms of a chain of\nprobabilistic dependencies over time (Zhang et al. 2023). Eq. 9 can\nbe expressed as\nğ‘¥ğ‘¡âˆ’1 =\nâˆšï¸\nÂ¯ğ›¼ğ‘¡âˆ’1\nğ‘¥ğ‘¡âˆ’âˆš1 âˆ’Â¯ğ›¼ğ‘¡ğœ–ğœƒ(xğ‘¡, ğ‘¡)\nâˆšÂ¯ğ›¼ğ‘¡\n+\nâˆšï¸ƒ\n1 âˆ’Â¯ğ›¼ğ‘¡âˆ’1 âˆ’ğœ2\nğ‘¡ğœ–ğœƒ(xğ‘¡, ğ‘¡)+ğœğ‘¡ğ‘§,\n(11)\nwith ğ‘§âˆ¼N (0, I), ğœ–ğœƒ(xğ‘¡, ğ‘¡) is the predicted neural network noise ğœ–ğ‘¡\nat time ğ‘¡, and ğœğ‘¡is a parameter learning whose variation determines\nthe difference in the posterior distribution. When ğœğ‘¡= 0, there is not\nrandom sampling and the sample is generated into a deterministic\nscenario. This is the core of DDIM model. Besides, since it does not\nneed to satisfy the Markov process, a subset {ğ‘¡1, .., ğ‘¡ğ‘ } âˆˆ{ğ‘¡1, .., ğ‘¡ğ‘‡}\nwith ğ‘ â‰ªğ‘‡can be created from the original ğ‘‡diffusion time-steps\nfor sampling inference, where ğ‘ is the number of steps in the new\ndiffusion subset. The inference DDIM algorithm is listed in Algo-\nrithm 3. DDPM and DDIM primarily differ in their approach to sam-\npling. While DDPM relies on a Markov process and requires many\ndiffusion steps to achieve high-quality results, it tends to be compu-\ntationally expensive (Weng 2021). The DDIM model offers several\nimprovements over DDPM. It can produce higher-quality samples\nin fewer steps, enhancing efficiency (Weng 2021). Moreover, DDIM\nmaintains a consistency property due to its deterministic generative\nprocess, ensuring that samples conditioned on the same latent vari-\nable share similar high-level features (Weng 2021). This consistency\nalso enables DDIM to perform meaningful semantic interpolation\nwithin the latent space, resulting in smoother and more interpretable\ntransitions between samples (Weng 2021).\n2.4 Conditioned Generation: Classifier-Free diffusion guidance\nWhile training generative models on the simulation, it is important to\ngenerate samples conditioned on the cosmological parameters. To ex-\nplicit incorporate parameter information into the diffusion process,\nwe employ the Classifier-Free Guidance (CFG) in our methodol-\nogy (Ho & Salimans 2022). This technique assumes an unconditional\ndenoising diffusion model ğ‘(ğ‘¥) parameterized through an estimator\nğœ–ğœƒ(ğ‘¥ğ‘¡, ğ‘¡) = ğœ–ğœƒ(ğ‘¥ğ‘¡, ğ‘¡, ğ‘¦= âˆ…)1 and a conditional model ğ‘ğœƒ(ğ‘¥|ğ‘¦) param-\neterized through ğœ–ğœƒ(ğ‘¥ğ‘¡, ğ‘¡, ğ‘¦). Both models are trained with the same\nneural network. In fact, the conditional diffusion model is trained on\ndata (ğ‘¥, ğ‘¦), where the conditioning cosmological parameters ğ‘¦are\nrandomly discarded by ğ›¾< 0.1 (being ğ›¾a sample drawn from an\nuniform distribution [0,1]) such that the model knows how to gen-\nerate images unconditionally as well. Therefore, the score estimator\ncan be written as (Ho & Salimans 2022)\nÂ¯ğœ–ğœƒ(ğ‘¥ğ‘¡, ğ‘¡, ğ‘¦) = ğœ–ğœƒ(ğ‘¥ğ‘¡, ğ‘¡, ğ‘¦) + ğœ”(ğœ–ğœƒ(ğ‘¥ğ‘¡, ğ‘¡) âˆ’ğœ–ğœƒ(ğ‘¥ğ‘¡, ğ‘¡, ğ‘¦)),\n(12)\nwhere ğœ”is a parameter that controls the strength of the classifier\nguidance. In our experiments, we found that ğœ”= [0, 0.5] provides\na suitable range of values to obtain good results. The authors (Ho\n& Salimans 2022) conclude in their studies that the diffusion model\nneeds to have a part dedicated to the unconditional generation task\nin order to produce classifier-free guided scores effective for sample\nquality.\nMNRAS 000, 1â€“13 (0000)\n\nGeneration of 3D dark matter density fields\n5\nğ‘¥1~ğœŒ1\nğ‘¥0~ğœŒ0\nğ‘¡\n1\n0\nFigure 2. Illustration of the generative model based on stochastic interpolants,\nwhich connects two densities ğœŒ0 and ğœŒ1 that represent the feature represen-\ntation of the cosmological parameters and the 3D density field respectively.\nThe time-dependent probability density ğœŒ(ğ‘¡) that bridges ğœŒ0 and ğœŒ1 is found\nthrough the the forward stochastic differential equation solutions Eq. 16 where\na drift function is computed by the UNet. Here, the vector field represented\nwith white arrows describes the drift function.\n2.5 Stochastic Interpolants (SI)\nAlthough diffusion-based methods have achieved impressive results\nin areas such as image generation, there is ongoing research into\nmethods that provide exact transport between arbitrary (not just Gaus-\nsian) probability densities within a finite time frame. Initially, score-\nbased diffusion models achieved the best results using Stochastic\nDifferential Equations (SDEs) (Albergo et al. 2023). However, recent\nresearch has shown that methods based on ordinary differential equa-\ntions (ODE) can achieve comparable or even superior performance\nif the scoring function is learned effectively. ODE-based methods\noffer significant advantages, including the availability of an exact\nand computationally tractable likelihood formula and the straightfor-\nward application of established adaptive integration techniques for\nsampling (Albergo & Vanden-EÄ³nden 2023). A recent generative\nmodel based on stochastic dynamics propose the use of stochastic\ninterpolants (SI) ğ‘¥ğ‘¡that connect a base density ğœŒ0 to the target ğœŒ1, but\nallow for bases that are more general than a Gaussian density. The\ndynamics can be described as (Albergo & Vanden-EÄ³nden 2023)\nğ‘¥(ğ‘¡) = ğ›¼(ğ‘¡)ğ‘¥0 + ğ›½(ğ‘¡)ğ‘¥1 + ğœ(ğ‘¡)ğ‘Š(ğ‘¡),\nğ‘¡âˆˆ[0, 1],\n(13)\nwhere by construction, it satisfies ğ‘¥(ğ‘¡= 0) = ğ‘¥0 âˆ¼ğœŒ0, and ğ‘¥(ğ‘¡= 1) =\nğ‘¥1 âˆ¼ğœŒ1. This approach therefore exactly bridge between samples\nfrom ğœŒ0 at ğ‘¡= 0, and from ğœŒ1 at ğ‘¡= 1. For a large class of densities, ğœŒ0\nand ğœŒ1 supported on Rğ‘‘, these distributions are absolutely continuous\nwith respect to the Lebesgue measure and ğœŒ(ğ‘¡) satisfies a family\nof forward and backward Fokker-Planck equations (Albergo et al.\n2023). Therefore, Eq. 13 can be realized by many different processes\nsuch as ODEs and SDEs, and whose densities at time ğ‘¡are given by\nğœŒ(ğ‘¡) (Albergo & Vanden-EÄ³nden 2023). Following the work in (Chen\net al. 2024; Sabti et al. 2024) let us write the functions under Eq. 13\nas ğ›¼(ğ‘¡) = ğœ(ğ‘¡) = 1 âˆ’ğ‘¡, ğ›½(ğ‘¡) = ğ‘¡2, and ğ‘Š= âˆšğ‘¡ğ‘§with ğ‘§âˆ¼N (0, ğ¼)\na Wiener process. The authors in (Chen et al. 2024; Albergo et al.\n1 Where for the unconditional model we input a null value âˆ…for the class\nidentifier y when predicting the score.\nAlgorithm 4 SDEs Training\n1: Input: Randomly select a simulation ğ‘¥0 and its labels from the\ntraining dataset distribution ğ‘(ğ‘¥0).\n2: Randomly select a time step ğ‘¡from the uniform distribution\n{1, ...,ğ‘‡}.\n3: Drawn sample from a Gaussian noise ğ‘§âˆ¼N (0, I) and build the\nWiener process.\n4: Compute ğ‘¥(ğ‘¡) and the velocity field defined in Eqs. (13)-(14)\nrespectively.\n5: Make a gradient descent step with âˆ‡ğœƒL[Ë†ğ‘£] defined in Eq.15 and\ncompute it via Monte Carlo sampling.\n6: Repeat steps 1-5 until converged.\n2023) also demonstrate that the velocity field associated with the\ninterpolant, Eq. (13) takes the form\nğ‘£(ğ‘¡, ğ‘¥0, ğ‘¥1) = Â¤ğ›¼(ğ‘¡)ğ‘¥0 + Â¤ğ›½(ğ‘¡)ğ‘¥1 + Â¤ğœ(ğ‘¡)ğ‘Š(ğ‘¡),\n(14)\nwhere the dot in the variables represents differentiation with respect\nto time ğ‘¡. The velocity field can be approximately computed with a\nneural network Ë†ğ‘£(ğ‘¡, ğ‘¥(ğ‘¡)) by minimizing the loss function\nL[Ë†ğ‘£] =\nâˆ«1\n0\nğ‘‘ğ‘¡Eğ‘¥0,ğ‘¥1âˆ¼ğœŒ0,ğœŒ1\n\u0002\n(Ë†ğ‘£(ğ‘¡, ğ‘¥(ğ‘¡)) âˆ’ğ‘£(ğ‘¡, ğ‘¥0, ğ‘¥1))2\u0003\n.\n(15)\nOnce trained, the velocity field will function as the drift term within\nthe stochastic differential equation (Sabti et al. 2024)\ndğ‘¥(ğ‘¡) = Ë†ğ‘£(ğ‘¡, ğ‘¥(ğ‘¡))dğ‘¡+ ğœ(ğ‘¡)dğ‘Š(ğ‘¡),\n(16)\nwhose solutions are such that ğ‘¥(ğ‘¡= 1) âˆ¼ğœŒ(ğ‘¥1|ğ‘¥0) and ğ‘Šaccounts\nfor another Wiener process. This equation expresses the evolution\nof ğ‘¥(ğ‘¡) in terms of two components, the first term describes the\ndeterministic part of the dynamics, while the second term accounts\nfor the stochastic component of the process. To suit this approach to\nour work, ğ‘¥0 represents a latent representation of the cosmological\nparameters generated by a neural network while ğ‘¥1 describes the 3D\nsimulation. Once the model is trained, the velocity field is substituted\nby the UNet in Eq. 16, and the initial volume (ğ‘¥(ğ‘¡= 0)) is given by\nthe feature representation for the cosmological parameters. The time\ninterval ğ‘¡âˆˆ[0, 1] is divided in 200 steps along which we solve\nEq. 16. The Stochastic differential equation was solved using the\nEuler second-order method. At the end, the emulator should generate\ndistributions of volumes ğ‘¥(ğ‘¡= 1) that resemble the characteristics of\nthe density field conditioned on the cosmological parameters.\n3 DATASET: MODIFIED GRAVITY SIMULATIONS\nWe used a dataset already generated by (GarcÃ­a-Farieta et al. 2024a).\nThese simulations were created with the COmoving Lagrangian Ac-\nceleration (COLA) algorithm (Tassev et al. 2013; Koda et al. 2016),\nin particular, the authors used MG-PICOLA2 (Winther et al. 2017), a\nmodified version of L-PICOLA (Howlett et al. 2015) that has been\nextensively tested against full N-body simulations and that extends\nthe gravity solvers to a variety of gravity models . The dataset con-\nsists in 2500 modify gravity simulations varying four cosmological\nparameters Î˜ = {Î©ğ‘š, â„, ğœ8, ğ‘“ğ‘…0}, where â„is the reduced Hubble\nparameter, ğœ8 the r.m.s. density fluctuation within a top-hat sphere\n2 The\ncode\ncan\nbe\nfound\nat\nhttps://github.com/HAWinther/\nMG-PICOLA-PUBLIC\nMNRAS 000, 1â€“13 (0000)\n\n6\nRiveros et al.\nAlgorithm 5 SDEs Sampling\n1: Randomly select a simulation ğ‘¥0 and its labels from the training\ndistribution, the trained model Ë†ğ‘£(ğ‘¡ğ‘›, ğ‘¥ğ‘›); and define a grid ğ‘¡0 =\n0 < ğ‘¡1 Â· Â· Â· < ğ‘¡ğ‘‡= 300.\n2: Set Î”ğ‘¡ğ‘›= ğ‘¡ğ‘›+1 âˆ’ğ‘¡ğ‘›, ğ‘›= 0 : ğ‘‡âˆ’1.\n3: Create a 3D image representation of the labels\n4: Drawn sample from a Gaussian noise ğ‘§ğ‘›âˆ¼N (0, I) and build the\nWiener process.\n5: Set ğ‘¥1 = ğ‘¥0 + Ë†ğ‘£(ğ‘¡0, ğ‘¥0)Î”ğ‘¡0 + ğœ(ğ‘¡0)âˆšÎ”ğ‘¡0ğ‘§0.\n6: for ğ‘›= 1 : ğ‘‡âˆ’1 do\n7:\nCompute Ë†ğ‘£ğ‘¡ğ‘›(ğ‘¥ğ‘›, ğ‘¡ğ‘›) from Eq. (16).\n8:\nSet ğ‘¥ğ‘›+1 = ğ‘¥ğ‘›+ Ë†ğ‘£(ğ‘¥ğ‘›, ğ‘¡ğ‘›)Î”ğ‘¡ğ‘›+ ğœ(ğ‘¡ğ‘›)âˆšÎ”ğ‘¡ğ‘›ğ‘§ğ‘›.\n9: end for\n10: Return: ğ‘¥ğ‘‡.\nTable 1. The summary of the set-up of the MG simulations. Left: cosmology\nparameters. Right: set-up parameters used for MG-PICOLA code.\nCosmologies\nSimulation setup\nÎ©ğ‘š\n[0.1, 0.5]\nBoxsize\n256 â„âˆ’1 Mpc\nâ„\n[0.5, 0.9]\nğ‘ğ‘\n1283\nğœ8\n[0.6, 1.0]\nGrid force\n1283\n0.1 log10 | ğ‘“ğ‘…0|\n[0.4, 0.6]\nIC\n2LPT ğ‘§ğ‘–ğ‘›ğ‘–= 49\nÎ©ğ‘\n0.0489\nSteps\n100\nğ‘›ğ‘ \n0.9665\nğ‘˜Ny\n1.58\nof 8 Mpc/â„radius and ğ‘“ğ‘…0 the amplitude of the modified gravity\nfunction in the Hu & Sawicki model (HS) (Hu & Sawicki 2007).\nThe remaining cosmological parameters are set to Î©ğ‘= 0.048206\nand ğ‘›ğ‘ = 0.96, which correspond to the values reported by Planck\nCollaboration et al. (2020). The parameter space is sampled with\nrandom numbers uniformly distributed within the specified ranges\nfor each parameter (see Table 1). Fig. 3 shows the distribution of\nthe 2500 ğ‘“(ğ‘…) cosmologies used in this work, presented in a plane\nprojection and highlighting the datasets used for training (light blue\ndots), testing (orange dots) and validation (green dots). Each sim-\nulation follows the dynamics of the particles 1283 in a small box\nof comoving side-length 256â„âˆ’1 Mpc, using 100 timesteps from an\ninitial redshift ğ‘§ğ‘–= 49 to a redshift ğ‘§= 0. The training set comprises\n80% of the data (and validation), which corresponds to 2000 boxes\ncontaining the overdensity fields, while the remaining 20% of the\ndata was used for testing. For each simulation, we estimate the den-\nsity field using a cloud-in-cell (CIC) particle mesh assignment on a\ngrid with 643 voxels. We consider the effective range of the power\nspectrum up to the Nyquist frequency, ğ‘˜Ny, which in our simulations\ncorresponds to ğ‘˜â‰ˆ0.75 Mpc/â„.\n4 METHODOLOGY\n4.1 Neural Network Architecture\nWhile DDPM and DDIM employ neural networks to predict noise\nat each time step during reverse diffusion, stochastic interpolants use\nthem to estimate the velocity field Ë†ğ‘£(ğ‘¡, ğ‘¥ğ‘¡). The architecture used in\nthis research for all approaches is the 3D-UNet depicted in Fig. 4.\nThis model starts with 64 Ã— 64 Ã— 64 voxels with 1 channel, which\nare passed to a calculating schedule across ğ‘‡= 1000 timesteps, ge-\nometrically (cosine) interpolating noise levels from a Beta Start of\n1 Ã— 10âˆ’4 to a Beta End of 0.02. Several experiments were performed\nusing lineal, polynomial, and sigmoid functions, however, cosine\n0.5\n0.6\n0.7\n0.8\n0.9\nh\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\nm\nTraining\nTesting\nValidation\n0.6\n0.7\n0.8\n0.9\n1.0\n8\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\nm\nTraining\nTesting\nValidation\n10\n6\n10\n5\n10\n4\nfR0\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\nm\nTraining\nTesting\nValidation\nFigure 3. Distribution of the 2500 ğ‘“(ğ‘…) cosmologies employed in the dif-\nfusion models in selected parameter planes. Light-blue dots represent the\ntraining dataset, orange dots the testing dataset, and green dots correspond\nto the validation dataset. The parameter planes shown are Î©ğ‘šversus â„, ğœ8,\nand ğ‘“ğ‘…0.\nfunctions provided the best performance. This UNet consists of an\nencoder, the middle module, and its decoder. The feature maps of\nthe same pixel level are concatenated via shortcut connections be-\ntween the encoder and decoder. In the encoder, max-pooling is used\nto down-sampling layer halves the feature maps, enhancing feature\nextraction and expanding the receptive field. On the other hand, up-\nsampling3D in the decoder increases the feature maps, progressively\nrestoring the spatial resolution of the original volume. The output\nof the decoder part is processed with a group normalization layer\nfollowed by an swish activation and a final convolutional block. In\nthe middle module, we have different configurations depending on\nthe method used (DDPM or SI). For the SI case, four ResNet blocks\nare sequently used. The ResNet block shown in Fig. 4-(b) processes\nboth the feature maps and the timesteps. The latter is first projected\nonto an embedding space of dimension 32 using sinusoidal scaling,\nand then processed through two dense layers of 32 neurons, each\nwith swish activation functions. In case that DDPM (and DDIM) is\nemployed, the middle module consists in two paired ResNet-Target\nblocks where the cosmological parameter information is inserted into\nthe architecture. Fig. 4-(c) illustrates the target block schema, where\nthe cosmological parameters are fed into a pre-trained neural network\nto get a 3D feature representation (explained later in Subsec. 4.2) of\nthese parameters. The resultant parameter voxel is then concatenated\nto the feature maps coming from the encoder part.\n4.2 Feature Representation for Cosmological Parameters\nWe built a 3D volume feature representation for the cosmological\nparameters to either aggregate it with the simulation boxes along\nwith the time-steps in DDPM (and DDIM) or define the base density\nğ‘¥0 âˆ¼ğœŒ0 in the SI approach. We propose to build this parameter\nvolume based on the so-called representation learning, a powerful\nMNRAS 000, 1â€“13 (0000)\n\nGeneration of 3D dark matter density fields\n7\n64 x 64 x 64 x 1\n32 x 32 x 32 x 1 \n32 x 32 x 32 x 8 \n16 x 16 x 16 x8\n16 x 16 x 16 x16\n8 x 8 x 8 x 16\n8 x 8 x 8 x 32\n4 x 4 x 4 x 32\n4 x 4 x 4 x 64\n4 x 4 x 4 x 64\n4 x 4 x 4 x 64\n(a) 3D U-Net architecture\n8 x 8 x 8 x 64\n8 x 8 x 8 x 32\n16 x 16 x 16 x32\n16 x 16 x 16 x8\n32 x 32 x 32 x 16 \n32 x 32 x 32 x 8\n64 x 64 x 64 x 8\nVoxel\nTime \n(c) Representation Learning of the\n  cosmological parameters \nRepresentation\nFeatures\n64 x 64 x 64 x 1\n(b) ResNet Block\nResBlock\nConv 3D\nGroupNorm\nTargetBlock(DDPM-DDIM) \nTime (SI) \nDense \nUpsampling3D \nConcatenate (SI) \nResNetBlock(DDPM-DDIM) \nReshape3D\nShortcut  Connection\nActivation Swish\nMax- pooling3D\nFigure 4. 3D UNet modules employed for all models in the paper. (a) UNet architecture composed of ResNet blocks and connections between blocks at each\nlevel of the encoder-decoder. (b) ResNet module schema. (c) Target block schema that transform the parameter space into a 3D representation to be inserted into\nthe UNet.\ntechnique that enable a neural network to automatically discover and\nlearn the most useful representations of raw data (Bengio et al. 2014).\nFirst, we developed a multioutput regression model using the neural\nnetwork displayed in Fig. 5. For this task, we compute the summaries\nfor all train, validation and test volumes such as the power spectra\n(PS), probability distribution function of the voxels (PDFs), and four\ndifferent configurations for the bispectra (Bis). Then, we take data\npairs ([Î©ğ‘š, h, ğœ8, ğ‘“ğ‘…0],[PS, PDFs, Bis1,..., Bis4]) for training the\nmodel in a supervised way. The network receives the cosmological\nparameters as input, which are then processed by two dense layers,\neach with 64 neurons, followed by a sigmoid activation function\nand batch normalization. The output features are reshaped into a\n(64, 64, 64, 1) volume and passed through three 3D convolutional\nlayers, each employing 16 filters, sigmoid activations, and batch\nnormalization. Then, a 3D convolutional layer with one filter along\nwith a sigmoid activation is applied generating a 3D representation\nof the input parameters with dimensions matching the simulation\nboxes. This sub-neural network yields the 3D representation used in\nthe diffusion models. Following with the neural network architecture,\na 3D global max pooling operation is applied to flatten the volume,\nresulting in six output branches, each corresponding to one of the pre-\ndefined summaries. The optimized network architecture is shown in\nFig. 5. Training is performed using a Huber loss, with weighted losses\nassigned to the power spectra and PDF to prioritize their accuracy.\n4.3 Training and summary statistics\nSimulation data normalization involved clipping values using the\nminimum of all maximum values found across the boxes in the\ntraining dataset. Subsequently, we applied a logarithmic scale and\nnormalized the data by subtracting the minimum logarithmic value\n(logmin) and dividing by the range of logarithmic values (logmax\n- logmin), both calculated from the training data. All models were\ntrained using the Huber loss in Eq. 7 instead of the standard mean\nsquared error. The models were optimized with the Adam optimizer\nemploying a learning rate of 10âˆ’4, a batch size of 16, and training for\n30 epochs. Callbacks were implemented to mitigate overfitting. The\nDDPM model, with approximately 15 million parameters, required\napproximately nine hours of training on a 16GB Nvidia T4 GPU,\nwhile the interpolant model required twelve hours on the same GPU.\n4.3.1 A quality metric for generated density fields: n-point statistics\nThe spatial distribution of dark matter is non-Gaussian, and remark-\nably little is known about the information encoded in it about cosmo-\nlogical parameters beyond the power spectrum. Therefore, it is crucial\nthat generative models can learn significant information well beyond\nits power spectrum. Therefore, to illustrate the quality generation\nof our emulators, we compute some summary statistics that provide\ninformation about the Gaussian and non-Gaussian signals. We start\nusing the one-point statistics, commonly known as the probability\nMNRAS 000, 1â€“13 (0000)\n\n8\nRiveros et al.\nğœ´ğ’, ğˆğŸ–, ğ’‡ğ‘¹ğŸ, ğ’‰\nğ‘«ğ’†ğ’ğ’”ğ’†ğŸ”ğŸ’+ Sig. + ğ‘©. ğ‘µ\nğ‘…ğ‘’ğ‘ â„ğ’‚ğ’‘ğ’†(64,64,64,1)\nğ‘«ğ’†ğ’ğ’”ğ’†ğŸ”ğŸ’ğŸ‘+ Sig. + ğ‘©. ğ‘µ\nğ‘ªğ’ğ’ğ’—ğŸ‘ğ‘«ğŸğŸ”, ğŸ‘+ ğ‘ºğ’Šğ’ˆ. +ğ‘©. ğ‘µ\nFeature Representation\nPower Spectrum\nğ‘«ğ’†ğ’ğ’”ğ’†ğŸ–+ Sig. + ğ‘©. ğ‘µ\nğ‘«ğ’†ğ’ğ’”ğ’†ğŸ‘ğŸ+ ReLU\nBispectrum\nğ‘«ğ’†ğ’ğ’”ğ’†ğŸ–+ Sig. + ğ‘©. ğ‘µ\nğ‘«ğ’†ğ’ğ’”ğ’†ğŸğŸ“+ ReLU\nPDF\nğ‘«ğ’†ğ’ğ’”ğ’†ğŸ–+ Sig. + ğ‘©. ğ‘µ\nğ’™ğŸ’ğ’ğ’–ğ’•ğ’‘ğ’–ğ’•ğ’”\nğ’‡ğ’ğ’“ğ’†ğ’‚ğ’„ğ’‰ğ’„ğ’ğ’ğ’‡.\nğ‘«ğ’†ğ’ğ’”ğ’†ğŸğŸ”+ Sig. + ğ‘©. ğ‘µ\nğ‘«ğ’†ğ’ğ’”ğ’†ğŸ‘ğŸ+ Sig. + ğ‘©. ğ‘µ\nğ‘³ğ’‚ğ’ğ’ƒğ’…ğ’‚ğ’™: ğ’™âˆ—ğŸğŸ\nGlobal MaxPooling 3D\nğ‘ªğ’ğ’ğ’—ğŸ‘ğ‘«ğŸğŸ”, ğŸ‘+ ğ‘ºğ’Šğ’ˆ. +ğ‘©. ğ‘µ\nFigure 5. Multioutput regression task for predicting the power spectra (PS),\nprobability distribution function of the voxels (PDFs), and four different\nconfigurations for the bispectra ([Bis1,..., Bis4]) from a set of cosmological\nparameters. Following the training phase, a submodel is extracted from the\nlayers preceding the Global MaxPool 3D in the neural network. This submodel\nenables the generation of a three-dimensional feature representation of the\ncosmological parameters, capturing their complex relationships and working\nas a conditioner for the generative models.\ndensity function (PDF). The PDF reveals density variations within\nthe simulated volume, identifying overdense regions like galaxy clus-\nters and dark matter halos, as well as underdense regions such as\ncosmic voids. The values of density contrast ğ›¿are binned using log-\narithmically spaced bins. The PDF of the cosmic density field is then\ndefined as the normalized number of cells as:\nğ‘ƒ(ğ›¿ğ‘–) =\nğ‘ğ‘–\nğ‘totalÎ”ğ›¿,\n(17)\nwhere ğ‘ğ‘–is the number of samples in the ğ‘–-th bin, ğ‘total is the\ntotal number of samples, and Î”ğ›¿is the width of each bin. The next\nstatistical moment is the matter power spectrum defined as\nâŸ¨ğ›¿(k) ğ›¿(kâ€²)âŸ©= (2ğœ‹)3ğ›¿ğ·(k + kâ€²) ğ‘ƒ(ğ‘˜),\n(18)\nwhere angular brackets denote ensemble average, ğ›¿ğ·is the 3D Dirac\ndelta function, which enforces the homogeneity of the density statis-\ntics, and k, kâ€² are Fourier modes. The fact that the power spectrum\ndepends only on the magnitude ğ‘˜â‰¡|ğ‘˜| is required by isotropy, which\nallow us to provide information about the Gaussian signal in the data.\nIn addition to the two-point statistics, we also considered the three-\npoint statistics of the density field. These statistics are able to capture\nany non-Gaussianities in the density field. The matter bispectrum\nğµ(ğ‘˜1, ğ‘˜2, ğ‘˜3) is defined as\nâŸ¨ğ›¿(k1) ğ›¿(k2) ğ›¿(k3)âŸ©= (2ğœ‹)3ğ›¿ğ·(k1 + k2 + k3) ğµ(ğ‘˜1, ğ‘˜2, ğ‘˜3) .\n(19)\nUnlike the power spectrum, which is only sensitive to the magnitude\nof Fourier modes, the bispectrum is the lowest-order correlator that is\nsensitive to phases. Because homogeneity constraints the wavenum-\nbers (ğ‘˜1 + ğ‘˜2 + ğ‘˜3) to form a closed triangle, we can also express\nthe bispectrum as a function of two magnitudes and an angle, i.e.\nğµ(ğ‘˜1, ğ‘˜2, ğœƒ). It is useful, particularly in analyses of modified theories\nof gravity to consider the reduced bispectrum\nğ‘„(ğ‘˜1, ğ‘˜2, ğ‘˜3) =\nğµ(ğ‘˜1, ğ‘˜2, ğ‘˜3)\nğ‘ƒ(ğ‘˜1) ğ‘ƒ(ğ‘˜2) + ğ‘ƒ(ğ‘˜2) ğ‘ƒ(ğ‘˜3) + ğ‘ƒ(ğ‘˜1) ğ‘ƒ(ğ‘˜3) ,\n(20)\nto remove the information that is already contained in the power\nspectrum. Note that ğ‘„(ğ‘˜1, ğ‘˜2, ğ‘˜3) can be written as ğ‘„(ğ‘˜1, ğ‘˜2, ğœƒ)\nwhich define a unique triangle given two out of the three arguments.\nWe use the Pylians3 library to compute these statistics3.\n5 RESULTS\nHaving thoroughly examined the methodologies employed for\nDDPM (and DDIM) as well as SI models, we now turn our attention\nto evaluating their performance in generating 3D density fields. To\nassess the efficacy of the DDPM model, we trained it on the rele-\nvant dataset and subsequently generated 50 synthetic samples. These\nsamples were then rigorously compared against a test set instance\nwith identical cosmological parameters, focusing on their summary\nstatistics. The outcomes of this analysis for the DDPM model are il-\nlustrated in Fig. 6. The results demonstrate that the DDPM-generated\nfields exhibit remarkable consistency with the true field. Not only do\nthey accurately capture the Gaussian signal, but they also success-\nfully recover a diverse range of bispectra configurations. Specifically,\ntwo of the bispectra configurations analysed were directly aligned\nwith those used during the training of the feature representation (as\ndetailed in Sec. 4.2), while the remaining configurations represent\ninterpolations between these key points. This highlights the mod-\nels ability to generalise and produce physically meaningful outputs,\neven for configurations not explicitly encountered during training.\nNotice that for lower wavenumbers(ğ‘˜), the predicted power spectrum\ndeviates significantly from the true one. This discrepancy can be at-\ntributed to the finite size of the volumes, which inherently imposes\na cut-off on large-scale modes. Due to the periodic boundary condi-\ntions and the limited spatial extent of the simulation boxes, modes\nwith wavelengths exceeding the box size are effectively truncated.\nAs a result, the power spectrum and bispectra, are influenced by\nthe absence of these large-scale fluctuations. For the latter, we can\nobserve slight deviations in their tails. These limitations are particu-\nlarly significant in cosmological simulations with a small resolution\nsize, as large-scale modes play a crucial role in shaping the structure\nof the density fields. As previously discussed, one of the primary\ndrawbacks of DDPM is the significant computational time required\nto generate samples. This is due to the iterative nature of the process,\nwhere the neural network must denoise the image over ğ‘‡= 1000\nsequential steps. To address this limitation, DDIM was introduced as\nan alternative approach during the inference process after training the\nDDPM model. DDIM accelerates the generation process by relaxing\nthe Markovian assumption, as detailed in Sec. 2.3. While this modi-\nfication substantially reduces inference time, it comes at the cost of a\nslight degradation in the quality of the generated samples. This trade-\noff is evident in Fig. 7, where the bispectra of the DDIM-generated\nsimulations show a noticeable, though modest, deterioration com-\npared to those produced by DDPM. The balance between sample\n3 https://pylians3.readthedocs.io/\nMNRAS 000, 1â€“13 (0000)\n\nGeneration of 3D dark matter density fields\n9\nModel\nPower Spectra\nBispectra\n(ğ‘˜1 = 2ğ‘˜2 = 0.3)\nPDF\nInference\nTime\nMSE\nMAE\nğ‘…2\nMSE\nMAE\nğ‘…2\nMSE\nMAE\nğ‘…2\nDDPM\n61.67\n1.70\n0.89\n6.95\n2.21\n0.81\n0.31\n0.27\n0.83\n3m 20.2s.\nDDIM\n69.25\n1.86\n0.80\n16.35\n3.42\n0.72\n1.02\n0.53\n0.41\n9.9s\nSI\n115.14\n2.29\n0.72\n22.56\n3.97\n0.64\n0.14\n0.18\n0.89\n45.9s\nTable 2. Assessment of the generative models through the test set, with bold values indicating superior performance. The results show that DDPM achieves the\nlowest error for most statistical moments, outperforming the majority of the models. However, SI performs best in terms of PDF accuracy. Additionally, DDIM\nstands out by generating synthetic datasets in just 10 seconds. Here we present the results specifically for the most standard bispectrum configuration ğ‘˜1 = 2ğ‘˜2.\n10\n3\n10\n1\n101\nPDF( )\nN-body\nDDPM\n10\n1\n100\n101\n102\nP(k) [(Mpc/h)3]\n0\n10\n20\nQ(\n12)\nk1 = k2 = 0.2 h/Mpc\n10\n1\n100\n1\n3\n5\nRatio PDFs\n10\n1\nk [h/Mpc]\n1\n3\n5\nRatio P(k)\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\n10\n20\n30\nQ(\n12)\nk1 = 0.25 h/Mpc, k2 = 0.15 h/Mpc\n10\n20\n30\nQ(\n12)\nk1 = 0.3 h/Mpc, k2 = 0.15 h/Mpc\n10\n20\n30\nQ(\n12)\nk1 = 0.3 h/Mpc, k2 = 0.2 h/Mpc\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\nFigure 6. Summary statistics for generated fields with DDPM corresponding to the fiducial value (Î©ğ‘š= 0.305,ğœ8 = 0.710, â„= 0.561, and 0.1 log10 | ğ‘“ğ‘…0| =\n0.43). Each panel shows the probabilistic distribution function PDF with 50 bins, power spectrum ğ‘ƒ(ğ‘˜), and four bispectra configuration ğ‘„(ğœƒ12). Solid orange\nline represents the mean over 50 generative samples, while the orange region defines the standard deviation. Bottom plots illustrate the percent error for each\nsummary statistics.\nquality and inference time is a critical consideration, particularly in\napplications requiring the bispectra to constrain cosmological param-\neters. During the validation phase, this trade-off must be carefully\ncalibrated to ensure that the reduction in computational cost does\nnot compromise the scientific utility of the generated samples. By\nfine-tuning this balance, DDIM enables the efficient production of\na high number of volume samples in a shorter time, making it a\npractical choice for large-scale simulations despite its minor quality\ntrade-offs. Note that in the DDIM model, the small Fourier modes\nexhibit behaviour consistent with the ground truth. However, devi-\nations begin to emerge for larger modes, reaching up to 30% error.\nThis discrepancy can be linked to the slight degradation in quality\nobserved in DDIM, as we typically expect precise reconstruction at\nscales below the Nyquist frequency. Despite this, the power spec-\ntrum can be recovered within tens of percent accuracy across the\nentire range. Finally, the statistics of a generated sample from the\nSI approach are illustrated in Fig. 8. It is evident that the SI method\nyields lower performance compared to the previous model. While\nSI successfully reconstructs the probability distribution function for\nthe majority of the samples, it struggles to accurately capture higher\nstatistical moments, despite displaying favourable trends and shapes\nrelative to the ground truth.In Table 2, we present the evaluation met-\nrics for all models using the entire test dataset. We employ the mean\nsquare error (MSE), mean absolute error (MAE), and the coefficient\nof determination (ğ‘…2) to assess the accuracy of the statistical mo-\nments derived from the power spectrum, a bispectrum configuration,\nand the probability density function (PDF). Our results indicate that\nthe Denoising Diffusion Probabilistic Model (DDPM) significantly\noutperforms the other models, achieving the lowest error across all\nmetrics. However, DDPM requires more time to generate volumes\ncompared to the other methods. In contrast, the Denoising Diffusion\nImplicit Model (DDIM) generates images in just 9.9ğ‘ , making it a\nMNRAS 000, 1â€“13 (0000)\n\n10\nRiveros et al.\n10\n2\n100\nPDF( )\nN-body\nDDIM\n10\n1\n100\n101\nP(k) [(Mpc/h)3]\n0\n10\n20\nQ(\n12)\nk1 = k2 = 0.2 h/Mpc\n10\n1\n100\n1\n3\n5\nRatio PDFs\n10\n1\nk [h/Mpc]\n1\n3\n5\nRatio P(k)\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\n10\n20\n30\nQ(\n12)\nk1 = 0.25 h/Mpc, k2 = 0.15 h/Mpc\n10\n20\n30\nQ(\n12)\nk1 = 0.3 h/Mpc, k2 = 0.15 h/Mpc\n10\n20\n30\nQ(\n12)\nk1 = 0.3 h/Mpc, k2 = 0.2 h/Mpc\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\nFigure 7. Summary statistics for generated fields with DDIM corresponding to the fiducial value (Î© = 0.5,ğœ8 = 0.7, â„= 0.2, and ğ‘“ğ‘…0 = 0.1). Each panel\nshows the probabilistic distribution function PDF with 50 bins, power spectrum ğ‘ƒ(ğ‘˜), and four bispectra configuration ğ‘„(ğœƒ12). Solid orange line represents the\nmean over 50 generative samples, while the orange region defines the standard deviation. Bottom plots illustrate the percent error for each summary statistics.\npractical choice for applications where faster generation is essential\nsuch as a parameter constraints. Additionally, we observe that the\nStochastic Interpolation (SI) model excels at recovering the PDF and\ngenerates data in less than a minute. We think that further refinement\nthrough hyperparameter tuning could enhance SI performance, po-\ntentially making it a highly accurate and efficient model in terms of\nboth precision and inference time.\n6 DISCUSSION\nThis work has demonstrated the potential of conditional generative\nmodelling to accurately create 3D dark matter density fields, cap-\nturing high-order statistical moments with considerable success. Our\napproach offers a promising avenue for generating realistic cosmolog-\nical structures, a crucial task for various analyses in cosmology. The\ndemonstrated consistency with higher-order statistics underscores\nthe model ability to capture the complex, non-Gaussian nature of\nthe cosmic web, a significant improvement over methods that rely\nsolely on two-point statistics. This capability is particularly relevant\nfor studying in future phenomena sensitive to the details of struc-\nture formation, such as gravity model, galaxy formation, weak lens-\ning and develop parameter estimation (GarcÃ­a-Farieta et al. 2024b;\nOno et al. 2024; Andrianomena et al. 2024a). However, our current\nmodel exhibits limitations, particularly at lower wavenumbers. This\nincreased uncertainty stems from the limited volume of the training\nsimulations. The relatively small box size restricts the representa-\ntion of large-scale structures, leading to less accurate predictions on\nthese scales. This limitation highlights the critical need for training\ndata that encompasses a wider range of scales to capture the full\nspectrum of cosmic structures. Future work will therefore prioritize\ntraining our models on significantly larger simulations, which will\nprovide access to a broader range of wave modes and improve the\nmodel performance in the low-wavenumber regime. This will be\ncrucial for accurately modelling large-scale structure and its impact\non cosmological observables (Sharma et al. 2024; Jamieson et al.\n2023b; GarcÃ­a-Farieta et al. 2024b). To address the computational\nchallenges associated with larger simulations, we plan to transition\nto latent diffusion models in future studies. This approach offers a\ncompelling pathway to enhance both training and generation effi-\nciency. By learning a latent space that is perceptually equivalent to\nthe simulation space, we can operate in a lower-dimensional space,\nsignificantly reducing the computational cost. The core assumption\nof latent diffusion, that noise perturbation in simulation and latent\nspaces are compatible with the generative process, allows for efficient\nsampling and manipulation of the latent representation. This will en-\nable us to train on larger and more complex simulations, ultimately\nleading to a more robust and accurate generative model (Rombach\net al. 2022; Podell et al. 2023). Furthermore, exploring the impact of\nbaryonic physics and different feedback mechanisms is essential for a\ncomplete understanding of structure formation. We intend to extend\nour analysis by training our models on data from the CAMELS sim-\nulation suite (Villaescusa-Navarro et al. 2021b,a), utilizing different\nastrophysical feedback prescriptions such as those implemented in\nthe IllustrisTNG (Springel et al. 2017) simulations. This will allow us\nMNRAS 000, 1â€“13 (0000)\n\nGeneration of 3D dark matter density fields\n11\n10\n3\n10\n1\n101\nPDF( )\nN-body\nSI\n10\n1\n100\n101\nP(k) [(Mpc/h)3]\n0\n10\n20\nQ(\n12)\nk1 = k2 = 0.2 h/Mpc\n10\n1\n100\n1\n3\n5\nRatio PDFs\n10\n1\nk [h/Mpc]\n1\n3\n5\nRatio P(k)\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\n10\n20\n30\nQ(\n12)\nk1 = 0.25 h/Mpc, k2 = 0.15 h/Mpc\n10\n20\n30\nQ(\n12)\nk1 = 0.3 h/Mpc, k2 = 0.15 h/Mpc\n10\n20\n30\nQ(\n12)\nk1 = 0.3 h/Mpc, k2 = 0.2 h/Mpc\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\n0\n1\n2\n3\n12\n1\n3\n5\nRatio Q12\nFigure 8. Summary statistics for generated fields with SI corresponding to the fiducial value (Î© = 0.5,ğœ8 = 0.7, â„= 0.2, and ğ‘“ğ‘…0 = 0.1). Each panel shows\nthe probabilistic distribution function PDF with 50 bins, power spectrum ğ‘ƒ(ğ‘˜), and four bispectra configuration ğ‘„(ğœƒ12). Solid orange line represents the mean\nover 50 generative samples, while the orange region defines the standard deviation. Bottom plots illustrate the percent error for each summary statistics.\nto investigate the influence of baryonic processes on the dark matter\ndistribution and to develop a more comprehensive model of cosmic\nstructure. Additionally, we plan to incorporate the effects of obser-\nvational distortions, such as redshift-space distortions and lensing\neffects, into our model. This will bring our generated density fields\ncloser to observable quantities and enhance their utility for cosmolog-\nical analyses. Finally, we are particularly interested in leveraging our\ngenerative model for parameter inference. By combining our model\nwith MCMC techniques, we can potentially constrain cosmological\nparameters and explore the degeneracy between different cosmolog-\nical models (HortÃºa et al. 2020; Mudur et al. 2024). The ability to\ngenerate realistic density fields efficiently opens up new possibilities\nfor exploring the likelihood surface and constrain the cosmological\nparameters faster.\n7 CONCLUSIONS\nIn this work, we have explored the application of conditional gener-\native modelling, specifically using Denoising Diffusion Probabilis-\ntic Models (DDPMs), along with their accelerated variant DDIMs,\nand Stochastic Interpolants (SI) to generate 3D dark matter density\nfields. Our analysis demonstrates the significant potential of dif-\nfusion models for this task. Our findings demonstrate that DDPM\nexcels in capturing the complex statistical properties of these fields,\naccurately reproducing both the power spectrum and bispectrum,\neven for configurations not explicitly encountered during training.\nHowever, the computational cost associated with DDPM iterative\ngeneration process presents a significant limitation. While DDIM\noffers a substantial speed-up in sample generation, it comes at the\nexpense of a slight reduction in accuracy, particularly at larger wave\nmodes. This trade-off between speed and accuracy is crucial and\nmust be carefully considered depending on the specific application.\nFinally, the SI model, while capturing some trends in the bispectrum\nand successfully reconstructing the probability distribution function\nfor most samples, exhibits lower overall performance compared to\nboth DDPM and DDIM, especially in capturing higher statistical\nmoments. Our quantitative evaluation confirms the superior perfor-\nmance of DDPM, followed by DDIM, highlighting the potential\nof diffusion-based generative models for cosmological applications.\nFuture work will focus on mitigating the limitations of DDPMs com-\nputational cost, potentially through further refinements of DDIM or\nexploration of other accelerated sampling techniques, and further ex-\nploring the use of these models for parameter inference and other key\ncosmological tasks. Additionally, addressing the low-wavenumber\ndiscrepancies observed in all models due to finite simulation volume\nwill be a priority, requiring the use of larger training simulations.\nOur code, and scripts used to produce the results in this paper can be\nfound at GithubÂ§.\nACKNOWLEDGEMENTS\nThis paper is based on work supported by the Google Cloud Re-\nsearch Credits program with the award GCP19980904 granted to\nH.J. HortÃºa. J.E. GarcÃ­a-Farieta research was financially supported\nMNRAS 000, 1â€“13 (0000)\n\n12\nRiveros et al.\nby the project â€œPlan Complementario de I+D+i en el Ã¡rea de As-\ntrofÃ­sicaâ€ funded by the European Union within the framework of\nthe Recovery, Transformation and Resilience Plan - NextGenera-\ntionEU and by the Regional Government of AndalucÃ­a (Reference\nAST22_00001).\nREFERENCES\nAkeson R., et al., 2019, arXiv e-prints, p. arXiv:1902.05569\nAlbergo M. S., Vanden-EÄ³nden E., 2023, Building Normalizing Flows with\nStochastic Interpolants (arXiv:2209.15571), https://arxiv.org/\nabs/2209.15571\nAlbergo M. S., Boffi N. M., Vanden-EÄ³nden E., 2023, Stochastic Interpolants:\nA Unifying Framework for Flows and Diffusions (arXiv:2303.08797),\nhttps://arxiv.org/abs/2303.08797\nAmendola L., et al., 2018, Living Reviews in Relativity, 21, 2\nAndrianomena S., Villaescusa-Navarro F., Hassan S., 2022, arXiv e-prints,\np. arXiv:2211.05000\nAndrianomena S., Hassan S., Villaescusa-Navarro F., 2024a, Cosmological\nmultifield emulator (arXiv:2402.10997), https://arxiv.org/abs/\n2402.10997\nAndrianomena S., Hassan S., Villaescusa-Navarro F., 2024b, arXiv e-prints,\np. arXiv:2402.10997\nArcelin B., Doux C., Aubourg E., Roucelle C., LSST Dark Energy Science\nCollaboration 2021, MNRAS, 500, 531\nBaumann D., Nicolis A., Senatore L., Zaldarriaga M., 2012, J. Cosmology\nAstropart. Phys., 2012, 051\nBengio Y., Courville A., Vincent P., 2014, Representation Learning: A\nReview and New Perspectives (arXiv:1206.5538), https://arxiv.\norg/abs/1206.5538\nBernardeau F., Colombi S., GaztaÃ±aga E., Scoccimarro R., 2002, Phys. Rep.,\n367, 1\nBhambra P., Joachimi B., Lahav O., Piras D., 2025, MNRAS, 536, 3138\nBlas D., Garny M., Konstandin T., 2014, J. Cosmology Astropart. Phys.,\n2014, 010\nCabass G., Ivanov M. M., Lewandowski M., Mirbabayi M., SimonoviÄ‡ M.,\n2023, Physics of the Dark Universe, 40, 101193\nCao H., Tan C., Gao Z., Xu Y., Chen G., Heng P.-A., Li S. Z., 2024, IEEE\nTransactions on Knowledge and Data Engineering, 36, 2814\nCarlson J., White M., Padmanabhan N., 2009, Phys. Rev. D, 80, 043531\nCarrasco J. J. M., Hertzberg M. P., Senatore L., 2012, Journal of High Energy\nPhysics, 2012, 82\nChen Y., Goldstein M., Hua M., Albergo M. S., Boffi N. M., Vanden-\nEÄ³nden E., 2024, Probabilistic Forecasting with Stochastic Interpolants\nand FÃ¶llmer Processes (arXiv:2403.13724), https://arxiv.org/\nabs/2403.13724\nCrocce M., Scoccimarro R., 2006, Phys. Rev. D, 73, 063519\nCroitoru F.-A., Hondru V., Ionescu R. T., Shah M., 2023, IEEE Transactions\non Pattern Analysis and Machine Intelligence, 45, 10850\nDESI Collaboration et al., 2016, arXiv e-prints, p. arXiv:1611.00036\nDiao K., Mao Y., 2023, arXiv e-prints, p. arXiv:2307.04976\nGM H., Gourisaria M. K., Pandey M., Rautaray S. S., 2020, Computer Science\nReview, 38, 100285\nGarcÃ­a-Farieta J. E., HortÃºa H. J., Kitaura F.-S., 2024a, A&A, 684, A100\nGarcÃ­a-Farieta J. E., Balaguera-AntolÃ­nez A., Kitaura F.-S., 2024b, A&A,\n690, A27\nGondhalekar Y., Bose S., Li B., Cuesta-Lazaro C., 2025, MNRAS, 536, 1408\nGoodfellow I. J., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair\nS., Courville A., Bengio Y., 2014, Generative Adversarial Networks\n(arXiv:1406.2661)\nHassan S., Andrianomena S., 2023, arXiv e-prints, p. arXiv:2311.00833\nHassan S., et al., 2022, ApJ, 937, 83\nHo\nJ.,\nSalimans\nT.,\n2022,\nClassifier-Free\nDiffusion\nGuidance\n(arXiv:2207.12598), https://arxiv.org/abs/2207.12598\nHo J., Jain A., Abbeel P., 2020, arXiv preprint arxiv:2006.11239\nHortÃºa H. J., Volpi R., Marinelli D., MalagÃ² L., 2020, Physical Review D,\n102\nHowlett C., Manera M., Percival W. J., 2015, Astronomy and Computing, 12,\n109\nHu W., Sawicki I., 2007, Phys. Rev. D, 76, 064004\nJamieson D., Li Y., de Oliveira R. A., Villaescusa-Navarro F., Ho S., Spergel\nD. N., 2023a, ApJ, 952, 145\nJamieson D., Li Y., de Oliveira R. A., Villaescusa-Navarro F., Ho S., Spergel\nD. N., 2023b, The Astrophysical Journal, 952, 145\nKoda J., Blake C., Beutler F., Kazin E., Marin F., 2016, MNRAS, 459, 2118\nKodi Ramanah D., Charnock T., Villaescusa-Navarro F., Wandelt B. D., 2020,\nMNRAS, 495, 4227\nKonstandin T., Porto R. A., Rubira H., 2019, J. Cosmology Astropart. Phys.,\n2019, 027\nKwon K. J., Hahn C., 2024, ApJ, 976, 76\nLamb\nA.,\n2021,\nA\nBrief\nIntroduction\nto\nGenerative\nModels\n(arXiv:2103.00265), https://arxiv.org/abs/2103.00265\nLaureÄ³s R., et al., 2011, arXiv e-prints, p. arXiv:1110.3193\nMalik K. A., Wands D., 2009, Phys. Rep., 475, 1\nMootoovaloo A., GarcÃ­a-GarcÃ­a C., Alonso D., Ruiz-Zapatero J., 2025, MN-\nRAS, 536, 190\nMudur N., Finkbeiner D. P., 2022, Can denoising diffusion probabilistic\nmodels generate realistic astrophysical fields? (arXiv:2211.12444),\nhttps://arxiv.org/abs/2211.12444\nMudur N., Cuesta-Lazaro C., Finkbeiner D. P., 2023a, Cosmological\nField Emulation and Parameter Inference with Diffusion Models\n(arXiv:2312.07534), https://arxiv.org/abs/2312.07534\nMudur N., Cuesta-Lazaro C., Finkbeiner D. P., 2023b, arXiv e-prints, p.\narXiv:2312.07534\nMudur N., Cuesta-Lazaro C., Finkbeiner D. P., 2024, Diffusion-HMC: Pa-\nrameter Inference with Diffusion Model driven Hamiltonian Monte Carlo\n(arXiv:2405.05255), https://arxiv.org/abs/2405.05255\nMustafa M., Bard D., Bhimji W., LukiÄ‡ Z., Al-Rfou R., Kratochvil J. M.,\n2019, Computational Astrophysics and Cosmology, 6, 1\nNguyen T., et al., 2024, arXiv e-prints, p. arXiv:2409.02980\nOno V., Park C. F., Mudur N., Ni Y., Cuesta-Lazaro C., Villaescusa-Navarro\nF., 2024, Debiasing with Diffusion: Probabilistic reconstruction of\nDark Matter fields from galaxies with CAMELS (arXiv:2403.10648),\nhttps://arxiv.org/abs/2403.10648\nOsato K., Nishimichi T., Bernardeau F., Taruya A., 2019, Phys. Rev. D, 99,\n063530\nPerraudin N., Srivastava A., Lucchi A., Kacprzak T., Hofmann T., RÃ©frÃ©gier\nA., 2019, Computational Astrophysics and Cosmology, 6, 5\nPerraudin N., Marcon S., Lucchi A., Kacprzak T., 2020, arXiv e-prints, p.\narXiv:2004.08139\nPlanck Collaboration et al., 2020, A&A, 641, A6\nPodell D., English Z., Lacey K., Blattmann A., Dockhorn T., MÃ¼ller J.,\nPenna J., Rombach R., 2023, SDXL: Improving Latent Diffusion Models\nfor High-Resolution Image Synthesis (arXiv:2307.01952), https://\narxiv.org/abs/2307.01952\nRodrÃ­guez A. C., Kacprzak T., Lucchi A., Amara A., Sgier R., Fluri J.,\nHofmann T., RÃ©frÃ©gier A., 2018, Computational Astrophysics and Cos-\nmology, 5, 4\nRombach R., Blattmann A., Lorenz D., Esser P., Ommer B., 2022,\nHigh-Resolution Image Synthesis with Latent Diffusion Models\n(arXiv:2112.10752), https://arxiv.org/abs/2112.10752\nRothschild T., Nagai D., Aung H., Green S. B., Ntampaka M., ZuHone J.,\n2022, MNRAS, 513, 333\nRouhiainen A., Giri U., MÃ¼nchmeyer M., 2021, arXiv e-prints, p.\narXiv:2105.12024\nRouhiainen A., MÃ¼nchmeyer M., Shiu G., Gira M., Lee K., 2024, Phys.\nRev. D, 109, 123536\nSaadeh D., Koyama K., Morice-Atkinson X., 2025, MNRAS, 537, 448\nSabti N., Reddy R., MuÃ±oz J. B., Mishra-Sharma S., Youn T., 2024, A Gen-\nerative Modeling Approach to Reconstructing 21-cm Tomographic Data\n(arXiv:2407.21097), https://arxiv.org/abs/2407.21097\nSalakhutdinov R., 2015, Annual Review of Statistics and Its Application, 2,\n361\nMNRAS 000, 1â€“13 (0000)\n\nGeneration of 3D dark matter density fields\n13\nSchanz\nA.,\nList\nF.,\nHahn\nO.,\n2023,\nStochastic\nSuper-resolution\nof\nCosmological\nSimulations\nwith\nDenoising\nDiffusion\nModels\n(arXiv:2310.06929), https://arxiv.org/abs/2310.06929\nSchaurecker D., Li Y., Tinker J., Ho S., Refregier A., 2021, arXiv e-prints, p.\narXiv:2111.06393\nSharma D., Dai B., Villaescusa-Navarro F., Seljak U., 2024, A field-level\nemulator for modeling baryonic effects across hydrodynamic simulations\n(arXiv:2401.15891), https://arxiv.org/abs/2401.15891\nSong\nJ.,\nMeng\nC.,\nErmon\nS.,\n2021,\nin\nInternational\nConference\non Learning Representations. https://openreview.net/forum?id=\nSt1giarCHLP\nSong J., Meng C., Ermon S., 2022, Denoising Diffusion Implicit Models\n(arXiv:2010.02502)\nSpringel V., et al., 2017, Monthly Notices of the Royal Astronomical Society,\n475, 676â€“698\nSquare Kilometre Array Cosmology Science Working Group et al., 2020,\nPubl. Astron. Soc. Australia, 37, e007\nTamosiunas A., Winther H. A., Koyama K., Bacon D. J., Nichol R. C.,\nMawdsley B., 2021, MNRAS, 506, 3049\nTassev S., Zaldarriaga M., Eisenstein D. J., 2013, J. Cosmology Astropart.\nPhys., 2013, 036\nUllmo M., Decelle A., Aghanim N., 2021, A&A, 651, A46\nUllmo M., Aghnim N., Decelle A., Aragon-Calvo M., 2024, arXiv e-prints,\np. arXiv:2403.02171\nVera C. Rubin Observatory LSST Solar System Science Collaboration et al.,\n2020, arXiv e-prints, p. arXiv:2009.07653\nVillaescusa-Navarro F., et al., 2021a, arXiv e-prints, p. arXiv:2109.10915\nVillaescusa-Navarro F., et al., 2021b, ApJ, 915, 71\nWelling M., Teh Y. W., 2011, in International Conference on Machine Learn-\ning. https://api.semanticscholar.org/CorpusID:2178983\nWeng\nL.,\n2021,\nDiffusion\nModels:\nA\nComprehensive\nOverview,\nhttps://lilianweng.github.io/posts/\n2021-07-11-diffusion-models/\nWinther H. A., Koyama K., Manera M., Wright B. S., Zhao G.-B., 2017,\nJ. Cosmology Astropart. Phys., 2017, 006\nYiu T. W. H., Fluri J., Kacprzak T., 2022, J. Cosmology Astropart. Phys.,\n2022, 013\nZhang G., Ji J., Zhang Y., Yu M., Jaakkola T., Chang S., 2023, Towards\nCoherent Image Inpainting Using Denoising Diffusion Implicit Models\n(arXiv:2304.03322)\nZhang X., Lachance P., Dasgupta A., Croft R. A. C., Di Matteo T., Ni Y.,\nBird S., Li Y., 2024, arXiv e-prints, p. arXiv:2408.09051\nZhao X., Ting Y.-S., Diao K., Mao Y., 2023, Can Diffusion Model Condi-\ntionally Generate Astrophysical Images? (arXiv:2307.09568), https:\n//arxiv.org/abs/2307.09568\nThis paper has been typeset from a TEX/LATEX file prepared by the author.\nMNRAS 000, 1â€“13 (0000)\n",
  "metadata": {
    "source_path": "papers/arxiv/Conditional_Diffusion-Flow_models_for_generating_3D_cosmic_density\n__fields_applications_to_fR_cosmologies_632fd3ff1cd10ee3.pdf",
    "content_hash": "632fd3ff1cd10ee304deea4d0ed65e983988d31dd7063b8dbca1f22e4fd05f9d",
    "arxiv_id": null,
    "title": "Conditional_Diffusion-Flow_models_for_generating_3D_cosmic_density\n__fields_applications_to_fR_cosmologies_632fd3ff1cd10ee3",
    "author": "",
    "creation_date": "D:20250225024317Z",
    "published": "2025-02-25T02:43:17",
    "pages": 13,
    "size": 2319477,
    "file_mtime": 1740470188.2833292
  }
}