{
  "text": "Graphy’our Data: Towards End-to-End Modeling, Exploring and\nGenerating Report from Raw Data\nLongbin Lai, Changwei Luo, Yunkai Lou, Mingchen Ju‡, Zhengyi Yang‡\n{longbin.lailb,pomelo.lcw,louyunkai.lyk}@alibaba-inc.com\n{mingchen.ju@student.,zhengyy.yang@}unsw.edu.au\nAlibaba Group, China; ‡University of New South Wales, Australia\nABSTRACT\nLarge Language Models (LLMs) have recently demonstrated remark-\nable performance in tasks such as Retrieval-Augmented Generation\n(RAG) and autonomous AI agent workflows. Yet, when faced with\nlarge sets of unstructured documents requiring progressive explo-\nration, analysis, and synthesis, such as conducting literature survey,\nexisting approaches often fall short. We address this challenge –\ntermed Progressive Document Investigation – by introducing Gra-\nphy, an end-to-end platform that automates data modeling, explo-\nration and high-quality report generation in a user-friendly manner.\nGraphy comprises an offline Scrapper that transforms raw docu-\nments into a structured graph of Fact and Dimension nodes, and an\nonline Surveyor that enables iterative exploration and LLM-driven\nreport generation. We showcase a pre-scrapped graph of over 50,000\npapers – complete with their references – demonstrating how Gra-\nphy facilitates the literature-survey scenario. The demonstration\nvideo can be found at https://youtu.be/uM4nzkAdGlM.\n1\nINTRODUCTION\nWe study real-world investigative tasks that require iterative explo-\nration and synthesis of large unstructured data corpora. We refer\nto this challenge as Progressive Document Investigation (PDI),\nan iterative process of identifying a focal topic, refining a relevant\ndataset, and ultimately generating high-quality reports, summaries,\nor recommendations. A motivating example of PDI is the litera-\nture survey process in academic research. Researchers start with a\ntopic of interest, identify a few seed papers, and conduct iterative\nrounds of investigation: skimming key elements (e.g., “abstract”,\n“challenges”, “solutions”), following references to additional papers,\nand expanding the set of relevant works. After collecting a suffi-\ncient corpus, they then synthesize their findings into a structured\nsurvey report – often by grouping papers by shared characteristics\n(e.g., addressing similar challenges or proposing similar solutions).\nThe advent of Large language models (LLMs) [2] have shown im-\npressive potentials for handling PDI, in particular with techniques\nlike Retrieval-Augmented Generation (RAG) [9] and autonomous AI\nagents [8]. While these methods excel at single-document queries\nand conversational workflows, they fall short for solving PDI. RAG-\nbased solutions often struggle to maintain consistency and organi-\nzation when applied to large-scale, multi-step explorations. Existing\nAI agent systems, on the other hand, risk error propagation across\nextensive pipelines, especially if they are expected to autonomously\nparse and link large collections of unstructured data. Moreover,\nboth methods typically provide limited support for iterative user\noversight and curation, which researchers often prefer to ensure\naccuracy and control.\nTo address these gaps, we propose Graphy, an end-to-end plat-\nform that streamlines the PDI workflow. We adopt the property\ngraph model for the need of iterative exploration in PDI. Drawing\ninspiration from business intelligence (BI) systems [7], we intro-\nduce Fact and Dimension nodes, analogous to Fact and Dimen-\nsion tables in BI. Here, Fact nodes represent the primary entities\nof interest, while Dimension nodes capture supplementary infor-\nmation. In a literature-survey context, each paper functions as a\nFact node (henceforth they are used interchangeably), and its ex-\ntracted contents, such as “abstract”, “challenges”, and “solutions”,\nserve as Dimension nodes. Although our demonstration centers\non the literature-survey scenario, Graphy is broadly applicable; in\nSection 4, we briefly illustrate its potential in financial use cases.\nFig. 1 provides an overview of Graphy, which consists of two\nmain roles: the offline Scrapper and the online Surveyor.\nOffline Scrapper. The Scrapper allows users to implement the\nInspection abstraction to direct the extraction of specific Dimen-\nsions from each document, often leveraging LLMs. This step trans-\nforms an unstructured document into a structured Fact nodelinked\nto predefined Dimension nodes. It simulates how a human re-\nsearcher would skim a document, pinpointing aspects such as ab-\nstract, challenges, and solutions. Additionally, a Navigation ab-\nstraction defines how Fact nodes are connected, enabling the re-\ntrieval of related items for progressive exploration. For instance,\nan Arxiv [1] Navigation automatically fetches and downloads\nresearch papers from this open-source repository.\nBecause both the extracted data from the Inspection and the\nlinked data from the Navigation are relatively stable, we run\nthe Scrapper offline. Upon completion, it produces a graph of\nFact nodes, Dimension nodes, and their interconnecting edges,\nwhich can be imported into a standard graph database (e.g., Graph-\nScope Interactive [6]).\nOnline Surveyor. Designing a user-friendly Surveyor on top of\ngraph databases poses two key challenges. First, unlike SQL, graph\nquery languages are less familiar to users. Second, graph explo-\nration can become unwieldy, particularly with “supernodes,” which\nhave extremely large numbers of connections. We address these\nchallenges with the Exploration, which is the main interface for\nnavigating the graph and selecting papers of interest. As shown in\nFig. 1, it offers a convenient Search module to initiate exploration.\nUsers can iteratively move from one set of nodes to their neighbors\n(referenced papers), with Cypher operations (e.g., NeighborQuery)\nseamlessly integrated into a UI interface inspired by BI toolkits [10].\nTo avoid overwhelming users, Exploration employ histograms\nand top-k selectors to allow users filter out neighbors of interests.\nEventually, users can proceed to the Generation module, which\nleverages LLMs for creating reports from the papers selected in\narXiv:2502.16868v1  [cs.DB]  24 Feb 2025\n\nLongbin Lai, Changwei Luo, Yunkai Lou, Mingchen Ju‡, Zhengyi Yang‡\nFigure 1: The design and demo case of literature survey of Graphy.\nthe Exploration. Users specify the report’s focus (e.g., challenges,\nsolutions), and the Generation leverages Fact and relevant Dimen-\nsion nodes to draft a mind map. After reviewing and refining, the\nsystem produces a coherent, structured report that mimics a human\nresearcher’s synthesis process. The final document can be exported\nin various formats (e.g., PDF, LaTeX) to facilitate academic writing.\nIn this paper, we demonstrate how Graphy can streamline the\nliterature-survey process. Specifically:\n• Data Extraction and Linking: With a predefined workflow,\nwe demonstrate how the Scrapper employs the Inspection to\nextract Fact and Dimension nodes from research papers, and\nhow the Navigation automatically expands from a set of seed\npapers to their cited references.\n• Paper Exploration: Using a pre-scrapped graph containing\napproximately 50,000 papers, 250,000 Dimension nodes, and\n160,000 references among the papers, we demonstrate how users\ncan effectively utilize the Exploration interface to progressively\nsearch for papers of interest, simulating the process of literature\nsurvey.\n• Report Generation: We demonstrate how the Generation col-\nlects essential information from the selected papers and creates\nmind maps in line with users’ intentions. We then showcase its\ncapability to transform these mind maps into a well-structured\nreport, which users can download in formats including PDF and\nTeX.\nWe have open-sourced both the Graphy codebase and the pre-\nscrapped research graph [3]. The approximate cost of scrapping\nthe research graph using the QWen-plus model [5] is $600.\n2\nARCHITECTURE\nThis section introduces the architecture of Graphy, which com-\nprises an Offline Scrapper and an Online Surveyor.\n2.1\nOffline Scrapper\nInspection. Given a paper document as input, the Inspection\nprocesses it to produce a structured representation comprising\nFact and Dimension nodes. The paper itself forms the Fact node,\nwhile its Dimension nodes are extracted through a Directed Acyclic\nGraph (DAG) of instructions. Each subnode’s definition aligns with\nthe user’s specific requirements. For simple dimensions (e.g., an\n“abstract”), users can employ rule-based methods such as regular\nexpressions. For more advanced tasks, the system supports indi-\nvidually configured LLM subnodes, allowing users to balance cost\nand performance. For instance, simpler processing can rely on local\nmodels [4], whereas more complex extraction may involve sophis-\nticated cloud-based models [2]. These LLM-based subnodes build\non a common workflow that chunks PDF text, stores it in a vector\ndatabase, and then retrieves only the most relevant chunks—based\non user-defined queries, for final extraction by the LLM.\n\"dag\": {\n\"nodes\": [ ...,\n{\n\"name\": \"Abstract\",\n\"extract_from\": { ... }, # the rule of extracting abstract\n\"output_schema\": { single_typed: ... } # the output formats\n},\n{\n\"name\": \"Challenges\",\n\"model\" : { \"name\": \"ollama/qwen2.5:7b\", ... },\n\"query\": \"Please summarize the challenges in this paper\",\n\"output_schema\": { array_typed: ... } # the output formats\n},\n{\n\"name\": \"Solutions\",\n\"model\" : { \"name\": \"qwen-plus\", ... },\n\"query\": \"Please summarize the solutions in this paper \\\nfor addressing the above challenges.\",\n\"output_schema\": { array_typed: ... }\n}, ...,\n],\n\"edges\": [ ...,\n{\"source\": \"Challenges\", \"target\": \"Solutions\" }\n]\n}\n\nGraphy’our Data: Towards End-to-End Modeling, Exploring and Generating Report from Raw Data\nFigure 2: The Search component of Graphy.\nA snippet of the PaperInspection DAG in Fig. 1 is shown above.\nThe subnode Abstract is rule-based for extracting the paper’s “ab-\nstract”, while two LLM-based subnodes form a chain: Challenges\nuses a locally deployed model (prefixed with “ollama/”) to identify\nchallenges, and Solutions leverages a cloud-based model to extract\nsolutions. Such chain formation allows the Solutions subnode to\nleverage the context provided by the Challenges subnode.\nNavigation. The Navigation is responsible for establishing con-\nnections between Fact nodes, and in this case particularly, linking\npapers through their references. Specifically, a subnode can be de-\nployed in the above “PaperInspection” to extract references from\na paper. These references are then processed by the Navigation\nto fetch additional paper documents. Currently, we have imple-\nmented a Navigation to retrieve papers from Arxiv [1]. For each\nreference, only those that can be matched and retrieved through\nthe Navigation are retained. The corresponding documents are\ndownloaded, and the Inspection workflow is repeated for these\nnew papers. In this demo, we only consider the Navigation that\nlinks papers to the referenced papers. The workflow is actually\ncustomizable. For instance, one could implement a Navigation to\nlink papers to their associated GitHub repositories.\nGraph Modelling. The results of Inspection and Navigation\nas shown in Fig. 1, naturally form a graph comprising Fact and\nDimension nodes. Each Fact node represents a paper, while the\noutputs generated by subnodes in the Inspection form a set of Di-\nmension nodes linked to their corresponding Fact node. This graph\nis incrementally expanded as new papers are processed. Specifically,\nwhen a new Fact node 𝑝2 is added, it is linked to an existing Fact\nnode 𝑝1 if 𝑝2 is retrieved by the Navigation based on references\nextracted from 𝑝1.\nA notable feature of the Inspection is the customizable “out-\nput_schema” field for each subnode in the DAG, which defines the\nschema (data fields and their data types) for the resulting Dimen-\nsion nodes. The output can be single-typed, such as abstract and\ntitle of the paper, which can be directly stored as attributes of the\nFact node. Alternatively, array-typed outputs like challenges and\nsolutions can be stored as separate Dimension nodes, each sharing\nthe same schema.\n2.2\nOnline Surveyor\nExploration. The Exploration component is designed to give\nusers an intuitive way to interact with the graph database while\nminimizing the learning curve.\nTraditional graph exploration typically relies on query languages,\nwhich can require extra effort to master. We address this by embed-\nding graph queries within interactive UI components. As shown\nin Fig. 2, the Search module in the Exploration helps users pin-\npoint their initial papers for exploration. Three key interactions\nare highlighted: “E1” searches all nodes containing the “year” at-\ntribute with a single click; “E2” displays a histogram of nodes by\n“year” providing a statistical overview; and “E3” filters and retrieves\nnodes for a specific year (e.g., 2023) by clicking the corresponding\nhistogram bar. These user actions are seamlessly translated into\nCypher queries and executed on the underlying graph database.\nFurthermore, encountering “supernodes” with exceedingly large\nnumbers of connections can often overwhelm users and disrupt the\nanalysis flow. To address this, we introduce a StatRefiner module\nthat intervenes before displaying all the neighbors. This module can\npresent neighbors either as a histogram, allowing users to quickly\noverview and multi-select by groups, or as a table, where they can\nsort by specific attributes and choose the top-k results for further\nexploration. In Section 3, we provide examples showing how this\napproach streamlines the exploration process.\nGeneration. Once users finish selecting papers in the Exploration,\nthey can employ the Generation to convert this explored data into\nstructured reports. By leveraging the natural language understand-\ning and summarization capabilities of LLMs, the Generation turns\nthe network of interconnected papers on the canvas into a mind\nmap and, ultimately, a well-formatted narrative report. This process\ninvolves three main steps: (1) Interpreting User Intentions: Users\ndescribe their desired report in natural language, from which LLM\ninfers which attributes and dimensions of the paper are needed.\nFor instance, if a user asks for a related work section focusing on\nthe paper’s challenges, the LLM may determine that the “title” and\n“abstract” attributes and the “challenges” dimension are required.\nUsers can review and refine these selections before proceeding. As\nthe dimensions are pre-extracted during the offline Scrapper phase,\nthe Generation can quickly retrieve them on demand. (2) Gener-\nating Mind Maps: Like a human expert, we prompt the LLM to\norganize the selected papers into a mind map based on the dimen-\nsions mentioned by the users, providing a high-level blueprint for\nthe final report. To accommodate context-size limitations, we adopt\nan iterative approach that feeds the LLM subsets of the data at a\ntime, gradually constructing the mind map for users to review. (3)\nWriting Reports: With the mind map in place, the LLM finalizes\nthe literature survey by generating a cohesive report, which can\nthen be downloaded in various formats (e.g., PDF or TeX) to support\nacademic writing.\n3\nDEMONSTRATING LITERATURE SURVEY\nWe demonstrate how Graphy applies to literature surveys, with em-\nphasis on the online Surveyor. We will showcase the functionalities\nof Scrapper using a video as it is time-consuming.\nThe online Surveyor, shown in Fig. 3, allows the demo attendees\nto explore a pre-extracted paper network containing over 50,000\npapers and 160,000 references. We first look into Fig. 3(a) that is\nthe interface of Exploration featuring three primary canvases,\nmetaphorically referred to as “Past”, “Present”, and “Future”. Here,\n“Past” displays already explored papers, and “Present” shows the\n\nLongbin Lai, Changwei Luo, Yunkai Lou, Mingchen Ju‡, Zhengyi Yang‡\n1\n3\n4\n2\n(b) Report Component\n(a) Exploration Component\nPast\nPresent\nFuture\n6\n7\n8\n9\n10\n11\nInterpreting User Intentions\nGenerating Mind Maps\nWriting Reports\n5\nFigure 3: The demonstration scenario of literature survey of Graphy.\ncurrently active papers for reviewing in detail, while “Future” high-\nlights the immediate neighbors (i.e., references) of the active papers.\nFor exploring the papers, the attendee 1 searches for seed papers\nwhose titles contain “Llama3” using the Search module; 2 then\nselects “The Llama 3 Herd of Models” and moves it to the “Present”\ncanvas to review its details. Next, 3 the attendee explores the\nselected paper’s references by pre-querying its neighbors. As de-\nscribed in Section 2.2, these neighbors are not immediately added\nto the canvas to avoid overwhelming the user; instead, 4 the\nStatRefiner module presents a histogram or table view, allowing\nattendees to focus on aggregated groups or order the data and fi-\nnally, 5 decide from the top-k papers for further exploration. By\ndoing so, these papers are added to the “Present”canvas, while the\npreviously active papers move to the “Past” canvas. By iteratively\nfollowing this workflow, attendees can explore as many papers as\nneeded, before proceeding to the Generation task.\nIn Fig. 3(b), 6 attendees click to input instructions for the report,\ne.g., “Please write me a related work, focusing on their challenge”.\nBased on this input, an LLM (QWen-Plus [5] for this demo) iden-\ntifies the relevant attributes and Dimension nodes needed for the\nreport, which are 7 displayed for user verification and possible\nmodification. In the example, the LLM highlights the “Challenge”\nnode as well as the “title” and “abstract” attributes from the selected\npapers. 8 These data are then passed to the LLM to produce a\nmind map, effectively categorizing the papers according to the iden-\ntified “Challenge”. 9 Attendees can review the mind map, and 10\nproceed to final report generation. The final report is built from the\nmind map and the user’s instructions, culminating in a point-by-\npoint narrative. Once completed, 11 attendees can download the\nreport in PDF or TeX format, complete with citations.\n4\nEXTENSION TO FINANCIAL SCENARIOS\nWe briefly discuss applying Graphy to two financial scenarios.\nCompany Relationship Analysis. In this scenario, each company\nis treated as a Fact node, and the data extracted by Inspection,\nsuch as revenues, main business areas and shareholder holdings ex-\ntracted from financial reports, are represented as Dimension nodes.\nThe Navigation component establishes inter-company relation-\nships by leveraging the financial or supply-chain dependencies\nmentioned in the reports. The generated graph can be used to\nidentify comparable competitors, uncover hidden relationships, or\nassess contagion effects.\nFinancial News Analysis. In this scenario, each news article\nserves as a Fact node, while pertinent details, such as described\nevents and stock performance indicators, can act as Dimension nodes.\nThe Navigation builds connections among these Fact nodes by\nidentifying shared symbols or overlapping financial metrics. This\nallows analysts to track the evolution of news stories, assess their\nmarket impact, or predict future trends based on historical patterns.\nREFERENCES\n[1] 2024. arXiv.org e-Print archive. https://arxiv.org/.\n[2] 2024. GPT-4o, the new flagship model that can reason across audio, vision, and text\nin real time. https://openai.com/index/hello-gpt-4o/\n[3] 2024. Graphy Code. https://github.com/GraphScope/portal/tree/main/python/graphy.\n[4] 2024. Ollama: Get up and running with large language models. https://ollama.com/\n[5] 2024. Top-performance foundation models from Alibaba Cloud.\nhttps://www.\nalibabacloud.com/en/solutions/generative-ai/qwen?_p_lc=1\n[6] Wenfei Fan, Tao He, Longbin Lai, and et al. 2021. GraphScope: A Unified Engine\nfor Big Graph Processing. Proc. VLDB Endow. 14, 12 (jul 2021), 2879–2892.\n[7] J. Gray, A. Bosworth, A. Lyaman, and H. Pirahesh. 1996. Data cube: a relational\naggregation operator generalizing GROUP-BY, CROSS-TAB, and SUB-TOTALS.\nIn ICDE. 152–159.\n[8] Shanshan Han, Qifan Zhang, and et al. 2024. LLM Multi-Agent Systems: Chal-\nlenges and Open Problems. https://arxiv.org/abs/2402.03578\n[9] Patrick Lewis, Ethan Perez, and et al. 2021. Retrieval-Augmented Generation for\nKnowledge-Intensive NLP Tasks. https://arxiv.org/abs/2005.11401\n[10] C. Stolte, D. Tang, and P. Hanrahan. 2002. Polaris: a system for query, analysis,\nand visualization of multidimensional relational databases. IEEE Transactions on\nVisualization and Computer Graphics 8, 1 (2002), 52–65.\n",
  "metadata": {
    "source_path": "papers/arxiv/Graphyour_Data_Towards_End-to-End_Modeling_Exploring_and_Generating\n__Report_from_Raw_Data_8f6e78fae99a5917.pdf",
    "content_hash": "8f6e78fae99a591722b3699f7c22850c90bcb056dfecc2a5ad63d10a0c433a5f",
    "arxiv_id": null,
    "title": "Graphy'our Data: Towards End-to-End Modeling, Exploring and Generating Report from Raw Data",
    "author": "",
    "creation_date": "D:20250225022559Z",
    "published": "2025-02-25T02:25:59",
    "pages": 4,
    "size": 4096139,
    "file_mtime": 1740470217.269264
  }
}