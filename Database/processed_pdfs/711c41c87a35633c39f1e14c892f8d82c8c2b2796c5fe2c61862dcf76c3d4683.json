{
  "text": "TabulaTime: A Novel Multimodal Deep Learning\nFramework for Advancing Acute Coronary\nSyndrome Prediction through Environmental and\nClinical Data Integration\nXin Zhang1, Liangxiu Han1*, Stephen White2*, Saad Hassan3,\nPhilip A Kalra4, James Ritchie4, Carl Diver5, Jennie Shorley6\n1*Department of Computing, and Mathematics, Manchester\nMetropolitan University, Manchester, M15 6BH, UK.\n2*Faculty of Medical Sciences, Newcastle University, Newcastle upon\nTyne, NE1 3BZ, UK.\n3Blackpool Teaching Hospitals NHS Foundation Trust, Blackpool\nVictoria Hospital, Whinney Heys Road Blackpool, FY3 8NR.\n4Northern Care Alliance, NHS Foundation Trust, Salford, M6 8HD, UK.\n5Department of Engineering, Manchester Metropolitan\nUniversity,Manchester, M15 6BH, UK.\n6Faculty of Business and Law, Manchester Metropolitan\nUniversity,Manchester, M15 6BH, UK.\n*Corresponding author(s). E-mail(s): l.han@mmu.ac.uk;\nsteve.white3@newcastle.ac.uk;\nContributing authors: x.zhang@mmu.ac.uk; saad.hassan@doctors.org.uk;\nphilip.kalra@nca.nhs.uk; james.ritchie@nca.nhs.uk; C.Diver@mmu.ac.uk;\nj.shorley@mmu.ac.uk;\nAbstract\nAcute Coronary Syndromes (ACS), encompassing conditions such as ST-segment\nelevation myocardial infarction (STEMI) and non-ST-segment elevation myocar-\ndial infarction (NSTEMI), remain a leading cause of global mortality. While\ntraditional Cardiovascular Risk Scores (CVRS) provide valuable insights, they\nprimarily rely on clinical data, often overlooking environmental factors like air\n1\narXiv:2502.17049v1  [cs.AI]  24 Feb 2025\n\npollution, which significantly impact cardiovascular health. Additionally, inte-\ngrating complex time-series environmental data with clinical datasets poses\nsignificant challenges due to issues in alignment and fusion.\nTo address these gaps, we propose TabulaTime, a novel multimodal deep learning\nframework that integrates clinical risk factors with air pollution data to enhance\nACS risk prediction. TabulaTime introduces three major innovations: (1) Multi-\nmodal feature integration to combine time-series air pollution data with clinical\ntabular data for improved predictive accuracy; (2) PatchRWKV, a new module\nfor automatic extraction of complex temporal patterns, overcoming limitations\nof traditional feature engineering and maintaining linear computational com-\nplexity; and (3) Enhanced interpretability using attention mechanisms to reveal\ninteractions between clinical and environmental factors.\nOur experimental evaluation demonstrated that TabulaTime achieves a 20.5%\nimprovement in accuracy compared to the best-performing traditional machine\nlearning model (CatBoost) and surpasses other models, including Random Forest\nand LightGBM, by 20.5% to 32.2%. The integration of air pollution data improves\naccuracy by 10.1%, emphasising the importance of environmental factors. The\nPatchRWKV module showed advanced performance in time-series analysis, out-\nperforming the state-of-the-art methods such as Multi-Layer Perceptrons (MLPs)\nbased methods (LightTS and Dlinera), Convolutional Neural Networks (CNNs)\nbased methods (TimesNet), Recurrent Neural Networks (RNNs) based meth-\nods (LSTM, GRU), and Transformers based methods (Autoformer, PatchTST)\nacross various tasks while maintaining efficiency. Additionally, feature impor-\ntance analysis identified key predictors of ACS, such as previous angina, systolic\nblood pressure, and pollutants like PM10 and NO2, highlighting the critical role\nof environmental-clinical interactions in ACS risk.\nThis framework bridges the gap between traditional clinical models and envi-\nronmental health insights, supporting personalised prevention strategies and\ninforming public health policies to mitigate the cardiovascular impact of air\npollution.\nKeywords: Acute Coronary Syndrome (ACS), Deep Learning, Multimodal Deep\nLearning, Time-Series Analysis, Environmental Data Integration, Clinical Risk\nPrediction, Air Pollution\n1 Introduction\nAcute Coronary Syndromes (ACS), a spectrum of conditions encompassing unstable\nangina, ST-segment elevation myocardial infarction (STEMI), and non-ST-segment\nelevation myocardial infarction (NSTEMI), is the leading cause of death globally,\nwith nearly half of these deaths due to ischaemic heart disease [1, 2]. Understand-\ning environmental factors is crucial for developing strategies to mitigate ACS risk.\nCardiovascular Risk Scores (CVRS) serve as statistical tools used to estimate a per-\nson’s risk of having a cardiovascular event, such as a heart attack or stroke, usually\nover the next 10 years. Various risk scores have been developed, each targeting differ-\nent populations, incorporating distinct risk factors, and possessing unique predictive\n2\n\nstrengths. Notable examples include the QRISK family of algorithms [3–5], Framing-\nham Risk Score (FRS)[6], Reynolds Risk Score [7] and European SCORE System [8].\nThese tools help clinicians assess and manage patients’ cardiovascular risk and target\nprophylactic therapy more effectively.\nHowever, there is a growing recognition that existing models may not fully capture\nthe comprehensive range of risk factors contributing to ACS. For example, QRISK3\nexplains 59.6% of the variation in time to diagnosis of CVD among women and 54.8%\namong men, leaving over 40% of the variation unexplained by the QRISK3 score [3].\nNumerous epidemiological studies have convincingly linked air pollution exposure to a\nheightened risk of ACS [9, 10]. Air pollutants, particularly particulate matter (PM2.5\nand PM10), nitrogen oxides (NOx), sulphur dioxide (SO2), and ozone (O3), trigger\ninflammation, oxidative stress, and change in blood vessel function, contributing to\ncardiovascular issues. For instance, Rus and Morno¸s [9]provides a broader look at the\nconnection between environmental factors and ACS, highlighting the increased risk\nassociated with PM2.5 exposure. Additionally, in [10], the researchers presented a large-\nscale study analysing the link between hourly air pollutant levels and ACS in over\n1 million patients, emphasising the roles of PM2.5, NO2, SO2, and CO in triggering\nACS. This gap necessitates novel approaches that leverage the power of environmental\ndata to enhance risk prediction accuracy.\nTraditional medical data used for acute coronary syndrome (ACS) prediction typ-\nically include patient demographics and clinical data. These data points, structured\nin a tabular manner, allow for relatively simple analysis and prediction models. In\ncontrast, the environmental data exists as a time series with more complex features,\ncapturing continuous changes over time. Most current studies often utilise manual\ntime series features, such as statistical features (e.g., maximum and minimum val-\nues, standard deviation) and temporal features (e.g., trends, event counts, anomalies).\nHowever, these methods do not fully leverage the extensive information embedded\nwithin time series data. Identifying and extracting the right features that represent the\ntemporal dependencies within time-series data can be time-consuming and requires\ndomain expertise [11].\nDeep learning models, such as recurrent neural networks (RNNs) [12], multi-layer\nperceptrons (MLPs) [13], convolutional neural networks (CNNs) [14] and transform-\ners [15], can automatically learn complex temporal features from raw time series data,\nreducing the need for extensive manual engineering. Several studies have leveraged\ndeep learning to analyse the relationship between air pollution exposure and health\noutcomes [16–19]. For instance, [20] implemented a hybrid CNN-LSTM (Long Short-\nTerm Memory) model to analyse hourly PM2.5 concentrations in Beijing, China, and\npredict air quality levels for health risk assessment. Similarly, (Tsai, Zeng, and Chang\n2018) used RNNs with LSTM to forecast PM2.5 concentrations, while[21] employed\nradial basis function (RBF) and MLP neural networks to model the temporal dynam-\nics of air pollution and its impact on respiratory hospital admissions. Despite the\nsuccess of advanced deep learning models in various fields, they can demonstrate lim-\nitations when processing multimodal data [22] . Integrating heterogeneous data types\nrequires sophisticated architectures capable of learning and representing the intricate\n3\n\nrelationships between different modalities. Furthermore, the alignment, synchronisa-\ntion, and fusion of multimodal data necessitates advanced techniques to ensure that the\ncombined information enhances, rather than detracts from, the model’s performance\n[23, 24].\nExisting research on ACS risk prediction primarily emphasises traditional clinical\ndatasets, often neglecting the significant influence of environmental factors. Integrating\nair pollution data into deep learning models offers a promising opportunity to enhance\nACS risk assessment and inform preventive cardiology strategies. This research aims\nto address these challenges by developing and validating a novel multimodal deep\nlearning based ACS prediction model, TabulaTime, specifically designed to improve\nCVD risk prediction through the integration of time-series air pollution features and\nclinical tabular data. Our proposed method offers several key contributions:\n1) Multimodal feature integration and ACS prediction: We propose a novel\nTabulaTime deep learning framework for multimodal feature integration and ACS\nprediction, combining extracted time-series features from air pollution datasets\nwith ACS risk factors obtained from clinical tabular data. This integration enables\nthe model to conditionally learn attention maps based on the multimodal features,\nthereby enhancing both predictive performance and interpretability.\n2) Automatic time-series feature extraction: We introduce PatchRWKV, an\nadvanced feature extraction module designed for automatic extraction of features\nfrom time-series data. The PatchRWKV module divides data into patches. It uses\nthe Receptance Weighted Key Value (RWKV) technique, which combines RNN\ncapabilities with attention mechanisms. This approach efficiently processes long\nsequences while maintaining linear computational complexity, making it more\nefficient than traditional RNNs and transformers, which have quadratic complex-\nity. By capturing both short-term and long-term patterns, PatchRWKV provides\na comprehensive representation of temporal dependencies. This capability is cru-\ncial for accurately detecting significant associations between pollution exposure\npatterns and ACS risk, which are often missed by traditional manual feature\nextraction methods.\n3) Enhanced interpretability: We employ attention mechanisms and feature\nimportance analysis to uncover potential interactions between air pollution, clin-\nical risk factors, and the onset of ACS. This approach ensures that the model’s\npredictions are both accurate and interpretable, providing deeper insights into\nhow environmental and clinical factors contribute to ACS risk.\nThis paper is structured as follows: Section 2 reviews related work, Section 3\ndetails the proposed TabulaTime framework, and Sections 4 and 5 present experimen-\ntal evaluations and discussions. The conclusion summarises findings and implications\nfor future research.\n4\n\n2 Related Work\n2.1 Traditional ACS Prediction Methods\nAcute Coronary Syndrome (ACS) risk prediction methods are essential tools for\nestimating an individual’s likelihood of experiencing cardiovascular events. Tradi-\ntional methods for predicting ACS risk such as Framingham Risk Score (FRS)[6],\nQRISK[3], Reynolds Risk Score [7] and European SCORE System [8] utilise a com-\nbination of demographic, clinical, lifestyle and medical history data to provide an\noverall risk assessment, but frequently cannot be utilised once a diagnosis of under-\nlying cardiovascular disease has been made. The data used can be categorised as\nfollows: 1) Demographic Information: Age, gender, and family history of cardiovascular\ndiseases[25]. 2) Clinical History: Previous incidences of myocardial infarction, angina,\nhypertension, diabetes, and hypercholesterolemia. 3) Laboratory and and Clinical\nTests: Blood pressure readings, cholesterol levels, and creatinine levels. 4) Electro-\ncardiogram (ECG) Readings: Used to diagnose the type and severity of myocardial\ninfarctions (e.g., Discrimination between STEMI and NSTEMI) [26].\nThese traditional methods systematically assess cardiovascular event risk. The\nFRS, Reynolds Risk Score, National Early Warning Score (NEWS) [27] and Global\nRegistry of Acute Coronary Events (GRACE) (‘Rationale and Design of the GRACE\n(Global Registry of Acute Coronary Events) Project: A Multinational Registry of\nPatients Hospitalized with Acute Coronary Syndromes’ 2001) primarily relied on\npoint-based systems incorporating traditional clinical and lifestyle factors. Each risk\nfactor was assigned a specific number of points based on predefined scales. The QRISK\nalgorithm employed a comprehensive multivariate approach using a wide array of data\npoints to reflect a diverse population. The European SCORE system utilised regional\nrisk charts to account for geographic variability in cardiovascular disease prevalence.\n2.2 Machine Learning in ACS Prediction\nWhile these traditional models have been instrumental in guiding clinical practice,\nthey have notable limitations in adaptability, data integration, and predictive accuracy.\nMachine learning/deep learning methods offer significant advantages in these areas,\nproviding more dynamic, accurate, and comprehensive risk assessments by leveraging\nadvanced data analytics and continuous learning capabilities [28]. Wu et al. [29] utilised\nmachine learning to predict in-hospital cardiac arrest in ACS patients, finding that\nthe XGBoost model outperformed traditional risk scores such as GRACE and NEWS ,\nachieving high accuracy and AUC. A total of 45 risk features were selected in this work\nfrom the electronic health record including age, gender, history of smoking and labo-\nratory features, Killip classification, vital signs, mental status, etc. Similarly, Hadanny\net al. [30] used Random Survival Forest (RSF) and deep neural network (DeepSurv)\nmodels to predict 1-year mortality in ACS patients, highlighting the improved per-\nformance of RSF over traditional methods. Acute Coronary Syndrome Israeli Survey\n(ACSIS) and the Myocardial Ischemia National Audit Project (MINAP) data were\nused in this work. 69 risk factors including demographics, prior medical history, prior\nmedication, clinical presentation, basic laboratory data with admission were selected\nand evaluated.\n5\n\nD’Ascenzo et al. [31] developed the PRAISE risk scores, a machine learning tool\nvalidated with external cohorts, which showed high accuracy in predicting post-\ndischarge outcomes for ACS patients. The 25 risk factors included 16 clinical variables,\n5 therapeutic variables, and 2 angiographic variables. Research by Emakhu et al. [32]\ncompared various machine learning techniques for predicting ACS outcomes based on\n58 variables, including demographic and clinical factors ( e.g. brain natriuretic pep-\ntide (BNP), creatinine, glucose, heart rate, red cell distribution width, systolic blood\npressure, and troponin), with models like XGBoost and RSF significantly improving\nprediction accuracy over traditional methods. Ke et al. [28] focused on early ACS onset\nprediction using ensemble methods such as gradient boosting, demonstrating the ben-\nefits of integrating machine learning into clinical practice for enhanced early detection\nand management of ACS using demographic characteristics, comorbidities, throm-\nbolytic therapy, laboratory test data, and physical examination data. The study in\n[33] concluded that the ML-based approach improved the prediction of mortality, par-\nticularly in patients with non-ST-segment elevation myocardial infarction (NSTEMI)\nbased on demographic characteristics, medical history, symptom, initial presenta-\ntion, laboratory findings, clinical manifestation, echocardiographic finding, coronary\nangiographic finding, and medication at discharge.\nIn recent years, deep learning techniques have shown significant advancements in\nvarious healthcare applications, including cardiovascular disease prediction. In [34], a\ndeep learning-based approach is introduced to analyse a massive volume of heteroge-\nneous electronic health records in order to predict MACEs following ACS. In [35]and\n[36], the authors introduce deep learning model for classifying ACS abnormalities using\nelectrocardiogram (ECG) data. However, due to the structured and tabular nature\nof clinical data, the application of deep learning models in ACS prediction remains\nrelatively limited compared to traditional machine learning approaches.\n2.3 Environmental Factors and ACS\nThe effects of environmental factors on ACS have also been increasingly studied.\nKu´zma et al. [37] investigated the short-term impact of air pollution on ACS incidence\nin industrial versus non-industrial areas, finding significant associations between air\npollution and ACS admissions. Chen et al. [10] examined hourly air pollutant concen-\ntrations and their association with ACS onset, employing a case-crossover design that\nrevealed a strong link between short-term exposure to pollutants and increased ACS\nrisk. Gestro et al. [38] developed models to analyse the delayed effects of air pollutants\non emergency department admissions for ACS, underscoring the need for continuous\nair quality monitoring.\nHowever, environmental time series data have more complex temporal properties\nthan clinic data. Current approaches often rely on manually selected features from\ntime series datasets, including basic statistical measures such as mean, variance, and\nautocorrelation. These methods may not capture all relevant information, particu-\nlarly complex, non-linear patterns. Recently, deep learning has emerged as a powerful\ntool for time series analysis, especially in examining the impact of air pollution on\nhealth outcomes. Various deep learning algorithms have been employed to analyse\ntime series environmental data, such as Recurrent Neural Networks (RNNs) [39, 40],\n6\n\nMulti-Layer Perceptrons (MLPs)[13], Convolutional Neural Networks (CNNs)[14], and\nTransformers [41].\nRNNs are specifically designed for sequence data, making them a natural fit for\ntime series analysis. Their internal state allows them to retain information from pre-\nvious inputs, which is crucial for understanding temporal dependencies. For instance,\nVillegas et al. [42] proposed a predictive model for COVID-19 mortality risk using\nRNNs with attention mechanisms to enhance interpretability. Results indicate that\nthe RNN model outperforms traditional baselines like Support Vector Classifier and\nRandom Forest in sensitivity and overall stability.\nMLPs, though simpler than other models, can effectively model temporal depen-\ndencies when applied along the temporal dimension. MLP methods encode these\ntemporal dependencies into the fixed parameters of MLP layers, adopting the MLP\nframework along the temporal axis. This approach allows MLPs to model sequential\npatterns in time-series data, providing a straightforward yet powerful means to analyse\ncomplex temporal relationships. Suttaket and Kok [43] introduced Rational Multi-\nLayer Perceptrons (RMLP) as a novel interpretable predictive model for healthcare,\naddressing the limitations of deep learning’s black-box nature. The model combined\nthe strengths of weighted finite state automata and multi-layer perceptrons to process\nsequential data from electronic health records (EHRs). The study demonstrated that\nRMLP achieved strong predictive accuracy and enhanced interpretability across six\nclinical tasks.\nCNNs are traditionally used for image processing but have been adapted for time\nseries analysis[44]. The key advantage of CNNs is their ability to capture local patterns\nand hierarchical features through convolutional operations.\nTransformers, introduced by Vaswani et al. [15], have revolutionised sequence\nmodelling by relying on self-attention mechanisms rather than recurrent structures.\nThis allows for parallel processing of data and better handling of long-range depen-\ndencies. Ni et al. [45] compared traditional time series models such as ARIMA and\nProphet with advanced transformers based models for predicting heart rate dynamics.\nThe study demonstrated that deep learning approaches, particularly transformer-\nbased models like PatchTST [46], significantly outperformed traditional methods in\ncapturing complex temporal dependencies and non-linear relationships.\nDespite their success, each of these models has specific strengths and limitations\nthat make them suitable for different aspects of time series analysis. RNNs and LSTMs\nare excellent for handling temporal dependencies but are computationally intensive\nand complex. MLPs are simpler but less effective for complex time series compared\nto RNNs or LSTMs and less flexible for variable-length sequences due to requiring\nfixed input sizes. CNNs excel at capturing local patterns but often miss long-term\ndependencies. Transformers are powerful but have quadratic complexity relative to\nsequence length, making them computationally expensive for very long sequences.\nMoreover, to the best of our knowledge, there are a few studies [47] combining time\nseries air pollution analysis and clinical data using deep learning algorithms for ACS\nprediction. Integrating heterogeneous data types remains challenging. Multimodal\ndeep learning frameworks are required to effectively combine clinical and environ-\nmental data, addressing issues related to alignment, synchronization, and fusion of\nmultimodal information.\n7\n\nOur proposed TabulaTime model represents a significant advancement in this field\nby leveraging deep learning to integrate time-series air pollution data with traditional\nclinical data. It efficiently processes long sequences while maintaining linear computa-\ntional complexity, making it more efficient than traditional RNNs and transformers,\nwhich have quadratic complexity. This approach addresses the limitations of previous\nmodels, providing a more comprehensive and accurate assessment of ACS risk.\n3 The Proposed Method\n3.1 Overview of the Framework\nIn this study, we propose a multimodal deep learning framework for modelling the\neffect of air pollution on ACS presentation by integrating time-series data with tab-\nular data, named TabulaTime. Figure 1 illustrates the flowchart of the TabulaTime\nframework, which comprises three main components:\n1) Input embedding. This component converts raw input data, such as words,\nimages, or time series data, into dense, continuous vectors that a deep learning\nmodel can process. This transformation enables the model to interpret and utilise\nthe data more effectively. For instance, clinical tabular data are embedded into\nvectors, allowing the model to learn simultaneously from both clinical and other\ndata types. This enhances the model’s ability to capture complex patterns and\nrelationships, thereby improving its overall predictive performance.\n2) Patched RWKV module (PatchRWKV) for automatic time-series sequential data\nfeature extraction, which includes patching and RWKV (Receptance Weighted\nKey Value). The patching process divides time-series data into fixed-size seg-\nments, enabling the model to focus on short-term patterns within each segment.\nThe RWKV module serves as the backbone for feature extraction, combining\nthe strengths of recurrent neural networks (RNNs) and attention mechanisms to\nefficiently process time series sequences. PatchRWKV excels at identifying both\nshort-term spikes and long-term trends in the data, providing a comprehensive\nrepresentation of temporal dependencies. This approach efficiently processes long\nsequences while maintaining linear computational complexity, making it more\nefficient than traditional RNNs and transformers, which have quadratic complex-\nity. By capturing both short-term and long-term patterns, PatchRWKV offers a\nthorough representation of temporal dependencies, crucial for accurately detect-\ning significant associations between pollution exposure patterns and ACS risk,\noften missed by traditional manual feature extraction methods.\n3) The multimodal feature integration and ACS prediction. In this part, we leverage\nattention mechanisms to integrate embedded tabular data features with extracted\ntime-series features from the Patched RWKV module. By generating an attention\nmap, the model assigns weights to different features, aligning data from vari-\nous types and providing explanations for the model’s decisions. This integration\nenhances the model’s predictive accuracy and interpretability, ensuring that the\ncombined information from different data sources contributes effectively to the\nACS risk prediction.\n8\n\nFig. 1 The flowchart of the proposed TabulaTime framework.\n3.2 Input Embedding\nIn this work, the input embedding consists of two parts: embedding clinical tabular\ndata and embedding air pollution time series data.\nEmbedding clinical tabular data involves several crucial steps as follows: First,\nhandling missing values is essential; we fill missing data with the mean value of the\nrespective attribute to minimise the impact on model prediction. Next, we encode cate-\ngorical variables using One-Hot encoding to convert them into binary vectors, allowing\nthe model to process categorical information effectively. Following this, data normali-\nsation and standardisation are applied, transforming features to have a mean of 0 and\na standard deviation of 1, which improves model performance by ensuring consistency\nin data scale. Finally, all features are concatenated into a single feature vector, serv-\ning as the input for model integration, enabling the deep learning framework to utilise\nthe comprehensive dataset efficiently.\nEmbedding air pollution time series data includes patching and patch embedding,\nwhich will be described in detail in a later section.\n3.3 PatchRWKV for Time-Series Feature Extraction\nThe PatchRWKV module is a core component of the TabulaTime model, designed to\nhandle and extract features from multivariate time-series data, such as air pollution\ndata. This module allows the model to manage both short-term spikes and long-term\ntrends, providing a comprehensive representation of temporal dependencies crucial\nfor accurate analysis. It integrates Recurrent Neural Networks (RNNs) and attention\nmechanisms to efficiently process long sequence data while maintaining linear com-\nputational complexity. The PatchRWKV consists of three key components: Patching,\nPatch Embedding, and the RWKV encoder. The rationale behind the model design is\nas follows:\n9\n\n1) Patching: Patching segments time-series data into fixed-size patches, allowing the\nmodel to focus on local temporal patterns within each patch and effectively cap-\nture short-term dependencies and variations. This enhances locality and semantic\nunderstanding, helping the model efficiently learn from short-term dependencies.\n2) Patch Embedding: The patch embedding component converts the patched data\ninto a format that the model can process. This step ensures that the data is\nprepared for deeper analysis by the subsequent components.\n3) RWKV Encoder: Multivariate time series data consists of multiple channels, each\nrepresenting different types of measurements taken over time. To extract effec-\ntive feature representations, it is crucial to understand the relationships between\ndifferent time periods (Time-Mixing) and between different features (Channel-\nMixing). The RWKV encoder serves as the backbone architecture of the model,\nincorporating Time-Mixing and Channel-Mixing to enhance the model’s ability\nto detect significant patterns and improve predictive performance. Time-Mixing\ninvolves using a linear combination of current and previous time steps along with\na multi-head Receptance Weighted Key Value (RWKV) operator to capture tem-\nporal dependencies across different time patches. This ensures that the model\neffectively learns the relationships between data points over various time steps,\nwhich is crucial for understanding how past events influence future outcomes in\na time series. Channel-Mixing is the process of using a vector of all the features\nfrom the time series and projecting it into the embedding space. This approach\ncombines information across different channels using robust non-linear opera-\ntions. Channel-Mixing helps the model learn the relationships between different\ntypes of data collected at the same time step, enhancing its ability to interpret\nmultivariate time series data effectively.\nThe following sections detail these components.\n3.3.1 Patching\nThe patching process consists of two stages: normalisation and patching. Instance\nnormalisation has recently been shown to mitigate the distribution shift effect between\ntraining and testing data. Therefore, we first normalise each univariate time-series\npollution dataset to have a zero mean and unit standard deviation before applying\npatching. Each input univariate time series is then tokenised through patching, with\npatches being either overlapping or non-overlapping, depending on the patch length\n(P) and stride (S). These patches are projected into a lower-dimensional space using a\nlearnable projection matrix, reducing the number of input tokens and computational\ncomplexity. In this study, we use hourly air pollution data and aim to capture localised\nfeatures of pollution for each day. Consequently, we set the patch size to 24 and do\nnot use overlapping patches.\n3.3.2 Patch Embedding\nIn patch embedding, each patch is embedded into a higher-dimensional vector by\napplying a linear transformation to flatten it. Then each patch is represented as a\nvector, which captures the essential information of that patch that can be processed\nby the RWKV model.\n10\n\n3.3.3 RWKV (Receptance Weighted Key Value) Encoder\nFig. 2 Architecture of the RWKV Encoder.\nThe RWKV architecture is designed to learn feature representations of time-series\ndata. It consists of stacked residual blocks, each containing a Time-Mixing and a\nChannel-Mixing sub-block (Figure 2 and Figure 3). These sub-blocks use recurrent\nstructures to incorporate past information effectively.\nTime Mixing Module\nFig. 3 Architecture of the time and channel mixing.\n11\n\nTo achieve time mixing in RWKV, the model interpolates between the inputs of the\ncurrent and previous time-steps. Given an input feature of xt and previous step xt−1,\na linear projection of the combination of the shifted previous step and the current\nstep is performed using the projection matrix within the block. This process involves\ncreating a weighted blend of xt and xt−1 to capture temporal dependencies effectively.\nRt = Wr · (µr ⊙xt + (1 −µr) ⊙xt−1)\nKt = Wk · (µk ⊙xt + (1 −µk) ⊙xt−1)\nVt = Wv · (µv ⊙xt + (1 −µv) ⊙xt−1)\n(1)\nWhere W means the weight signifying the positional weight decay vector, a train-\nable parameter within the model. R is the receptance vector acts as the receiver of\npast information. K is the Key vector performs a role analogous to K in traditional\nattention mechanisms. V: The Value vector functions similarly to V in conventional\nattention processes.\nThen a Multi-head WKV Operator is used to operate the attention mechanism\nbut with a linear time and space complexity. This recurrent behaviour in RWKV is\narticulated through the time-dependent update of the WKV vectors. The formula of\nsingle head WKV operator is given by.\nwkvt = diag(u) · kT\nt · vt +\nt−1\nX\ni=1\ndiag(w)(t−1−i) · kT\ni · vi\n(2)\nwhere w and u are two trainable parameters. The parameter u is a bonus that\nrewards the model for encountering a token for the first time, specifically the current\ntoken. This ensures the model pays more attention to the current token, preventing\nany potential degradation of w. Another important parameter is w, which is a channel-\nwise time decay vector per head. Furthermore, we transform parameter w within the\nrange (0,1), ensuring that diag(w) represents a contraction matrix.\nLike the transformer structure, we use the multi-head WKV to enhance the model’s\ncapacity which is formally described by the following equation:\nMHwkvt = Concat\n\u0000wkv1\nt , . . . , wkvh\nt\n\u0001\n(3)\nWhere h is the number of heads. Finally, an output gating mechanism controls the\nflow of information from the recurrent unit to the next layer or the final output. This\ngating is implemented using the SiLU activation function and receptance. The output\nvector ot per head is given by:\not = (SiL U (gt) ⊙LayerNorm (rt · wkvt)) Wo\n(4)\nWhere LayerNorm operates on each of h heads separately. This gating ensures that\nonly relevant information is passed forward, improving the model’s ability to make\naccurate predictions by filtering out noise and focusing on significant data.\nChannel Mixing Module\nIn the channel-mixing block, channels are mixed by strong non-linear operations as\nfollow:\n12\n\nk′\nt = W ′\ng · (µ′\nk ⊙xt + (1 −µ′\nk) ⊙xt−1)\nr′\nt = W ′\nr · (µ′\nr ⊙xt + (1 −µ′\nr) ⊙xt−1)\nv′\nt = ReLU2 (k′\nt) · W ′\nv\no′\nt = Sigmoid (r′\nt) ⊙v′\nt\n(5)\nwhere we adopt the squared ReLU activation function to enhance the non-linearity.\n3.4 Multimodal Feature Integration and Prediction\nFig. 4 An illustrative example of using attention mechanisms for multimodal feature integration.\nFeature integration and prediction in the TabulaTime model combine extracted\nfeatures from time-series air pollution data with tabular clinical data for ACS risk\nprediction(Figure 4). This model integrates tabular data embedding feature represen-\ntations of time-series data into an attention module, enabling the network to learn\nattention maps conditionally based on the tabular data. This integration enhances the\nnetwork’s ability to pinpoint what, where, and when to focus on in the data, lead-\ning to improved performance in tasks involving both time series and tabular data.\nSpecifically, the tabular data is embedded into the same dimension as the feature rep-\nresentations of the time-series data and passed through shared layers. This allows the\nattention maps to be computed conditionally on the tabular data, facilitating a more\nnuanced and effective feature integration process.\nGive the input X ∈RC, the feature integration can be formulated as:\nˆXc = σ (W2 · δ (W1 · Xc))c · Xc\n(6)\nWhere W1 ∈R\nc\nr ×c and W2 ∈RC× c\nr are the weight matrices of the two fully\nconnected layers. σ denotes the ReLU activation function. σ (W2 · δ (W1 · Xc))c refers\nto the generated attention map. As a final step, a MLP is added at the end of the\nmodel to predict the ACS risk.\n13\n\nThis process ensures that the model effectively integrates and leverages both\nthe tabular and time-series data, leading to more accurate and reliable ACS risk\npredictions.\n4 Experimental Evaluation\n4.1 Experimental Design\nTo evaluate the efficacy of the TabulaTime model, we conduct three comprehensive\nexperiments, each designed to assess distinct aspects of its performance:\n1) Model Performance Analysis\nThis experiment evaluates the predictive accuracy of TabulaTime for Acute\nCoronary Syndrome (ACS) risk. We test the model using varying air pollution\ndata durations (3, 7, 10, and 14 days) to identify the optimal time window.\nSubsequently, we compare its performance against traditional machine learning\nmodels, including Random Forest, LightGBM [48], and CatBoost[49], under two\nscenarios: (a) incorporating air pollution data, and (b) excluding air pollution\ndata. These comparisons quantify the significance of environmental factors in\nenhancing predictive accuracy. Additionally, the generalizability of TabulaTime\nare assessed across varying time periods and air conditions.\n2) PatchRWKV Module Evaluation\nThis experiment focus on the PatchRWKV module’s capability in feature\nextraction from time-series data. Using three publicly available datasets, we\nbenchmark its performance in both classification and forecasting tasks, highlight-\ning its ability to efficiently capture complex temporal patterns. We select several\nState-of-the-art models and referenced their results, which includes most recent\nand extensive empirical studies on time-series. The selected models include:\nMulti-Layer Perceptrons (MLPs) -based models: LightTS [50], LightTS\nis a MLPs model which is straightforward and computationally efficient, suitable\nfor real-time and large-scale applications.\nConvolutional Neural Networks (CNNs)-based models: TimesNet [51],\nTimesNet is a CNN model which is efficient in capturing local patterns and\nhierarchical features in time-series data, providing a solid comparison for the\nfeature extraction capabilities of the PatchRWKV module .\nTransformers-based models: Autoformer[52], PatchTST [46]. Transformer\nhave revolutionised sequence modelling with their self-attention mechanisms,\nexcelling in capturing long-range dependencies. Both Autoformer and PatchTST\nrepresent state-of-the-art approaches in time-series analysis with their decompo-\nsition mechanism and patching mechanism.\nRecurrent Neural Networks (RNNs) -based models: Gated Recurrent\nUnit (GRU) [53] and Long Short-Term Memory (LSTM) [54] are designed for\nsequence data and known for modelling temporal dependencies effectively. These\nmodels provide a comparison for the recurrent structures within the PatchRWKV\nmodule.\n3) Feature Importance and Model Interpretability\n14\n\nThis study aim to understand the interplay between clinical and environmental\nfactors in ACS STEMI VS NSTEMI prediction. By analyzing feature impor-\ntance scores, we identified the key predictors and their relative contributions,\nenhancing the model’s interpretability and offering valuable insights for targeted\ninterventions. The feature importance is calculated using permutation feature\nimportance[55]. This method assesses the increase in the model’s prediction error\nwhen a feature’s values are shuffled. If shuffling a feature increases the model\nerror, the feature is considered important, as the model relies on it for predictions.\nConversely, if shuffling does not affect the model error, the feature is deemed\nunimportant, as the model ignores it for predictions. We first calculate feature\nimportance as the drop in the model’s validation metric when a feature value is\nrandomly shuffled. Then, we calculate step importance to show the significance\nof each time period.\n4.2 Dataset Description\nThe study utilises two primary datasets to evaluate the performance of the TabulaTime\nmodel: 1) Salford MINAP dataset which contains clinical data from the Myocardial\nIschaemia National Audit Project (MINAP) collected in Salford, UK. 2) Air Pollu-\ntion Dataset which contains hourly measurements of various air pollutants collected\nfrom the Salford Eccles monitoring station in Salford, Greater Manchester, United\nKingdom. 3) Additionally, to evaluate the performance of PatchRWKV, we have also\nused three public available time series datasets including Weather [56], Heartbeat\nMonitoring Dataset and Self-Regulation of Slow Cortical Potentials (SCP) Dataset.\n4.2.1 Salford MINAP Dataset\nThe Myocardial Ischaemia National Audit Project (MINAP) is a domain within the\nNational Cardiac Audit Programme (NCAP) that contains information about the\ncare provided to patients who are admitted to hospital with acute coronary syn-\ndromes (heart attack). It is collected and analysed to illustrate the ‘patient journey’\nfrom a call to the emergency services or their self-presentation at an Emergency\nDepartment, through diagnosis and treatment at the hospital, to the prescription of\npreventive medications on discharge. A pseudonymised dataset was obtained under\nethical approval (REC reference: 22/YH/0250) after confidentiality advisory group\nreview (CAG reference: 22/CAG/0155) for use in this study.\nIn this work, 21 risk factors including patient demographics, clinical history, med-\nications, vital signs and diagnostic indicators are selected to predict the ACS risk and\ndifferentiate between STEMI and NSTEMI based on their relevance and significance\nin clinical and environmental contexts.\nFactors such as previous Acute Myocardial Infarction (AMI), angina, hyper-\ntension, hypercholesterolemia, peripheral vascular disease, cerebrovascular disease,\nasthma/COPD, chronic renal failure, heart failure, smoking status, diabetes, previous\nPCI (Percutaneous Coronary Intervention), and previous CABG (Coronary Artery\nBypass Graft) are included. These factors are crucial as they provide a comprehen-\nsive view of a patient’s medical history and risk factors associated with cardiovascular\n15\n\ndiseases[57, 58]. Use of ACEI or ARB (Angiotensin-Converting Enzyme Inhibitors\nor Angiotensin II Receptor Blockers), systolic blood pressure (BP), height, weight,\nBMI (Body Mass Index), family history of coronary heart disease (CHD), creatinine\nlevels, and statin use are considered. These factors help in assessing the ongoing treat-\nment, physiological conditions, and genetic predisposition of patients. The detailed\nrisk factors are shown in Table 1.\nBased upon electrical heart tracings – electrocardiograms or ECGs recorded during\na heart attack, patients are diagnosed as having suffered either ST-elevation myocar-\ndial infarction (STEMI) or non-ST elevation myocardial infarction (NSTEMI). In\nthe annual NCAP report, the terms ‘higher-risk’ and ‘lower-risk’ have been used to\ndifferentiate STEMI from NSTEMI.\nMedical Conditions and Measurements\nCounting and calculation formulae\nPrevious AMI (Acute Myocardial Infarction)\nYes 381/No 597\nPrevious Angina\nYes 470/No 511\nHypertension\nYes 591/No 389\nHypercholesterolaemia\nYes 623/No 358\nPeripheral Vascular Disease\nYes 103/No 877\nCerebrovascular Disease\nYes 125/No 855\nAsthma/COPD\nYes 274/No 704\nChronic Renal Failure\nYes 143/No 837\nHeart Failure\nYes 187/No 792\nSmoking Status\nEx 384/Current smoker 251/Never 343\nDiabetes\nYes 298/No 683\nPrevious PCI (Percutaneous Coronary Intervention)\nYes 184/No 797\nPrevious CABG (Coronary Artery Bypass Graft)\nYes 99/No 880\nACEI or ARB (Angiotensin-Converting Enzyme Inhibitors or Angiotensin II Receptor Blockers)\nYes 471/No 507\nSystolic BP (Blood Pressure)\n137.5 ± 27.1\nHeight\n166.6 ± 10.3\nWeight\n78.1 ± 20.57\nBMI\nBMI =\nWeight\n( Height )2\nFamily History of CHD (coronary heart disease)\nYes 176 /No 785\nCreatinine\n112.4 ± 90.3\nStatin\nYes 592/No 386\nAge\n71.1 ± 13.7\nSTEMI\n123/587\nTable 1 Feature used in MINAP dataset.\n4.2.2 Air Pollution Dataset\nThis air pollution dataset contains hourly measurements of various air pollutants col-\nlected from the Salford Eccles monitoring station (UKA00339) in the United Kingdom.\nThe time range covered by the data is from January 1, 2016, to December 31, 2019.\nThe primary indicators monitored include levels of Nitrogen Oxides (NOx), Nitric\nOxide (NO), Particulate Matter (PM10), and Nitrogen Dioxide (NO2), all measured\nin micrograms per cubic meter (µg/m³).\n4.2.3 Public Datasets\nWeather[56], which is recorded every 10 minutes through the whole of the year 2020,\ncontains 21 meteorological indicators, such as air temperature, humidity, etc. This\ndataset is used for time series forecasting. Heartbeat Monitoring Dataset[59] is used to\nclassify and monitor heartbeats. The dataset consists of sequences of heartbeat signals,\n16\n\noften represented as electrocardiogram (ECG) readings, which need to be classified\ninto different categories such as normal or abnormal heartbeats. Self-Regulation of\nSlow Cortical Potentials (SCP) Dataset [60] is used for studying self-regulation of brain\nactivity, specifically the ability to control slow cortical potentials (SCPs), which are\nslow voltage changes in the brain’s electrical activity. The dataset includes sequences\nof brain activity measurements, which need to be classified to understand patterns\nrelated to self-regulation capabilities.\n4.3 Performance Metrics\nIn this study, we evaluate the performance of our proposed TabulaTime model using\nseveral key metrics that are standard in the fields of classification and forecasting.\nThese metrics provide a comprehensive view of the model's predictive capabilities\nand its effectiveness in handling both classification tasks (e.g., predicting STEMI or\nNSTEMI) and forecasting tasks (e.g., forecasting air pollution levels).\n4.3.1 Classification Metrics\nFor classification tasks such as distinguishing between STEMI and NSTEMI cases,\nthe following metrics were used:\nAccuracy: Accuracy is a widely used metric that represents the proportion of\ncorrectly predicted instances among the total instances.\nAccuracy =\nTP + TN\nTP + FP + FN + TN\n(7)\nPrecision: Proportion of true positive predictions out of all positive predictions\nmade by the model, highlighting prediction reliability.\nRecall: Proportion of true positive predictions out of all actual positive cases,\nindicating the model’s ability to detect positive instances.\nPrecision =\nTP\nTP + FP\n(8)\nF1-Score: Harmonic mean of Precision and Recall, balancing both metrics for a\ncomprehensive assessment of classification performance.\nRecall =\nTP\nTP + FN\n(9)\nROC Curve and AUC (Area Under the Curve): The ROC curve is a\ngraphical representation of a classification model’s performance across all classifica-\ntion thresholds. It plots the True Positive Rate (TPR) against the False Positive Rate\n(FPR). The AUC provides a single scalar value to summarize the model’s performance;\na higher AUC indicates better model performance.\n4.3.2 Forecasting Metrics\nMean Squared Error (MSE) and Mean Absolute Error (MAE): MSE mea-\nsures the average squared difference between the actual and predicted values. It is\n17\n\nparticularly sensitive to large errors, making it a suitable metric for assessing the accu-\nracy of continuous predictions. MAE is another metric used to measure the average\nmagnitude of errors in a set of predictions, without considering their direction (pos-\nitive or negative). It provides a clear interpretation of the average error in the same\nunits as the data. MSE and MAE are calculated as:\nMSE = 1\nn\nn\nX\ni=1\n(ˆyi −yi)2\n(10)\nMAE = 1\nn\nn\nX\ni=1\n|ˆyi −yi|\n(11)\nWhere ˆyi is the predicted value and yi is the actual value.\n5 Results\n5.1 The Performance Evaluation of TabulaTime in ACS\nPrediction\nThe evaluation of the TabulaTime model was conducted through a series of experi-\nments to assess its predictive performance for description of Acute Coronary Syndrome\n(ACS) risk. The experiments were designed to evaluate the influence of time-series\nair pollution data, compare TabulaTime with existing machine learning models, and\nanalyse its generalization capabilities under varying conditions.\n5.1.1 Impact of Time-Series Length for ACS Prediction\nThe model was tested with time-series air pollution data of varying lengths (3, 7, 10,\nand 14 days) to identify the optimal time window for ACS prediction. As shown in\nTable 2, the 10-day time series achieved the best results, with an accuracy of 82.3%\nand an AUC of 0.91, outperforming other time lengths across all metrics. This suggests\nthat a 10-day window strikes a balance between capturing essential trends and avoiding\nnoise introduced by excessive data. Shorter windows (3 and 7 days) lacked critical\ninformation, while longer windows (14 days) diluted key patterns.\nTime Series Length (Days)\nAccuracy\nPrecision\nRecall\nF1-Score\nAUC\n3 Days\n0.815\n0.809\n0.822\n0.815\n0.882\n7 Days\n0.820\n0.817\n0.825\n0.821\n0.894\n10 Days\n0.823\n0.820\n0.830\n0.825\n0.914\n14 Days\n0.819\n0.813\n0.820\n0.816\n0.894\nTable 2 Model prediction performance with time-series air pollution data of varying lengths.\n18\n\n5.1.2 Comparison With Existing Machine Learning Models for\nACS Risk Prediction\nIn this section, we evaluated the performance of the proposed method for ACS risk pre-\ndiction, compared it with several state-of-the-art machine learning models, including\nRandom Forests (RF), Light Gradient Boosting Machines(LightGBM), and CatBoost.\nThe aim of this task was to predict whether a patient had STEMI or NSTEMI under\ndifferent scenarios with and without air pollution data included. The accuracies of the\nproposed method and the existing models were reported in Table 3.\nRandom Forests (RF) is an ensemble learning technique that constructs multiple\ndecision trees and outputs from either the mode of the classes (for classification)\nor the mean prediction (for regression) from the individual trees. This method is\nrobust against overfitting and handles a large number of input features effectively.\nBoth LightGBM and CatBoost are gradient boosting algorithms that are particularly\nwell-suited for structured/tabular data, offering high performance and efficiency.\nMethods\nRandom Forest (RF)\nLightGBM\nCatboost\nThe proposed TabulaTime\nW/O air pollution\n0.6\n0.645\n0.665\n0.753\nWith air pollution\n0.627\n0.655\n0.688\n0.829\nTable 3 Model performance between traditional machine learning method and proposed method.\nThe performance metrics are provided for two scenarios: without considering air\npollution and with considering air pollution. In both scenarios, TabulaTime con-\nsistently outperforms RF, LightGBM and Catboost. When air pollution data was\nincluded, TabulaTime significantly outperformed the other models. It performed 32.2%\nbetter than Random Forest, 27.5% better than LightGBM, and 20.5% better than\nCatBoost. Without the inclusion of air pollution data, TabulaTime performs 25.5%\nbetter than Random Forest, 16.7% better than LightGBM, and 13.2% better than\nCatBoost.\nBoth models showed an improvement when air pollution is included as a factor.\nThe performance of RF improves by 4.5% (from 0.6 to 0.627), LightGBM improved by\n1.6% (from 0.645 to 0.655) and Catboost improves by 3.5% % (from 0.665 to 0.688).\nTabulaTime's performance improved by 10.1% (from 0.753 to 0.829). This indicated\nthat incorporating air pollution data enhanced the predictive capabilities of both mod-\nels, but the improvement was more pronounced for TabulaTime. Figure 5 and Figure 6\nreported the Area Under the Receiver Operating Characteristic Curve (AUC-ROC)\nfor the best-performing machine learning model (Catboost) and the proposed Tabula-\nTime. The results confirm that the model performance improved with the inclusion of\nair pollution indicators. The ROC of the Catboost increased from 0.67 to 0.72, while\nthe proposed TabulaTime improved the prediction accuracy from 0.83 to 0.91.\n5.1.3 Generalisation Performance Under Varying Conditions\nThe generalisability of a model is a crucial indicator of its performance. Notably,\nduring the COVID-19 lockdown in the UK (March 2020 to December 2021), there was\n19\n\nFig. 5 ROC curve of Catboost with and without air pollution.\nFig. 6 ROC curve of TabulaTime with and without air pollution.\na significant decline in air pollution levels. However, the incidence of heart attacks,\nparticularly NSTEMI, increased, a trend confirmed by various studies [61, 62].\nWe have evaluated the model performance across three distinct periods: pre-\nCOVID (January 2016 to December 2019), during the COVID lockdown (March 2020\nto December 2021), and post-COVID lockdown (January 2022 to December 2023).\nFigure 7 illustrates the PM10 levels and the daily incidence of heart attacks during\nthese periods. The model’s accuracy for these periods was 0.829, 0.788, and 0.802,\nrespectively, despite significant fluctuations in air pollution levels. This consistency in\nmodel accuracy across different conditions indicates that our model remains effective\nunder various scenarios.\n20\n\nFig. 7 Changes in air pollution indicator PM10 and heart attack daily incidence over different\nperiods.\n5.2 The Performance of PatchRWKV\nIn the second experiment, we evaluated the performance of the proposed time series\nfeature extraction module (PatchRWKV). Two types of tasks were used to evaluate\nthe model’s performance: Classification and Forecasting.\n5.2.1 Classification\nThe aim of this experiment was to assess the model’s ability to learn high-level\nrepresentations through sequence-level classification in time series data. We selected\nthree multivariate datasets from medical diagnosis including heartbeat monitoring and\nSelf-regulation of Slow Cortical Potentials and ACS prediction.\nMethods\nLightTS\nDLinear\nTimesNet\nAutoformer\nPatchTST\nGRU\nLSTM\nPatchRWKV\nHeartbeat\n0.751\n0.751\n0.756\n0.737\n0.771\n0.722\n0.751\n0.780\nSelfRegulationSCP1\n0.898\n0.873\n0.846\n0.887\n0.904\n0.549\n0.744\n0.918\nSelfRegulationSCP2\n0.511\n0.505\n0.556\n0.544\n0.567\n0.533\n0.517\n0.572\nACS\n0.681\n0.667\n0.676\n0.686\n0.678\n0.676\n0.686\n0.703\nTable 4 Model performance on classification tasks.\nTable 4 presents the classification accuracy of eight time series processing models\nacross four classification tasks (Heartbeat, SelfRegulationSCP1, SelfRegulationSCP2,\nACS). In Heartbeat task, PatchRWKV improved by 0.9% over PatchTST and showed\na significant improvement of 5.8% over GRU. In SelfRegulationSCP1 and SelfRegula-\ntionSCP2 tasks, PatchRWKV (91.80 and 57.20) outperformed the next best method,\nPatchTST (90.40 and 56.70), by 1.40% and 0.50 %. In the ACS classification task,\nPatchRWKV (70.28) outperformed the LSTM and Autoformer (both 68.58), by 1.7%.\nPatchRWKV consistently outperformed the other models, achieving the highest\naccuracy across all tasks: Heartbeat: 78%, SelfRegulationSCP1: 91.8%, SelfRegula-\ntionSCP2: 57.2% and ACS: 70.28%. The improvements range from 0.50% to 36.85%,\nindicating that PatchRWKV is a robust and effective method for these classification\n21\n\ntasks, especially with a substantial advantage in more complex tasks like SelfRegu-\nlationSCP1. Traditional models like GRU and LSTM lag significantly behind newer\narchitectures, indicating a shift in effectiveness towards more advanced methods like\nPatchTST and TimesNet.\n5.2.2 Forecasting\nThe aim of this experiment was to evaluate the performance of the proposed and com-\npared models in time series forecasting tasks for weather and air pollution prediction.\nTwo real-world datasets were used: the Weather Dataset and the Salford Air Pollution\nDataset.\nFor the Weather Dataset, 144 historical time steps (24 hours) were used to forecast\nthe next 48 time steps (8 hours), for two indicators: pressure and temperature. In\nthe Salford Air Pollution Dataset, 240 historical time steps (10 days) were used to\npredict the next 48 time steps (2 days) for four indicators: Particulate Matter (PM10),\nNitrogen Dioxide (NO2), Nitrogen Oxides (NOx) and Nitric Oxide (NO).\nMethods\nWeather\nSalford Air Pollution\nMSE\nMAE\nMSE\nMAE\nMLP-based\nLightTS\n0.261\n0.312\n0.693\n0.511\nDLinear\n0.249\n0.3\n0.695\n0.508\nCNN-based\nTimesNet\n0.259\n0.287\n0.78\n0.504\nTransformer-based\nAutoformer\n0.338\n0.382\n0.707\n0.49\nPatchTST\n0.231\n0.266\n0.685\n0.481\nRNN-based\nGRU\n0.225\n0.286\n0.718\n0.524\nLSTM\n0.199\n0.262\n0.722\n0.52\nPatchRWKV\n0.177\n0.264\n0.674\n0.473\nTable 5 Model performance on forecasting tasks.\nTable 5 presents the performance of various time series processing model on two\nforecasting tasks. The models are categorized into four types: MLP-based, CNN-based,\nTransformer-based, and RNN-based. Performance was evaluated using two metrics:\nMean Squared Error (MSE) and Mean Absolute Error (MAE). The PatchRWKV\napproach demonstrates superior performance on both datasets, achieving the lowest\nMSE and highly competitive MAE values. Figure 8 showed the forecasting results\nof PatchRWKV on the two real datasets forecasting tasks. The model results were\nsuccessful in predicting the trends of the pollution indicators. This indicates that\nPatchRWKV is highly effective in terms of both accuracy and robustness compared to\nother methods evaluated. Meanwhile, the RNN-based models generally outperformed\nother types in weather forecasting, with PatchRWKV and LSTM showing particularly\nstrong results.\n5.2.3 Computing Efficiency Analysis\nWe have conducted a complexity analysis of the PatchRWKV, and its competing\nmodels as shown in Table 6. GRU, LSTM, LightTS, DLinear, PatchRWKV have a\n22\n\nFig. 8 The forecasting result of PatchRWKV on Weather (a and b) and Salford Air Pollution dataset\n(c,d,e and f)\nMethod\nTime Complexity\nTest Step\nParameter\nGRU\nO(L)\nL\n38,709,216\nLSTM\nO(L)\nL\n9,216,192\nLightTS\nO(L)\n1\n11,128\nDLinear\nO(L)\n1\n18,624\nTimesNet\nO(kˆ2L)\n1\n1,193,781\nPatchTST\nO(Lˆ2)\n1\n677,984\nAutoformer\nO(LlogL)\n1\n882,709\nPatchRWKV\nO(L)\n1\n468,144\nTable 6 Computational complexity comparison. L is the sequence length; k is the kernel size of\nconvolutions. The GRU and LSTM are sequential processing that have L test step to capture\nlong-term dependencies. For the rest models, only 1 test step needed for processing the entire\nsequence in parallel, enabling faster inference.\nlinear time complexity relative to the sequence length L. This is efficient for longer\nsequences as the complexity grows at a controlled rate. TimesNet is a CNN based\nmodel that introduces a quadratic factor based on the kernel size k. PatchTST and\nAutoformer which are two transformer-based model that have quadratic and loga-\nrithmic complexity concerning the sequence length L. For the Test Step, GRU and\nLSTM are traditional RNN models with L number of test steps, which means they\n23\n\nrequire multiple steps proportional to the length of the sequence, which may increase\nthe computational load during testing or inference. In contrast, models like LightTS,\nDLinear, TimesNet, PatchTST, Autoformer, and PatchRWKV need only 1 test step as\nthey process the entire sequence in parallel, enabling faster inference. For the count of\nparameters, GRU (38,709,216) and LSTM (9,216,192) have significantly higher param-\neter counts compared to others due to the RNN's computational mechanism. The\nproposed PatchRWKV (468,144) have relatively low parameter counts, which gener-\nally translates to more lightweight models that are faster and require less memory,\nmaking them suitable for scenarios where computational resources are limited.\n5.3 Feature Importance and Model Interpretability\nFig. 9 Feature importance on ACS STEMI VS NSTEMI prediction.\n24\n\nIn this work, we reported feature importance to explain how models make decisions\nto predict STEMI VS. NSTEMI.The analysis highlights the contributions of 25 risk\nfactors (Figure 9), encompassing patient demographics, clinical history, vital signs,\nmedications, diagnostic indicators, and air pollution metrics. The analysis revealed\nthat Systolic Blood Pressure (SBP) was the most influential predictor of STEMI and\nNSTEMI, with the highest importance score (0.084), emphasizing its critical role in\ncardiovascular function. Body Mass Index (BMI) followed as the second most impor-\ntant feature (0.073), highlighting the metabolic influence on cardiovascular health,\nparticularly in chronic conditions. Air quality metrics, such as PM10sum, PM10max,\nand NO2sum, were also significant contributors, underscoring the acute and cumu-\nlative impact of air pollution on cardiovascular risk. Moderately important features\nincluded creatinine levels (0.055), indicative of renal function, and age at admission\n(0.064), a well-established cardiovascular risk factor. Additionally, historical factors\nlike angina and smoking status provided valuable insights into patient-specific risks.\nWhile metabolic factors like diabetes and hypertension were relevant, their lower\nimportance scores suggests a more indirect role in the model. Lesser but notable con-\ntributors included peripheral vascular disease and prior CABG/PCI, reflecting the\nbackground conditions associated with ACS risk.\nFig. 10 Day-wise Importance for ACS Prediction.\nFigure 10 showed the average importance of air qiality each day for predicting\nACS risk. The daily step importance analysis revealed that pollution levels on the day\nprior to a clinical presentation of ACS (Day 1) held the highest predictive significance,\nfollowed by a gradual decline in relevance for preceding days. This finding emphasizes\nthe acute impact of short-term pollution exposure on presentation of ACS.\nTable 7 presented the quartile cutoff values of key clinical and environmental factors\nalong with t-test p-values, significant differences between STEMI and NSTEMI cases\nemerge, highlighting distinct chronic and acute influences. Systolic BP is significantly\n25\n\nSTEMI\nNSTEMI\nT-test p-value\n25%\n50%\n75%\n25%\n50%\n75%\nSystolic BP\n114\n128\n146\n121\n138\n156\n0.0019 (<0.05)\nCreatinine\n70.75\n86\n99\n72\n88\n108\n0.0049 (<0.05)\nAge At Admission\n59\n71\n80.25\n60\n72\n81\n0.4911 (>0.05)\nBMI\n23.36\n26.02\n29.5\n24.53\n28.03\n32.23\n0.0021 (<0.05)\nPM10sum\n748.94\n910.2\n1226.46\n769.85\n978.45\n1379.95\n0.0487 (<0.05)\nNOsum\n160.45\n345.22\n751.63\n157.07\n296.12\n681.47\n0.4883 (>0.05)\nNO2sum\n1092.68\n1502.32\n2045.5\n1112.78\n1462.57\n2049.09\n0.628 (>0.05)\nNOXsum\n1318.5\n2060.17\n3244.01\n1388.16\n1916.61\n3054.62\n0.5147 (>0.05)\nPM10max\n22.4\n27.55\n40.89\n22\n29.73\n43.5\n0.4147 (>0.05)\nNOmax\n11.07\n35.66\n82.02\n11.1\n28.43\n77.36\n0.9342 (>0.05)\nNO2max\n40.21\n54.79\n67.28\n40.12\n53.04\n68.63\n0.8793 (>0.05)\nNOXmax\n55.79\n103.91\n175.8\n55.86\n91.64\n181.47\n0.8761 (>0.05)\nTable 7 Comparison of key clinical and environmental predictors for STEMI and NSTEMI cases.\nThe Quartile Cutoff values represent the 25th, 50th (median), and 75th percentiles of each\npredictor’s distribution. The statistical significance of these variables (p < 0.05) supports their\nclinical relevance in distinguishing STEMI from NSTEMI.\nhigher in NSTEMI (75th percentile = 156) compared to STEMI (75th percentile =\n146, p = 0.00187), suggesting that chronic hypertension is more prevalent in NSTEMI,\nwhereas lower BP in STEMI reflects acute cardiovascular dysfunction. BMI follows\na similar trend, with higher values in NSTEMI (75th percentile = 32.23 vs. 29.5 in\nSTEMI, p = 0.00207), reinforcing the role of chronic obesity. Creatinine levels are\nalso significantly elevated in STEMI (p = 0.00490), indicating potential acute kidney\ninjury or pre-existing renal impairment as contributors. Notably, PM10 exposure is\nsignificantly higher in STEMI cases (p = 0.04867), suggesting that short-term envi-\nronmental triggers may precipitate acute coronary events, while NO, NOX, and NO2\nlevels showed no significant difference (p > 0.05), implying a lesser role in STEMI/N-\nSTEMI differentiation. However, the lack of statistical significance in several AQIs\nmay be due to the fact that STEMI and NSTEMI cases occurred on the same day,\nreducing the distinction between pollution-related effects. Age at admission trends\nslightly higher in NSTEMI (75th percentile = 81 vs. 80.25 in STEMI), but the differ-\nence is not statistically significant (p = 0.49108). These findings emphasize the chronic\nnature of NSTEMI, driven by hypertension and obesity, versus the acute nature of\nSTEMI, potentially triggered by air pollution exposure, highlighting the need for tar-\ngeted prevention strategies such as improved hypertension and obesity management\nand air quality interventions to mitigate ACS risk.\n6 Discussion\nThis study presents TabulaTime, a novel deep learning-based method designed to\nintegrate air pollution data with clinical risk factors for predicting Acute Coronary\nSyndrome (ACS). The results from our experiments suggest that combining environ-\nmental and clinical data significantly improves prediction accuracy, reinforcing the\nneed to include environmental factors in cardiovascular risk models.\nTraditional cardiovascular risk scores, such as QRISK3, FRS, and GRACE, pri-\nmarily rely on clinical data and do not include dynamic environmental influences. By\n26\n\nincorporating air pollution data, the TabulaTime model addresses this gap, providing\na more comprehensive risk assessment tool. This integration is particularly relevant\ngiven the growing body of evidence linking air pollution to adverse cardiovascular out-\ncomes. For instance, pollutants such as PM10, NO2, NO, and NOx have been shown\nto exacerbate cardiovascular conditions through mechanisms like inflammation and\noxidative stress [10, 63]. In this work, the presence of environmental factors like PM10\nand NO2 among the more important features indicates that air quality and pollu-\ntion may be significant predictors in the context of the model, possibly relating to\nrespiratory or cardiovascular conditions. Our experimental results demonstrate that\nincluding air pollution data improves the accuracy of ACS risk prediction by 10.1%,\na substantial gain over traditional clinical-only models. This finding aligns with prior\nepidemiological studies linking air pollutants (PM10, NO2, NOx) with increased car-\ndiovascular stress, inflammation, and thrombotic events. By incorporating real-time\nexposure data, TabulaTime provides a more holistic assessment of ACS risk, high-\nlighting the immediate effects of environmental exposure in triggering cardiovascular\nevents.\nOne of the major innovations in TabulaTime is the PatchRWKV module, an effi-\ncient time-series feature extraction module that combines Recurrent Neural Networks\n(RNNs) and Transformer-based self-attention mechanisms. Our experiments across\nmultiple classification and forecasting tasks confirmed that PatchRWKV surpassed\nstate-of-the-art models such as PatchTST, Autoformer, and TimesNet, while main-\ntaining linear computational complexity. The patching strategy, which isolates local\ntemporal patterns (e.g., daily pollution cycles), allows the model to discern subtle\nexposure-response relationships that manual feature engineering might miss. This\ncapability is critical for public health applications, where identifying high-risk periods\n(e.g., days with PM10 ¿40 µg/m³) can inform real-time interventions.\nWhen compared to Random Forest (RF), LightGBM, and CatBoost, TabulaTime\nsignificantly outperformed these traditional machine learning models, achieving a\n32.2% improvement over RF and a 20.5% improvement over CatBoost. Notably, even\nwithout environmental data, TabulaTime still maintains a superior performance, sug-\ngesting that its novel multimodal feature integration and advanced temporal feature\nextraction contribute significantly to its predictive strength.\nThe robustness of TabulaTime was tested under different environmental and tem-\nporal conditions. Notably, during the COVID-19 lockdown (2020–2021)—when air\npollution levels were drastically reduced, our model maintains high predictive accuracy\n(78.8%), despite the altered exposure conditions. This result underscores TabulaTime’s\nadaptability to fluctuating environmental factors, making it potentially valuable for\nreal-time health monitoring systems.\nClinically, TabulaTime’s interpretability offers actionable insights. The use of\nattention mechanisms and feature importance analysis enhances the interpretabil-\nity of the model. Our analysis identified Systolic Blood Pressure (SBP), Body Mass\nIndex (BMI), PM10, and NO2 as the most influential features for ACS risk prediction\n(Figure 9) . The high importance of PM10 and NO2 suggests a strong link between air\npollution and acute cardiovascular events, reinforcing the need for air quality moni-\ntoring as a preventive healthcare measure. Additionally, the day-wise analysis of air\n27\n\npollution exposure (Figure 10) revealed that pollution levels one day prior to ACS\nonset were the most predictive, suggesting that short-term exposure triggers acute\ncardiovascular events. This result is clinically significant, as it supports policies advo-\ncating for real-time air quality alerts and public health interventions in high-pollution\nareas.\nDespite its strengths, the TabulaTime model has several limitations. The model\nwas tested using data from Salford, UK, so it may not work exactly the same way in\nother regions where air pollution levels and healthcare conditions are different. Future\nstudies should test the model in other or larger locations to see if it can be applied\nmore widely. Also, while PM10, and NO2 were identified as important pollutants, other\nenvironmental factors like temperature, humidity, and noise levels were not included in\nthis study. Adding these in the future could make the predictions even more accurate.\nIn conclusion, TabulaTime is a powerful tool for ACS prediction that integrates\nenvironmental and clinical data. It is more accurate, efficient, and adaptable than tra-\nditional models, offering valuable insights for both clinical decision-making and public\nhealth policies. With further validation and refinement, it could play a significant role\nin personalized healthcare, air pollution monitoring, and real-time risk assessment.\n7 Conclusion and Future work\nThis study introduces TabulaTime, a novel multimodal model that integrates time-\nseries air pollution data with traditional clinical data to investigate their influence on\nAcute Coronary Syndrome (ACS) presentation. The results demonstrated that Tab-\nulaTime effectively incorporated these elements, achieving outstanding performance.\nNotably, the PatchRWKV module significantly enhanced the model’s accuracy by cap-\nturing both short-term and long-term pollution exposure trends, a major advancement\nin temporal feature extraction.\nThe experimental results underscored TabulaTime’s effectiveness in improving\npredictive accuracy across various tasks. Our TabulaTime outperformed other state-of-\nthe-art machine learning models, such as Random Forests, LightGBM, and CatBoost,\nby margins ranging from 16.7% to 32.2%, showcasing its robustness and efficacy.\nSpecifically, our findings highlighted the critical role of environmental factors in cardio-\nvascular risk assessment. The inclusion of air quality data led to a 10.1% improvement\nin accuracy compared to scenarios where such data was omitted, emphasizing the\nimportance of integrating environmental factors in ACS risk prediction—an aspect\noften overlooked in traditional models.\nFurthermore, the PatchRWKV module demonstrated superior performance in\ntime-series classification and forecasting tasks. In classification tasks, it outper-\nformed state-of-the-art models such as LightTS, DLinear, TimesNet, Autoformer\nand PatchTST. In forecasting tasks, PatchRWKV consistently delivered lower Mean\nSquared Error (MSE) and Mean Absolute Error (MAE) compared to other mod-\nels, demonstrating robust predictive capabilities for both weather and air pollution\nindicators.\nThe model maintained high accuracy despite significant fluctuations in air pollu-\ntion levels, with accuracy rates of 82.9%, 78.8%, and 80.2% for pre-COVID, during\n28\n\nCOVID lockdown, and post-COVID periods, respectively. This adaptability suggested\nthat TabulaTime was applicable across diverse geographical and temporal contexts.\nThe feature importance analysis revealed that clinical factors such as previous angina\nand systolic blood pressure, alongside environmental pollutants like PM10 and NO2,\nare significant predictors of ACS risk. Interestingly, metabolic factors such as BMI\nand hypertension, while still relevant, were less influential in this model. This finding\nsuggested that while metabolic factors contributed to cardiovascular risk, the interac-\ntion between clinical history and environmental exposure played a more pivotal role\nin the context of ACS prediction.\nOverall, TabulaTime represents a significant advancement in ACS risk modelling\nby integrating environmental and clinical data, offering a comprehensive approach\nto preventive cardiology. The findings suggest that future predictive models should\ninclude environmental data to enhance accuracy and provide more holistic insights into\npatient health, thereby aiding in more effective clinical decision-making and targeted\ninterventions.\nOur future work will includes continuously validating TabulaTime across diverse\ngeographic settings to enhance its generalizability, accounting for variations in air pol-\nlution levels, socio-demographics, and healthcare access. Additionally, incorporating\npersonalized risk assessments—factoring in genetic predisposition, lifestyle, and comor-\nbidities—could improve individualized ACS prediction. Beyond air pollution, integrat-\ning broader environmental and socioeconomic factors, such as healthcare accessibility,\nwould further refine the model into a comprehensive health risk assessment tool.\nThese advancements will enhance TabulaTime’s impact on clinical decision-making\nand public health strategies.\nAcknowledgement\nFunding support: British Heart Foundation Doug Gurr Cardiovascular Catalyst Award\n(BHF-CC/22/250021). Liangxiu Han is supported by EPSRC (EP/X013707/1).\nReferences\n[1] Reed, G.W., Rossi, J.E., Cannon, C.P.: Acute myocardial infarction. The Lancet\n389(10065), 197–210 (2017) https://doi.org/10.1016/S0140-6736(16)30677-8\n[2] Bergmark, B.A., Mathenge, N., Merlini, P.A., Lawrence-Wright, M.B., Giugliano,\nR.P.: Acute coronary syndromes. Lancet (London, England) 399(10332), 1347–\n1358 (2022) https://doi.org/10.1016/S0140-6736(21)02391-6 . PMID: 35367005\nPMCID: PMC8970581\n[3] Hippisley-Cox, J., Coupland, C., Brindle, P.: Development and validation of\nQRISK3 risk prediction algorithms to estimate future risk of cardiovascular dis-\nease: prospective cohort study. BMJ, 2099 (2017) https://doi.org/10.1136/bmj.\nj2099\n29\n\n[4] Hippisley-Cox, J., Coupland, C., Vinogradova, Y., Robson, J., May, M., Brindle,\nP.: Derivation and validation of QRISK, a new cardiovascular disease risk score\nfor the United Kingdom: prospective open cohort study. Bmj 335(7611), 136\n(2007). publisher: British Medical Journal Publishing Group\n[5] Hippisley-Cox, J., Coupland, C., Robson, J., Brindle, P.: Derivation, validation,\nand evaluation of a new QRISK model to estimate lifetime risk of cardiovascu-\nlar disease: cohort study using QResearch database. Bmj 341 (2010). publisher:\nBritish Medical Journal Publishing Group\n[6] Hemann, B.A., Bimson, W.F., Taylor, A.J.: The Framingham Risk Score: An\nAppraisal of Its Benefits and Limitations. American Heart Hospital Journal 5(2),\n91–96 (2007) https://doi.org/10.1111/j.1541-9215.2007.06350.x\n[7] Ridker, P.M., Buring, J.E., Rifai, N., Cook, N.R.: Development and validation of\nimproved algorithms for the assessment of global cardiovascular risk in women: the\nReynolds Risk Score. Jama 297(6), 611–619 (2007). publisher: American Medical\nAssociation\n[8] Nashef, S.A., Roques, F., Michel, P., Gauducheau, E., Lemeshow, S., Sala-\nmon, R., Group, E.S.: European system for cardiac operative risk evaluation\n(Euro SCORE). European journal of cardio-thoracic surgery 16(1), 9–13 (1999).\npublisher: Elsevier Science BV\n[9] Rus, A.-A., Morno¸s, C.: The Impact of Meteorological Factors and Air Pollutants\non Acute Coronary Syndrome. Current Cardiology Reports 24(10), 1337–1349\n(2022) https://doi.org/10.1007/s11886-022-01759-5\n[10] Chen, R., Jiang, Y., Hu, J., Chen, H., Li, H., Meng, X., Ji, J.S., Gao, Y., Wang,\nW., Liu, C., Fang, W., Yan, H., Chen, J., Wang, W., Xiang, D., Su, X., Yu, B.,\nWang, Y., Xu, Y., Wang, L., Li, C., Chen, Y., Bell, M.L., Cohen, A.J., Ge, J.,\nHuo, Y., Kan, H.: Hourly Air Pollutants and Acute Coronary Syndrome Onset\nin 1.29 Million Patients. Circulation 145(24), 1749–1760 (2022) https://doi.org/\n10.1161/CIRCULATIONAHA.121.057179\n[11] Torres, J.F., Hadjout, D., Sebaa, A., Mart´ınez-´Alvarez, F., Troncoso, A.: Deep\nLearning for Time Series Forecasting: A Survey. Big Data 9(1), 3–21 (2021) https:\n//doi.org/10.1089/big.2020.0159\n[12] Connor, J.T., Martin, R.D., Atlas, L.E.: Recurrent neural networks and robust\ntime series prediction. IEEE transactions on neural networks 5(2), 240–254\n(1994). publisher: IEEE\n[13] Mayer, H.A., Schwaiger, R.: Evolutionary and coevolutionary approaches to\ntime series prediction using generalized multi-layer perceptrons. In: Proceed-\nings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No.\n99TH8406), vol. 1, pp. 275–280 (1999). IEEE. [Online; accessed 2024-07-31].\n30\n\nhttps://ieeexplore.ieee.org/abstract/document/781936/\n[14] Zhao, B., Lu, H., Chen, S., Liu, J., Wu, D.: Convolutional neural networks for\ntime series classification. Journal of systems engineering and electronics 28(1),\n162–169 (2017). publisher: BIAI\n[15] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N.,\nKaiser, L., Polosukhin, I.: Attention Is All You Need. arXiv:1706.03762 [cs] (2017).\narXiv: 1706.03762\n[16] Gugnani, V., Singh, R.K.: Analysis of deep learning approaches for air pollution\nprediction. Multimedia Tools and Applications 81(4), 6031–6049 (2022) https:\n//doi.org/10.1007/s11042-021-11734-x\n[17] Zhou, X., Tong, W., Li, L.: Deep learning spatiotemporal air pollution data in\nChina using data fusion. Earth Science Informatics 13(3), 859–868 (2020) https:\n//doi.org/10.1007/s12145-020-00470-9\n[18] Ghufran Isam Drewil, D.R.J.A.-B.: Forecast Air Pollution in Smart City Using\nDeep Learning Techniques: A Review Ghufran Isam Drewil , Dr. Riyadh Jab-\nbar Al-Bahadili (2021) https://doi.org/10.5281/ZENODO.4737746 . publisher:\n[object Object] version: 7\n[19] Subramaniam, S., Raju, N., Ganesan, A., Rajavel, N., Chenniappan, M., Prakash,\nC., Pramanik, A., Basak, A.K., Dixit, S.: Artificial Intelligence Technologies for\nForecasting Air Pollution and Human Health: A Narrative Review. Sustainability\n14(16), 9951 (2022) https://doi.org/10.3390/su14169951 . number: 16 publisher:\nMultidisciplinary Digital Publishing Institute\n[20] Bekkar, A., Hssina, B., Douzi, S., Douzi, K.: Air-pollution prediction in smart\ncity, deep learning approach. Journal of Big Data 8(1), 161 (2021) https://doi.\norg/10.1186/s40537-021-00548-1\n[21] Miranda, A.C., Santana, J.C.C., Yamamura, C.L.K., Rosa, J.M., Tambourgi,\nE.B., Ho, L.L., Berssaneti, F.T.: Application of neural network to simulate the\nbehavior of hospitalizations and their costs under the effects of various pollut-\ning gases in the city of S˜ao Paulo. Air Quality, Atmosphere, & Health 14(12),\n2091–2099 (2021) https://doi.org/10.1007/s11869-021-01077-9 . PMID: 34745381\nPMCID: PMC8556003\n[22] Jabeen, S., Li, X., Amin, M.S., Bourahla, O., Li, S., Jabbar, A.: A Review on\nMethods and Applications in Multimodal Deep Learning. ACM Transactions on\nMultimedia Computing, Communications, and Applications 19(2s), 1–41 (2023)\nhttps://doi.org/10.1145/3545572\n[23] Gandhi, A., Adhvaryu, K., Poria, S., Cambria, E., Hussain, A.: Multimodal\nsentiment analysis: A systematic review of history, datasets, multimodal fusion\n31\n\nmethods, applications, challenges and future directions. Information Fusion 91,\n424–444 (2023). publisher: Elsevier\n[24] Liang, P.P., Zadeh, A., Morency, L.-P.: Foundations & Trends in Multimodal\nMachine Learning: Principles, Challenges, and Open Questions. ACM Computing\nSurveys, 3656580 (2024) https://doi.org/10.1145/3656580\n[25] Steen, D.L., Khan, I., Andrade, K., Koumas, A., Giugliano, R.P.: Event Rates and\nRisk Factors for Recurrent Cardiovascular Events and Mortality in a Contempo-\nrary Post Acute Coronary Syndrome Population Representing 239 234 Patients\nDuring 2005 to 2018 in the United States. Journal of the American Heart Associa-\ntion 11(9), 022198 (2022) https://doi.org/10.1161/JAHA.121.022198 . publisher:\nWiley\n[26] Bhatt, D.L., Lopes, R.D., Harrington, R.A.: Diagnosis and Treatment of Acute\nCoronary Syndromes: A Review. JAMA 327(7), 662–675 (2022) https://doi.org/\n10.1001/jama.2022.0358\n[27] Smith, G.B., Prytherch, D.R., Meredith, P., Schmidt, P.E., Featherstone, P.I.:\nThe ability of the National Early Warning Score (NEWS) to discriminate\npatients at risk of early cardiac arrest, unanticipated intensive care unit admis-\nsion, and death. Resuscitation 84(4), 465–470 (2013) https://doi.org/10.1016/j.\nresuscitation.2012.12.016\n[28] Ke, J., Chen, Y., Wang, X., Wu, Z., Zhang, Q., Lian, Y., Chen, F.: Machine\nlearning-based in-hospital mortality prediction models for patients with acute\ncoronary syndrome. The American Journal of Emergency Medicine 53, 127–134\n(2022) https://doi.org/10.1016/j.ajem.2021.12.070 . PMID: 35033770\n[29] Wu, T.T., Lin, X.Q., Mu, Y., Li, H., Guo, Y.S.: Machine learning for early pre-\ndiction of in-hospital cardiac arrest in patients with acute coronary syndromes.\nClinical Cardiology 44(3), 349–356 (2021) https://doi.org/10.1002/clc.23541 .\nPMID: 33586214 PMCID: PMC7943901\n[30] Hadanny, A., Shouval, R., Wu, J., Gale, C.P., Unger, R., Zahger, D., Gottlieb, S.,\nMatetzky, S., Goldenberg, I., Beigel, R., Iakobishvili, Z.: Machine learning-based\nprediction of 1-year mortality for acute coronary syndrome. Journal of Cardiology\n79(3), 342–351 (2022) https://doi.org/10.1016/j.jjcc.2021.11.006\n[31] D’Ascenzo, F., De Filippo, O., Gallone, G., Mittone, G., Deriu, M.A., Iannaccone,\nM., Ariza-Sol´e, A., Liebetrau, C., Manzano-Fern´andez, S., Quadri, G., Kinnaird,\nT., Campo, G., Simao Henriques, J.P., Hughes, J.M., Dominguez-Rodriguez, A.,\nAldinucci, M., Morbiducci, U., Patti, G., Raposeiras-Roubin, S., Abu-Assi, E.,\nDe Ferrari, G.M., PRAISE study group: Machine learning-based prediction of\nadverse events following an acute coronary syndrome (PRAISE): a modelling\nstudy of pooled datasets. Lancet (London, England) 397(10270), 199–207 (2021)\nhttps://doi.org/10.1016/S0140-6736(20)32519-8 . PMID: 33453782\n32\n\n[32] Emakhu, J., Monplaisir, L., Aguwa, C., Arslanturk, S., Masoud, S., Nassereddine,\nH., Hamam, M.S., Miller, J.B.: Acute coronary syndrome prediction in emer-\ngency care: A machine learning approach. Computer Methods and Programs in\nBiomedicine 225, 107080 (2022) https://doi.org/10.1016/j.cmpb.2022.107080 .\nPMID: 36037605\n[33] Lee, W., Lee, J., Woo, S.-I., Choi, S.H., Bae, J.-W., Jung, S., Jeong, M.H., Lee,\nW.K.: Machine learning enhances the performance of short and long-term mor-\ntality prediction model in non-ST-segment elevation myocardial infarction. Sci-\nentific Reports 11(1), 12886 (2021) https://doi.org/10.1038/s41598-021-92362-1\n. publisher: Nature Publishing Group\n[34] Duan, H., Sun, Z., Dong, W., Huang, Z.: Utilizing dynamic treatment information\nfor mace prediction of acute coronary syndrome. BMC Medical Informatics and\nDecision Making 19, 1–11 (2019)\n[35] Liu, Y., Liu, J., Qin, C., Jin, Y., Li, Z., Zhao, L., Liu, C.: A deep learning-based\nacute coronary syndrome-related disease classification method: A cohort study\nfor network interpretability and transfer learning. Applied Intelligence 53(21),\n25562–25580 (2023)\n[36] Liu, W.-C., Lin, C.-S., Tsai, C.-S., Tsao, T.-P., Cheng, C.-C., Liou, J.-T., Lin,\nW.-S., Cheng, S.-M., Lou, Y.-S., Lee, C.-C., et al.: A deep learning algorithm\nfor detecting acute myocardial infarction: Deep learning model to detect ami.\nEuroIntervention 17(9), 765 (2021)\n[37] Ku´zma, L., Wa´nha, W., Kralisz, P., Kazmierski, M., Bach´orzewska-Gajewska, H.,\nWojakowski, W., Dobrzycki, S.: Impact of short-term air pollution exposure on\nacute coronary syndrome in two cohorts of industrial and non-industrial areas:\nA time series regression with 6,000,000 person-years of follow-up (ACS - Air\nPollution Study). Environmental Research 197, 111154 (2021) https://doi.org/\n10.1016/j.envres.2021.111154\n[38] Gestro, M., Condemi, V., Bardi, L., Tomaino, L., Roveda, E., Bruschetta, A.,\nSolimene, U., Esposito, F.: Short-term air pollution exposure is a risk factor\nfor acute coronary syndromes in an urban area with low annual pollution rates:\nResults from a retrospective observational study (2011–2015). Archives of Car-\ndiovascular Diseases 113(5), 308–320 (2020) https://doi.org/10.1016/j.acvd.2020.\n03.013\n[39] H¨usken, M., Stagge, P.: Recurrent neural networks for time series classification.\nNeurocomputing 50, 223–235 (2003). publisher: Elsevier\n[40] Hewamalage, H., Bergmeir, C., Bandara, K.: Recurrent neural networks for time\nseries forecasting: Current status and future directions. International Journal of\nForecasting 37(1), 388–427 (2021). publisher: Elsevier\n33\n\n[41] Zeng, A., Chen, M., Zhang, L., Xu, Q.: Are transformers effective for time series\nforecasting? In: Proceedings of the AAAI Conference on Artificial Intelligence, vol.\n37 https://ojs.aaai.org/index.php/AAAI/article/view/26317, ???, pp. 11121–\n11128 (2023). issue: 9. https://ojs.aaai.org/index.php/AAAI/article/view/26317\n[42] Villegas, M., Gonzalez-Agirre, A., Guti´errez-Fandi˜no, A., Armengol-Estap´e, J.,\nCarrino, C.P., P´erez-Fern´andez, D., Soares, F., Serrano, P., Pedrera, M., Garc´ıa,\nN., Valencia, A.: Predicting the evolution of COVID-19 mortality risk: A Recur-\nrent Neural Network approach. Computer Methods and Programs in Biomedicine\nUpdate 3, 100089 (2023) https://doi.org/10.1016/j.cmpbup.2022.100089\n[43] Suttaket, T., Kok, S.: Interpretable Predictive Models for Healthcare via Rational\nMulti-Layer Perceptrons. ACM Trans. Manage. Inf. Syst. (2024) https://doi.org/\n10.1145/3671150 . Just Accepted\n[44] M¨uller, P.N., M¨uller, A.J., Achenbach, P., G¨obel, S.: Imu-Based Fitness Activity\nRecognition Using CNNs for Time Series Classification. Sensors 24(3), 742 (2024)\nhttps://doi.org/10.3390/s24030742 . number: 3 publisher: Multidisciplinary Dig-\nital Publishing Institute\n[45] Ni, H., Meng, S., Geng, X., Li, P., Li, Z., Chen, X., Wang, X., Zhang, S.: Time\nSeries Modeling for Heart Rate Prediction: From ARIMA to Transformers (2024)\nhttps://doi.org/10.48550/arXiv.2406.12199 . arXiv:2406.12199 [cs]\n[46] Nie, Y., Nguyen, N.H., Sinthong, P., Kalagnanam, J.: A Time Series is Worth 64\nWords: Long-term Forecasting with Transformers (2023). arXiv:2211.14730 [cs]\n[47] Sayed, M.S., Rony, M.A.T., Islam, M.S., Raza, A., Tabassum, S., Daoud, M.S.,\nMigdady, H., Abualigah, L.: A Novel Deep Learning Approach for Forecasting\nMyocardial Infarction Occurrences with Time Series Patient Data. Journal of\nMedical Systems 48(1), 53 (2024) https://doi.org/10.1007/s10916-024-02076-w\n[48] Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., Liu, T.-Y.:\nLightgbm: A highly efficient gradient boosting decision tree. Advances in neural\ninformation processing systems 30 (2017)\n[49] Prokhorenkova, L., Gusev, G., Vorobev, A., Dorogush, A.V., Gulin, A.: Catboost:\nunbiased boosting with categorical features. Advances in neural information\nprocessing systems 31 (2018)\n[50] Zhang, T., Zhang, Y., Cao, W., Bian, J., Yi, X., Zheng, S., Li, J.: Less Is More:\nFast Multivariate Time Series Forecasting with Light Sampling-oriented MLP\nStructures (2022) https://doi.org/10.48550/arXiv.2207.01186 . arXiv:2207.01186\n[cs]\n[51] Wu, H., Hu, T., Liu, Y., Zhou, H., Wang, J., Long, M.: Timesnet: Temporal 2d-\nVariation Modeling for General Time Series Analysis (2023) https://doi.org/10.\n34\n\n48550/arXiv.2210.02186 . arXiv:2210.02186 [cs]\n[52] Wu, H., Xu, J., Wang, J., Long, M.: Autoformer: Decomposition Transformers\nwith Auto-Correlation for Long-Term Series Forecasting (2022) https://doi.org/\n10.48550/arXiv.2106.13008 . arXiv:2106.13008 [cs]\n[53] Cho, K., Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk,\nH., Bengio, Y.: Learning Phrase Representations using RNN Encoder-Decoder for\nStatistical Machine Translation (2014) https://doi.org/10.48550/arXiv.1406.1078\n. arXiv:1406.1078 [cs, stat]\n[54] Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation\n9(8), 1735–1780 (1997) https://doi.org/10.1162/neco.1997.9.8.1735 . publisher:\nMIT Press\n[55] Fisher, A., Rudin, C., Dominici, F.: All models are wrong, but many are useful:\nLearning a variable’s importance by studying an entire class of prediction models\nsimultaneously. Journal of Machine Learning Research 20(177), 1–81 (2019)\n[56] Bahdanau, D., Cho, K., Bengio, Y.: Neural Machine Translation by Jointly Learn-\ning to Align and Translate (2016) https://doi.org/10.48550/arXiv.1409.0473 .\narXiv:1409.0473 [cs, stat]\n[57] Rhyou, H.-I., Park, T.-H., Cho, Y.-R., Park, K., Park, J.-S., Kim, M.-H., Kim,\nY.-D.: Clinical factors associated with the development of atrial fibrillation in\nthe year following STEMI treated by primary PCI. Journal of cardiology 71(2),\n125–128 (2018). publisher: Elsevier\n[58] Yunyun, W., Tong, L., Yingwu, L., Bojiang, L., Yu, W., Xiaomin, H., Xin, L.,\nWenjin, P., Li, J.: Analysis of risk factors of ST-segment elevation myocardial\ninfarction in young patients. BMC Cardiovascular Disorders 14(1), 179 (2014)\nhttps://doi.org/10.1186/1471-2261-14-179\n[59] Kanani, P., Padole, M.: Ecg Heartbeat Arrhythmia Classification Using Time-\nSeries Augmented Signals and Deep Learning Approach. Procedia Computer\nScience 171, 524–531 (2020) https://doi.org/10.1016/j.procs.2020.04.056\n[60] Birbaumer, N., Ghanayim, N., Hinterberger, T., Iversen, I., Kotchoubey, B.,\nK¨ubler, A., Perelmouter, J., Taub, E., Flor, H.: A spelling device for the paralysed.\nNature 398(6725), 297–298 (1999) https://doi.org/10.1038/18581 . publisher:\nNature Publishing Group\n[61] Little, C.D., Kotecha, T., Candilio, L., Jabbour, R.J., Collins, G.B., Ahmed,\nA., Connolly, M., Kanyal, R., Demir, O.M., Lawson, L.O.: Covid-19 pandemic\nand STEMI: pathway activation and outcomes from the pan-London heart\nattack group. Open Heart 7(2), 001432 (2020). publisher: Archives of Disease in\nchildhood\n35\n\n[62] Topol, E.J.: Covid-19 can affect the heart. Science 370(6515), 408–409 (2020)\nhttps://doi.org/10.1126/science.abe2813\n[63] Braunwald, E.: Air pollution: challenges and opportunities for cardiology. Euro-\npean Heart Journal 44(19), 1679–1681 (2023) https://doi.org/10.1093/eurheartj/\nehac791\n36\n",
  "metadata": {
    "source_path": "papers/arxiv/TabulaTime_A_Novel_Multimodal_Deep_Learning_Framework_for_Advancing\n__Acute_Coronary_Syndrome_Prediction_through_Environmental_and_Clinical_Data\n__Integration_711c41c87a35633c.pdf",
    "content_hash": "711c41c87a35633c39f1e14c892f8d82c8c2b2796c5fe2c61862dcf76c3d4683",
    "arxiv_id": null,
    "title": "TabulaTime_A_Novel_Multimodal_Deep_Learning_Framework_for_Advancing\n__Acute_Coronary_Syndrome_Prediction_through_Environmental_and_Clinical_Data\n__Integration_711c41c87a35633c",
    "author": "",
    "creation_date": "D:20250225024022Z",
    "published": "2025-02-25T02:40:22",
    "pages": 36,
    "size": 2168386,
    "file_mtime": 1740470190.8194983
  }
}