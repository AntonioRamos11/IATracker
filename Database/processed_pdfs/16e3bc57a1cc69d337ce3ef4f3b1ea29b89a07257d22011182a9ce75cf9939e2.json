{
  "text": "IGDA: Interactive Graph Discovery Agent\nIGDA: INTERACTIVE GRAPH DISCOVERY THROUGH LARGE\nLANGUAGE MODEL AGENTS\nAlex Havrilla1,2,∗, David Alvarez-Melis1, Nicolo Fusi1\nMicrosoft Research1, Georgia Tech2\nABSTRACT\nLarge language models (LLMs) have emerged as a powerful method for discovery. Instead\nof utilizing numerical data, LLMs utilize associated variable semantic metadata to predict\nvariable relationships. Simultaneously, LLMs demonstrate impressive abilities to act as\nblack-box optimizers when given an objective f and sequence of trials. We study LLMs at\nthe intersection of these two capabilities by applying LLMs to the task of interactive graph\ndiscovery: given a ground truth graph G∗capturing variable relationships and a budget of I\nedge experiments over R rounds, minimize the distance between the predicted graph ˆGR\nand G∗at the end of the R-th round. To solve this task we propose IGDA, a LLM-based\npipeline incorporating two key components: 1) an LLM uncertainty-driven method for\nedge experiment selection 2) a local graph update strategy utilizing binary feedback from\nexperiments to improve predictions for unselected neighboring edges. Experiments on eight\ndifferent real-world graphs show our approach often outperforms all baselines including a\nstate-of-the-art numerical method for interactive graph discovery. Further, we conduct a\nrigorous series of ablations dissecting the impact of each pipeline component. Finally, to\nassess the impact of memorization, we apply our interactive graph discovery strategy to a\ncomplex, new (as of July 2024) causal graph on protein transcription factors, finding strong\nperformance in a setting where memorization is impossible. Overall, our results show\nIGDA to be a powerful method for graph discovery complementary to existing numerically\ndriven approaches.\n1\nINTRODUCTION\nGiven a set of variables X1, ..., Xn, the graph discovery task involves finding a graph G∗on the nodes\nX1, ..., Xn whose edges capture causal relationships between the parent (source) and child (target). Often,\nobservational data can be collected for the variables X1, ..., Xn. This data can then be used to predict an initial\ngraph G0 using statistical causal discovery techniques (Spirtes & Zhang, 2016). Recently, large language\nmodels (LLMs) have emerged as a competitive alternative method for predicting causal graphs (Kıcıman\net al., 2024; Abdulaal et al., 2024; Chen et al., 2024). Unlike pre-existing statistical methods, LLMs require\nno observational data (Kıcıman et al., 2024), instead relying purely on semantic metadata such as variable\nnames and descriptions. Another related line a work (Yang et al., 2024) investigates the abilities of LLMs to\nact as in-context black-box optimizers. Given an objective function f and an evaluation budget B, the LLM\nis tasked with finding a maximizer x∗of f by sequentially proposing queries {xi}B\ni=1 and observing their\nassociated values {f(xi)}B\ni=1. Taken together, these directions suggest a powerful new application of LLMs:\ninteractive graph discovery.\n∗Work done during internship\n1\narXiv:2502.17189v1  [cs.LG]  24 Feb 2025\n\nIGDA: Interactive Graph Discovery Agent\nGiven an initial predicted graph ˆG0 and a series of experiment rounds 1, ..., R, the interactive graph discovery\nproblem involves minimizing some distance d( ˆGk, G∗) between the predicted graph ˆGk at round k and the\ntrue graph G∗(unknown to the learner) through a sequence of targeted experiments on edges e = (X, Y )\ntesting the effect of the parent variable X on the child variable Y . The edge experiment operation is kept\npurposefully abstract, requiring only that binary feedback be given indicating the presence or absence of\nan edge. In practice this operation can be implemented via any number of experimental procedures (e.g.\nvia hard interventions in the formal causal sense (Pearl, 2009) or empirical methods such as randomized\ncontrolled trials (Sibbald & Roland, 1998)). The IGD problem setup captures the process researchers go\nthrough everyday when designing and prioritizing experiments, guided by their prior experience, to study\nnumerous potential relationships between any number of variables.\nThe interactive graph discovery problem requires the agent to solve two key sub-tasks:\n1. Experiment selection: Selecting which edges (Xi, Xj) to target for experimentation in the next round.\n2. Graph updates: Updating the predicted graph from ˆGk−1 to ˆGk given binary feedback based on the\noutcome of the previous experiments.\nWe propose to solve this task with the Interactive Graph Discovery Agent (IGDA): a novel LLM agent\nuncertainty-driven approach as an alternative to existing statistical methods (Olko et al., 2024; Scherrer et al.,\n2022). While statistical models can work well in some settings, they crucially rely on the abundance of\ndomain specific observational and interventional numerical data. For many problems, such data might be\nhard or impossible acquire. LLMs, however, potentially contain relevant latent knowledge derived from vast\namounts of variable semantic metadata contained in their pre-training or internet corpora. Further, we find\nthat, via a combination of broad background knowledge and reasoning abilities, advanced LLMs (Grattafiori\net al., 2024) are capable of updating their predictions and confidences when presented with experimental\nfeedback revealing unexpected relationships between a subset of edges. This makes LLM based approaches a\npowerful alternative to statistical methods when numerical data is not available.\nIn particular, IGDA predicts and maintains uncertainty estimates for each unknown edge e ∈ˆGk. Edges\nare then selected for experimentation by prioritizing those with the highest uncertainty. When feedback is\nreceived on the selected edges, pairwise-local updates on both edge predictions and uncertainty estimates are\nperformed for each edge in ˆG sharing a parent or child variable with an experimented edge. This process\ncontinues for R rounds with I edges selected for experimentation each round. We benchmark IGDA on eight\nreal world graphs, finding uncertainty driven selection with local updates outperforms baselines. In summary,\nwe make the following contributions:\n• The interactive graph discovery problem as a novel setting for evaluating LLM capabilities.\n• LLM-based uncertainty-guided edge experiment selection as a policy for prioritizing edge experimentation.\n• A local update strategy for robustly updating the predicted graph Gk with binary experiment feedback.\n• Ablations rigorously evaluating the contribution of each pipeline component and other discovery strategies.\n2\nBACKGROUND AND RELATED WORK\nCausal Discovery and LLMs.\nThe causal discovery task involves learning causal relationships from\nobserved empirical data (Peters et al., 2017; Spirtes & Zhang, 2016). Many proposed algorithms exist (Spirtes\net al., 1993; Yu et al., 2019; Nauta et al., 2019; Zheng et al., 2018; Chickering, 2002) attempting to solve\nthe causal discovery problem. However, these methods are known to struggle on real world graphs where\nobservations are noisy or common structural assumptions are violated (Chevalley et al., 2023; Tu et al., 2019).\nRecently, LLMs have emerged as an alternative approach to causal discovery (Kıcıman et al., 2024; Abdulaal\net al., 2024; Vashishtha et al., 2023; Li et al., 2024; Lampinen et al., 2023). Kıcıman et al. (2024) first\n2\n\nIGDA: Interactive Graph Discovery Agent\ninvestigated the capability of LLMs to act as zero-shot causal discovery agents using only semantic information\nand pairwise prompting on each variable pair. Follow-up work (Abdulaal et al., 2024) further improves LLM\npredictions with observational data by selecting for predictions which maximize data likelihood. Vashishtha\net al. (2023) utilize triplet prompting to prevent cycles when the causal graph is acyclic. They show only a\ntopological ordering on variables is required for many common causal reasoning tasks (Chu et al., 2023).\nOther works (Zhou et al., 2024; Chen et al., 2024) benchmark LLMs across a range of causality related tasks\nincluding causal discovery and causal inference confirming that LLMs struggle with integrating numerical\ndata.\nAnother line of work more related to our proposed interactive causal discovery problem studies how to\nincorporate background knowledge into causal discovery algorithms (Meek, 2013). Define a set of background\nknowledge as the tuple K = (F, R), where F specifies a set of “forbidden” graph edges and R specifies a set\nof “required” graph edges. Meek (2013) presents an algorithm for constructing a causal graph consistent with\nK by leveraging an assumed structural directed acyclic graph (DAG) property. Building on Meek (2013),\nChickering (2002) proposes a greedy search algorithm that performs well in practice.\nMost related are statistical methods from the causal discovery literature which aim to efficiently choose a\nsequence of interventions to discover causal structure (Scherrer et al., 2022; Olko et al., 2024). In particular,\nGradient based Interventional Targeting (GIT) (Olko et al., 2024) utilizes existing neural causal discovery\nmethods (Lippe et al., 2022) to learn a distribution over possible graph structures and variable assignments.\nFor each round of intervention, GIT prioritizes variables whose simulated interventional distribution have\nlarge gradient with respect to the structural training loss.\nIn contrast to these works, our proposed algorithm utilizes LLMs to reason about the semantic/physical, as\nopposed to formal/structural, relationships between variables and edges in causal graphs. For this reason\nwe are not required to make any structural assumptions on an underlying DAG, as is common in the causal\ndiscovery literature. This is desirable as in practice many real-world causal graphs are cyclic and poorly\nstructured (Zhu et al., 2024; Huang et al., 2021). Additionally our method does not rely on observational or\ninterventional data for real world graphs which may be expensive to acquire but crucial for good performance\nwith statistical methods.\nLLMs as Optimizers.\nAnother growing line of work utilizes LLMs as black-box optimizers (Yang et al.,\n2024; Roohani et al., 2024). Yang et al. (2024) introduce the notion of an LLM as a generic optimizer and\nuse it to optimize performance objectives stemming from a range of tasks including linear regression and\nmathematical word problems (Cobbe et al., 2021). Other works (Madaan et al., 2023; Havrilla et al., 2024)\nexamine the self-refinement capabilities of LLMs where the LLM must reason and self-improve on earlier\nresponses. A growing number of papers apply LLMs to optimal experiment design and discovery (Roohani\net al., 2024; AI4Science & Quantum, 2023; Gao et al., 2024; Majumder et al., 2024; Jansen et al., 2024).\nRoohani et al. (2024) apply LLMs to gene discovery tasks which aim to find highly-influential parent genes\naffecting the regulation of a downstream target gene. Majumder et al. (2024); Jansen et al. (2024) both present\nbenchmarks evaluating the ability of LLMs to perform real-world and synthesized discovery tasks.\n3\nMETHOD\nSetup.\nAs input we are given a set of variables X1, ..., Xn with associated metadata including variable\nnames and variable descriptions. We use the notation Y →X to indicate when variable Y has a direct\neffect on variable X and the set of parents of a variable X as Pa(X) = {Xi : Xi →X}. We can then\nconsider the directed ground truth graph G∗= {(Xi, Xj) : Xi ∈Pa(Xj)} with unlabeled and unweighted\nedges. The only assumed graph structure is simplicity i.e. no self-edges or multi-edges. No additional\nstructure on the graph (such as acyclicity) is assumed. We can frame the prediction of G∗as an edge-wise\nbinary classification problem over the complete graph Kn, where an edge (Xi, Xj) has the label lij = 1\n3\n\nIGDA: Interactive Graph Discovery Agent\nFigure 1: Diagram of the interactive graph discovery process through LLMs. The process begins by predicting\nedges and confidences for each edge. Interactive discovery then proceeds by selecting the most uncertain\nedges for experimentation. The LLM then updates its predictions and confidences for edges adjacent to the\nselected edge. Note: only edges predicted as present are shown.\nif Xi →Xj and lij = 0 otherwise. G∗can then be written as a collection of ground truth labelings\nG∗= {(Xi, Xj, lij) : 1 ≤i ̸= j ≤n}.\nThe interactive graph discovery task then aims to learn G∗by interacting with the discovery environment via\nexperiments on each edge (Xi, Xj). We define an experiment on an edge (Xi, Xj) as an operation revealing\nthe ground truth label li,j. This experiment operation is purposefully kept abstract for generality and could\ncorrespond to any number of real-world experimental experimental strategies including formal do operations\n(Pearl, 2009) or empirical randomized control trials (Sibbald & Roland, 1998). Interactive graph discovery\nthen proceeds in two phases:\nPhase 1 (Zero-shot prediction): Produce an initial graph prediction ˆG0 using available variables\nX1, ..., Xn plus semantic metadata.\nPhase 2 (Interactive Discovery): Over a series of R rounds, propose I edge experiments on\n(Xi, Xj) each round and receive binary feedback on lij. Use this to produce an updated prediction\nˆGr−1 →ˆGr\nWe evaluate the accuracy of a prediction ˆG using the F1 objective, i.e.\nF1(G∗, ˆG) = 2 · Precision ˆ\nG · Recall ˆ\nG\nPrecision ˆ\nG + Recall ˆ\nG\nwhere Precision ˆ\nG and Recall ˆ\nG are computed with the label predictions (Xi, Xj, ˆlij) ∈ˆG and lij as\nground truth. The goal of the interactive discovery process is then to maximize F1(G∗, ˆGR).\nMethod.\nOur proposed method IGDA begins by generating a zero-shot graph prediction ˆG0. A prediction\nfor each variable pair (Xi, Xj), 1 ≤i ̸= j ≤n, is generated by prompting an LLM to reason about Xi →Xj\nin a manner similar to the pairwise-prompting strategy utilized in Kıcıman et al. (2024). In addition, we\nprompt the LLM to reason about its confidence in the prediction and output a confidence score from 1 - 100.\nSection A shows the exact prompt used. To obtain a reliable confidence estimate we sample the LLM K = 16\n4\n\nIGDA: Interactive Graph Discovery Agent\nAlgorithm 1 Interactive Graph Discovery Through LLMs\nprocedure LLMGRAPHDISCOVERY( ˆG, R, I)\n▷ˆG: initial graph (confidences), R: rounds, I:\nexperiments/round\nfor r ←1 to R do\n▷Step 1: select edges for experimentation\nsorted edges ←sort( ˆG, key = “conf”)\nexperiments ←sorted edges[1 : I]\nbinary feedback ←do experiments(experiments)\n▷Step 2: update ˆG using feedback\nfor i ←1 to I do\nedge, edge gt ←experiments[i], binary feedback[i]\nadjacent edges ←get adjacent edges(edge)\nfor a ←1 to length(adjacent edges) do\nˆG[a][“update confs”] ←LLMLocalUpdate(edge, edge gt, a)\nend for\nend for\nfor a in ˆG do\nˆG[a][“conf”] ←mean( ˆG[a][“update confs”])\nˆG[a][“pred”] ←1 ˆ\nG[a][“conf”]>0\nend for\nend for\nreturn ˆG\nend procedure\ntimes. We denote the initial confidence for (Xi, Xj) as c0\nij and set it to be the (signed) average over K = 16\noutput confidences. The initial edge label l0\nij is then taken as the boolean l0\nij = 1c0\nij≥0. This gives us the\ninitial prediction ˆG0.\nNext, in each experimentation round r ≤R, we sort the confidence scores {cr\nij : 1 ≤i, j ≤n} by absolute\nvalue and experiment on the I edges with the lowest absolute confidence (and highest uncertainty). This\nreveals the ground truth labels lij for for each experimented edge (Xi, Xj). Using this feedback, we update the\npredicted edge labels for experimented edges to lr+1\nij\n= lij and the confidences to cr+1\nij\n= 100. Additionally,\nwe prompt the LLM, conditioned on the ground truth label lij, to update its prediction and confidence for each\nedge (Xi, Xk) or (Xl, Xj), 1 ≤k, l ≤n which shares a node with (Xi, Xj) and has absolute confidence\nless than 100. We call each update to an edge (Xl, Xk) a local update. It may be that an edge (Xl, Xk) is\nadjacent to multiple experimented edges (Xi1, Xj1), (Xi2, Xj2) in a single round and thus receives multiple\nlocal updates. To manage these cases we set the next confidence cr+1\nlk\nto the (signed) average of all individual\nlocal updates to cr\nlk. Then we set lr+1\nlk\n= 1clk≥0 as before. This continues until the final round R is reached.\nWe call the complete discovery pipeline the Interactive Graph Discovery Agent (IGDA). A diagram of the\nfull pipeline is shown in Figure 1. We report all prompts in appendix A.\n4\nRESULTS\nWe evaluate our approach on seven real-world graphs. The graphs range in size from 8 to 30 nodes (variables)\nand vary widely in structure (some are acyclic while others are cyclic). Details for each graph can be found\nin Appendix D. To produce initial zero-shot graph predictions ˆG0 for all graphs we utilize pairwise causal\nprompting as in Kıcıman et al. (2024) with Meta-Llama-3-70B-Instruct (Grattafiori et al., 2024) as\n5\n\nIGDA: Interactive Graph Discovery Agent\nFigure 2: Results on real world graphs showing F1 score of the predicted graph against percentage of edges\nin the graph selected. IGDA almost always outperforms both the random baseline and static selection via\nuncertainty. Note: static confidence selection without local updates is deterministic and thus has no confidence\nintervals. Additionally, GIT is not reported on the Arctic graph because the grpah is cyclic.\nthe base LLM. We chose Meta-Llama-3-70B-Instruct as at the time of our experiments it was the\nbest open-source model with advanced reasoning and instruction following capabilities For the interactive\ndiscovery phase we then initialize all methods using ˆG0. We compare our method against several baselines:\nRandom selection: Starting from ˆG0 we randomly select edges for experimentation. After receiving\nbinary feedback we update incorrect predictions on experiment edges for the next round. We do not\nallow edges to be selected for experimentation twice.\nStatic confidence selection: We select edges for experimentation based on the initial confidence\nscores cij. No updates are performed beyond fixing incorrect predictions in the experimentation set.\nGradient-based Intervention Targeting (GIT): We adapt the statistical GIT method (Olko et al.,\n2024) by selecting the node at each round which has a) not already been selected and b) has the\nlargest loss gradient under a neural causal model (Lippe et al., 2022) trained with all available\nobservational and interventional training data. We initially train the model with 5000 observational\ndatapoints sampled from the ground-truth graph. 100 additional interventional datapoints on the\nexperiment node are sampled from the ground-truth graph and added to the training set after each\nround of experimentation.\nMeta-Llama-3-70B-Instruct is used as the base LLM when applicable. To assess performance, we\nplot the mean F1 score, averaged over five independent runs, against the percentage of edges selected in each\ngraph. Results are shown in Figure 2.\nUncertainty driven experiment selection with local updates performs best.\nUncertainty driven exper-\niment selection with the LLM utilizing experimental feedback for local updates performs best on nearly\nall graphs. Further, it outperforms the random selection baselines at nearly every round on every graph, at\ntimes by up to 0.5 absolute F1 score. The only exception to this is the Arctic sea ice graph where local\nupdates initially perform poorly. We attribute this to the highly cyclic and thus harder-to-predict graph\nstructure. Additionally, the method significantly outperforms the statistical GIT baseline on both Az and\nCovid graphs and remains competitive on the rest. Figure 3 plots the average rank of all methods over all\n6\n\nIGDA: Interactive Graph Discovery Agent\nFigure 3: Average rank of each method when numbered from 0 to 2 across each timestep on each graph. The\nfull LLM driven update agent consistently achieves rank 0 across all timesteps. Note: lower is better.\ntimesteps, confirming IGDA’s strong performance. Notably, even on graphs where the LLM proposes a poor\nzero-shot initial prediction, the LLM is able to recover quickly, converging to the correct structure with local\nupdates. This suggests the LLM is able to effectively utilize experiment feedback even when lacking detailed\ndomain knowledge.\nLocal updates can outperform random selection even with few experiments.\nAllowing the LLM to make\nlocal edge updates using experiment feedback quickly improves the predicted graph even when relatively few\nedges are selected. This behavior is particularly desirable, as in practice it may be expensive to experiment on\neven a small fraction of all edges. On some graphs, where the initial LLM confidence estimates are good,\nthe static confidence selection baseline without local updates is also able to quickly outperform random\nselection. Yet, even when the initial confidence estimates are subpar, local updates compensate and allow\nfor the prediction to quickly improve with just a few edge experiments. This again demonstrates the broad\neffectiveness of local updates even when initial predictions are poor.\nStatic uncertainty driven selection performs better than random selection.\nDespite not fully utilizing\nexperimental feedback, static uncertainty driven selection still outperforms the random selection baseline\non five out of seven graphs. This method performs particularly well on AZ and Covid graphs where the\ninitial LLM predictions are already reasonably good. On these graphs static uncertainty selection quickly\noutperforms randomly selection and is competitive even with local updates. This shows that, on a subset\nof the graphs, the LLM’s confidence in its predictions are well-calibrated, allowing our selection policy to\nprevent wasting experiments on edges which are most likely already correct. However, we also see the LLM’s\nconfidence estimates can be poorly calibrated on graphs for which the initial predictions are inaccurate. See\nfor example the Asphyxia and Neuropathic pain graphs, which start with initial F1 score less than 0.2. On\nthese graphs the static confidence selection component struggles to outperform the random baseline.\nGIT performance heavily depends on availability of both observational and interventional data\nWith\nample data (5000 observational samples and 100 interventional samples per node) the statistical GIT methods\nperforms well on most graphs where it is applicable (i.e. the graph is acyclic). However, we find this good\nperformance heavily depends on the availability of such data, with decreases in both observational and\ninterventional sample sizes significantly impacting results. In Figure 4 we plot the performance of GIT on the\nAsphyxia graph with varying amounts of data demonstrating this effect. Results on more graphs are presented\n7\n\nIGDA: Interactive Graph Discovery Agent\nFigure 4: GIT with varying amounts of observational and interventional data. Decreasing either observational\nor interventional sample sizes can decrease performance by over 0.2 F1 score.\nFigure 5: % Improvement from experiments vs. LLM prediction updates across timesteps. Improvement\ndirectly from LLM updates peaks early but then falls off. Improvement from experiments stays constant or\nimproves with more experiments as confidence scores become better calibrated.\nin the appendix. In contrast, IGDA does not depend at all on the availability of numerical observational or\ninterventional data. Instead, IGDA relies on the complementary availability of semantic metadata of graph\nvariables within either its pretraining dataset or on the internet.\nIn an effort to better understand the factors behind IGDA’s success we conduct a number of ablations in the\nfollowing section.\n4.1\nABLATIONS\nImpact of experiment improvements versus update improvements\nAs a starting point we define the\nnet graph improvement in a round r as the difference between the number of edges correctly classified in\nin ˆGr versus in ˆGr−1. If an edge (Xi, Xj) is correctly classified in ˆGr but not in ˆGr−1 we say it has been\n8\n\nIGDA: Interactive Graph Discovery Agent\nimproved. Recall there are two potential mechanisms of improvement for (Xi, Xj): 1) (Xi, Xj) was selected\nfor experimentation in the previous round r −1 and feedback on the experiment was received at the start\nof round r 2) sThe prediction for (Xi, Xj) was updated by the LLM after receiving experiment feedback\nfor an adjacent edge (Xk, Xl). We call the former improvements experiment improvements and the latter\nupdate improvements. In a given round r we are interested in how much of the net improvement for a graph\nis due to experiment improvements versus update improvements. To examine this, we plot both quantities\nin Figure 5 for the discovery processes discussed in the previous section. In addition, we plot the net graph\nimprovement and total number of edges changed from each round.\nIn all seven graphs we see both the total number of changed edges and the net improved edges peak at the\nfirst round and then decay towards zero. Notably, on some graphs there is a significant gap between net\nimprovement and total change, indicating many edges changed during dynamic updates are misclassified after\npreviously being correctly classified. This decline in total and net change is reflected in the number of update\nimprovements which peak early and sharply decline to zero. This observation supports our intuition above\nthat allowing the LLM to dynamically update edge predictions without direct experimental feedback on the\nedge can dramatically improve performance at small percentages of experiments. In contrast, experiment\nimprovement accounts for a smaller percentage (less than 40%) of edge improvements early on. However,\nin most graphs the number of experiment improvements stays nearly constant until at least 50% of edges\nare already selected. As a result, improvement from experiments grows to account for 90% of all edge\nimprovements for rounds performed during this period. This demonstrates improvements from experiment\nand updates complement each other, with update improvement driving net improvement early and\nexperiment improvement driving net improvement later on.\nOur analysis here also confirms the effectiveness of allowing the LLM agent to update both the prediction\nand confidence for an edge. Even when only considering improvements from experiments when doing local\nupdates, we see a major improvement over the static confidence baseline. This suggests the updates made\nto edge confidence scores are equally important in achieving good performance, allowing for sustained\nexperiment improvement throughout the discovery process.\nImpact of Confidence Based Selection and Local Prompting\nWe now ablate the impact of two key\ncomponents of our discovery strategy: 1) confidence based edge selection and 2) local update prompting.\nTo ablate 1) we directly prompt the LLM to generate a list of edges to experiment on instead of selecting\nvia confidence. This requires us to put the entire current predicted graph ˆGr in-context. When dynamically\nupdating ˆGr after receiving experimental feedback we remove all confidence estimates but retain the local\nprompting strategy. To ablate 2) we retain the same confidence edge selection proposed but replace local\nupdate prompts after with a single global update prompt containing the current prediction ˆGr and all recently\nreceived experiment feedback. We report the results of running the interactive discovery process with these\nmethods in Figure 6.\nWe find both ablations struggle to perform better than the random baseline. Local updates without confidence\nselection perform well early on but fall off quickly. F1 score on the Covid graph even regresses after the initial\nimprovements, likely due to incorrect local updates and a poor experiment selection policy. This suggests\nin addition to providing a strong experiment selection procedure, maintaining running confidence estimates\nfor each edge reduces the variance of local updates from experiment feedback. Turning to the ablation for\nlocal prompting, we again find performance not much better than the random baseline. Surprisingly, even\non Covid where the static confidence selection performs well, confidence based selection + global updates\nstill struggles. This indicates the base LLM is not able to correctly update the predicted graph when giving\neverything in context at once. This further motivate the practical importance of the local prompting procedure,\nwhich greatly simplifies the context the LLM must consider in each model call. Additionally, we note that for\nlarge enough graphs, putting everything in context is simply not feasible. By contrast, local prompting is\neasily scalable to larger graphs, albeit at a quadratic cost.\n9\n\nIGDA: Interactive Graph Discovery Agent\nFigure 6: Ablating confidence based edge selection and local update prompting.\nFigure 7: Performance of LLM driven interactive discovery on different sized models. Small LLMs (8B\nparams) underperform the random baseline.\nImpact of the LLM Model Size\nThe above experiments exclusively use a single base LLM (\nMeta-Llama-3-70B-Instruct) to perform both the initial round of zero-shot edge predictions and\ndynamically update edge predictions/confidences using experiment feedback. Now, we examine the impact\nof changing both the base model size and type. In Figure 7 we initialize the discovery process with zero-\nshot predictions made by\nMeta-Llama-3-70B-Instruct and run local updates using the smaller\nMeta-Llama-3-8B-Instruct as well as two models from the Qwen2 series.\nWe find the original\nMeta-Llama-3-70B-Instruct consistently performs best on all graphs at every\ntime step. The other 70B model,\nQwen2-72B-Instruct, performs similarly but consistently worse.\nIn contrast, on the Asia and Covid graphs, both 8B models perform worse than even the random baseline.\nSurprisingly\nMeta-Llama-3-8B-Instruct performs reasonably well on the Sangiovese graph, per-\nforming similarly even to the 9x larger Qwen2 70B model. Overall however these results indicate performance\non the interactive graph discovery task can be substantially improved with model scale.\nWe next investigate the performance of different models on the initial zero-shot edge prediction task. Using\nthe pairwise confidence estimation prompt in Section A we prompt each of four models to produce a zero-shot\nprediction ˆG0 with edge confidence values. Using the predicted confidence estimates we run greedy static\nconfidence selection procedure as in 4. Ranks for each selection procedure averaged over all graphs are\nplotted in Figure 11. F1 scores in each graph are reported in Figure 10 in the Appendix.\nImpact of Memorization\nThe success of LLMs in discovery stems from their immense background\nknowledge acquired during pre-training. This background knowledge informs the model during edge\nprediction and confidence calibration, allowing for strong performance even zero-shot. However, if benchmark\ngraphs are contained verbatim in pre-training data, memorization becomes a significant confounding factor. To\ninvestigate to what extent memorization impacts performance we find a recently published graph (published\nin July 2024) from Zhu et al. (2024) modeling the gene regulatory network underlying 29 protein transcription\nfactors. Because Meta-Llama-3-70B-Instruct finished training in 2023 this graph is guaranteed to\n10\n\nIGDA: Interactive Graph Discovery Agent\nFigure 8: Performance curves of uncertainty driven selection + local prompting vs. baselines on the Brain\ngraph (Zhu et al., 2024) recently published in July 2024. Both LLM-driven methods perform well despite the\ngraph not possibly being in the LLM’s training data. Note: GIT is not reported because the graph is cyclic.\nbe memorization free. Figure 8 plots the performance of uncertainty driven edge selection + local updates\ncompared to the static selection and random baseline.\nFigure 8 shows our confidence driven selection + local update approach performs very well even on graphs\nwith minimal memorization contamination. As previously observed, local prediction updates allow for fast\nimprovement over the random baseline even with a small number of experiments. Surprisingly, the static\nconfidence selection approach also works well here. This indicates zero-shot edge confidence scores can be\nwell calibrated on graphs with no contamination from memorization. We additionally note this graph has a\ncomplex structure with many cycles of varying lengths. This shows our method performs well even on graphs\nwhich strongly violate often assumed DAG conditions.\n5\nCONCLUSIONS AND FUTURE WORK\nIn this work we proposed IGDA as a novel application of LLMs to interactive graph discovery. Our\nexperiments confirm the proposed IGDA method significantly outperforms baselines. Our ablations confirm\nboth uncertainty driven edge selection and local updates using experiment feedback as importantly contributing\nto the method’s good performance. Further, this method is complementary to existing statisical methods for\nexperiment design or causal discovery (e.g. GIT (Olko et al., 2024)). Statistical methods utilize available\nobservational/interventional numerical data to make predictions and confidence estimates whereas IGDA\nutilizes available variable semantic metadata to make predictions and confidence estimates. Designing a\nmethod leveraging both numerical and semantic variable data is promising future work.\nREFERENCES\nAbdulaal, A., adamos hadjivasiliou, Montana-Brown, N., He, T., Ijishakin, A., Drobnjak, I., Castro, D. C.,\nand Alexander, D. C. Causal modelling agents: Causal graph discovery through synergising metadata- and\ndata-driven reasoning. In The Twelfth International Conference on Learning Representations, 2024. URL\nhttps://openreview.net/forum?id=pAoqRlTBtY.\n11\n\nIGDA: Interactive Graph Discovery Agent\nAI4Science, M. R. and Quantum, M. A. The impact of large language models on scientific discovery: a\npreliminary study using gpt-4, 2023. URL https://arxiv.org/abs/2311.07361.\nChen, S., Xu, M., Wang, K., Zeng, X., Zhao, R., Zhao, S., and Lu, C. Clear: Can language models really\nunderstand causal graphs?, 2024. URL https://arxiv.org/abs/2406.16605.\nChevalley, M., Roohani, Y., Mehrjou, A., Leskovec, J., and Schwab, P. Causalbench: A large-scale benchmark\nfor network inference from single-cell perturbation data, 2023. URL https://arxiv.org/abs/\n2210.17283.\nChickering, D. M. Optimal structure identification with greedy search. J. Mach. Learn. Res., 3:507–554,\n2002. URL https://api.semanticscholar.org/CorpusID:1191614.\nChu, Z., Huang, J., Li, R., Chu, W., and Li, S. Causal effect estimation: Recent advances, challenges, and\nopportunities, 2023. URL https://arxiv.org/abs/2302.00848.\nCobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J.,\nNakano, R., Hesse, C., and Schulman, J. Training verifiers to solve math word problems, 2021. URL\nhttps://arxiv.org/abs/2110.14168.\nGao, S., Fang, A., Huang, Y., Giunchiglia, V., Noori, A., Schwarz, J. R., Ektefaie, Y., Kondic, J., and Zitnik,\nM. Empowering biomedical discovery with ai agents, 2024. URL https://arxiv.org/abs/2404.\n02831.\nGrattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur, A., Schelten,\nA., Vaughan, A., Yang, A., Fan, A., Goyal, A., Hartshorn, A., Yang, A., Mitra, A., Sravankumar, A.,\nKorenev, A., Hinsvark, A., Rao, A., Zhang, A., Rodriguez, A., Gregerson, A., Spataru, A., Roziere, B.,\nBiron, B., Tang, B., Chern, B., Caucheteux, C., Nayak, C., Bi, C., Marra, C., McConnell, C., Keller, C.,\nTouret, C., Wu, C., Wong, C., Ferrer, C. C., Nikolaidis, C., Allonsius, D., Song, D., Pintz, D., Livshits, D.,\nWyatt, D., Esiobu, D., Choudhary, D., Mahajan, D., Garcia-Olano, D., Perino, D., Hupkes, D., Lakomkin,\nE., AlBadawy, E., Lobanova, E., Dinan, E., Smith, E. M., Radenovic, F., Guzm´an, F., Zhang, F., Synnaeve,\nG., Lee, G., Anderson, G. L., Thattai, G., Nail, G., Mialon, G., Pang, G., Cucurell, G., Nguyen, H.,\nKorevaar, H., Xu, H., Touvron, H., Zarov, I., Ibarra, I. A., Kloumann, I., Misra, I., Evtimov, I., Zhang, J.,\nCopet, J., Lee, J., Geffert, J., Vranes, J., Park, J., Mahadeokar, J., Shah, J., van der Linde, J., Billock, J.,\nHong, J., Lee, J., Fu, J., Chi, J., Huang, J., Liu, J., Wang, J., Yu, J., Bitton, J., Spisak, J., Park, J., Rocca,\nJ., Johnstun, J., Saxe, J., Jia, J., Alwala, K. V., Prasad, K., Upasani, K., Plawiak, K., Li, K., Heafield, K.,\nStone, K., El-Arini, K., Iyer, K., Malik, K., Chiu, K., Bhalla, K., Lakhotia, K., Rantala-Yeary, L., van der\nMaaten, L., Chen, L., Tan, L., Jenkins, L., Martin, L., Madaan, L., Malo, L., Blecher, L., Landzaat, L.,\nde Oliveira, L., Muzzi, M., Pasupuleti, M., Singh, M., Paluri, M., Kardas, M., Tsimpoukelli, M., Oldham,\nM., Rita, M., Pavlova, M., Kambadur, M., Lewis, M., Si, M., Singh, M. K., Hassan, M., Goyal, N., Torabi,\nN., Bashlykov, N., Bogoychev, N., Chatterji, N., Zhang, N., Duchenne, O., C¸ elebi, O., Alrassy, P., Zhang,\nP., Li, P., Vasic, P., Weng, P., Bhargava, P., Dubal, P., Krishnan, P., Koura, P. S., Xu, P., He, Q., Dong,\nQ., Srinivasan, R., Ganapathy, R., Calderer, R., Cabral, R. S., Stojnic, R., Raileanu, R., Maheswari, R.,\nGirdhar, R., Patel, R., Sauvestre, R., Polidoro, R., Sumbaly, R., Taylor, R., Silva, R., Hou, R., Wang,\nR., Hosseini, S., Chennabasappa, S., Singh, S., Bell, S., Kim, S. S., Edunov, S., Nie, S., Narang, S.,\nRaparthy, S., Shen, S., Wan, S., Bhosale, S., Zhang, S., Vandenhende, S., Batra, S., Whitman, S., Sootla, S.,\nCollot, S., Gururangan, S., Borodinsky, S., Herman, T., Fowler, T., Sheasha, T., Georgiou, T., Scialom,\nT., Speckbacher, T., Mihaylov, T., Xiao, T., Karn, U., Goswami, V., Gupta, V., Ramanathan, V., Kerkez,\nV., Gonguet, V., Do, V., Vogeti, V., Albiero, V., Petrovic, V., Chu, W., Xiong, W., Fu, W., Meers, W.,\nMartinet, X., Wang, X., Wang, X., Tan, X. E., Xia, X., Xie, X., Jia, X., Wang, X., Goldschlag, Y., Gaur, Y.,\nBabaei, Y., Wen, Y., Song, Y., Zhang, Y., Li, Y., Mao, Y., Coudert, Z. D., Yan, Z., Chen, Z., Papakipos,\nZ., Singh, A., Srivastava, A., Jain, A., Kelsey, A., Shajnfeld, A., Gangidi, A., Victoria, A., Goldstand,\n12\n\nIGDA: Interactive Graph Discovery Agent\nA., Menon, A., Sharma, A., Boesenberg, A., Baevski, A., Feinstein, A., Kallet, A., Sangani, A., Teo, A.,\nYunus, A., Lupu, A., Alvarado, A., Caples, A., Gu, A., Ho, A., Poulton, A., Ryan, A., Ramchandani, A.,\nDong, A., Franco, A., Goyal, A., Saraf, A., Chowdhury, A., Gabriel, A., Bharambe, A., Eisenman, A.,\nYazdan, A., James, B., Maurer, B., Leonhardi, B., Huang, B., Loyd, B., Paola, B. D., Paranjape, B., Liu,\nB., Wu, B., Ni, B., Hancock, B., Wasti, B., Spence, B., Stojkovic, B., Gamido, B., Montalvo, B., Parker,\nC., Burton, C., Mejia, C., Liu, C., Wang, C., Kim, C., Zhou, C., Hu, C., Chu, C.-H., Cai, C., Tindal, C.,\nFeichtenhofer, C., Gao, C., Civin, D., Beaty, D., Kreymer, D., Li, D., Adkins, D., Xu, D., Testuggine,\nD., David, D., Parikh, D., Liskovich, D., Foss, D., Wang, D., Le, D., Holland, D., Dowling, E., Jamil,\nE., Montgomery, E., Presani, E., Hahn, E., Wood, E., Le, E.-T., Brinkman, E., Arcaute, E., Dunbar, E.,\nSmothers, E., Sun, F., Kreuk, F., Tian, F., Kokkinos, F., Ozgenel, F., Caggioni, F., Kanayet, F., Seide, F.,\nFlorez, G. M., Schwarz, G., Badeer, G., Swee, G., Halpern, G., Herman, G., Sizov, G., Guangyi, Zhang,\nLakshminarayanan, G., Inan, H., Shojanazeri, H., Zou, H., Wang, H., Zha, H., Habeeb, H., Rudolph, H.,\nSuk, H., Aspegren, H., Goldman, H., Zhan, H., Damlaj, I., Molybog, I., Tufanov, I., Leontiadis, I., Veliche,\nI.-E., Gat, I., Weissman, J., Geboski, J., Kohli, J., Lam, J., Asher, J., Gaya, J.-B., Marcus, J., Tang, J., Chan,\nJ., Zhen, J., Reizenstein, J., Teboul, J., Zhong, J., Jin, J., Yang, J., Cummings, J., Carvill, J., Shepard, J.,\nMcPhie, J., Torres, J., Ginsburg, J., Wang, J., Wu, K., U, K. H., Saxena, K., Khandelwal, K., Zand, K.,\nMatosich, K., Veeraraghavan, K., Michelena, K., Li, K., Jagadeesh, K., Huang, K., Chawla, K., Huang,\nK., Chen, L., Garg, L., A, L., Silva, L., Bell, L., Zhang, L., Guo, L., Yu, L., Moshkovich, L., Wehrstedt,\nL., Khabsa, M., Avalani, M., Bhatt, M., Mankus, M., Hasson, M., Lennie, M., Reso, M., Groshev, M.,\nNaumov, M., Lathi, M., Keneally, M., Liu, M., Seltzer, M. L., Valko, M., Restrepo, M., Patel, M., Vyatskov,\nM., Samvelyan, M., Clark, M., Macey, M., Wang, M., Hermoso, M. J., Metanat, M., Rastegari, M., Bansal,\nM., Santhanam, N., Parks, N., White, N., Bawa, N., Singhal, N., Egebo, N., Usunier, N., Mehta, N., Laptev,\nN. P., Dong, N., Cheng, N., Chernoguz, O., Hart, O., Salpekar, O., Kalinli, O., Kent, P., Parekh, P., Saab, P.,\nBalaji, P., Rittner, P., Bontrager, P., Roux, P., Dollar, P., Zvyagina, P., Ratanchandani, P., Yuvraj, P., Liang,\nQ., Alao, R., Rodriguez, R., Ayub, R., Murthy, R., Nayani, R., Mitra, R., Parthasarathy, R., Li, R., Hogan,\nR., Battey, R., Wang, R., Howes, R., Rinott, R., Mehta, S., Siby, S., Bondu, S. J., Datta, S., Chugh, S.,\nHunt, S., Dhillon, S., Sidorov, S., Pan, S., Mahajan, S., Verma, S., Yamamoto, S., Ramaswamy, S., Lindsay,\nS., Lindsay, S., Feng, S., Lin, S., Zha, S. C., Patil, S., Shankar, S., Zhang, S., Zhang, S., Wang, S., Agarwal,\nS., Sajuyigbe, S., Chintala, S., Max, S., Chen, S., Kehoe, S., Satterfield, S., Govindaprasad, S., Gupta, S.,\nDeng, S., Cho, S., Virk, S., Subramanian, S., Choudhury, S., Goldman, S., Remez, T., Glaser, T., Best, T.,\nKoehler, T., Robinson, T., Li, T., Zhang, T., Matthews, T., Chou, T., Shaked, T., Vontimitta, V., Ajayi, V.,\nMontanez, V., Mohan, V., Kumar, V. S., Mangla, V., Ionescu, V., Poenaru, V., Mihailescu, V. T., Ivanov, V.,\nLi, W., Wang, W., Jiang, W., Bouaziz, W., Constable, W., Tang, X., Wu, X., Wang, X., Wu, X., Gao, X.,\nKleinman, Y., Chen, Y., Hu, Y., Jia, Y., Qi, Y., Li, Y., Zhang, Y., Zhang, Y., Adi, Y., Nam, Y., Yu, Wang,\nZhao, Y., Hao, Y., Qian, Y., Li, Y., He, Y., Rait, Z., DeVito, Z., Rosnbrick, Z., Wen, Z., Yang, Z., Zhao, Z.,\nand Ma, Z. The llama 3 herd of models, 2024. URL https://arxiv.org/abs/2407.21783.\nHavrilla, A., Raparthy, S., Nalmpantis, C., Dwivedi-Yu, J., Zhuravinskyi, M., Hambro, E., and Raileanu, R.\nGlore: When, where, and how to improve llm reasoning via global and local refinements, 2024. URL\nhttps://arxiv.org/abs/2402.10963.\nHuang, Y., Kleindessner, M., Munishkin, A., Varshney, D., Guo, P., and Wang, J. Benchmarking of data-driven\ncausality discovery approaches in the interactions of arctic sea ice and atmosphere. Frontiers in Big Data,\n4, 2021. ISSN 2624-909X. doi: 10.3389/fdata.2021.642182. URL https://www.frontiersin.\norg/journals/big-data/articles/10.3389/fdata.2021.642182.\nJansen, P., Cˆot´e, M.-A., Khot, T., Bransom, E., Mishra, B. D., Majumder, B. P., Tafjord, O., and Clark,\nP. Discoveryworld: A virtual environment for developing and evaluating automated scientific discovery\nagents, 2024. URL https://arxiv.org/abs/2406.06769.\nKıcıman, E., Ness, R., Sharma, A., and Tan, C. Causal reasoning and large language models: Opening a new\nfrontier for causality, 2024. URL https://arxiv.org/abs/2305.00050.\n13\n\nIGDA: Interactive Graph Discovery Agent\nLampinen, A. K., Chan, S. C. Y., Dasgupta, I., Nam, A. J., and Wang, J. X. Passive learning of active causal\nstrategies in agents and language models, 2023. URL https://arxiv.org/abs/2305.16183.\nLi, P., Wang, X., Zhang, Z., Meng, Y., Shen, F., Li, Y., Wang, J., Li, Y., and Zhu, W. Realtcd: Temporal\ncausal discovery from interventional data with large language model, 2024. URL https://arxiv.\norg/abs/2404.14786.\nLippe, P., Cohen, T., and Gavves, E. Efficient neural causal discovery without acyclicity constraints, 2022.\nURL https://arxiv.org/abs/2107.10483.\nMadaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S.,\nYang, Y., Gupta, S., Majumder, B. P., Hermann, K., Welleck, S., Yazdanbakhsh, A., and Clark, P. Self-refine:\nIterative refinement with self-feedback, 2023. URL https://arxiv.org/abs/2303.17651.\nMajumder, B. P., Surana, H., Agarwal, D., Mishra, B. D., Meena, A., Prakhar, A., Vora, T., Khot, T.,\nSabharwal, A., and Clark, P. Discoverybench: Towards data-driven discovery with large language models,\n2024. URL https://arxiv.org/abs/2407.01725.\nMeek, C. Causal inference and causal explanation with background knowledge, 2013. URL https:\n//arxiv.org/abs/1302.4972.\nNauta, M., Bucur, D., and Seifert, C. Causal discovery with attention-based convolutional neural net-\nworks. Mach. Learn. Knowl. Extr., 1:312–340, 2019. URL https://api.semanticscholar.\norg/CorpusID:68070067.\nOlko, M., Zajac, M., Nowak, A., Scherrer, N., Annadani, Y., Bauer, S., Kucinski, L., and Milos, P. Trust\nyour gradient: Gradient-based intervention targeting for causal discovery, 2024. URL https://arxiv.\norg/abs/2211.13715.\nPearl, J. Causality: Models, Reasoning and Inference. Cambridge University Press, USA, 2nd edition, 2009.\nISBN 052189560X.\nPeters, J., Janzing, D., and Schlkopf, B. Elements of Causal Inference: Foundations and Learning Algorithms.\nThe MIT Press, 2017. ISBN 0262037319.\nRoohani, Y., Vora, J., Huang, Q., Steinhart, Z., Marson, A., Liang, P., and Leskovec, J. Biodiscoveryagent:\nAn ai agent for designing genetic perturbation experiments, 2024. URL https://arxiv.org/abs/\n2405.17631.\nScherrer, N., Bilaniuk, O., Annadani, Y., Goyal, A., Schwab, P., Sch¨olkopf, B., Mozer, M. C., Bengio,\nY., Bauer, S., and Ke, N. R. Learning neural causal models with active interventions, 2022. URL\nhttps://arxiv.org/abs/2109.02429.\nSibbald, B. and Roland, M. Understanding controlled trials: Why are randomised controlled trials important?\nBMJ, 316(7126):201, jan 1998. doi: 10.1136/bmj.316.7126.201.\nSpirtes, P. and Zhang, K. Causal discovery and inference: concepts and recent methodological advances.\nApplied Informatics, 3(1):3, 2016. ISSN 2196-0089. doi: 10.1186/s40535-016-0018-x. URL https:\n//doi.org/10.1186/s40535-016-0018-x.\nSpirtes, P., Glymour, C., and Scheines, R. Causation, prediction, and search. 1993. URL https://api.\nsemanticscholar.org/CorpusID:117765107.\nTu, R., Zhang, K., Bertilson, B. C., Kjellstr¨om, H., and Zhang, C. Neuropathic pain diagnosis simulator for\ncausal discovery algorithm evaluation, 2019. URL https://arxiv.org/abs/1906.01732.\n14\n\nIGDA: Interactive Graph Discovery Agent\nVashishtha, A., Reddy, A. G., Kumar, A., Bachu, S., Balasubramanian, V. N., and Sharma, A. Causal\ninference using llm-guided discovery, 2023. URL https://arxiv.org/abs/2310.15117.\nYang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., and Chen, X. Large language models as optimizers,\n2024. URL https://arxiv.org/abs/2309.03409.\nYu, Y., Chen, J., Gao, T., and Yu, M. Dag-gnn: Dag structure learning with graph neural networks, 2019.\nURL https://arxiv.org/abs/1904.10098.\nZheng, X., Aragam, B., Ravikumar, P., and Xing, E. P. Dags with no tears: Continuous optimization for\nstructure learning, 2018. URL https://arxiv.org/abs/1803.01422.\nZhou, Y., Wu, X., Huang, B., Wu, J., Feng, L., and Tan, K. C. Causalbench: A comprehensive benchmark for\ncausal learning capability of llms, 2024. URL https://arxiv.org/abs/2404.06349.\nZhu, Y., Benos, P. V., and Chikina, M. A hybrid constrained continuous optimization approach for optimal\ncausal discovery from biological data. Bioinformatics, 40(Supplement2):ii87–ii97, 09 2024. URL https:\n//doi.org/10.1093/bioinformatics/btae411.\n15\n\nIGDA: Interactive Graph Discovery Agent\nA\nPROMPTS\nZero-shot Confidence Estimation Prompt\n{task description} Your goal is to understand the direct causal parents of {target}. Another variable\nis a direct causal parent of {target} if an experiment on the variable affects {target} and there are no\nother causal parents between the variable and {target}. Now, you must determine whether {parent} is\na causal parent of {target}. Here is a list of all other variables to consider:\n{variables info}\nDo some brainstorming, comparing relevant characteristics of both variables and then print your\njudgment at the end of your response enclosed in the tags <decision>YES/NO</decision>. Print\nYES if {parent} is causal. Otherwise print NO. You should also print your confidence from a scale\nfrom 1 - 100 (with 100 being most confident) in the tags <confidence>...< /confidence>.\nInformation about {target}: {target info}\nInformation about {parent}: {parent info}\nParent Update Prompt\nYou are a causal discovery expert. You have been given the following list of variables and tasked\nwith predicting the true causal graph through a sequence of experiments on edges.\n{variables info}\nNote: each edge has an associated confidence value from 1 - 100. The presence of an edge is\nrepresented as (A−>B,CONFIDENCE) where A is the parent and B is the child. The absence of an\nedge is represented as (NOT A−>B, CONFIDENCE)\nFrom one experiment you have discovered {experiment feedback} Previously you predicted\n{experiment prediction}\nNow you should update your belief about the other edges of {parent} based on the results of the\nexperiment. Consider the predicted edge\n{other edge prediction}\nNow you should reason about how to update your belief about the above edge based on the ex-\nperiment.\nThis means you can either keep your confidence the same, update your confidence,\nor\nchange your prediction entirely.\nAt the end of your response give your updated predic-\ntion at the end of your response in the format <decision>PARENT/NOT CAUSAL</decision>\n<confidence>CONFIDENCE</confidence>. Print ’PARENT’ if the edge should be present and\n’NOT CAUSAL’ if the edge should be absent.\nYou should do this in three steps.\nStep 1: Brainstorm what physical causal connection there may be, if any.\nStep 2: Reason about what the experiment feedback tells you. Think carefully about how similar the\nnew child is to the experimental child.\nStep 3: Give your final decision.\n16\n\nIGDA: Interactive Graph Discovery Agent\nChild Update Prompt\nYou are a causal discovery expert. You have been given the following list of variables and tasked\nwith predicting the true causal graph through a sequence of experiments on edges.\n{variables info}\nNote: each edge has an associated confidence value from 1 - 100. The presence of an edge is\nrepresented as (A−> B,CONFIDENCE) where A is the parent and B is the child. The absence of an\nedge is represented as (NOT A−>B, CONFIDENCE)\nFrom one experiment you have discovered {experiment feedback} Previously you predicted\n{experiment prediction}\nNow you should update your belief about the other edges of {child} based on the results of the\nexperiment. Consider the predicted edge\n{other edge prediction}\nNow you should reason about how to update your belief about the above edge based on the ex-\nperiment.\nThis means you can either keep your confidence the same, update your confidence,\nor\nchange your prediction entirely.\nAt the end of your response give your updated predic-\ntion at the end of your response in the format <decision>PARENT/NOT CAUSAL</decision>\n<confidence>CONFIDENCE</confidence>. Print ’PARENT’ if the edge should be present and\n’NOT CAUSAL’ if the edge should be absent.\nYou should do this in three steps.\nStep 1: Brainstorm what physical causal connection there may be, if any.\nStep 2: Reason about what the experiment feedback tells you. Think carefully about how similar the\nnew parent is to the experiment parent.\nStep 3: Give your final decision.\n17\n\nIGDA: Interactive Graph Discovery Agent\nB\nGIT ABLATIONS\nFigure 9 plot GIT performance (Olko et al., 2024) over six causal graphs with varying amounts of observational\nand interventional data.\nFigure 9: GIT ablations with varying amounts of observational and interventional data.\nC\nSTATIC CONFIDENCE SELECTION OVER MULTIPLE MODELS\nFigure 10 reports the results of applying static confidence experiment selection using various models. Figure\n11 reports the average rank for each model across benchmarked graphs.\n18\n\nIGDA: Interactive Graph Discovery Agent\nFigure 10: Static confidence selection over multiple models.\nD\nCAUSAL GRAPHS\nVisualizations of causal graph benchmarks.\n19\n\nIGDA: Interactive Graph Discovery Agent\nFigure 11:\nStatic confidence based selection ranks for different models averaged across graphs.\nMeta-Llama-3-70B-Instruct is the only model to consistently outperform random guessing. Note:\nlower is better.\nFigure 12: Arctic sea ice causal graph.\n20\n\nIGDA: Interactive Graph Discovery Agent\nFigure 13: Asia causal graph.\nFigure 14: Asphyxia causal graph.\n21\n\nIGDA: Interactive Graph Discovery Agent\nFigure 15: Alzheimers causal graph.\nFigure 16: Covid causal graph.\n22\n\nIGDA: Interactive Graph Discovery Agent\nFigure 17: Neuropathic pain causal graph.\nFigure 18: Sangiovese causal graph.\n23\n\nIGDA: Interactive Graph Discovery Agent\nFigure 19: Brain causal graph.\n24\n",
  "metadata": {
    "source_path": "papers/arxiv/IGDA_Interactive_Graph_Discovery_through_Large_Language_Model_Agents_16e3bc57a1cc69d3.pdf",
    "content_hash": "16e3bc57a1cc69d337ce3ef4f3b1ea29b89a07257d22011182a9ce75cf9939e2",
    "arxiv_id": null,
    "title": "IGDA_Interactive_Graph_Discovery_through_Large_Language_Model_Agents_16e3bc57a1cc69d3",
    "author": "",
    "creation_date": "D:20250225025117Z",
    "published": "2025-02-25T02:51:17",
    "pages": 24,
    "size": 3398453,
    "file_mtime": 1740470172.8903027
  }
}