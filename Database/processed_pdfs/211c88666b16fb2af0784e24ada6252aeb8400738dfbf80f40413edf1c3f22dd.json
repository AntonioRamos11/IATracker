{
  "text": "arXiv:2502.17392v1  [cs.AI]  24 Feb 2025\n1\nEmoti-Attack: Zero-Perturbation Adversarial\nAttacks on NLP Systems via Emoji Sequences\nYangshijie Zhang\nLanzhou University, Lanzhou, China\nEmail: zhangyshj2023@lzu.edu.cn\nAbstract—Deep neural networks (DNNs) have achieved re-\nmarkable success in the ﬁeld of natural language processing\n(NLP), leading to widely recognized applications such as Chat-\nGPT. However, the vulnerability of these models to adversarial\nattacks remains a signiﬁcant concern. Unlike continuous domains\nlike images, text exists in a discrete space, making even minor\nalterations at the sentence, word, or character level easily per-\nceptible to humans. This inherent discreteness also complicates\nthe use of conventional optimization techniques, as text is non-\ndifferentiable. Previous research on adversarial attacks in text\nhas focused on character-level, word-level, sentence-level, and\nmulti-level approaches, all of which suffer from inefﬁciency or\nperceptibility issues due to the need for multiple queries or\nsigniﬁcant semantic shifts.\nIn this work, we introduce a novel adversarial attack method,\nEmoji-Attack, which leverages the manipulation of emojis to\ncreate subtle, yet effective, perturbations. Unlike character- and\nword-level strategies, Emoji-Attack targets emojis as a distinct\nlayer of attack, resulting in less noticeable changes with minimal\ndisruption to the text. This approach has been largely unexplored\nin previous research, which typically focuses on emoji insertion as\nan extension of character-level attacks. Our experiments demon-\nstrate that Emoji-Attack achieves strong attack performance on\nboth large and small models, making it a promising technique\nfor enhancing adversarial robustness in NLP systems.\nIndex Terms—Adversarial Attack, Zero-Perturbation.\nI. INTRODUCTION\nD\nEEP neural networks (DNNs) have garnered signiﬁ-\ncant achievements within the NLP ﬁeld, giving rise\nto renowned applications like ChatGPT . Nevertheless, it is\ncrucial to focus on the vulnerability of these NLP models to\nadversarial attacks for their protection. Contrary to the continu-\nous nature of the image domain, text exists in a discrete space.\nThis implies that any alterations, whether at the sentence,\nword, or even character level, are readily noticeable to humans,\nmaking it challenging to create unnoticeable perturbations.\nFurthermore, the discrete nature of text data renders it non-\ndifferentiable, leading to the ineffectiveness of conventional\noptimization techniques. Studies on adversarial textual attacks\nhave been broadly categorized into character-level, word-level,\nsentence-level, and multi-level approaches . At the character\nlevel, attacks involve altering words by means of insertion,\nomission, misspelling, substitution, or transposition of char-\nacters. Such modiﬁcations are readily identiﬁable by people.\nYet, character-level attacks necessitate numerous queries to\nascertain the speciﬁc characters to target. Word-level tactics\ninvolve modifying text by inserting, removing, or substituting\nkeywords. Like their character-level counterparts, these attacks\nalso demand repeated queries to identify the target words.\nBoth attacks are iterative, potentially leading to inefﬁciency in\npractical NLP use cases due to the need for multiple queries\nper iteration. Sentence-level attacks entail altering the entire\ntext by rephrasing or appending nonsensical sentences to the\noriginal text. The substantial alterations caused by sentence-\nlevel attacks might occasionally alter the fundamental meaning\nof the text. Perturbations at the character, word, and sentence\nlevels can result in signiﬁcant semantic shifts from the original\ncontent and are readily discernible by human observers.\nWe propose a groundbreaking technique known as emoji-\nlevel attacks within textual adversarial methods. This ap-\nproach, which diverges from character- and word-level attacks,\ntargets the manipulation of emoji, offering a less noticeable,\nand less-word-perturbation. Studies to date have not ade-\nquately explored the potential of emoji in adversarial contexts,\nwith some research merely toying with emoji insertion as an\nextension of character-level strategies.\nOur innovation lies in treating emoji modiﬁcations as a\ndistinct layer of attack on par with character, word, and\nsentence-level approaches.\nOur contributions are as following:\n(1) We propose Emoji-Attack , a novel type of adversarial\nattack that utilizes seemingly harmless or even playful emoti-\ncons to manipulate NLP systems.\n(2) Emoji-Attack demonstrates strong attack performance\non both large and small models.\nII. PROBLEM FORMULATION\nA. Zero-Word-Perturbation Attack Framework\nContemporary adversarial attack methods predominantly\nrely on direct text modiﬁcations, inevitably compromising\nsemantic integrity and triggering detection mechanisms [1].\nBuilding upon insights from [2] demonstrating the signiﬁcant\ninﬂuence of emojis on NLP model behavior, we propose a\nnovel zero-word-perturbation adversarial attack framework.\nOur approach achieves adversarial effects through strategic\nemoji sequence placement while preserving complete textual\nintegrity.\nFor a given text x and emoji sequences s, s′ ∈S(E), we\nformalize the sequence concatenation operation:\ns ⊕x ⊕s′ = cat(s) · x · cat(s′),\n(1)\n0000–0000/00$00.00 © 2025 IEEE\n\n2\nwhere cat denotes the sequence concatenation operation, with\ns and s′ representing the preﬁx and sufﬁx emoji sequences,\nrespectively.\nGiven a target classiﬁcation model ftgt : X →Y and an\ninput text x ∈X, our framework identiﬁes emoji sequences\ns, s′ ∈S(E) satisfying:\nftgt(s ⊕x ⊕s′) ̸= ftgt(x).\n(2)\nThe framework incorporates two fundamental constraints.\nFirst, [3] establishes the importance of emotional consistency\nbetween emoji sequences and the original text:\nfsen(s) = fsen(s′) = fsen(x).\n(3)\nAdditionally, we impose length constraints: lmin ≤|s|, |s′| ≤\nlmax.\nThe optimization objective maximizes prediction divergence\nwhile maintaining these constraints:\nmax\ns,s′∈S(E) L(s ⊕x ⊕s′, y),\n(4)\nwhere the loss function quantiﬁes the prediction divergence:\nL(s⊕x⊕s′, y) = log ptgt(ˆy|s⊕x⊕s′)−log ptgt(y|s⊕x⊕s′). (5)\nHere, y represents the original label, ˆy denotes the highest-\nconﬁdence incorrect label, and ptgt(·|·) indicates the model’s\nprediction probability.\nTo evaluate attack stealthiness comprehensively, we intro-\nduce a metric function η : X × S(E) × S(E) →[0, 1] [4]:\nη(x, s, s′) = α · δ(x, s, s′) + (1 −α) · γ(|s| + |s′|),\n(6)\nwhere δ(x, s, s′) assesses sentiment consistency across com-\nponents, and γ(l) implements a length-based penalty:\nγ(l) = max(0, 1 −\nl −lmin\nlmax −lmin\n).\n(7)\nThis formalization establishes a novel paradigm for adver-\nsarial attacks, achieving effective model manipulation while\nmaintaining perfect textual integrity through strategically po-\nsitioned emoji sequences.\nB. Emoji Sequence Space\nTo formalize our zero-word-perturbation attack methodol-\nogy within a rigorous mathematical framework, we construct\na comprehensive emoji sequence space encompassing both\nstandard Unicode emoji characters (e.g., grinning-face, ﬁre)\nand ASCII-based emoticons (e.g., ”:)”, ”QaQ”, ”;-P”). This\ndual-modality representation space enables more expressive\nadversarial sequence generation while maintaining naturalness\nin the resultant perturbations.\n[5] establishes fundamental\nproperties of emoji sequence composition, providing theoret-\nical foundations for our construction.\nLet E denote the ﬁnite set of all available emojis. We\nformally deﬁne the emoji sequence space S(E) as:\nS(E) = {s = (e1, . . . , el)|ei ∈E, lmin ≤l ≤lmax}.\n(8)\nTo ensure emotional consistency in sequence construction,\nwe introduce sentiment-speciﬁc subspaces. For each sentiment\nlabel y ∈Y, we deﬁne its corresponding sequence subspace\nSy as:\nSy = {s ∈S(E)|fsen(s) = y}.\n(9)\nA fundamental property of our constructed sequence space\nlies in its completeness. Speciﬁcally, for any input text x ∈X\nand target label y ∈Y, there exists at least one emoji se-\nquence s ∈S(E) that simultaneously satisﬁes both emotional\nconsistency and adversarial effectiveness:\n(fsen(s) = fsen(x)) ∧(ftgt(s ⊕x ⊕s′) ̸= ftgt(x)).\n(10)\nThe existence of such sequences emerges from the rich com-\nbinatorial structure of our emoji sequence space. For sequences\nof length l, the space admits |E|l possible combinations,\nproviding substantial ﬂexibility in sequence construction while\nmaintaining semantic naturalness. This theoretical foundation,\nsupported by the compositional properties established in [5],\nensures both the expressiveness and practical applicability of\nour framework.\nC. Emotional Consistency Framework\nA critical component of our zero-word-perturbation attack\nframework lies in maintaining emotional consistency between\nthe injected emoji sequences and the original text. Recent\nadvances in multimodal emotion analysis [6] demonstrate the\nsigniﬁcance of such alignment in ensuring attack impercep-\ntibility. We present a rigorous mathematical framework for\nquantifying and ensuring this crucial consistency property.\nLet fsen : S(E) →Y denote a mapping function that as-\nsociates emoji sequences with sentiment labels. We formalize\nthe sentiment consistency evaluation through a binary function\nδ : X × S(E) × S(E) →{0, 1}:\nδ(x, s, s′) = 1(fsen(s) = fsen(s′) = fsen(x)).\n(11)\nTo establish a comprehensive evaluation framework for\ngenerated sequences, we integrate this consistency measure\ninto a broader stealthiness metric. The resultant function\nη : X ×S(E)×S(E) →[0, 1] synthesizes emotional alignment\nwith sequence efﬁciency:\nη(x, s, s′) = α · δ(x, s, s′) + (1 −α) · γ(|s| + |s′|),\n(12)\nwhere the parameter α ∈[0, 1] mediates the trade-off between\nsentiment consistency preservation and sequence length opti-\nmization.\nOur framework provides rigorous theoretical guarantees\nregarding the existence of adversarial sequences that simulta-\nneously achieve attack effectiveness and maintain emotional\nconsistency. For any input text x and an arbitrarily small\npositive constant ǫ > 0:\n\n3\n∃s, s′ ∈S(E) : ftgt(s⊕x⊕s′) ̸= ftgt(x)∧η(x, s, s′) ≥1−ǫ. (13)\nThis fundamental guarantee emerges from two key prop-\nerties:\n1\nthe rich expressiveness of the constructed emoji\nsequence space, and 2\nthe careful design of our consistency\nevaluation mechanism. The guarantee ensures the theoretical\nfeasibility of generating adversarial examples that achieve both\nattack success and high stealthiness under our comprehensive\nmetric.\nIII. METHODOLOGY\nA. Two-Phase Learning Framework\nThe efﬁcient identiﬁcation of optimal emoji sequences\nwithin the vast search space presents signiﬁcant computational\nchallenges. [7] demonstrates that direct optimization through\nreinforcement learning often converges to suboptimal solutions\ndue to insufﬁcient semantic prior knowledge. Drawing from\nadvances in hybrid learning approaches [8], we develop a two-\nphase learning framework that systematically combines super-\nvised pretraining with reinforcement learning optimization.\nThe ﬁrst phase employs supervised learning, leveraging\nan auxiliary sentiment analysis model fsen to establish fun-\ndamental semantic mappings. The optimization objective is\nformalized as:\nLsup(θ) = −1\n|D|\nX\n(x,s)∈D\nl\nX\nt=1\nlog πθ(st|s1:t−1, x, l),\n(14)\nwhere πθ denotes the parameterized policy function and D\nrepresents the training dataset. This pretraining process es-\ntablishes robust semantic priors for subsequent optimization\nstages.\nBuilding upon [9], the second phase implements a compre-\nhensive MDP-based framework. The optimization objective is\nformulated as:\nJ(θ) = Ex∼D\n\u0002\nEl∼pl\n\u0002\nEs∼πθ(·|x,l)[R(x, s)]\n\u0003\u0003\n,\n(15)\nwhere we design a multi-component reward function balancing\nattack effectiveness with sequence diversity:\nR(x, s) = αRatk(x, s) + βRdiv(x, l).\n(16)\nTo enhance training stability, we incorporate the reward\nsmoothing mechanism proposed by [10]:\n˜R(x, s) = 1\nk\nt\nX\ni=t−k+1\nRi(x, s).\n(17)\nThis framework addresses the challenge of optimal sequence\ngeneration through three key innovations: 1 Integration of su-\npervised pretraining for establishing semantic priors 2\nMulti-\ncomponent reward structure incorporating attack effectiveness\nand sequence diversity\n3\nAdvanced stability enhancement\nthrough temporal reward smoothing\nThe combination of these components enables efﬁcient\noptimization of attack effectiveness while maintaining se-\nquence naturalness, with the entropy-based reward mechanism\nensuring robust performance throughout the training process.\nB. Specialized Sequence Generator\nThe implementation of efﬁcient zero-word-perturbation ad-\nversarial attacks necessitates a specialized generator architec-\nture capable of precisely modeling the semantic relationships\nbetween textual content and emoji sequences. Building upon\nthe foundational sequence-to-sequence framework established\nby [11] and [12], we develop an enhanced architecture in-\ncorporating novel components speciﬁcally designed for emoji\nsequence generation.\nA fundamental innovation in our approach lies in the\nconstruction of a uniﬁed vocabulary space that seamlessly\nintegrates both textual and emoji tokens:\nV = Vt ∪Ve,\n(18)\nwhere Vt and Ve represent the text and emoji vocabularies,\nrespectively. This uniﬁed representation enables coherent pro-\ncessing of both modalities during sequence generation. We\nenhance the standard attention mechanism through the intro-\nduction of a dynamic mask matrix M, modulating information\nﬂow between modalities, with Mij = 0 for intra-modality\nattention and Mij = β for cross-modality interactions.\nThe cornerstone of our architectural innovation is the Emoji\nLogits Processor (ELP), implementing dynamic probability\nadjustment for token generation:\npout = ELP(pin) = soft(Wpin + b).\n(19)\nOur optimization framework incorporates multiple essen-\ntial objectives. The semantic consistency component Lsem =\n−log P(fsen(s)\n=\nfsen(x)) enforces emotional alignment\nbetween generated sequences and input text, while the ad-\nversarial effectiveness measure Ladv = −R(x, s) quantiﬁes\nattack success. Following [13], we employ an entropy-based\ndiversity term Ldiv = −H(πθ(·|x, l)) to promote sequence\nvariation. These components integrate into a uniﬁed objective\nfunction:\nL = Lsem + λ1Ladv + λ2Ldiv,\n(20)\nwhere hyperparameters λ1 and λ2 regulate the balance be-\ntween competing optimization objectives. This specialized\narchitecture, through its uniﬁed vocabulary representation,\ndynamic attention masking, and novel ELP component, en-\nables effective generation of adversarial emoji sequences while\nmaintaining semantic coherence with the original text content.\nIV. EXPERIMENT\nTo rigorously evaluate our proposed EmotiAttack frame-\nwork, we designed a comprehensive experimental protocol\nutilizing two benchmark datasets: Go Emotion and Tweet\nEmoji. The Go Emotion dataset comprises emotion-labeled\ntext instances across multiple ﬁne-grained emotional cate-\ngories, while the Tweet Emoji dataset consists of Twitter posts\n\n4\nTABLE I\nEMOJI-ATTACK’S PERFORMANCE ON ROBERTA AND BERT MODELS WITH PERTURBATIONS OF VARYING SIZES.\nDataset\nModel\nSize\nPert. Rate\nASR (%)\nAvg. Time (s)\nAvg. Query\nGo Emotion\nRoBERTa\ntop1\n0\n79.51\n0.05\n1.00\ntop3\n0\n90.25\n0.08\n1.40\ntop15\n0\n95.17\n0.09\n3.01\ntop30\n0\n96.09\n0.09\n3.77\nBERT\ntop1\n0\n73.13\n0.03\n1.00\ntop3\n0\n77.87\n0.07\n1.46\ntop15\n0\n82.64\n0.04\n4.10\ntop30\n0\n87.52\n0.12\n8.10\nTweet Emoji\nRoBERTa\ntop1\n0\n71.54\n0.06\n1.00\ntop3\n0\n86.78\n0.06\n1.46\ntop15\n0\n92.56\n0.07\n2.92\ntop30\n0\n95.00\n0.08\n3.85\nBERT\ntop1\n0\n40.46\n0.06\n1.00\ntop3\n0\n59.16\n0.07\n2.08\ntop15\n0\n84.74\n0.08\n4.89\ntop30\n0\n90.58\n0.09\n6.62\nwith associated emoji usage patterns. Both datasets provide\ndiverse linguistic contexts, enabling thorough assessment of\nour framework’s generalizability.\nFor\ntarget models,\nwe\nemployed two\nstate-of-the-art\ntransformer-based architectures: BERT and RoBERTa, both\nﬁne-tuned for their respective classiﬁcation tasks. All experi-\nments were conducted on an NVIDIA RTX 3090 GPU with\n24GB VRAM. Our implementation utilizes PyTorch with the\nAdamW optimizer for gradient-based optimization.\nTo systematically investigate the relationship between\nsearch space dimensionality and attack performance, we eval-\nuated four distinct search space conﬁgurations: top-1, top-3,\ntop-15, and top-30. This experimental design enables precise\ncharacterization of the trade-off between attack effectiveness\nand computational efﬁciency. Throughout our evaluations, we\nmaintain consistent preprocessing protocols and evaluation\nmetrics to ensure fair comparison across different experimental\nconditions.\nA. Attack Performance Analysis\nTable I presents the performance metrics of our EmotiAttack\nframework across varying search space conﬁgurations. The\nmost notable characteristic is the consistently maintained 0%\nperturbation rate across all experimental settings, underscoring\nour framework’s fundamental advantage: preserving complete\ntextual integrity of the original content while achieving effec-\ntive model manipulation.\nOur approach demonstrates remarkably high attack success\nrates (ASR) across both datasets. For the RoBERTa model on\nGo Emotion, we achieve ASR values ranging from 79.51%\nwith top-1 constraints to 96.09% with top-30 search space.\nSimilarly, on Tweet Emoji, RoBERTa exhibits vulnerability\nwith ASR values from 71.54% to 95.00%. The BERT model\nshows substantial susceptibility as well, with ASR values\nranging from 73.13% to 87.52% on Go Emotion and from\n40.46% to 90.58% on Tweet Emoji.\nThe computational efﬁciency of our framework is particu-\nlarly noteworthy, with average processing time per sample con-\nsistently below 0.12 seconds across all conﬁgurations. Query\nrequirements remain minimal, with average query counts rang-\ning from 1.00 to 8.10, signiﬁcantly outperforming traditional\nadversarial attack methods that typically require substantially\nhigher query volumes.\nThe results reveal a clear correlation between search space\nsize and attack performance. As the search space expands\nfrom top-1 to top-30, we observe monotonic improvements\nin ASR across all experimental conﬁgurations. This scalable\nconﬁgurability enables ﬂexible adjustment based on speciﬁc\noperational requirements. For instance, on the Tweet Emoji\ndataset with the BERT model, expanding from top-1 to top-30\nincreases ASR from 40.46% to 90.58%, while only modestly\nincreasing the processing time from 0.06 to 0.09 seconds and\nqueries from 1.00 to 6.62.\nInterestingly, RoBERTa consistently exhibits higher vul-\nnerability compared to BERT, particularly at smaller search\nspace conﬁgurations. This differential susceptibility could be\nattributable to their distinct pre-training objectives and contex-\ntual encoding mechanisms.\nB. Performance Evaluation on State-of-the-Art Large Lan-\nguage Models\nWhile traditional NLP models represent a signiﬁcant ap-\nplication domain for adversarial attacks, recent advancements\nin large language models (LLMs) have fundamentally trans-\nformed the natural language processing landscape. To compre-\nhensively evaluate our EmotiAttack framework’s generalizabil-\n\n5\nTABLE II\nEMOJI-ATTACK’S PERFORMANCE ON LLMS WITH PERTURBATIONS OF VARYING SIZES.\nDataset\nSize\nQwen2.5-7b-Instruct\nLlama3-8b-Instruct\nGPT4o\nClaude3.5Sonnet\nGemini-Exp-1206\nGo Emotion\nTop15\n89.00%\n80.37%\n75.00%\n76.85%\n77.81%\nTop30\n92.66%\n85.68%\n79.00%\n82.32%\n83.28%\nTweet Emoji\nTop15\n92.32%\n87.10%\n81.00%\n77.49%\n86.82%\nTop30\n95.34%\n90.12%\n86.00%\n81.99%\n90.35%\nity and practical signiﬁcance, we conducted extensive exper-\niments targeting state-of-the-art LLMs, including both open-\nsource models (Qwen2.5-7b-Instruct, Llama3-8b-Instruct) and\nproprietary systems (GPT4o, Claude3.5Sonnet, Gemini-Exp-\n1206).\nTable II presents the attack success rates across ﬁve distinct\nLLM architectures using our zero-word-perturbation approach.\nWe evaluated two search space conﬁgurations—top-15 and\ntop-30—to investigate the relationship between search space\ndimensionality and attack effectiveness in the LLM domain.\nThe results demonstrate a remarkable ﬁnding: contemporary\nLLMs exhibit substantial vulnerability to our emoji-based\nadversarial attack methodology.\nThe experimental outcomes reveal several notable patterns.\nFirst, our approach achieves exceptional attack success rates\nacross all evaluated LLMs, with ASR values ranging from\n75.00% to 92.66% on the Go Emotion dataset and from\n77.49% to 95.34% on the Tweet Emoji dataset. These high\nsuccess rates underscore a fundamental vulnerability in cur-\nrent LLM architectures that persists despite their signiﬁcantly\nlarger parameter counts and more sophisticated pre-training\nregimes compared to traditional NLP models.\nAmong the evaluated models, Qwen2.5-7b-Instruct exhibits\nthe highest susceptibility to our attack methodology, with\nASR values reaching 92.66% and 95.34% under top-30 search\nspace conﬁguration for Go Emotion and Tweet Emoji datasets,\nrespectively. Notably, even the most robust model in our evalu-\nation, GPT4o, demonstrates substantial vulnerability with ASR\nvalues of 79.00% and 86.00% under the same experimental\nconditions.\nThe consistent vulnerability pattern across diverse LLM\narchitectures—spanning different model families, parame-\nter scales, and training methodologies—indicates a systemic\nweakness in how current language models process and in-\nterpret emoji sequences in conjunction with textual content.\nThis ﬁnding has profound implications for LLM deployment\nin security-critical applications, particularly as these models\nincreasingly serve as fundamental components in automated\ndecision systems.\nThe observed vulnerability becomes particularly concerning\nwhen considering the rapid proliferation of LLM-based appli-\ncations across critical domains including content moderation,\ninformation retrieval, and automated decision-making. Our\nresults suggest that malicious actors could potentially ma-\nnipulate model outputs through strategically positioned emoji\nsequences without modifying the underlying textual content,\nthereby circumventing traditional content ﬁltering mechanisms\nthat focus primarily on textual perturbations.\nFurthermore, the scalable conﬁgurability of our attack\nmethodology, demonstrated through the consistent perfor-\nmance improvements when expanding from top-15 to top-30\nsearch space, highlights the framework’s adaptability across\ndifferent operational constraints. This conﬁgurability enables\nprecise calibration of attack parameters to target speciﬁc model\narchitectures effectively.\nThe demonstrated effectiveness of EmotiAttack against\nstate-of-the-art LLMs represents a signiﬁcant contribution to\nunderstanding model robustness in the evolving NLP land-\nscape. By exposing a critical vulnerability that persists across\nboth traditional models and cutting-edge LLMs, our ﬁndings\nunderscore the urgent need for developing more robust defense\nmechanisms that speciﬁcally address emoji-based manipula-\ntion vectors.\nV. CONCLUSION\nIn\nthis\npaper,\nwe\nintroduce\nEmoti-Attack,\na\nZero-\nPerturbation Adversarial Attacks on NLP Systems via Emoji\nSequences. It can attack the small model and LLMs\nREFERENCES\n[1] X. Yang, Y. Gong, W. Liu, J. Bailey, D. Tao, and W. Liu, “Semantic-\npreserving adversarial text attacks,” IEEE Transactions on Sustainable\nComputing, vol. 8, no. 4, pp. 583–595, 2023.\n[2] H. Ma, W. Cao, J. Peng, J. Ren, and Y. Zhang, “Security evaluation\nof emojis in nlp tasks,” in 2024 IEEE International Conference on Big\nData and Smart Computing (BigComp).\nIEEE, 2024, pp. 8–15.\n[3] S. Gupta, A. Singh, and V. Kumar, “Emoji, text, and sentiment polarity\ndetection using natural language processing,” Information, vol. 14, no. 4,\np. 222, 2023.\n[4] Y. Cheng, S. Luo, Y. Wan, L. Pan, and X. Li, “Strongly concealed\nadversarial attack against text classiﬁcation models with limited queries,”\nNeural Networks, vol. 183, p. 106971, 2025.\n[5] B. Weissman, J. Engelen, L. Thamsen, and N. Cohn, “Compositional\naffordances of emoji sequences,” Language@ Internet, vol. 22, no.\nSpecial Issue, pp. 57–73, 2024.\n[6] G. Bao, L. Sun, R. Zhang, B. Zhang, Z. Shen, and S. Chen, “Research\non image-text multimodal emotions analysis with fused emoji,” in 2024\n27th International Conference on Computer Supported Cooperative\nWork in Design (CSCWD).\nIEEE, 2024, pp. 18–23.\n[7] D. Tirumala, A. Galashov, H. Noh, L. Hasenclever, R. Pascanu,\nJ. Schwarz, G. Desjardins, W. M. Czarnecki, A. Ahuja, Y. W. Teh\net al., “Behavior priors for efﬁcient reinforcement learning,” Journal\nof Machine Learning Research, vol. 23, no. 221, pp. 1–68, 2022.\n[8] T. Wang and D. E. Chang, “Improved reinforcement learning through\nimitation learning pretraining towards image-based autonomous driv-\ning,” in 2019 19th international conference on control, automation and\nsystems (ICCAS).\nIEEE, 2019, pp. 1306–1310.\n\n6\n[9] X. Ji and G. Li, “Regret-optimal model-free reinforcement learning\nfor discounted mdps with short burn-in time,” Advances in Neural\nInformation Processing Systems, vol. 36, 2024.\n[10] V. Lee, P. Abbeel, and Y. Lee, “Dreamsmooth: Improving model-\nbased reinforcement learning via reward smoothing,” arXiv preprint\narXiv:2311.01450, 2023.\n[11] I. Sutskever, “Sequence to sequence learning with neural networks,”\narXiv preprint arXiv:1409.3215, 2014.\n[12] D. Bahdanau, “Neural machine translation by jointly learning to align\nand translate,” arXiv preprint arXiv:1409.0473, 2014.\n[13] X. Zhang, J. Guan, Y. Liu, and G. Wang, “Morl4pdes: Data-driven dis-\ncovery of pdes based on multi-objective optimization and reinforcement\nlearning,” Chaos, Solitons & Fractals, vol. 180, p. 114536, 2024.\n\nThis figure \"fig1.png\" is available in \"png\"\n format from:\nhttp://arxiv.org/ps/2502.17392v1\n",
  "metadata": {
    "source_path": "papers/arxiv/Emoti-Attack_Zero-Perturbation_Adversarial_Attacks_on_NLP_Systems_via\n__Emoji_Sequences_211c88666b16fb2a.pdf",
    "content_hash": "211c88666b16fb2af0784e24ada6252aeb8400738dfbf80f40413edf1c3f22dd",
    "arxiv_id": null,
    "title": "Emoti-Attack_Zero-Perturbation_Adversarial_Attacks_on_NLP_Systems_via\n__Emoji_Sequences_211c88666b16fb2a",
    "author": "",
    "creation_date": "D:20250224220956-05'00'",
    "published": "20250224220956-05'00'",
    "pages": 7,
    "size": 146562,
    "file_mtime": 1740470151.9929101
  }
}