{
  "text": "Version Date: February 22, 2025 \nTeleology-Driven Affective Computing: \nA Causal Framework for Sustained Well-Being \n \nBin Yin, Chong-Yi Liu#, Liya Fu and Jinkun Zhang \n \nAbstract — Affective computing has advanced significantly over the past two decades, achieving remarkable progress in emotion \nrecognition and generation. However, current approaches remain largely focused on short-term pattern recognition, lacking a \ncomprehensive theoretical framework to guide affective agents in aligning with long-term human well-being. To address this gap, \nwe propose a teleology-driven affective computing framework, which unifies major emotion theories — basic emotion, appraisal, \nand constructivist approaches — under the premise that affect is an adaptive, goal-directed process that facilitates survival and \ndevelopment. Building on this foundation, our framework emphasizes the alignment of agent responses with personal/individual \nand group/collective well-being over extended timescales. We advocate for developing a large-scale “dataverse” of personal \naffective events, capturing the longitudinal interplay between beliefs, goals, actions, and outcomes using real-world experience \nsampling and immersive virtual reality. By leveraging causal modeling, this “dataverse” enables AI systems to infer individuals’ \nunique affective concerns and provide tailored interventions that support sustained well-being. Furthermore, we introduce a meta-\nreinforcement learning paradigm to train affective agents in simulated environments. This allows them to dynamically adapt to \nevolving affective concerns and balance hierarchical goals—ranging from immediate affective concerns to long-term self-\nactualization. We call for a shift from traditional modeling based on statistical correlations to causal reasoning, enhancing agents' \nability to predict and proactively respond to emotional challenges. Ultimately, this framework offers a conceptual foundation for \ndeveloping adaptive, personalized, and ethically aligned affective computing systems that promote meaningful human-AI \ninteractions and long-term societal well-being. \n \nIndex Terms — Affective computing, Human-computer interaction, Human factors, Causality, Deep reinforcement learning, \nPsychology, Social intelligence.\n 1. INTRODUCTION \nHE scientific community, long emphasizing rational \nthought, logical reasoning, operationalization, and \nreproducibility, has often regarded emotions with a \ncertain detachment. Consequently, when Picard [1] first \nproposed the concept of affective computing, it garnered \nlimited attention. However, addressing certain engineering \nchallenges inevitably involves engaging with emotions, often \nconsidered “irrational.” For instance, early computer vision \nsystems were largely modeled after the structure and function \nof the human visual cortex [2]. Yet, creating such systems was \nnot merely about detecting high-contrast lines or distinguishing \napples from pears; it required identifying elements of interest \nand adapting to shifting priorities automatically — tasks that no \npurely engineering-based approach could achieve [3]. Marvin \nMinsky emphasized that emotions are not the antithesis of \nrationality but are critical mechanisms enabling humans to \nmake efficient decisions in complex environments [4]. He \nviewed emotions as a strategic selection system governing \nthoughts and actions, determining when to persist, abandon, or \nswitch goals. This perspective aligns closely with the core \nobjectives of affective computing, which aims to endow \ncomputational systems with similar strategic adaptability, a \nfoundational \nstep \ntoward \nintelligent \nhuman-computer \ninteraction. \n \n    These authors contributed equally to this work and are co-first authors.  \nAll authors are affiliated with the School of Psychology, Fujian Normal University, Fuzhou, Fujian 350117, China. \nCorresponding author: Bin Yin, Ph.D. (Email: byin@fjnu.edu.cn; luckbin@163.com; ORCID: 0000-0003-1105-8905).  \nThe value of affective computing has been validated in \nvarious artificial intelligence (AI) applications, such as \nintelligent assistants, social robots, virtual reality, and \naugmented reality systems. The capacity for emotional \nunderstanding and responsiveness significantly enhances user \nexperiences. Beyond enabling more natural and human-like \ninteractions, affective computing also plays vital roles in \nhealthcare, education, and psychotherapy [5]. Driven by this \nexpanded understanding of emotional functionality, an \nincreasing number of engineers and computer scientists have \nbeen drawn to this previously “niche” field. They provide a \nvariety of information technology tools and engineering \ncapabilities to create a computing system that can accurately \nperceive, recognize, understand and respond to human \nemotions based on behavioral cues and contextual situations [5]. \nAs a result, affective computing has evolved into an \ninterdisciplinary domain, integrating insights from psychology, \ncomputer \nscience, \ninformation \ntechnology, \nmechanical \nengineering, and bioengineering [5], [6]. Researchers aim to \ncreate intelligent agents that better understand human emotional \nneeds [1], fostering harmonious human-computer interactions \nand advancing user-centered AI [7], [8], [9]. \nCurrent research in affective computing primarily focuses on \ntwo areas: emotional analysis [10], [11] and the generation and \nexpression of emotions [12], [13]. Emotional analysis involves \nmodeling and recognizing multidimensional emotional signals \nT\n\n2 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \ncollected from text, speech, and visual inputs [14], while \nemotional generation leverages generative models to simulate \nhuman-like emotional expressions [15]. Recent advancements in \ndeep learning [11] and the creation of large datasets [16] have \nsignificantly enhanced emotional analysis. For example, in text-\nbased emotional analysis, a critical research challenge is \nclassifying sentiments (e.g., positive or negative) from textual \ndata, such as product reviews. Domain shift problems often arise \nwhen training and testing data originate from different \ndistributions, leading to performance degradation. To address \nthis, Ganin et al., [17] introduced Domain Adversarial Neural \nNetworks (DANN) to bridge distributional gaps between source \nand target domains. \nDespite achieving high accuracy in emotion recognition tasks \nthrough machine learning models trained on large datasets, these \nmodels still lack genuine emotional understanding. They often \nfail to infer the causes of emotions, predict behavioral outcomes, \nor hypothesize how interventions might alter emotional \ntrajectories. In the realm of emotional generation, large language \nmodels (LLMs) like ChatGPT can produce word-for-word \nresponses resembling human emotional expressions through \nspecific training methods. However, true empathy and emotional \nconcern remain beyond the capabilities of LLMs [18]. While \nthese models can simulate forms of empathetic and affectionate \nexpressions, they do not replicate the essence or underlying \ngenerative processes of emotional experiences. For humans, \nidentifying others' emotional states and expressing one's own \nemotions is a continuous and integrated process. However, \nwhether built on discrete [19], [20] or dimensional models of \nemotion [21], [22], [23], existing algorithms for emotion \nrecognition often fail to guide affective AI systems on actionable \nresponses. This highlights the absence of a comprehensive \nframework in affective computing. \nThe complexity and diversity of affective phenomena pose \nchallenges for traditional reductionist methods to fully elucidate \ntheir underlying mechanisms. Fundamental questions in affective \ncomputing \ninclude: \nWhat \nprinciples \ngovern \nemotional \ninteractions? How are emotional states formed and developed \nthrough individual-environment interactions? How to effectively \ndistinguish the different triggers of affective states, such as grief \ncaused by the loss of a loved one and sadness triggered by a \ndecline in academic performance? After recognizing emotions, \nhow should AI systems respond appropriately to support \neffective emotional interaction? Addressing these questions \nrequires a clear theoretical framework and robust technical \nsolutions to bridge the gap between emotion recognition and \ndecision-making. Teleology offers a systematic perspective for \nunderstanding the functional roles of emotions in adapting to \nenvironments and achieving goals [24]. By incorporating \nteleological principles, we aim to redefine the design of affective \nagents. This paper introduces a teleology-based research \nframework for affective computing, encompassing theoretical \nfoundations, interaction principles, dataset development, and \nalgorithmic modeling. By conceptualizing affect as adaptive and \ngoal-oriented products, our objective is to surpass traditional \npattern recognition methods and provide a systematic perspective \nfor advancing the field. \nThe remainder of this paper is organized as follows: Section \n2 examines major contemporary emotion theories from a \nteleological perspective. Section 3 reviews the state of research \nin affective computing, focusing on mainstream computational \nmodels and their theoretical assumptions. Section 4 proposes \ninteraction principles for affective agents based on teleology and \nexplores the construction of corresponding datasets and \nalgorithmic models, culminating in a comprehensive teleology-\nbased affective computing framework. Section 5 summarizes and \nprovides conclusions. \n2. A TELEOLOGICAL PERSPECTIVE ON MAJOR EMOTION \nTHEORIES \nContemporary emotion theories have yet to reach a consensus \non fundamental assumptions, with even the basic definition of \n“emotion” remaining a contentious issue [25], [26], [27], [28], \n[29], [30]. These theoretical paradigms propose various \nperspectives, including basic emotion theories, appraisal theories, \nand constructivist approaches (both psychological and social) \n[31]. While these theories offer unique perspectives, long-\nstanding criticisms and misunderstandings have hindered the full \ndevelopment and application of their core ideas. This has left the \nfield of affective computing without a unified theoretical \nframework. Just as the Industrial Revolution relied on the \nfoundational principles of Newtonian physics to drive \ntechnological progress, achieving the goal of creating genuine \naffective agents requires addressing the foundational gaps in \npsychological theories of emotion and integrating these insights \ninto computational systems. Teleology provides a powerful \nintegrative framework by emphasizing affects as functional tools \nthat organisms use to adapt to their environments and achieve \ngoals. This perspective bridges the divides between basic \nemotion theories, appraisal theories, and constructivist \napproaches, underscoring the core role of affects in helping \nindividuals adapt and achieve their objectives. \nWhen applied to psychology, teleology posits that mental \nconstructs exist to serve adaptive or functional purposes [32]. In \nstudying affective phenomena, this perspective prompts us to \nconsider why humans evolved affects. To serve evolutionary \npurposes, affects must be linked to functional components in the \nphysical world [33]. Specifically, affects can be defined as \npsychological mechanisms supporting life [25], [29] and \nnaturally extend the observation of affective phenomena from \nhumans to other animals [34], [35], [36], [37], [38], [39], [40], \n[41], [42]. From this perspective, affect serve as internal states \nthat mediate between causes and outcomes of actions. Their \nfunctional significance can be demonstrated through operant and \nreinforcement processes, revealing remarkable conservation \nacross species. Despite criticism tying consciousness tightly to \naffects and questioning the study of affects in animals unable to \nself-report, \nneuroscience \nresearch \nincreasingly \nreveals \nconvergent neural mechanisms underlying affective responses \nacross species [37], [43], [44], [45]. Panksepp [44] introduced the \nconcept of \"affective neuroscience,\" integrating the shared \nfunctions of affective systems across species and highlighting \naffects as foundational to the development of complex cognitive \n\n3 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \nabilities. \nThe teleological approach provides a psychological rationale \nfor explaining behavior, focusing on biological needs or goals \n[32]. For instance, fear (an emotional response) triggers \nbehavioral actions (such as freezing or fleeing) aimed at \nprotecting the organism from potential harm. Each action is goal-\ndriven during interactions with the external environment. In \ncontrast, mechanisms based purely on mathematics, probability, \ngeometry, or logic, which disregard physical implementation \nfactors, do not align with the goal-oriented paradigm that \nunderlies biological intelligence [46]. At a broader biological \nlevel, maintaining self-continuity and coherence serves as the \noverarching principle guiding all actions [24]. This principle \nensures that biological systems maintain homeostasis within \nspecific ranges [47]. The fundamental biological goals of \nsecuring comfort and propagating genes underpin a wide range \nof affective phenomena, from simple interests and moods to more \ncomplex desires, ethics, and aesthetics [44]. Cross-species \nresearch provides evidence for the evolutionary continuity of \nemotional systems, which act as a universal currency in decision-\nmaking: pleasure motivates behavior persistence, while \ndiscomfort drives avoidance [48]. \nModern theories of emotion emphasize their adaptive \nfunctions. Basic emotion theories agree that distinct functional \nemotions evolved to address specific adaptive challenges — \nrecurring threats or opportunities related to survival and health \n[44], [47], [49]. For example, Ekman [50] argued that emotional \nprocesses coordinate physiological, non-verbal, attentional, \ncognitive, motivational, sensory, and behavioral responses when \ntriggered by specific contexts. Appraisal theorists similarly \nrecognize the adaptive nature of emotions, defining them as \nmechanisms that drive organisms to respond appropriately to \nenvironmental changes. Arnold [51] described emotions as \napproach responses to beneficial stimuli or avoidance responses \nto harmful ones. This evaluation process continuously monitors \nthe relationship between an organism and its “comfort zone”, \nintegrating multiple dimensions such as needs, goals, and values \n[52]. Thus, even in identical situations, individuals may generate \ndifferent emotional responses based on their unique appraisals. \nConstructivist approaches view emotions as brain-generated \nconstructs shaped by combinations of basic sensory inputs, \nconcepts, and categories, influenced by both cognitive processes \nand biological factors. Emotional expressions and physiological \nfeatures are closely tied to past experiences, exhibiting flexibility \nand context dependence. For instance, a smile’s muscle \nmovements might convey anger in one context but friendliness \nor joy in another. \nThe classification principles of emotions reflect differing \nextensions of teleological assumptions in emotional theories. \nScientists debate whether emotions should be described along \ndimensions like valence and arousal or as discrete entities [53]. \nBasic emotion theories typically adopt a discrete view, dividing \nemotions into categories defined by specific emotional programs. \nEach category represents an organism’s relationship with its \nenvironment, such as fear protecting against harm or disgust \nrejecting harmful substances [50]. In contrast, appraisal theories \nargue for dimensional constructs, suggesting that emotions arise \nfrom evaluative patterns along multiple dimensions. These \ndimensions combine in diverse ways to produce a broad spectrum \nof emotional states. For appraisal theorists, emotions are \nvalenced according to their alignment with goals or goal states. \nPositive emotions arise when goals are achieved, while negative \nemotions reflect failures. An organism’s primary task is not to \nprocess information but to fulfill its goals, necessitating \ncontinuous cycles of actions that serve these goals [54], [55]. \nAppraisal theory conceptualizes goals as the individual’s well-\nbeing, with the appraisal process serving to detect and evaluate \nthe importance of the environment’s impact on well-being [56]. \nWithin this framework, the appraisal process assesses the \ninfluence of the environment on an individual’s well-being, \nincorporating multidimensional factors such as needs, beliefs, \nand attachments [52], [56], [57], [58]. It is crucial to recognize \nthat these concerns precede specific emotions and exist \nindependently of them, functioning as an emotional state akin to \ndesire [59]. \nWhile constructivism recognizes the utility of emotion \ncategories, it emphasizes that valence and arousal are central \nfeatures that vary depending on the context and the individual's \nexperiences. Emotional instances emerge as events occurring in \nspecific contexts. When the brain reconstructs past events similar \nto the present, it generates categories containing potential future \nemotional instances [27]. These categories encapsulate abstract \npsychological features such as goals, values, and threats, \nemphasizing the importance of concerns in the emotional \ngeneration process. \nIn summary, although differing metaphysical and mechanistic \nassumptions underpin these theories, teleological principles — \nfocusing on goal-directed behaviors and adaptive functions — \noffer a way to unify them into a cohesive framework. Schiller et \nal. [24] proposed the concept of the “Human Affectome,” a \nframework integrating diverse assumptions about emotions into \na unified model. This model views affects as dynamic \nphenomena emerging from the interactions between organisms \nand their environments, encompassing both concerns (factors \ninfluencing affective experiences) and features (adaptive changes \nsuch as valence and arousal). This framework provides a novel \nperspective and integrative strategies for advancing research in \naffective computing. \n3. CURRENT RESEARCH IN AFFECTIVE COMPUTING \nCurrent research in affective computing can be broadly \ndivided into two main domains: emotional analysis and \nemotional generation/expression. The former focuses on \nmodeling and recognizing patterns in external emotional \nexpressions (such as facial expressions, vocal tones, and \nmovements) and physiological signals (e.g., heart rate, blood \npressure, pulse, and body temperature). The latter aims to \ndevelop affective agents capable of generating emotions and \nassessing possible user emotional responses by calculating events \nand evaluating outcomes [61]. This section will analyze \nmainstream computational models and research achievements in \nthese two domains, as well as evaluate the theoretical \nassumptions underpinning them. \n\n4 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \n3.1 Emotional Analysis － Modeling and Recognizing \nEmotional Representations \nLiving organisms consistently use emotional expressions to \ncommunicate with others, even across species. For humans, such \nexpressions aid in coordinating personal, interpersonal, and \nsocial behaviors. One of the key goals of affective computing is \nto “understand” the underlying emotional states of interaction \npartners. Humans typically express emotions through a \ncombination of verbal communication, vocal intonation, facial \nexpressions, and body language. Researchers have attempted to \ninfer users’ emotional states using single-modal physical data, \nwith studies focusing on text sentiment analysis, speech emotion \nrecognition, and visual emotion recognition (for detailed reviews \nof these three areas, see [9]). Traditional single-modal emotion \nrecognition typically relies on a process called “feature \nengineering” [62], where relevant emotion-related features are \nextracted from raw data and input into predictive models that \noutput corresponding emotional states. Deep neural networks, by \naggregating activations from interconnected layers of processing \nunits (neurons), can automatically extract useful features from \nraw data [63], enabling end-to-end emotional analysis. However, \npattern recognition based on external emotional expressions is \nnot always reliable. Social norms or individual concerns about \njudgment can lead people to unconsciously or deliberately mask \ntheir true emotional states, reducing the accuracy of single-modal \nemotion recognition methods. \nIn uncovering hidden emotions, micro-expression recognition \n(MER) in visual emotion analysis often performs better [64], [65], \n[66]. Ekman’s research showed that micro-expressions, as a \nspecific type of facial expression, are typically involuntarily \ndisplayed when individuals attempt to hide their true feelings, \nreflecting spontaneous facial movements in response to \nemotional stimuli [67], [68], [69]. Thus, micro-expressions \nprovide a valuable source of information for decoding authentic \nemotional states. Like general facial expression recognition, \nMER involves categorizing facial images or sequences into \ncorresponding emotion classes. However, detecting these \nfleeting, subtle facial movements is often more challenging [64]. \nEarly MER approaches also relied on manually crafted facial \nfeatures. Tools such as the Facial Action Coding System (FACS) \ndeveloped by Ekman [70] and the Micro-Expression Training \nTool (METT) provided researchers with essential prior \nknowledge for encoding features (for comprehensive reviews of \nMER’s historical evolution and technological advancements, see \n[71], [72], [73], [74]). In recent years, more advanced models, \nsuch as 3D Convolutional Neural Networks (3D CNNs) and \nRecurrent Neural Networks (RNNs), have been used to capture \nthe spatiotemporal characteristics of micro-expressions (e.g., \n[75], [76], [77], [78], [79], [80], [81], [82]). Despite significant \nprogress achieved using deep learning-based MER, challenges \nremain, particularly concerning datasets. Guoying Zhao and \ncollaborators [64], [83] found that although numerous micro-\nexpression datasets have been developed, most remain limited in \nsize, containing only a few hundred samples. Additionally, these \ndatasets often suffer from imbalanced emotion categories and are \npredominantly collected in laboratory settings, which limits the \ngeneralizability of MER models to real-world environments. \nPhysiological signals (e.g., EEG, skin conductance, and ECG) \nalso represent emotion-related indicators that are difficult to \nconsciously control, as they reflect central and autonomic \nnervous system activities associated with emotional states [84], \n[85]. Picard and her team utilized multi-channel signals from the \nautonomic nervous system to identify human emotional states. \nThey developed various wearable devices [86], [87] and non-\ncontact devices [88], [89] capable of recording physiological \nsignals such as skin conductance, heart rate, and physical activity \nin real-life scenarios. These physiological measurements provide \nobjective data to identify risk factors for high stress and poor \nmental \nhealth \n[90], \n[91], \n[92], \n[93]. \nMoreover, \nelectroencephalography (EEG) has become an essential signal \nfor recording central nervous system activity due to its non-\ninvasive, fast, portable, and cost-effective nature. EEG signals \nare widely used in fields such as entertainment, virtual reality, \nand e-healthcare for identifying emotional states [94], [95]. \nWhile \nEEG \nsignals \ndirectly \nreflect \nthe \nbrain’s \nelectrophysiological activity, linking them to the central nervous \nmechanisms of emotional states [96], practical challenges remain \nin model transferability and generalization. In EEG emotion \nrecognition research, researchers often address individual \ndifferences within the same dataset to construct models \ngeneralizable to all individuals [97], [98], [99], [100]). However, \nvariability in devices, experimental designs, and stimuli across \ndatasets necessitates further exploration of how knowledge \ntrained on one dataset can be transferred to others [96]. \nWhen external environments become overly complex, single-\nmodal signals are often affected by noise, resulting in reduced \nemotion recognition performance. Considering that humans \nexpress emotions through multiple modalities rather than relying \non a single channel, research has increasingly focused on \nmultimodal emotion recognition (e.g., [14], [101], [102], [103], \n[104]). Similar to single-modal approaches, multimodal emotion \nrecognition involves extracting features from raw data across \ndifferent modalities and training classifiers to predict emotional \nstates. However, inherent issues arise from asynchronous \nsampling rates across modalities, leading to misaligned data \nduring fusion [103], [105]. To address this, Tsai et al., [103] \ndeveloped a model based on the Transformer framework that \nfacilitates cross-modal interactions. The multi-head attention \nmodule in this framework allows for directional pairwise cross-\nmodal attention and further focuses on interactions between \nmultimodal sequences across varying time steps, achieving \nalignment and fusion of information. Additionally, recent studies \nhave focused on addressing feature space distribution gaps \ncaused by multimodal signal heterogeneity (e.g., [101], [102], \n[104]). In general, multimodal emotion analysis requires \nselecting appropriate single-modal emotion data and determining \na fusion strategy, which may occur at the feature level, decision \nlevel, model level, or through hybrid approaches [9], [106]. The \nsuccess of multimodal emotion analysis systems lies in the \ncareful choice of data and fusion strategy [73], which often \noutperform single-modal recognition systems [107]. \n\n5 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \n3.2 Modeling Emotional Generation Processes \nIn the domain of modeling emotional generation, appraisal \ntheories have become dominant. Many computational models \nbased on appraisal theories have been widely applied in human-\ncomputer interaction systems, particularly for generating \nemotional expressions in real-time interactive characters (e.g., \n[108], [109]). The central assumption of appraisal theories is that \nindividuals continuously monitor and evaluate changes in the \nenvironment that are relevant to their concerns, with emotions \narising from these evaluations [110], [111]. Lazarus [52] \nintroduced the concept of the “person-environment relationship” \nto describe the adaptive processes between agents and their \nenvironments. This relationship allows agents to derive the \nsignificance of external events relative to their beliefs, desires, \nand intentions, thereby generating or inferring emotional \nresponses. Some computational models do not explicitly \nrepresent these relationships but still support the derivation of \nevent meanings to produce emotional reactions. For instance, the \nEMA model (named in honor of Richard Lazarus’s book \nEmotion and Adaptation) [112] constructs causal explanations of \nthe current situation, incorporating beliefs, desires, and intentions. \nThese causal explanations generate appraisal frames for \nsignificant events, which in turn yield emotional responses based \non the outcomes of these appraisals. Other approaches have \nemployed Bayesian inference [113], [114], [115] or Partially \nObservable Markov Decision Processes (POMDP) [116] to \nmodel this derivation process. More recently, the Belief-Desire-\nIntention (BDI) software architecture, which simulates human \ncognitive processes [117], has been increasingly used to design \naffective agents (e.g., [118], [119], [120], [121]). These BDI-\nbased agents can not only model the process of emotion \nelicitation (i.e., how emotions are triggered based on the agent’s \nbeliefs, desires, and intentions) but also simulate the impact of \nemotions on cognitive processes and action choices [122]. \nThe cognitive appraisal theory proposed by Ortony, Clore, \nand Collins (OCC), [123] further refines the triggers for \nemotional generation by distinguishing between events, actions \nby others, and objects as different types of stimuli. Based on these \ntriggers, the theory provides a new classification scheme for \nemotions and establishes structural relationships between \nspecific appraisal variables and emotional labels. For example, it \nspecifies how combinations of appraisal variables can elicit \nemotions such as shame [124]. Due to its structured nature, the \nOCC model is considered a “computationally friendly” \nframework for modeling emotion generation [61]. Dias et al., \n[125] built the Fearnot AffecTIve Mind Architecture (FAtiMA) \nbased on the OCC model, which integrates planning capabilities \ninto affective agents. A key component of this architecture, \nOCCAffectDerivation, generates emotions based on appraisal \nvariables derived from the OCC model, such as desirability, \ndesirability-for-others, and praiseworthiness. For example, if an \nevent has a positive desirability value exceeding the pre-defined \nthreshold for joy, the model generates the emotion of joy. \nConversely, events with negative desirability may result in \ndistress. Other computational models also employ the appraisal \nvariables proposed in the OCC theory, including AR [126], EM \n[108], FLAME [127], ALMA [128] and GAMYGDALA [109]. \nHowever, as Hudlicka [61] noted, the highly structured nature of \nthe OCC model is a double-edged sword. On the one hand, its \ndetailed specifications provide a clear and systematic guideline \nfor computational representation of emotions. On the other hand, \nthe fine-grained descriptions of specific structures may not \nalways be necessary, as certain models might not need to \ndifferentiate between events, actions by others, or objects to \nderive emotions. \nIn addition to the OCC theory, other cognitive appraisal \ntheorists have proposed their own sets of appraisal variables that \nintelligent agents can use to generate distinct emotional responses, \ne.g., Frijda [129], Roseman [130], Scherer [131], C. A. Smith and \nEllsworth [132]. These variables include novelty, intrinsic \nvalence, certainty, goal conduciveness, agency, control, and \ncompatibility with personal or social standards [133]. While \nthese variables are less structurally detailed compared to the OCC \nmodel, they provide a unified framework for emotion \ncomputation, where specific emotions can be represented as \nvectors of appraisal variables. Scherer’s proposed variables [58], \n[110], [131] have been adopted in computational models such as \nWASABI [134] and PEACTIDM [135]. These theories clarify \nthe mapping between appraisal variables and emotional states, \nmodeling the appraisal process as the cause of emotion \ngeneration. Once the pattern of appraisal variables is determined, \ncorresponding emotional states can be derived through simple if-\nthen rules, often represented by discrete emotion labels [136], \n[137]. \nEarly computational appraisal models often employed \nsymbolic rule-based systems to map appraisal variables to \nspecific emotional states (e.g., [108], [127], [128], [134], [135]). \nHowever, with the rapid development of deep learning and neural \nnetwork technologies [63], [138], connectionist approaches have \ngained momentum. Researchers now use neural networks \ncomposed of numerous simple processing units to simulate the \nappraisal process [139], [140], [141]. Deep learning-based \naffective computing has become a dominant trend, as the strong \nfitting capabilities of deep neural networks allow them to model \ncomplex relationships between data without relying on explicitly \nprogrammed rules. Ong et al., [140] applied the paradigm of deep \nprobabilistic programming to affective computing, combining \ndata-driven (deep learning) and theory-driven (probabilistic \nprogramming) approaches to model uncertainties in the \nemotional generation process. Additionally, LLMs have \nintroduced new methods for simulating the appraisal process, as \nthey can generate semantically meaningful outputs based on \nextensive text datasets that may implicitly represent certain \nhuman psychological processes [142], [143]. In practice, Wei et \nal., [144] demonstrated that the performance of LLMs depends \nnot only on the model itself but also on the quality of prompts. \nThey proposed the “Chain-of-Thought” prompting concept, \nwhich uses step-by-step reasoning examples to guide LLMs, \nsignificantly enhancing their reasoning capabilities. Croissant et \nal. [145] applied this paradigm to simulate the emotional \nappraisal process. By integrating contextual information and \nrole-playing elements into a memory system, their approach \nallowed LLMs to evaluate situations and generate or infer \nemotions based on appraisal prompts. However, while LLMs \n\n6 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \ntrained with deep learning can provide contextually appropriate \nresponses based on semantic understanding [142], [146], [147], \nthey do not simulate the genuine emotional generation process. \nInstead, they produce statistically plausible responses based on \ninput data. Consequently, the performance of these deep \nlearning-based appraisal models remains limited by the quality of \ntraining data and the inherent statistical properties of the models \n[148]. \n3.3 Limitations of Current Affective Computing Models and \nFuture Directions \nBoth single-modal and multimodal emotion recognition \napproaches share a common foundational assumption: internal \nemotional states manifest in observable external and \nphysiological signals. These measurable signals are then mapped \nback to corresponding emotional states using discrete or \ndimensional models. Discrete models classify emotions into a \nfinite set of categories. Among them, Ekman’s basic emotion \ntheory and its variants have been widely applied in emotion \nrecognition research. Ekman proposed that certain emotions (e.g., \nanger, disgust, fear, happiness, sadness, and surprise) are \nuniversally present across cultures and assumed that each basic \nemotion corresponds to distinct response components (e.g., facial \nexpressions and physiological reactions) that tend to co-occur \nduring emotional episodes [50]. \nHowever, empirical studies have shown that even when \nresearchers use the same emotional labels, the described \nemotional states often differ [149], [150]. Additionally, current \nneuroimaging techniques have not provided evidence supporting \nthe existence of distinct “neural fingerprints” for each basic \nemotion [151]. While Ekman acknowledged the existence of \nvariants within each basic emotion family and the blending of \nemotions at specific moments, he also maintained that the \nboundaries between basic emotion categories should remain \ndistinct. Neuroscientific research increasingly highlights that \ncomplex psychological phenomena, including emotions, are \nmediated by distributed neural activation networks [152]. This \nsuggests that, from a neurophysiological perspective, clear \nboundaries between different categories of basic emotions may \nnot exist [60]. In fact, contemporary psychology research places \ngreater emphasis on the functional labels of basic emotions. \nMany studies suggest functionally distinguishing basic emotions; \nfor instance, “disgust” can be further categorized into emotional \nresponses to contamination versus destruction, reflecting \ndifferent adaptive problems [149], [153], In animal studies, \nresearchers have linked emotional elicitation contexts, neural \ncircuits, and observable behaviors, documenting responses \nresembling basic emotions. However, researchers often avoid \ncolloquial emotional labels such as “joy” or “fear” and prefer \nmotivational behavioral labels like “wanting” or “defense” to \ndescribe these reactions [44], [154], [155]. \nThe computational models in emotion recognition have yet to \nincorporate the functional characteristics of emotions fully. Even \nmodels based on dimensional theories have similar limitations \n(e.g., [156], [157]). While these techniques are valuable for \napplications such as public opinion monitoring, sentiment \nanalysis, and health management, they often fall short of \nachieving the ultimate goal of creating affective agents capable \nof truly understanding user emotions and providing appropriate \nresponses. Key questions remain unanswered: What constitutes \na “correct response” in affective interaction systems? What \ndefines a “natural and smooth” interaction? Answering these \nquestions requires a teleological perspective to understand the \nentire process of emotion generation and its functional \nsignificance. Currently, emotional response systems typically \nfollow a default approach: reading human emotional cues, \ncategorizing emotions, and responding based on predefined \npatterns. In these designs, the complexity and diversity of \nemotions are often reduced to fixed categories and preset reaction \npatterns. While convenient to implement, these designs overlook \nthe deeper purposiveness and dynamism of emotions, making \nthem less adaptable and realistic in long-term interactions. For \ninstance, Terzis et al. [158] designed an emotion feedback system \nemploying parallel and reactive empathy to manage learners’ six \nemotional states (happiness, anger, sadness, surprise, fear, and \ndisgust). When a learner displayed fear, the system first mirrored \nthe emotion through parallel empathy, using fearful facial \nexpressions and vocal tones, and then shifted to joyful \nexpressions and tones (reactive empathy) to alleviate the \nlearner’s fear and encourage continued efforts. While practical, \nthis approach has inherent flaws. Firstly, the psychological \nvalidity of such categorical classifications remains debated. \nSecondly, the lack of understanding of the teleological principles \nbehind emotions limits the system’s ability to influence and alter \nusers’ emotional states effectively. In psychology, empathy \ninvolves perceiving the inner subjective world of another person, \nunderstanding their sources of distress or sorrow, and conveying \nmeaningful responses. Emotional generation is thus a \nconstructive process, deeply individualistic [27]. Predefined \nuniform responses cannot adequately simulate genuine emotional \nresponses.  \nPrimarily focuses on individual-level dynamics, appraisal \ntheory enables agents to generate or understand emotions based \non their evaluations of psychological events concerning their own \nor others’ concerns. It addresses key questions: How are specific \nemotions mapped from stimulus events? Are these mappings \ndirect, or do they involve intermediate appraisal processes (e.g., \nnovelty, desirability, or agency)? How do internal stimuli (e.g., \nmemories or anticipated events) interact with external stimuli \n(reflecting contextual features) to jointly influence emotion \ngeneration? Answering these questions allows continuous \ncomparison between environmental changes and individual \naffective concerns, providing opportunities to operationalize \nteleological principles in emotional machines. Accordingly, \nsome computational appraisal models enable developers to set \nspecific affective concerns for affective agents [109]. These \nconcerns allow agents to perform personalized actions based on \ntheir internal goals. However, such hand-designed affective \nagents can enhance user experiences only in narrowly defined \nscenarios, such as gaming, and often fail to respond to the \naffective concerns of individuals during complex interactions.  \nMoreover, models trained on large datasets and deep learning \ntechniques can offer statistically optimal solutions at the group \nlevel. However, just as group-level relationships cannot fully \n\n7 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \nreplace individual relationships [159], solutions appropriate for \ngroups cannot be entirely applied to individuals. Behavioral \nsciences use longitudinal data collection to better separate within-\nperson and between-person effects [160]. Recent advancements \nin LLMs have enabled personalization by recording detailed \ninteraction histories and preferences, achieving alignment with \nusers [161]. In human-computer interaction, personalized \naffective computing models have also emerged, leveraging \ntechniques like fine-tuning and multi-task learning [162]. \nTherefore, modeling individual affective concerns using these \ntechnologies represents the next critical goal for affective agents. \n4. TELEOLOGY-DRIVEN AFFECTIVE COMPUTING  \nIn Section 3, we reviewed the major research directions and \nsignificant achievements in the field of affective computing, \nalong with a detailed analysis of the theoretical foundations \nbehind these advancements. We identified that these studies lack \nexplicit standards and principles for affective interaction at the \ntheoretical level. Hence, in this section, we first propose design \nprinciples for interactive affective agents based on teleological \nperspectives — aligning with personal/individual and even \ngroup/collective well-being over extended time scales. \nSubsequently, we discuss the database and algorithmic models \nrequired to align with these principles. The integration of these \ndatabase and models can help capture the complexity of affective \ndynamics, revealing the multidimensional characteristics of \nemotions and their causal relationships. Ultimately, this \nframework aims to construct a comprehensive teleological \naffective computing paradigm, transitioning from theoretical \nprinciples to corresponding data and algorithms (see Figure 1). \n \nFigure 1. Overview of the teleological affective computing \nframework. This research framework comprises response \nprinciples, dataset construction, and algorithm models. Based on \ntwo core response principles (highlighted in blue) — aligning \nwith personal/individual well-being and group/collective well-\nbeing — the process begins by collecting individual-level \naffective event data to construct a personal affective event \n“dataverse.” On this basis, causal inference is employed to \nestablish generative models of personal affective events. These \nmodels are then used to train agents in virtual environments for \neffective \nactions. \nUltimately, \nthrough \nrepeated \nmeta-\nreinforcement learning simulations of human-agent interactions \nin virtual settings, agents dynamically adapt and optimize their \nalignment with both individual and group/collective well-being. \n4.1 Principles of Affective Interaction Guided by Teleology \nAs highlighted in Section 2, the predominant emotion theories \nconverge in advocating teleological principles from different \nperspectives. Schiller et al. [24] describe this principle as a \ncomprehensive synthesis of existing emotional theories. They \ncharacterize emotions as phenomena where actions are \nperformed based on an individual’s comfort zone (addressing \naffective concerns) while monitoring the adaptation process \n(displaying affective features). For participants in affective \ninteractions, understanding each other’s affective concerns is \neven more critical than identifying immediate affective states. \nAffective concerns represent the causes, explanations, and \nrelationships between individuals and physical or psychological \nobjects in their environment. Interaction participants can only \ninfluence or modulate the other’s emotional experience \neffectively by understanding the objects that underpin their \naffective concerns. These concerns are structured hierarchically, \nstarting from an individual as the reference point, organized from \nproximal and specific to distal and abstract levels [24]. However, \nthe hierarchical nature of affective concerns still fails to explain \ntrade-offs among different concerns over extended time scales, \nraising questions about how individuals define their overall \noptimal state. \nTo address this, Schiller et al. [24] propose a global concern \nalgorithm to summarize hierarchically structured concerns at \nbroader temporal scales. Global concerns transcend specific \nobjects, encompassing all object-specific concerns — frequently \nreferred to in affect research as personal well-being [52], [56], \n[110], [129], [163], [164]. This construct represents the synthesis \nand prioritization of hierarchically structured concerns, guiding \nindividuals in choosing among multiple competing concerns. \nNotably, fulfilling hierarchical concerns does not always \ncontribute to global concerns. For instance, gambling can provide \nexcitement (a heightened physiological pleasure) for some \nplayers, sustaining long-term participation. However, as with all \naddictive behaviors, such prolonged engagement sacrifices other \nhierarchical concerns. Gamblers might spend excessive money, \nneglect relationships, or abandon academic and career goals. \nEven if gambling yields temporary positive experiences, this \nstate is unlikely to be termed “well-being.” Becker and Bernecker \n[165] explored the relationship between immediate pleasures and \nlong-term goals in self-control research, noting that pursuing \nhedonistic activities often incurs opportunity costs, limiting \nenjoyment. \nThe conflict between global concerns and hierarchical \nconcerns embodies tensions between the whole and its parts, \nlong-term versus short-term, and differing levels of positivity. S. \nYu [166] suggested that higher-level well-being is not merely the \nsum of positive states. Temporary negative emotions can create \nconditions for overall positivity. Particularly when pursuing \nhigher-level affective concerns, individuals often endure \ncomplex actions and environmental interactions. During these \nprocesses, setbacks might evoke short-term negative emotions \nthat lay the groundwork for subsequent positive feedback. For \nexample, researchers experiencing academic setbacks may feel \nfrustration and disappointment, yet these emotions can prompt \n\n8 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \ncritical reflection, improving strategies and leading to valuable \ninsights. Negative emotions, under specific circumstances, do not \nimpede long-term development but foster higher-level efforts and \noverall positive transformations [166]. Our ultimate pursuit is not \nmoment-to-moment positive experiences but optimal affective \nstates across extended time scales. Trajectories aligned with \nglobal concerns lead to positive mood, while deviations foster \nnegativity. When all energy aligns efficiently with global \nconcerns, the organism achieves optimal adaptation to its \nenvironment, experiencing a state of effortless control and order, \nreferred to as “flow” [167], [168]. \nThe complex dynamics of positive and negative transitions in \naffective phenomena motivate a dynamic perspective defined by \nthe multilayered interconnectedness of human experiences [166], \n[169]. Active inference provides a valuable framework for \ninterpreting these dynamic processes. Its foundational principle \ninvolves comparing the brain’s internal models with the external \nenvironment to generate predictions, which are then iteratively \nadjusted based on actual feedback. This dynamic feedback \nregulation enables individuals to minimize cognitive errors and \noptimize responses to environmental stimuli by updating beliefs \nand behaviors [170], [171]. Under the active inference \nperspective, the valence component of emotion is modeled as the \nrate of error dynamics. Slower-than-expected error reduction \nsignifies negative valence, while faster-than-expected error \nreduction indicates positive valence [172], [173], [174], [175]. \nExpanding this concept, Miller et al., [175] distinguished \nbetween local and global error dynamics to explain the difference \nbetween transient and enduring happiness. Local dynamics \ninvolve adjustments to specific action strategies, reflecting task-\nspecific performance in reducing predictive errors. Global \ndynamics concern an individual’s overall predictive performance \nacross multiple life domains, reflecting how uncertainties are \nmanaged over a lifetime. To maintain mental well-being, \nindividuals must balance local and global error dynamics, \noptimizing resource allocation between maintaining current \nstrategies and seeking new ones. While reducing predictive errors \nwithin specific domains is crucial, individuals must also address \nmultiple affective concerns across their lives, reallocating \nresources to sustain growth and adaptability. Through this \nbalancing act, individuals adapt to environmental challenges \nwhile introducing temporary uncertainties to foster growth and \nskill acquisition. \nBased on the multilayered analysis of affective phenomena, \nwe can define three hierarchical principles for interactive \nresponses between affective agents and humans (see Figure 2): \n1) Aligning with individual hierarchical concerns. The \naffective agent can calculate the relevance of a particular stimuli \nto the individual and help the individual reduce prediction errors \nin specific tasks; 2) Aligning with personal/individual well-\nbeing. The affective agent is capable of calculating the relevance \nof multiple objects to the individual, and also flexibly modeling \nthe process by which the individual updates the weights of \ndifferent hierarchical concerns over a longer time scale, based on \ncontextual changes; 3) Aligning with group/collective well-\nbeing. The affective agent can simultaneously consider the well-\nbeing of all directly or indirectly interacting individuals and seek \nways to maximize group/collective well-being. Ideally, the \naffective agent should be human-centered, providing highly \npersonalized responses. This not only requires the agent to \nunderstand the hierarchical concerns of the interacting \nindividuals, but also to guide the individual toward broader \nglobal concerns through responses, interactions, and engagement. \nIt can not only recognize an individual’s current needs and \nemotions but also promote the enhancement of both individual \nand even group/collective well-being over a longer time scale. \n \nFigure 2. Three-layered interaction principles under \nteleological guidance: aligning with individual hierarchical \nconcerns, aligning with personal/individual well-being, and \naligning with group/collective well-being. \nThe different-colored cubes represent various objects in the \nenvironment, while bidirectional arrows indicate relationships \nbetween individuals and objects. Aligning with individual \nhierarchical concerns requires the agent to calculate specific \nassociations between the individual and each object, helping to \nreduce prediction errors for specific tasks but failing to resolve \nconflicts between tasks. Aligning with personal/individual well-\nbeing involves prioritizing hierarchical concerns in a context-\nsensitive manner across the time scale represented by the arrows. \nAligning with group/collective well-being goes further by \nsimultaneously \nconsidering \nthe \nwell-being \nof \nmultiple \nindividuals, making trade-offs among different interactive \nobjects to maximize group benefits.  \n \n4.2 Develop a “Dataverse” of Personal Affective Events \nBreakthroughs in deep learning owe much to the availability \nof \nlarge-scale \ndatasets \n[176]. \nSimilarly, \nconstructing \ncomputational models that align with well-being requires first \ncollecting data that reflect human growth and well-being. As \ndiscussed earlier, teleological perspectives on affects consider \naffective phenomena as arising from adaptive interactions \nbetween agents and their environments. This concept resonates \nwith ecological psychology, which examines how individuals’ \npsychology and behavior are shaped by natural and social \nenvironments over extended time scales. The roots of ecological \n\n9 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \npsychology can be traced to James Watson’s behaviorism, which \nemphasized the connection between micro-environments and \nbehavioral responses [177]. In developmental psychology, \nBronfenbrenner, influenced by Lewi’s field theory and \nVygotsky’s sociohistorical perspective, proposed an ecological \nsystems theory that systematically analyzed the nested structures \nof environments individuals inhabit [178], [179], [180]. Building \non these foundations, psychologists from diverse domains —\ncognition, development, motivation, and personality —\nintroduced finer-grained concepts and theories to describe \nhuman-environment interactions. Schiller et al. [24] argue that \nagents in interactions actively orient toward their concerns, \nwhich define the content of affective experiences. Dweck [181] \nposited those three fundamental psychological needs —\nacceptance, \npredictability, \nand \ncompetence — underpin \nmotivation and personality, significantly influencing personal \nwell-being and growth, particularly in early life. Extending this, \nDweck identified four needs — trust, control, self-esteem/status, \nand self-coherence — arising from combinations of basic \npsychological needs. These often demand complex schemas and \nmetacognitive skills. Comparing Schiller et al. [24] and Dweck \n[181], we find that Schiller’s operational concerns align with \nDweck’s needs for trust, control, and self-esteem/status. Self-\ncoherence, a synthesis of these needs, forms the core of all \nconcerns. By monitoring self-coherence, individuals can closely \ntrack their well-being, consistent with Schiller’s concept of \nglobal concerns (see Figure 3). Thus, adaptation to the \nenvironment can be seen as agents balancing different concerns \nor needs based on environmental affordances. \nFigure 3. Structural model of affective events. \nThe generation of affective events can be described using the motivational framework proposed by Urhahne and Wijnia [184]. The \ncentral circular arrows represent the dynamic interaction between the self and the situation. The model starts with the “Self,” which \ninteracts and adapts to the situation through beliefs, goals, actions, and outcomes/consequences to generate specific affective \nexperiences. The blue box on the far left contains components defining an individual’s unique basic needs or concerns. According to \nDweck’s [181] basic need theory, three core needs — competence, predictability, and acceptance — combine to form self-coherence. \nTheir pairwise combinations further represent more complex psychological needs: self-esteem/status, control, and trust. The concerns \noutlined in Schiller et al. [24] align well with these psychological needs, as the dashed box indicates. Inspired by Bronfenbrenner's \n[178] ecological systems model, the green box on the far right describes interactive situations more precisely through social, cultural, \nand environmental contexts. Finally, the red box at the bottom represents the features of affective experiences, including valence, \narousal, and persistence.  \n \nAlthough humans share universal needs, individuals differ in \nthe emphasis placed on these needs. For instance, some prioritize \nself-esteem and social status, seeking recognition and \nachievement, while others value trust and security, favoring \nstable relationships and environments. These variations also \nextend to how individuals fulfill these needs. To achieve need-\nrelated goals, individuals must hold beliefs supporting successful \ngoal attainment, shaped by past interactions with their \nenvironments [181]. As individuals develop, their needs may \nevolve throughout life, further amplifying individual differences \n(see Figure 4). Considering these individual differences, it \nbecomes crucial to build personalized affective models. This \nprocess requires moving beyond aggregated group data to \nindividual-level data collection and modeling. Abstract statistical \nsummaries (e.g., means or prototypes) often fail to capture \nindividual uniqueness adequately [182]. Research in education \nby Saqr et al., [183] highlights the limitations of models trained \non aggregated data for individual-level predictions, emphasizing \nthe importance of collecting and analyzing individual data. \nDifferences in individuals’ dependency on various needs \ndefine each unique self, serving as the motivational starting point \nfor behavior [184]. Needs and concerns shape key domains for \npersonal/individual well-being and optimal development — the \n\n10 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \n“comfort zone” — while also providing the motivational drive to \nfulfill these needs [181], [185]. The integrated framework \nproposed by Urhahne and Wijnia [184], which differentiates \ndimensions of motivation such as self, goals, actions, outcomes, \nand consequences, illuminates how individuals interact with their \nenvironment based on needs, generating emotional experiences. \n \nFigure 4. Inter-individual and intra-individual differences in \nhierarchical \naffective \nconcerns \n(expectations \nfor \npsychological need fulfillment). Horizontal comparisons \nillustrate variations in the composition of psychological needs \nacross individuals, representing inter-individual differences. \nVertical comparisons show how an individual’s need \ncomposition changes across different stages of growth and \ndevelopment, representing intra-individual differences. \n \nSynthesizing Schiller et al.’s explanation of affective \nphenomena \n[24], \nDweck’s \nbasic \nneed \ntheory \n[181], \nBronfenbrenner's ecological systems theory [178], and Urhahne \nand Wijnia’s motivational framework [184] allows for a finer-\ngrained analysis of affective generation processes (see Figure 3). \nWhen analyzing individual affective experiences, beyond \nconsidering valence and arousal, we introduce the dimension of \npersistence. While most emotion studies focus on momentary \nintensity, variations in affective persistence offer critical insights \ninto long-term affective impacts [186]. Neuroscientific studies \nsuggest that affective experiences can “spill over” to other stimuli \ndue to sustained amygdala activity following affective arousal \n[187], [188]. Affective persistence is closely linked to individual \nhealth and well-being [189]. Thus, incorporating persistence into \naffective experience analysis helps identify emotionally \nimpactful events in daily life. \nBy integrating these diverse theoretical perspectives, we can \nbetter describe emotionally significant events for individuals and \ndesign corresponding data collection methodologies. Each data \nentry should provide a comprehensive description of the affective \nevent: the context in which the individual acted, the beliefs \nguiding their choices, the goals they pursued, the actions they \nundertook, the outcomes they achieved, and the extent to which \nthese outcomes satisfied or failed to satisfy their internal concerns \nor needs, ultimately eliciting specific affective experiences. \nWithin this theoretical framework, each variable can exhibit \nmultiple dimensions rather than being limited to scalar values \nwith two extreme endpoints. \nThese affective event datasets, collected on an individual \nbasis, essentially sample the life histories of individuals. Each \nsmall data subset represents an individual’s adaptation process to \nthe environment over a specific period. These fragments form a \nlarge-scale database of affective events that captures trajectories \nof affective phenomena across countless human individuals and \nother affective agents in not only various contexts but also \ndocuments affective dynamics at the group level (see Figure 5). \nThis group-level entity is not a simple aggregation of individuals \nbut \na \nunique \n“whole” \nwith \ndistinctive \npsychological \ncharacteristics and affective concerns [190]. In fact, the data used \nto train models is far more critical than often realized. \nMuttenthaler et al. [191] demonstrated that the scale and \narchitecture of neural networks have a smaller impact on the \nconsistency between model representations and human behavior \nthan the training dataset and objective functions. Similar to how \nImageNet [192] advanced breakthroughs in visual recognition \ntasks through large-scale, high-quality datasets in computer \nvision, this affective event “dataverse” serves as the foundation \nfor affective computing, offering immense potential. It can \ndirectly address the question central to AI: “What should we \nlearn?” Unlike static datasets constructed in laboratory settings, \nthese affective event datasets must be captured dynamically in \nreal-life situations to authentically reflect the affective adaptation \nprocesses of individuals and groups. \n \nFigure 5. Schematic representation of the affective event \n“dataverse.” The blue concentric circles represent the horizontal \nscope of the affective event “dataverse,” encompassing the \naffective trajectories of individuals, groups, and cross-species \naffective agents. The spiral arrows symbolize the temporal \nevolution of affective events, illustrating the longitudinal \ndynamics of affect. These fragments of affective events converge \ninto a large-scale affective event “dataverse,” capturing the \naffective trajectories and dynamic adaptations of diverse entities \nin multifaceted contexts. \n \n\n11 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \nIn this context, dynamic assessment methods provide \neffective tools for capturing people’s momentary states in \neveryday life [193], [194], [195]. Representative approaches \ninclude Ecological Momentary Assessment (EMA) [194] and \nDay Reconstruction Method (DRM) [196]. EMA uses \nrandomized sampling multiple times a day to capture the \ndynamic changes in affective events at high frequency, including \ncontextual features, belief states, and immediate reactions, while \nminimizing recall bias. This real-time collection method not only \nrecords the interaction process between individual goals and \ncontexts but also reveals patterns in how affective experiences \ndynamically evolve with contextual changes. In contrast, DRM \nprovides a more macroscopic perspective, requiring participants \nto reflect on and document major affective events over the course \nof a day. This method is suitable for capturing the trajectories of \nsignificant affective events and helping individuals summarize \ntheir satisfaction of personal needs over longer time scales. \nThrough DRM, researchers can analyze how multidimensional \nfeatures of affective events intertwine over time and track the \nrealization of affective concerns. Combining these two \napproaches enables a multi-level data collection strategy that \ncaptures both micro-level details of momentary states and macro-\nlevel trends of affective events. The complementary nature of \nreal-time and retrospective methods allows for a more precise \nmapping of the complex structure of affective events. \nBeyond sampling and observing individuals’ everyday states, \nImmersive Virtual Reality (IVR) technology offers new \npossibilities for collecting intervention data on affective events. \nCurrently, IVR technology is widely applied in education [197], \n[198], [199] and memory research [200]. By constructing highly \nimmersive virtual environments, IVR enables researchers to \nprecisely control situational variables and observe individuals’ \naffective responses under different conditions. This is \nparticularly useful for studying affective events in real life that \nare difficult to capture or cannot be repeated [197], [201], [202] \n— such as dangerous situations, rare affective experiences, or \nhigh-pressure \ndecision-making \nprocesses. \nIn \nvirtual \nenvironments, researchers can create scenarios such as public \nspeaking, social conflicts, or emergency rescues while \nmanipulating environmental factors to explore how these \nelements influence affective events’ occurrence and development. \nAdditionally, IVR can elicit affective responses closely \nresembling real-world reactions, enhancing the ecological \nvalidity of affective data. For instance, simulating failure or \nsuccess in a virtual setting allows researchers to directly observe \nhow changes in goal achievement or need satisfaction affect \nindividuals’ affective states. \nHowever, whether using dynamic assessment or IVR \ntechnologies, obtaining user data requires addressing privacy and \nsecurity concerns. Unlike traditional machine learning methods \nthat rely on centralized databases, federated learning allows \nmultiple users (clients) to collaborate in training a shared global \nmodel without sharing local device data, thereby protecting user \nprivacy while enabling cross-device collaboration [203]. \nAdditionally, anonymization remains a primary method for \nreducing privacy risks in data sharing, ensuring that anonymized \ninformation cannot be traced back to individuals, thus posing no \nthreat to user privacy [204]. \nApart from privacy issues, data bias is another critical \nchallenge. Data collected by researchers for various purposes \ninevitably carries inherent biases. Increasingly, philosophers of \nscience acknowledge that the ideal of purely value-neutral \nscience is unattainable, as all scientific practices inevitably \ninvolve value judgments [205]. Although bias is not a new issue, \ndata-driven AI models may amplify existing biases or even create \nnew ones [206]. Affective event data collected via dynamic \nassessment and IVR technologies may similarly be prone to \nbiases. In dynamic assessment, biases often arise from \nparticipants’ memory distortions, which are influenced by \nselective recall and temporal factors. In IVR, biases may result \nfrom discrepancies between virtual scenarios designed by \nresearchers and real-world contexts, potentially impacting \nparticipants’ affective responses and experiences. To mitigate \nthese issues, researchers can increase the diversity and \nauthenticity of scenarios and use repeated sampling and recall to \nreduce memory distortions in data. Moreover, enhancing the \nrealism of virtual scenarios and participants’ immersion ensures \nthat scenarios are more closely aligned with real-life experiences, \nreducing biases introduced by virtual settings. \nFinally, to implement this data collection approach across \nbroader populations and contexts, we recommend small-scale \npilot studies in volunteers’ everyday environments. These pilots \ncan address key issues in data collection, such as the effectiveness \nof scenario design, bias control, and privacy protection measures. \nAfter resolving these challenges, the approach can be scaled to \nmore diverse populations and contexts, enabling large-scale, \ngeneralized affective event data collection. This iterative process \nallows for continuous optimization of data collection methods, \nenhancing data quality and providing richer, more accurate \ntraining data for subsequent model development. \n4.3 \nConstructing \nAffective \nAgents \nAligned \nwith \nPersonal/Individual and Group/Collective Well-Being \nIn addition to high-quality datasets, designing algorithmic \narchitectures for training affective agents aligned with \npersonal/individual and group/collective well-being is equally \ncritical. We define “alignment with well-being” as an agent’s \ncapacity to modify the external world through actions to better \nreflect personal/individual or group/collective preferences. In \ncognitive psychology terms, this goal requires the agent to \npossess a theory of mind, enabling it to infer the mental states of \nothers. This overarching objective can be decomposed into two \nkey sub-tasks: (1) Inferring the causal structure underlying \nindividual affective event data to accurately simulate real \nindividuals with unique comfort zones; and (2) utilizing this \nsimulator to interact with affective agents, allowing them to \nlearn, through environmental feedback, how to align \npersonal/individual or group/collective well-being over the \nlong term. In this section, we explore how to construct affective \nagents \ncapable \nof \naligning \npersonal/individual \nand \ngroup/collective well-being by addressing these two tasks and \ntheir interrelations. Notably, the goal is to clarify challenges and \ndirections rather than provide a fully developed implementation \nplan. \n\n12 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \n4.3.1 Generative Models for Real Individuals: Causal Modeling \nof Personal Affective Events \nHumans \ntypically \nunderstand \na \nspecific \nperson’s \npsychological state and predict their responses in future situations \nby observing and interacting minimally. This is done in an \nunsupervised manner, independent of any specific task, \nespecially as relevant affective event experiences accumulate \nover time. For example, when reading Hamlet, although the plot \ndoes not explicitly state it, readers can infer from Hamlet’s \nactions that he feels anger and sadness due to the death of his \nfather and the remarriage of his mother. Additionally, we can \nmake counterfactual inferences: if Hamlet’s father had not died \nor if his mother had not married his uncle, Hamlet’s affective \nstate might have been entirely different. Through this, we can \nquickly grasp the hidden causal relationships behind affective \nevents of characters, even with limited information, and predict \npossible affective changes. As affective experiences accumulate, \nwe are able to effectively infer how an individual will respond \nemotionally in specific situations and determine whether these \naffective experiences will persist. However, this task is \nchallenging for machine learning models based on statistical \napproaches. Most of the success of machine learning is attributed \nto large-scale pattern recognition on independently and \nidentically \ndistributed \n(i.i.d.) \ndata, \nwhich \nestablishes \ndependencies between variables [207]. In the field of affective \ncomputing, it can model the correlation between externally \nobservable information and an individual’s internal affective \nexperience. For example, how likely is a specific facial \nexpression to indicate happiness? Given the observed weather \nconditions and activities, a person is engaged in, what is the \nprobability that they are experiencing a particular affective state? \nWhile these association-based predictions can achieve a \nreasonable level of accuracy, they may still fall short of truly \nguiding affective interactions. In the aforementioned example, a \nfacial expression recognition model can determine that a person’s \nexpression shows anger, but if we ask, “If this person were \nsmiling instead of frowning, would they still be angry?” the \nmodel would typically be unable to answer. Even if it can tell us \nthe correlation between “anger” and “frowning,” it cannot predict \nhow the affective state would change if the facial expression \nchanges. This is because statistical models are accurate only \nunder certain assumptions and within the same experimental \nrange, and applying interventions changes the data distribution, \nleading to inaccurate predictions [207], [208], [209], [210]. \nSimply learning statistical correlations between variables \ndoes not generalize well to non-i.i.d. data; it requires the learning \nof underlying causal models [208]. Unlike correlations between \ndata, causal relationships focus on structural knowledge of the \ndata-generating process, which allows for interventions and \nchanges, enabling agents to act in the imaginative space [207]. \nRecent research by Richens and Everitt [211] indicates that \nlearning causal models of the data-generating process is essential \nfor agents to cope with large-scale distributional changes. Only \nby recognizing causal relationships between features and labels \nin training data can agents adapt to changes in covariates and \nlabels. In fact, a key characteristic of human cognitive ability is \ninferring underlying patterns and structures from sparse data \n[212], and causal structure learning is considered a pathway to \nachieving AI similar to human cognition [213]. In the field of \naffective computing, this means we need to build models about \nindividuals from affective event data to faithfully simulate real \nindividual responses in various changing contexts. \nFor a long time, psychologists have attempted to identify a \nfew key variables that lead to specific affective experiences and \nexplore the possible causal relationships between these variables \nthrough experiments. In this process, other variables that may \nhave weaker correlations are often treated as environmental noise. \nWhen affective instances emerge from a complex causal network \nfull of relevant meaning, this approach can lead to an explosion \nof potential variable combinations [182]. Let’s imagine the \nspecific process of affective generation. When hiking in the forest, \na sudden sound from the grass triggers your fear response. This \nemotion is not directly caused by the sound itself but could \ninvolve multiple factors. Your prior experience, such as having \nbeen attacked by wild animals before, links this sound to danger. \nThe current environmental uncertainty, such as the darkness and \nsilence of the forest, amplifies your unease. Your physiological \nstate, such as tension or fatigue, makes your body more sensitive \nto the sound, with physiological reactions like rapid heartbeat and \nsweating further intensifying your fear. Cultural interpretations \nof forest sounds might also lead you to perceive the sound as an \nominous omen. These factors do not simply add up but interact \nnon-linearly, forming a complex causal network, meaning the \ngeneration of fear is a dynamic, individualized process rather \nthan a direct result of a single factor [182]. \nOne of the core assumptions of interactionist approaches is \nthat there is a complex relationship between behavior and the \ncontext in which an individual finds themselves [214]. Contexts \ninclude not only the physical world at specific times and places \nbut also the socio-cultural background. Affective experiences \narise from the dynamic interaction between an individual’s \ninternal environment and the external context. An individual’s \ninternal environment is defined by a set of variables, including \nneeds, goals, and beliefs, all of which combine to form the current \nstate of the individual. Affective event data from an individual’s \nexperience is longitudinal research conducted over time in \ndifferent environments. These observational data violate the \nassumption of independent and identical distribution, preserving \nonly structural independence, thus effectively supporting the \nidentification of causal structures [207], [208], [215]. However, \nthese direct observations of the real world often do not directly \ninclude the causal variables we are interested in; instead, we need \nto learn the representations of these variables from the raw data. \nCausal representation learning focuses on learning these \nvariables from raw high-dimensional data [207]，The raw data \nD is transformed into a joint distribution sample X of n causal \nvariables, represented as: \n( )\nX\nD\n\n=\n \n \n \n   (1) \nwhere  is a neural network serving as a nonlinear function, \nmapping causal variables to their joint distribution samples \n，and each causal variable is a d-dimensional vector. \nDue to the diversity of data sources, emotional event data may \n\n13 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \ninvolve multi-modal information such as text, speech, and video, \nso a unified representation method must be found for these \nvariables. Recent studies have addressed this issue by embedding \ninputs from different modalities into a common space where \nsemantic similarity is related to distance [216]. Moreover, some \njoint representation learning methods allow direct comparison of \ndifferent multi-modal information [217], [218], [219]. \nThe relationships between variables can be represented as a \nDirected Acyclic Graph (DAG) based on an adjacency matrix A, \nwhere the elements of A describe the dependencies and directions \nbetween the variables. Causal structure learning aims to infer a \nweighted adjacency matrix that describes these relationships \nfrom X. A common approach to achieve this is through Structural \nEquation Modeling (SEM). SEM provides a framework for \nestablishing causal path models from variables to outcomes by \nassuming linear or nonlinear relationships between them. \nSpecifically, SEM views each variable as a linear combination of \nother variables plus a noise term, and the weights and directions \nof the adjacency matrix are estimated through optimization \nmethods [220]. The mathematical relationship between the \ncausal graph structure and the samples can be described by a \nlinear generative model: \n                \n(\n)\n1\n+ =\n-\nT\nT\nX Z\nI A\nZ\nX\nA\n−\n=\n \n \n(2) \nwhere the noise variable z is used to model exogenous \nvariables that are not explicitly included in the causal structure. \nEquation (2) indicates that each observed variable Xi can be \nregarded as a linear weighted combination of its direct causal \nparent variables, plus an independent noise term Zi. This \nexpression can be further extended to non-linear transformations, \nas demonstrated by Y. Yu et al. [220], who used parameterized \nneural networks to perform non-linear transformations on Z and \nX, providing a more general version of SEM. \nIn the Bayesian inference framework, the learning of \ngenerative models aims to infer the parameters of the model \nthrough observed data, thereby characterizing the causal structure \nand generation mechanism between variables. Given the \nobserved samples \nk\nX  and the distribution of latent variables \n( )\np z , the generative model is learned by maximizing the log \nmarginal likelihood: \n(\n)\n(\n)\n1\n1\n1\n1\nlog\nlog\n,\nn\nn\nk\nk\nk\nk\np X\np X\nz dz\nn\nn\n=\n=\n=\n\n\n\n      (3) \nHowever, the marginalization integrals involved in this \nequation are often difficult to compute analytically, so variational \ninference methods are commonly employed in practice. \nVariational inference approximates the true posterior distribution \n(\n)\n|\nk\np z X\n by introducing a parameterized variational posterior \ndistribution (\n)\n|\nk\nq z X\n and optimizing the evidence lower bound \n(ELBO), which serves as a substitute for directly maximizing the \nlog marginal likelihood. For a single sample, the ELBO is \nexpressed as: \n(\n)\n(\n)\n( )\n(\n)\n(\n)\n(\n)\n|\nlog\n|\n||\nlog\n|\nk\nk\nk\nELBO\nk\nk\nk\nELBO\nKL\nq z X\np X\nL\nL\nD\nq z X\np z\nE\np X\nz\n\n\n\n= −\n+\n\n\n(4) \nwhere the first term is the Kullback-Leibler (KL) divergence \n(≥0), which measures the closeness of the variational posterior  \n(\n)\n|\nk\nq z X\nto the prior distribution \n( )\np z , and the second term \nmeasures the reconstruction capability of the generative model \nunder the variational posterior. In generative models, the variable \nz is used to reconstruct \nk\nX with a probability density (\n)\n|\nk\np X\nz . \nThe adjacency matrix A is a parameter that needs to be learned. \nBy maximizing the \nk\nELBO\nL\n, we can efficiently approximate the \ntrue posterior distribution and infer the adjacency matrix A in the \ngenerative model. To ensure that the learned A satisfies the \nacyclic property, the loss function often includes an acyclicity \nconstraint [221]. This process effectively addresses the \ncomputational difficulty of direct marginalization integrals and \nprovides a feasible approximate inference method for learning \ncomplex generative models. \nThis generative model is capable of simulating real \nindividuals with unique comfort zones and exhibiting their \naffective experience characteristics under various hypothetical \nscenarios. Compared to existing human behavior simulation \nmethods based on LLMs [222], [223], the generative model \nconstructed from affective event data introduces longitudinal \nbehavioral data, uncovering the complex interactions between \nindividuals and their environments — interactions that typically \nexceed the scope of conventional language training corpora. \nMoreover, by capturing latent intrinsic causal structures rather \nthan relying solely on correlation-based modeling, this model \nachieves a higher level of simulation accuracy. By applying \nhypothetical conditions to key nodes, the model can predict \nspecific individuals’ behavioral patterns along with their \naccompanying affective experiences. Hierarchical concerns can \nbe interpreted as combinations of external environmental node \nstates that correspond to different positive experiences. \n4.3.2 Learning from Simulated Interactions: Training Affective \nagents through Meta-Reinforcement Learning \nTraining an agent capable of taking action and engaging in \npositive interactions with users cannot typically rely on \nsupervised learning, as it is challenging to obtain a large dataset \nof optimal action decisions, especially when considering \ndifferent interaction targets and contexts. Thus, the agent must \nlearn what constitutes good actions through continual trial-and-\nerror interactions with its environment — a process known as \nReinforcement Learning (RL) [224]. In the classical RL \nparadigm, an agent interacts extensively with its environment, \nobserves the current state s, and generates an action a through a \npolicy π. This action leads to a change in the environment’s state \nand a feedback reward r from the environment. The goal of the \nagent’s actions is to maximize cumulative reward Gt. \nAlthough RL has enabled agents to perform well in narrowly \ndefined tasks, these agents often fail to generalize their \ncapabilities to new tasks [225]. Evidently, we aspire to train a \n\n14 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \ngeneral-purpose affective agent rather than needing to collect \nvast amounts of data and retrain it from scratch for every new \ninteraction target or context. To effectively handle diverse real-\nworld contexts and interaction targets, an ideal affective agent \nmust be capable of quickly adapting to changes in its external \nenvironment after only a few interactions while continuously \nimproving its behavior as more data accumulates. This ability, \nreferred to as continual learning, is fundamental to constructing \nadaptive AI systems [226]. \nBuilding such an adaptive system is critical for training \ngeneral-purpose affective agents. The complex causal network \nunderlying individual affective event data is not static but evolves \ndynamically over time as individuals develop. Piaget’s genetic \nepistemology provides strong theoretical support for this \nviewpoint. Genetic epistemology emphasizes that individuals’ \ncognitive structures (schemas) continuously develop through \ninteractions with their environment. This nonlinear process, \ncharacterized by constant assimilation and accommodation, \nenables individuals to progress from one state of equilibrium to \nanother [227]. Consequently, an individual’s affective responses \nand processing mechanisms dynamically adjust with changes in \ntheir cognitive structure, reflecting the ongoing evolution of their \ncognitive and affective framework. This continual developmental \nprocess can also be observed at the group level. Comparing \nhuman culture, animal culture, epigenetics, and parental effects, \nMorgan & Feldman [228] concluded that the uniqueness of \nhuman culture lies in its ability to continuously accumulate and \nnever cease developing. This inherent potential for infinite \ndevelopment implies that the generative model for affective event \ndata must account for not only inter-individual differences but \nalso intra-individual variability. The data observed over a given \nperiod represents only a fragment of an individual’s life trajectory. \nIn addressing the dynamic changes within interaction models and \nexternal environments, fostering agents’ adaptability may be a \nmore effective strategy than constructing precise global \ndynamics models (see Figure 6). \nIn typical continual learning setups, the learner must \nsequentially acquire knowledge across various content, including \nnew tasks, new examples of old tasks, and different contexts, to \nadapt incrementally to dynamically distributed data [229], [230]. \nThe primary challenge lies in achieving efficient adaptation to \nnew distributions while maintaining the ability to capture prior \ndistributions —  a balance between learning plasticity and \nmemory stability [226], [231]. In this context, Khetarpal et al. \n[232] highlighted the natural alignment between continual \nlearning and RL. The interactive paradigm of RL provides a \nrobust framework for studying the trade-off between stability and \nplasticity. This interaction mechanism allows dynamic temporal \nsettings to be naturally modeled as continuous environment \nproblems in RL, enabling solutions to continual learning \nchallenges while leveraging RL theories and methods. \nMeta-Reinforcement Learning (meta-RL), a representative \nmethod in continual RL, offers an effective solution. The core \nidea of meta-learning is to acquire knowledge across tasks to \nenable rapid adaptation to new tasks, thereby reducing \ndependence on large training datasets [233], [234], [235], [236]. \nBy learning how to adapt efficiently across multiple tasks, meta-\nlearning equips learners to quickly adjust strategies for new tasks \nwhile retaining memory of old ones. This minimizes the risk of \ncatastrophic forgetting and enhances long-term learning \ncapabilities in dynamic environments [237]. One significant \nadvantage of meta-learning is its ability to imbue neural network \nsystems with inductive biases akin to symbolic models [238]. In \nthe language domain, McCoy & Griffiths [239] demonstrated \nthat meta-learning effectively transfers the strong inductive \nbiases of Bayesian models into neural networks. Using a Model-\nAgnostic Meta-Learning (MAML) algorithm, researchers were \nable to integrate Bayesian priors (symbolic grammar) into neural \nnetworks, endowing them with the inductive biases of symbolic \nmodels. This enabled neural networks to efficiently learn \nlanguage structures even in low-data settings. Recently, the meta-\nlearning framework has proven to be an ideal tool for \nconstructing general-purpose models [233]. \nTo train general-purpose affective agents capable of adapting \nto dynamic environments through meta-RL, a key challenge is \ndesigning and constructing virtual training environments \nencompassing diverse interaction targets and contexts. Given the \nhigh costs and limitations of acquiring real-world data, RL agents \ntypically rely on virtual environments for training [240].To \nensure that agents trained in virtual environments are deployable \nin real-world scenarios, researchers must design environments \nthat closely simulate real-world physical and social conditions. \nFor physical environments, numerous simulators already exist \nthat replicate real-world scenarios and physical laws (e.g., [241], \n[242], [243]), providing agents with high-fidelity sensory and \naction settings. For social environments, modeling must further \nencompass diverse individual behavior patterns. For instance, Qi \net al., [244] developed a simulator named CivRealm, inspired by \nthe game Civilization. This simulator offers an open-ended \nstochastic environment where agents can learn complex \ninterpersonal interaction rules in diplomacy and negotiation. \nHowever, physical-rule-based simulators alone are insufficient \nfor affective agents. Affective agents must handle more complex \ntask scenarios, including understanding and responding to \ninteraction targets’ affective concerns and balancing multiple \ngoals in dynamic contexts. \nTo achieve this, the virtual training environment must be \ncapable of simulating not only the real physical world but also \nincorporating generative models that emulate the affective \ndynamics of real individuals (refer to Section 4.3.1). The former \nprovides high-fidelity sensory and action settings, while the latter \nsimulates complex affective interactions at the social level. \nAffective generative models, trained on real individuals’ \naffective event data, can generate context-sensitive virtual \ninhabitants whose behaviors and responses are influenced by \naffective concerns, the environment, and the agent’s actions. \nEmbedding these generative models into world-model scripts \nallows the creation of dynamic 3D environments with diverse \naffective \ninteraction \ntasks. \nExamples \ninclude \nagents \ncollaborating with multiple virtual inhabitants to complete \nresource allocation tasks, finding balanced solutions in \nemotionally tense conflict scenarios, or providing comfort and \nsupport through verbal and behavioral means. Affective agents \nmust process high-dimensional stimuli, understand the affective \n\n15 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \nconcerns of interaction targets, and plan response pathways based \non environmental affordances. Additionally, as the generative \nmodels are derived directly from real individuals’ affective data, \nthese virtual inhabitants exhibit highly personalized affective \ncharacteristics, making training tasks more realistic. In such \nmultimodal affective interaction environments, affective agents \ncan incrementally develop capabilities for perceiving, adapting to, \nand planning for complex affective scenarios through meta-RL, \nlaying a solid foundation for real-world deployment. Research \nfrom the machine learning community has already demonstrated \nthe feasibility of training agents capable of performing a wide \nvariety of tasks (e.g., [245], [246]).\nFigure 6. Training trajectory of affective agents in the Meta-Reinforcement Learning (Meta-RL) framework, progressing \nfrom aligning with personal/individual well-being to group/collective well-being.  \nThe upper section of the figure represents the outer loop of Meta-RL, where the agent gradually adapts across tasks, evolving from \nindividual-level tasks (e.g., interacting with a single user) to more complex group-level tasks (e.g., coordinating affective states across \nmultiple users). Each task in the task flow consists of two components: a generative model and a world model. The humanoid icon \nrepresents the generative model, which is built using real-world affective event data to simulate the affective responses and decision-\nmaking processes of virtual inhabitants. The globe icon represents the world model, which provides high-fidelity perception and action \nscenarios to simulate the external environment required for physical and social interactions within the task. The lower-left and lower-\nright sections represent the inner loops of the Meta-RL process, corresponding to specific implementations of aligning with \npersonal/individual and group/collective well-being, respectively. In the early stages, the focus is on aligning with personal/individual \nwell-being by exploring potential strategies through reinforcement learning (illustrated by the blue pathway), ultimately identifying \nthe optimal strategy (red pathway) that guides the user’s affective state toward the target state. In tasks aimed at aligning \ngroup/collective well-being (lower right), the agent must address uncertainties such as conflicts in individual preferences and \nincomplete signals, integrating the diverse needs of multiple users to optimize affective interaction pathways and achieve a harmonious \nand optimal group/collective affective state. Through Meta-RL, affective agents generalize knowledge across tasks, enhancing their \nadaptability in dynamic environments and demonstrating their potential for scaling from individual emotion optimization to social \ncollaboration systems. \n \nIn RL, environmental rewards are the core mechanism driving \nan agent’s ability to learn complex skills. As noted by Silver et al. \n[247], reward mechanisms can enable AI to develop various \nsophisticated abilities, including language comprehension, \nlearning, social interaction, generalization, and imitation. In \naffective interaction tasks, the design of an appropriate reward \nfunction is crucial for training affective agents. These agents need \nto dynamically adjust their behavior based on environmental \naffordances to assist interaction partners in achieving their \naffective concerns and, in doing so, receive rewards. However, in \npractical scenarios, fully satisfying all levels of affective \nconcerns is often unachievable, especially considering the \ninherent conflicts between certain layers of affective needs. \nTherefore, the reward function should assign differentiated \nweights to various levels of affective concerns to establish clear \npriorities. This weighting mechanism emulates how individuals \nintegrate multiple goals and optimize resource allocation in the \npursuit of long-term well-being. In this process, the three \ndimensions of affective experience — valence, arousal, and \n\n16 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \npersistence — play a critical role in shaping the affective agent’s \nbehavioral choices. Valence indicates whether an emotion is \npositive or negative; the agent should prioritize actions that \npromote positive experiences while mitigating negative ones. \nArousal reflects the intensity of an affective state, directly \ninfluencing the agent’s response urgency and intensity. High-\narousal affective states demand immediate responses, while low-\narousal contexts may require more measured and cautious \nbehavioral strategies. Persistence, on the other hand, pertains to \nthe duration of an affective experience, influencing how affective \ngoals should be pursued. The reward mechanism should balance \nshort-term rewards with long-term objectives, preventing \nimmediate gratification from undermining long-term well-being. \nAchieving \nglobal \nconcerns \ndoes \nnot \nnecessitate \nsimultaneously fulfilling all levels of affective concerns; rather, \nit emphasizes the effective allocation of resources to achieve \nhigher-level holistic coordination. While the specific means of \nachieving global concerns vary among individuals, positive \npsychology theories provide universal descriptions of well-being, \noffering principled guidance for reward function design. These \ntheories present two primary perspectives on well-being: \nhedonism and eudaimonia. The former defines happiness as the \naccumulation of positive experiences [248]. Although satisfying \naffective concerns at different levels can bring positive \nexperiences, the quality and longevity of these experiences vary. \nWithin the hedonistic tradition, goals that yield longer-lasting \npositive experiences should be prioritized with higher weight. \nConversely, the eudaimonic perspective views a fulfilling and \ndeeply satisfying life as the true definition of well-being, \nemphasizing the realization of personal potential [249]. From this \nviewpoint, affective agents should not only help achieve \nimmediate needs, such as fulfilling physiological demands, but \nalso actively facilitate goals that are distant in metabolic impact, \nsuch as exploring the environment to satisfy curiosity. The latter \noften contributes more to a fulfilling and meaningful life. In this \ncontext, highly aroused states (e.g., anxiety or feelings of urgency) \nindicate the need for affective agents to respond swiftly and \nadaptively to prevent extreme affective deprivation. \nWe propose that these seemingly opposing views on well-\nbeing — short-term gratification and long-term fulfillment — \nmay represent different aspects of the same overall well-being \nstate. Achieving short-term, intense positive affect in a rigid, \naddictive manner is unsustainable, as it hampers an individual’s \nability to explore environmental affordances, leading to fixation \non specific attractors [166], [175], [250]. In contrast, goals that \nrequire complex actions and delayed feedback often lead to richer \nand more enduring positive experiences, such as shaping the \nenvironment. Similarly, pursuing self-actualization does not \nimply the rejection of all pleasurable activities; for instance, \nprolonged mental and physical exhaustion is detrimental to \ncreative endeavors. \nA feasible approach, integrating the aforementioned \nperspectives, is to assign higher priority to affective concerns that \nhave a distant metabolic impact yet contribute to long-term \npositive experiences, while dynamically adjusting weight \nallocations based on changes in arousal levels. This ensures that \npressing affective concerns are not left unmet for extended \nperiods, thereby achieving a dynamic balance between pursuing \ncomplex goals and maintaining fundamental stability (see Figure \n7). This approach is further supported by the Tri-Reference-Point \ntheory proposed by X. T. Wang and Johnson [251]. The tri-\nreference-point theory posits that decision-makers typically \nconsider three critical points when making choices: the current \nstate, the optimal goal, and the worst-case scenario [251]. In \naffective computing, the current state ensures that urgent \naffective concerns are promptly addressed, the optimal goal \nfocuses on achieving long-term affective equilibrium, and the \nworst-case scenario prevents the system from becoming \nimbalanced due to prolonged neglect of specific affective \nconcerns. By dynamically adjusting weight allocations, the \nsystem can effectively balance short-term demands and long-\nterm objectives. When an affective agent detects that the \ninteraction partner is in a high-arousal affective state, it indicates \nan urgent and intense affective concern. In such cases, the agent \nmust take immediate action to address the present affective \nconcern, ensuring timely and prioritized responses to high-\narousal states. This responsive mechanism enables the affective \nagent to remain sensitive to the user’s current affective state while \nsimultaneously working toward long-term well-being, thereby \noptimizing the interaction experience dynamically. For instance, \nwhen an individual experiences a positive valence and high-\narousal emotional state — such as joy, excitement, or a sense of \nachievement — they exhibit heightened responsiveness to \nenvironmental stimuli. In this scenario, the affective agent should \nadopt an encouraging and supportive approach, reinforcing the \nuser’s positive emotions and further facilitating goal attainment. \nFor example, when an individual completes a task and feels \nexcited, the affective agent can enhance this positive emotion by \noffering praise, rewards, or new exploration opportunities, \nthereby enriching the experience and motivating the individual to \npursue higher achievements. This strategy not only helps \nmaintain positive emotions but also fosters deeper engagement in \nthe interaction process. Conversely, when an individual \nexperiences a negative valence and high-arousal emotional state \n— such as anxiety, anger, or distress — the affective agent must \nemploy emotional soothing strategies to help the individual \nregain emotional stability. For instance, if a person feels anxious \nabout a particular issue, the affective agent can guide them \nthrough deep breathing exercises, provide emotional support, or \noffer reassuring language to alleviate distress. Additionally, the \nagent can assist in identifying the root cause of the negative \nemotion and suggest coping strategies or psychological support \nto help the individual manage their emotions effectively. By \nimplementing such strategies, the affective agent not only \nalleviates negative emotions but also promotes emotional self-\nregulation, helping individuals regain composure and stability. \nThis, in turn, enhances the overall affective interaction \nexperience, ensuring that both immediate needs and long-term \nwell-being goals are addressed in a balanced and adaptive \nmanner. \nThis design logic can also be extended to affective interaction \nscenarios involving multiple interaction targets, simulating how \n\n17 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \nagents optimize group/collective well-being. Within this \nframework, the definition of global well-being can expand from \nfocusing on a single individual to encompassing the joint well-\nbeing of all interaction targets, thereby supporting affective \nagents in aligning overall interests within multi-agent ecosystems. \nThe range of interaction targets can go beyond human agents to \ninclude all living beings in the natural world, aiming for the \nmaximization of ecosystem well-being. However, addressing the \nprioritization of well-being across different interaction targets \nposes a complex issue involving ethics and social values, which \nrequires further exploration. In summary, by scientifically \ndesigning reward functions, affective interaction principles can \nbe effectively embedded into the action objectives of affective \nagents, providing both theoretical and practical support for deep \ncollaboration between humans and algorithms. \nBeyond creating a large number of complex training tasks, to \nensure the learning progress of affective agents, we must also \ndesign a training strategy that allows the agent to sample tasks \nwithin its “zone of proximal development” [245], thereby \nimproving agent performance and sample efficiency. The core of \nthis strategy lies in controlling the dynamic changes in the \nenvironment, which can be reflected in two aspects: first, changes \nin task competency requirements, and second, changes in the \ninternal structure of interaction targets. Regarding task \ncompetency requirements, the difficulty of training tasks should \ntransition smoothly and gradually increase, rather than abruptly \njumping to tasks far beyond the agent’s current capability, \nensuring that the agent can continually enhance its ability to \nrespond within a relatively stable capability range. As for \nchanges in the internal structure of interaction targets, the \naffective needs or behavioral characteristics of virtual \nenvironment interaction targets should not change too drastically \nbut instead should align with the learning stages of the agent, \nadjusting incrementally. By controlling the gradual changes in \ntask competency requirements and the internal structure of \ninteraction targets, the agent can form a stable learning path \nbetween adjacent tasks, thereby gradually mastering more \ncomplex coping strategies in affective interactions and \nsimulating the natural process of individual development. This \nstrategy not only accelerates the agent's learning efficiency but \nalso improves its adaptability and generalization capabilities in \ndealing with various affective concerns and interaction needs in \ncomplex and dynamic real-world environments. \nOverall, meta-RL is an ideal tool for building general-purpose \naffective agents. It effectively promotes the rapid adaptation and \ncontinual learning of agents in dynamic environments. By \nconstructing structural models based on individual affective \nevent data, we can design diverse and challenging virtual training \nenvironments, driving agents to continually optimize their \naffective response strategies. \nFigure 7. Reward function design for affective agents to balance long-term goals with immediate affective concerns. \nDuring interactions with users, affective agents take actions to maximize rewards, represented by smiley icons. The agent aims to \nfulfill various affective concerns of the user, guiding them toward a target state characterized by positive valence, moderate arousal, \nand high affective persistence — indicative of long-lasting positive experiences. However, while pursuing long-term goals, the agent \nmust also remain responsive to the user’s pressing affective concerns in the present moment. When a user exhibits negative emotions \naccompanied by high arousal levels, it signals a significant unmet affective need. In such instances, the reward weighting dynamically \nadjusts to prompt the agent to take immediate actions that address the current affective deficit. This adaptive approach ensures an \noptimal balance between addressing short-term affective concerns and achieving overarching long-term well-being goals. \n\n18 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \n5. CONCLUSION \nIn this paper, we present a research framework based on the \nfundamental principles of teleology aimed at guiding agents’ \nbehavior in perception, decision-making, and action. The \ncriterion for aligning with long-term well-being requires agents \nto more carefully identify subtle differences between individual \npositive experiences and prioritize helping individuals pursue \ngoals that bring sustained positive experiences rather than short-\nterm, high-arousal intense stimuli, which may have addictive \nproperties. Decoding the internal states of others and \nunderstanding what truly benefits long-term well-being are key \nsteps in developing agents’ empathy. On this foundation, \nenabling AI to empathize with the harm or joy of others may \nrequire AI to possess various affective concerns that can be \nfulfilled by the environment [252], as well as instructions to \nsimulate and maintain internal homeostasis [253]. \nHowever, although affective agents aligned with long-term \nwell-being \nprovide \nan \nideal \npath \nfor \nachieving \npersonal/individual well-being, they still face the risk of bias \nwhen considering group well-being alignment. A group consists \nof a set of interrelated, interacting “elements,” and what benefits \nthe group may not necessarily maximize the well-being of each \ngroup member [166]. Thus, balancing the well-being of each \n“element” when considering the “whole” becomes an important \nand inevitable non-technical issue. In fact, sympathy and care in \nhuman society are always biased [254], [255]. Increasing \nevidence shows that people are more likely to empathize with \nindividuals who resemble themselves [256], [257]. This bias is \nespecially prominent in the alignment of group well-being. How \nto design systems that can fairly balance the needs of both the \ngroup and the individual remains a challenge to be addressed. \nIn this paper, we did not provide a direct and explicit answer \nto this issue. Instead, we propose a reliable path for developing \nscalable capabilities — large-scale simulations based on meta-\nRL. By incorporating basic social principles into the design of \nreward functions, agents can plan optimal paths within limited \nattempts, potentially benefiting human well-being at a level \nbeyond current human wisdom. In this process, we advocate for \nintegrating more psychological and sociological theories, \nparticularly the discussions of well-being in positive psychology. \nWe suggest that principles aimed at helping others pursue more \nlasting positive experiences should be incorporated into the \ndesign of reward functions. AI should prioritize goals that bring \nsustained positive experiences to individuals, such as building \nstrong interpersonal relationships or achieving self-fulfillment \nand spiritual satisfaction, rather than pursuing short-term \npleasure or avoiding negative emotions. However, whether such \nlong-term, profound affective experiences are more beneficial for \nlong-term well-being or if other answers exist remains an open \nquestion that requires further research by psychologists. In \naddition, directly modeling the developmental process of core \nneeds from infancy to old age [181] may provide a more \ncomplete approach than training adaptive models. For example, \nwell-being in infancy primarily relies on basic physiological \nneeds and dependence on caregivers, while, as individuals age, \ntheir well-being needs gradually shift toward higher-level self-\nactualization and social connection. In this process, agents need \nto dynamically adjust their understanding of well-being and \naction strategies based on the individual’s life stage and \npsychological development needs to better support long-term \nwell-being. Finally, while we emphasize personalized modeling \nand response, we do not exclude existing open statistical \ntechniques, which may provide important priors to help agents \nbetter understand affective dynamics and individual differences. \nThe semantic space theory proposed by Cowen & Keltner [258] \ncan help capture the systematic changes in emotion-related \nbehaviors, and studies show that emotional patterns have \ncomplex, multidimensional characteristics and exhibit some \ncommon regularities across different cultures and situations, \nalthough their specific manifestations may vary depending on \ncultural and environmental differences [259], [260]. This line of \nresearch can provide strong empirical and methodological \nsupport for how we can use group-level statistical data to gain \nprior information on affective cognition. \nIn conclusion, in meta-RL-based simulations, agents can \nadjust according to these psychological and sociological theories, \nwhile also conducting large-scale simulations to explore how to \nbalance the complex relationship between individual and group \nwell-being in diverse social environments. This simulation \nprocess enables agents to continuously adapt and optimize its \nbehavior strategies in dynamic and changing environments, \naiming to maximize individual or group well-being. By \nintegrating theoretical achievements from psychology, sociology, \nand other fields, this approach not only provides a solid \ntheoretical foundation for the design of affective agents but also \noffers new ideas and methods for applying these theories to \ncomplex social contexts. Ultimately, this interdisciplinary \nintegration aims not to provide a “perfect” answer directly but \nthrough multi-level simulations and analyses to help us better \ndiscover and solve potential problems, thereby promoting more \nharmonious development between AI and human society. \nACKNOWLEDGMENT \nThis work was funded by the Joint Fund to Promote Cross-\nStraits Scientific and Technological Cooperation (Project No. \nU1805263) and the Humanities and Social Science Fund of the \nMinistry of Education of China (Project No. 23YJAZH183). B. \nYin is also partially supported by the Research Start-Up Fund for \n“Overseas Talent—Young Talent” from Fujian Normal \nUniversity (Project No. Z0210509). The funders had no role in \nthe preparation of this work. \nAUTHOR CONTRIBUTIONS \nB. Yin initiated and supervised the work presented in this \narticle and played a leading role in developing the research \nframework. C.-Y. Liu conducted critical research in relevant \nareas. Together, B. Yin and C.-Y. Liu created the initial \nstructure of the paper and led discussions on its iterative \nimprovements. Both authors wrote the majority of the sections \nof the paper. L. Fu and J. Zhang initiated discussions on several \n\n19 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \nkey topics, provided significant feedback on the content, and \ncontributed to revising the article. All authors approved the \nfinal version of the manuscript. \nREFERENCES \n[1] \nR. W. Picard, Affective Computing. MIT Press, 2000. \n[2] \nY. Aloimonos and A. Rosenfeld, “Computer Vision,” Science, vol. \n253, no. 5025, pp. 1249–1254, Sep. 1991, \ndoi:10.1126/science.1891713 \n[3] \nR. W. Picard, “Affective Computing: From Laughter to IEEE,” \nIEEE Transactions on Affective Computing., vol. 1, no. 1, pp. 11–\n17, Jan. 2010, doi: 10.1109/T-AFFC.2010.10 \n[4] \nM. Minsky, The Emotion Machine: Commonsense thinking, \nartificial intelligence, and the future of the human mind. Simon and \nSchuster, 2007. \n[5] \nR. A. Calvo, S. D’Mello, J. M. Gratch, and A. Kappas, The Oxford \nHandbook of Affective Computing. Oxford University Press, 2015. \n[6] \nK. R. Scherer, T. Bänziger, and E. Roesch, A Blueprint for Affective \nComputing: A Sourcebook and Manual. Oxford University Press, \n2010. \n[7] \nE. Cambria, D. Das, S. Bandyopadhyay, and A. Feraco, “Affective \ncomputing and sentiment analysis,” A Practical Guide to Sentiment \nAnalysis, Socio-Affective Computing, vol 5. Springer, Cham. pp. 1–\n10, 2017. doi: 10.1007/978-3-319-55394-8_1 \n[8] \nR. W. Picard, E. Vyzas, and J. Healey, “Toward machine emotional \nintelligence: Analysis of affective physiological state,” IEEE \nTransactions on Pattern Analysis and Machine Intelligence, vol. 23, \nno. 10, pp. 1175–1191, 2001. doi: 10.1109/34.954607 \n[9] \nY. Wang et al., “A Systematic Review on Affective Computing: \nEmotion Models, Databases, and Recent Advances,” Mar. 20, 2022, \narXiv:2203.06935. Accessed: Jul. 07, 2024. [Online]. Available: \nhttp://arxiv.org/abs/2203.06935 \n[10] \nS. Poria, E. Cambria, R. Bajpai, and A. Hussain, “A review of \naffective computing: From unimodal analysis to multimodal fusion,” \nInformation Fusion, vol. 37, pp. 98–125, Sep. 2017. \ndoi:10.1016/j.inffus.2017.02.003 \n[11] \nP. V. Rouast, M. T. Adam, and R. Chiong, “Deep learning for \nhuman affect recognition: Insights and new developments,” IEEE \nTransactions on Affective Computing, vol. 12, no. 2, pp. 524–543, \n2019. doi: 10.1109/TAFFC.2018.2890471 \n[12] \nM. Firdaus, H. Chauhan, A. Ekbal, and P. Bhattacharyya, “EmoSen: \nGenerating sentiment and emotion controlled responses in a \nmultimodal dialogue system,” IEEE Transactions on Affective \nComputing, vol. 13, no. 3, pp. 1555–1566, 2020. \ndoi:10.1109/TAFFC.2020.3015491 \n[13] \nQ. Li, P. Li, Z. Ren, P. Ren, and Z. Chen, “Knowledge bridging for \nempathetic dialogue generation,” in Proceedings of the AAAI \nconference on artificial intelligence, 2022, pp. 10993–11001. \ndoi:10.1609/aaai.v36i10.21347 \n[14] \nF.-J. Ren et al., “Tracking Emotions Using an Evolutionary Model \nof Mental State Transitions: Introducing a New Paradigm,” Intell \nComput, vol. 3, p. 0075, Jan. 2024, doi: 10.34133/icomputing.0075 \n[15] \nK. Wang and X. Wan, “Sentigan: Generating sentimental texts via \nmixture adversarial networks.,” in Proceedings of the Twenty-\nSeventh International Joint Conference on Artificial Intelligence \n(IJCAI-18), pp. 4446–4452, 2018. \n[16] \nE. Douglas-Cowie et al., “The HUMAINE database: Addressing the \ncollection and annotation of naturalistic and induced emotional \ndata,” in Affective Computing and Intelligent Interaction: Second \nInternational Conference, ACII 2007 Lisbon, Portugal, September \n12-14, 2007 Proceedings 2, Springer, 2007, pp. 488–500. doi: \n10.1007/978-3-540-74889-2_43. \n[17] \nY. Ganin et al., “Domain-adversarial training of neural networks,” \nJournal of Machine Learning Research, vol. 17, no. 59, pp. 1–35, \n2016. \n[18] \nG. Shteynberg et al., “Does it matter if empathic AI has no \nempathy?,” Nature Machine Intelligence, vol. 6, no. 5, pp. 496–497, \nMay 2024, doi: 10.1038/s42256-024-00841-7. \n[19] \nC. E. Izard, “Basic emotions, relations among emotions, and \nemotion-cognition relations.,” Psychological Review, vol. 99, no. 3, \npp. 561–565, 1992. doi: 10.1037/0033-295X.99.3.5611992. \n[20] \nJ. L. Tracy and R. W. Robins, “Show your pride: Evidence for a \ndiscrete emotion expression,” Psychological Science, vol. 15, no. 3, \npp. 194–197, 2004. doi: 10.1111/j.0956-7976.2004.01503008.x. \n[21] \nJ. R. Fontaine, K. R. Scherer, E. B. Roesch, and P. C. Ellsworth, \n“The world of emotions is not two-dimensional,” Psychological \nScience, vol. 18, no. 12, pp. 1050–1057, 2007. doi: 10.1111/j.1467-\n9280.2007.02024.x \n[22] \nR. Plutchik, “A general psychoevolutionary theory of emotion,” in \nTheories of Emotion, Elsevier, 1980, pp. 3–33. \n[23] \nJ. A. Russell, “A circumplex model of affect.,” Journal of \nPersonality and Social Psychology, vol. 39, no. 6, p. 1161, 1980. \ndoi: 10.1037/h0077714 \n[24] \nD. Schiller et al., “The Human Affectome,” Neuroscience & \nBiobehavioral Reviews, vol. 158, p. 105450, Mar. 2024, doi: \n10.1016/j.neubiorev.2023.105450 \n[25] \nR. Adolphs and D. Andler, “Investigating Emotions as Functional \nStates Distinct From Feelings,” Emotion Review, vol. 10, no. 3, pp. \n191–201, Jul. 2018, doi: 10.1177/1754073918765662 \n[26] \nD. J. Anderson and R. Adolphs, “A Framework for Studying \nEmotions across Species,” Cell, vol. 157, no. 1, pp. 187–200, Mar. \n2014, doi: 10.1016/j.cell.2014.03.003 \n[27] \nL. F. Barrett, “The theory of constructed emotion: an active \ninference account of interoception and categorization,” Soc Cogn \nAffect Neurosci, p. nsw154, Oct. 2016, doi: 10.1093/scan/nsw154. \n[28] \nJ. LeDoux, “Rethinking the Emotional Brain,” Neuron, vol. 73, no. \n4, pp. 653–676, Feb. 2012, doi: 10.1016/j.neuron.2012.02.004 \n[29] \nM. Malezieux, A. S. Klein, and N. Gogolla, “Neural Circuits for \nEmotion,” Annu. Rev. Neurosci., vol. 46, no. 1, pp. 211–231, Jul. \n2023, doi: 10.1146/annurev-neuro-111020-103314 \n[30] \nJ. Panksepp, “Toward a cross-species neuroscientific understanding \nof the affective mind: do animals have emotional feelings?,” Am. J. \nPrimatol., vol. 73, no. 6, pp. 545–561, Jun. 2011, \ndoi:10.1002/ajp.20929 \n[31] \nJ. J. Gross and L. Feldman Barrett, “Emotion Generation and \nEmotion Regulation: One or Two Depends on Your Point of View,” \nEmotion Review, vol. 3, no. 1, pp. 8–16, Jan. 2011, \ndoi:10.1177/1754073910380974 \n[32] \nL. F. Barrett, “Functionalism cannot save the classical view of \nemotion,” Social Cognitive and Affective Neuroscience, vol. 12, no. \n1, pp. 34–36, Jan. 2017, doi: 10.1093/scan/nsw156 \n[33] \nA. B. Eder, “A perceptual control theory of emotional action,” \nCognition and Emotion, vol. 37, no. 7, pp. 1167–1184, Oct. 2023, \ndoi: 10.1080/02699931.2023.2265234 \n[34] \nN. Albuquerque, K. Guo, A. Wilkinson, C. Savalli, E. Otta, and D. \nMills, “Dogs recognize dog and human emotions,” Biology Letters, \nvol. 12, no. 1, p. 20150883, Jan. 2016, doi: 10.1098/rsbl.2015.0883 \n[35] \nN. Albuquerque, D. S. Mills, K. Guo, A. Wilkinson, and B. \nResende, “Dogs can infer implicit information from human \nemotional expressions,” Anim Cogn, vol. 25, no. 2, pp. 231–240, \nApr. 2022, doi: 10.1007/s10071-021-01544-x \n[36] \nS. B. Barker, J. S. Knisely, C. M. Schubert, J. D. Green, and S. \nAmeringer, “The Effect of an Animal-Assisted Intervention on \nAnxiety and Pain in Hospitalized Children,” Anthrozoös, vol. 28, no. \n1, pp. 101–112, Mar. 2015, \ndoi:10.2752/089279315X14129350722091 \n[37] \nI. B.-A. Bartal, J. Decety, and P. Mason, “Empathy and pro-social \nbehavior in rats,” Science, vol. 334, no. 6061, pp. 1427–1430, 2011. \ndoi: 10.1126/science.1210789 \n[38] \nI. B.-A. Bartal et al., “Anxiolytic treatment impairs helping behavior \nin rats,” Frontiers in Psychology, vol. 7, p. 850, 2016. \ndoi:10.3389/fpsyg.2016.00850 \n[39] \nT. Bortolato, A. D. Friederici, C. Girard-Buttoz, R. M. Wittig, and \nC. Crockford, “Chimpanzees show the capacity to communicate \nabout concomitant daily life events,” iScience, vol. 26, no. 11, p. \n108090, Nov. 2023, doi: 10.1016/j.isci.2023.108090 \n[40] \nE. F. Briefer, A.-L. Maigrot, R. Mandel, S. B. Freymond, I. \nBachmann, and E. Hillmann, “Segregation of information about \nemotional arousal and valence in horse whinnies,” Sci Rep, vol. 5, \nno. 1, p. 9989, Apr. 2015, doi: 10.1038/srep09989 \n[41] \nD. Buttelmann, J. Call, and M. Tomasello, “Do great apes use \nemotional expressions to infer desires?,” Developmental Science, \nvol. 12, no. 5, pp. 688–698, Sep. 2009, doi: 10.1111/j.1467-\n7687.2008.00802.x \n[42] \nA. S. Heller, “From Conditioning to Emotion: Translating Animal \nModels of Learning to Human Psychopathology,” Neuroscientist, \n\n20 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \nvol. 26, no. 1, pp. 43–56, Feb. 2020, doi: \n10.1177/1073858419866820 \n[43] \nQ. Do and M. E. Hasselmo, “Neural circuits and symbolic \nprocessing,” Neurobiology of Learning and Memory, vol. 186, p. \n107552, Dec. 2021, doi: 10.1016/j.nlm.2021.107552 \n[44] \nJ. Panksepp, “What is an emotional feeling? Lessons about affective \norigins from cross-species neuroscience,” Motivation and Emotion, \nvol. 36, no. 1, pp. 4–15, Mar. 2012, doi: 10.1007/s11031-011-9232-\ny \n[45] \nA. Pérez‐Manrique and A. Gomila, “The comparative study of \nempathy: sympathetic concern and empathic perspective‐taking in \nnon‐human animals,” Biological Reviews, vol. 93, no. 1, pp. 248–\n269, Feb. 2018, doi: 10.1111/brv.12342 \n[46] \nD. W. McShea, “Evolutionary trends and goal directedness,” \nSynthese, vol. 201, no. 5, p. 178, May 2023, doi: 10.1007/s11229-\n023-04164-9 \n[47] \nA. Damasio and G. B. Carvalho, “The nature of feelings: \nevolutionary and neurobiological origins,” Nature Reviews \nNeuroscience, vol. 14, no. 2, pp. 143–152, Feb. 2013, doi: \n10.1038/nrn3403 \n[48] \nM. Mendl and E. S. Paul, “Animal affect and decision-making,” \nNeuroscience & Biobehavioral Reviews, vol. 112, pp. 144–163, May \n2020, doi: 10.1016/j.neubiorev.2020.01.025 \n[49] \nP. Ekman and D. Cordaro, “What is meant by calling emotions \nbasic,” Emotion Review, vol. 3, no. 4, pp. 364–370, 2011. doi: \n10.1177/1754073911410740 \n[50] \nP. Ekman, “An argument for basic emotions,” Cognition & Emotion, \nvol. 6, no. 3–4, pp. 169–200, 1992. \ndoi:10.1080/02699939208411068 \n[51] \nM. B. Arnold, Emotion and Personality. Vol. 1. Psychological \nAspects. Columbia University Press. 1960. \n[52] \nR. S. Lazarus, Emotion and Adaptation. Oxford University Press, \n1991. \n[53] \nE. Harmon-Jones, C. Harmon-Jones, and E. Summerell, “On the \nImportance of Both Dimensional and Discrete Models of Emotion,” \nBehavioral Sciences, vol. 7, no. 4, p. 66, Sep. 2017, doi: \n10.3390/bs7040066 \n[54] \nA. Moors, Demystifying emotions: A typology of theories in \npsychology and philosophy. Cambridge University Press, 2022. \n[55] \nA. Moors, Y. Boddez, and J. De Houwer, “The Power of Goal-\nDirected Processes in the Causation of Emotional and Other \nActions,” Emotion Review, vol. 9, no. 4, pp. 310–318, Oct. 2017, \ndoi: 10.1177/1754073916669595 \n[56] \nA. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, \n“Appraisal Theories of Emotion: State of the Art and Future \nDevelopment,” Emotion Review, vol. 5, no. 2, pp. 119–124, Apr. \n2013, doi: 10.1177/1754073912468165 \n[57] \nN. H. Frijda, The Laws of Emotion. New York: Psychology Press, \n2017. \n[58] \nK. R. Scherer, “Feelings integrate the central representation of \nappraisal-driven response organization in emotion,” in Feelings and \nEmotions: The Amsterdam Smposium, 2004, pp. 136–157. \n[59] \nR. C. Roberts, Emotions: An essay in aid of moral psychology. \nCambridge University Press, 2003. \n[60] \nA. Scarantino, Emotion Theory: The Routledge Comprehensive \nGuide: Volume I: History, Contemporary Theories, and Key \nElements, 1st ed. New York: Routledge, 2024. doi: \n10.4324/9781315559940. \n[61] \nE. Hudlicka, “Guidelines for designing computational models of \nemotions,” International Journal of Synthetic Emotions (IJSE), vol. \n2, no. 1, pp. 26–79, 2011. doi: 10.4018/jse.2011010103. \n[62] \nG. Dong and H. Liu, Feature engineering for machine learning and \ndata analytics. CRC press, 2018. \n[63] \nJ. Schmidhuber, “Deep Learning in Neural Networks: An \nOverview,” Neural Networks, vol. 61, pp. 85–117, Jan. 2015, doi: \n10.1016/j.neunet.2014.09.003. \n[64] \nY. Li, J. Wei, Y. Liu, J. Kauttonen, and G. Zhao, “Deep Learning \nfor Micro-Expression Recognition: A Survey,” IEEE Transactions \non Affective Computing, vol. 13, no. 4, pp. 2028–2046, Oct. 2022, \ndoi: 10.1109/TAFFC.2022.3205170. \n[65] \nT. Pfister, Xiaobai Li, G. Zhao, and M. Pietikainen, “Recognising \nspontaneous facial micro-expressions,” in 2011 International \nConference on Computer Vision, Barcelona, Spain: IEEE, Nov. \n2011, pp. 1449–1456. doi: 10.1109/ICCV.2011.6126401. \n[66] \nB. Xia, W. Wang, S. Wang, and E. Chen, “Learning from Macro-\nexpression: a Micro-expression Recognition Framework,” in \nProceedings of the 28th ACM International Conference on \nMultimedia, Seattle WA USA: ACM, Oct. 2020, pp. 2936–2944. \ndoi: 10.1145/3394171.3413774 \n[67] \nP. Ekman, “Darwin, deception, and facial expression,” Annals of the \nNew York Academy of Sciences, vol. 1000, no. 1, pp. 205–221, 2003. \ndoi: 10.1196/annals.1280.010 \n[68] \nP. Ekman, “Lie catching and microexpressions,” in The Philosophy \nof Deception, London: U.K.: Oxford University Press, 2009, pp. \n118–133. \n[69] \nP. Ekman and W. V. Friesen, “Constants across cultures in the face \nand emotion,” Journal of Personality and Social Psychology, vol. \n17, no. 2, p. 124, 1971. doi: 10.1037/h0030377 \n[70] \nP. Ekman and W. V. Friesen, “Facial Action Coding System: A \nTechnique for the Measurement of Facial Movement,” Palo Alto, \nCA: Consulting Psychologists Press, 1978. \n[71] \nX. Ben et al., “Video-based facial micro-expression analysis: A \nsurvey of datasets, features and algorithms,” IEEE Transactions on \nPattern Analysis and Machine Intelligence, vol. 44, no. 9, pp. 5826–\n5846, 2021. doi: 10.1109/TPAMI.2021.3067464 \n[72] \nK. M. Goh, C. H. Ng, L. L. Lim, and U. U. Sheikh, “Micro-\nexpression recognition: an updated review of current trends, \nchallenges and solutions,” The Visual Computer, vol. 36, pp. 445–\n468, 2020. doi: 10.1007/s00371-018-1607-6 \n[73] \nT. Meng, X. Jing, Z. Yan, and W. Pedrycz, “A survey on machine \nlearning for data fusion,” Information Fusion, vol. 57, pp. 115–129, \n2020. doi: 10.1016/j.inffus.2019.12.001 \n[74] \nM. Takalkar, M. Xu, Q. Wu, and Z. Chaczko, “A survey: facial \nmicro-expression recognition,” Multimedia Tools and Applications, \nvol. 77, no. 15, pp. 19301–19325, 2018. doi: 10.1007/s11042-017-\n5317-2 \n[75] \nM. Bai and R. Goecke, “Investigating LSTM for micro-expression \nrecognition,” in Companion Publication of the 2020 International \nConference on Multimodal Interaction, 2020, pp. 7–11. doi: \n10.1145/3395035.3425248 \n[76] \nJ. Huang, X. Zhao, and Lim. Zheng, “SHCFNet on Micro-\nexpression recognition system,” in 2020 13th International \nCongress on Image and Signal Processing, BioMedical Engineering \nand Informatics (CISP-BMEI), IEEE, 2020, pp. 163–168. doi: \n10.1109/CISP-BMEI51763.2020.9263671 \n[77] \nD. H. Kim, W. J. Baddar, and Y. M. Ro, “Micro-expression \nrecognition with expression-state constrained spatio-temporal \nfeature representations,” in Proceedings of the 24th ACM \nInternational Conference on Multimedia, 2016, pp. 382–386. doi: \n10.1145/2964284.2967247 \n[78] \nS.-T. Liong, Y. S. Gan, J. See, H.-Q. Khor, and Y.-C. Huang, \n“Shallow triple stream three-dimensional cnn (ststnet) for micro-\nexpression recognition,” in 2019 14th IEEE International \nConference on Automatic Face & Gesture Recognition (FG 2019), \nIEEE, 2019, pp. 1–5. doi: 10.1109/FG.2019.8756567 \n[79] \nS. C. Nistor, “Multi-staged training of deep neural networks for \nmicro-expression recognition,” in 2020 IEEE 14th International \nSymposium on Applied Computational Intelligence and Informatics \n(SACI), IEEE, 2020, pp. 29–34. \ndoi:10.1109/SACI49304.2020.9118811 \n[80] \nM. Peng, C. Wang, T. Bi, Y. Shi, X. Zhou, and T. Chen, “A novel \napex-time network for cross-dataset micro-expression recognition,” \nin 2019 8th international conference on affective computing and \nintelligent interaction (ACII), IEEE, 2019, pp. 1–6. \ndoi:10.1109/ACII.2019.8925525 \n[81] \nL. Yao, X. Xiao, R. Cao, F. Chen, and T. Chen, “Three stream 3D \nCNN with SE block for micro-expression recognition,” in 2020 \nInternational Conference on Computer Engineering and Application \n(ICCEA), IEEE, 2020, pp. 439–443. \ndoi:10.1109/ICCEA50009.2020.00101 \n[82] \nR. Zhi, M. Liu, H. Xu, and M. Wan, “Facial micro-expression \nrecognition using enhanced temporal feature-wise model,” in \nCyberspace Data and Intelligence, and Cyber-Living, Syndrome, \nand Health: International 2019 Cyberspace Congress, CyberDI and \nCyberLife, Beijing, China, December 16–18, 2019, Proceedings, \nPart II 3, Springer, 2019, pp. 301–311. doi: 10.1007/978-981-15-\n1925-3_22 \n\n21 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \n[83] \nG. Zhao, X. Li, Y. Li, and M. Pietikäinen, “Facial Micro-\nExpressions: An Overview,” Proceedings of the IEEE, vol. 111, no. \n10, pp. 1215–1235, Oct. 2023, doi: 10.1109/JPROC.2023.3275192 \n[84] \nZ. Ahmad and N. Khan, “A Survey on Physiological Signal-Based \nEmotion Recognition,” Bioengineering, vol. 9, no. 11, p. 688, Nov. \n2022, doi: 10.3390/bioengineering9110688 \n[85] \nS. M. Alarcao and M. J. Fonseca, “Emotions Recognition Using \nEEG Signals: A Survey,” IEEE Trans. Affective Comput., vol. 10, \nno. 3, pp. 374–393, Jul. 2019, doi: 10.1109/TAFFC.2017.2714671 \n[86] \nM. Garbarino, M. Lai, S. Tognetti, R. Picard, and D. Bender, \n“Empatica E3 - A wearable wireless multi-sensor device for real-\ntime computerized biofeedback and data acquisition,” in \nProceedings of the 4th International Conference on Wireless Mobile \nCommunication and Healthcare - “Transforming healthcare \nthrough innovations in mobile and wireless technologies,” Athens, \nGreece: ICST, 2014. doi: 10.4108/icst.mobihealth.2014.257418 \n[87] \nMing-Zher Poh, N. C. Swenson, and R. W. Picard, “A Wearable \nSensor for Unobtrusive, Long-Term Assessment of Electrodermal \nActivity,” IEEE Trans. Biomed. Eng., vol. 57, no. 5, pp. 1243–1252, \nMay 2010, doi: 10.1109/TBME.2009.2038487 \n[88] \nM.-Z. Poh, D. J. McDuff, and R. W. Picard, “Non-contact, \nautomated cardiac pulse measurements using video imaging and \nblind source separation,” Opt. Express, vol. 18, no. 10, p. 10762, \nMay 2010, doi: 10.1364/OE.18.010762 \n[89] \nM.-Z. Poh, D. J. McDuff, and R. W. Picard, “Advancements in \nNoncontact, Multiparameter Physiological Measurements Using a \nWebcam,” IEEE Trans. Biomed. Eng., vol. 58, no. 1, pp. 7–11, Jan. \n2011, doi: 10.1109/TBME.2010.2086456 \n[90] \nJ. A. Healey and R. W. Picard, “Detecting Stress During Real-World \nDriving Tasks Using Physiological Sensors,” IEEE Trans. Intell. \nTransport. Syst., vol. 6, no. 2, pp. 156–166, Jun. 2005, doi: \n10.1109/TITS.2005.848368 \n[91] \nA. Sano et al., “Recognizing Academic Performance, Sleep Quality, \nStress Level, and Mental Health using Personality Traits, Wearable \nSensors and Mobile Phones,” Int Conf Wearable Implant Body Sens \nNetw, vol. 2015, pp. 1-6, Jun. 2015, doi: \n10.1109/BSN.2015.7299420 \n[92] \nA. Sano et al., “Identifying Objective Physiological Markers and \nModifiable Behaviors for Self-Reported Stress and Mental Health \nStatus Using Wearable Sensors and Mobile Phones: Observational \nStudy,” J Med Internet Res, vol. 20, no. 6, p. e210, Jun. 2018, doi: \n10.2196/jmir.9410 \n[93] \nA. Sano and R. W. Picard, “Stress Recognition Using Wearable \nSensors and Mobile Phones,” in 2013 Humaine Association \nConference on Affective Computing and Intelligent Interaction, \nGeneva, Switzerland: IEEE, Sep. 2013, pp. 671–676. doi: \n10.1109/ACII.2013.117 \n[94] \nM. Ali, A. H. Mosa, F. Al Machot, and K. Kyamakya, “EEG-based \nemotion recognition approach for e-healthcare applications,” in \n2016 Eighth International Conference on Ubiquitous and Future \nNetworks (ICUFN), IEEE, 2016, pp. 946–950. doi: \n10.1109/ICUFN.2016.7536936 \n[95] \nC. Hondrou and G. Caridakis, “Affective, natural interaction using \nEEG: sensors, application and future directions,” in Artificial \nIntelligence: Theories and Applications: 7th Hellenic Conference on \nAI, SETN 2012, Lamia, Greece, May 28-31, 2012. Proceedings 7, \nSpringer, 2012, pp. 331–338. doi: 10.1007/978-3-642-30448-4_42 \n[96] \nX. Li et al., “EEG-based Emotion Recognition: A Tutorial and \nReview,” ACM Comput. Surv., vol. 55, no. 4, pp. 1–57, Apr. 2023, \ndoi: 10.1145/3524499 \n[97] \nJ. Atkinson and D. Campos, “Improving BCI-based emotion \nrecognition by combining EEG feature selection and kernel \nclassifiers,” Expert Systems with Applications, vol. 47, pp. 35–41, \n2016. doi: 10.1016/j.eswa.2015.10.049 \n[98] \nX. Li, D. Song, P. Zhang, G. Yu, Y. Hou, and B. Hu, “Emotion \nrecognition from multi-channel EEG data through convolutional \nrecurrent neural network,” in 2016 IEEE International Conference \non Bioinformatics and Biomedicine (BIBM), IEEE, 2016, pp. 352–\n359. doi: 10.1109/BIBM.2016.7822545 \n[99] \nE. S. Salama, R. A. El-Khoribi, M. E. Shoman, and M. A. W. \nShalaby, “EEG-based emotion recognition using 3D convolutional \nneural networks,” International Journal of Advanced Computer \nScience and Applications, vol. 9, no. 8, 2018 \n[100] \nN. Thammasan, K. Fukui, and M. Numao, “Application of deep \nbelief networks in eeg-based dynamic music-emotion recognition,” \nin 2016 International Joint Conference on Neural Networks \n(IJCNN), IEEE, 2016, pp. 881–888. doi: \n10.1109/IJCNN.2016.7727292 \n[101] \nD. Hazarika, R. Zimmermann, and S. Poria, “MISA: Modality-\nInvariant and -Specific Representations for Multimodal Sentiment \nAnalysis,” in Proceedings of the 28th ACM International \nConference on Multimedia, Seattle WA USA: ACM, Oct. 2020, pp. \n1122–1131. doi: 10.1145/3394171.3413678 \n[102] \nT. Liang, G. Lin, L. Feng, Y. Zhang, and F. Lv, “Attention is not \nEnough: Mitigating the Distribution Discrepancy in Asynchronous \nMultimodal Sequence Fusion,” in 2021 IEEE/CVF International \nConference on Computer Vision (ICCV), Montreal, QC, Canada: \nIEEE, Oct. 2021, pp. 8128–8136. doi: \n10.1109/ICCV48922.2021.00804 \n[103] \nY.-H. H. Tsai, S. Bai, P. Pu Liang, J. Z. Kolter, L.-P. Morency, and \nR. Salakhutdinov, “Multimodal Transformer for Unaligned \nMultimodal Language Sequences,” Proc Conf Assoc Comput \nLinguist Meet, vol. 2019, pp. 6558–6569, Jul. 2019, doi: \n10.18653/v1/p19-1656 \n[104] \nD. Yang, S. Huang, H. Kuang, Y. Du, and L. Zhang, “Disentangled \nRepresentation Learning for Multimodal Emotion Recognition,” in \nProceedings of the 30th ACM International Conference on \nMultimedia, Lisboa Portugal: ACM, Oct. 2022, pp. 1642–1651. doi: \n10.1145/3503161.3547754 \n[105] \nB. Chen, Q. Cao, M. Hou, Z. Zhang, G. Lu, and D. Zhang, \n“Multimodal emotion recognition with temporal and semantic \nconsistency,” IEEE/ACM Transactions on Audio, Speech, and \nLanguage Processing, vol. 29, pp. 3592–3603, 2021. doi: \n10.1109/TASLP.2021.3129331 \n[106] \nA. Gandhi, K. Adhvaryu, S. Poria, E. Cambria, and A. Hussain, \n“Multimodal sentiment analysis: A systematic review of history, \ndatasets, multimodal fusion methods, applications, challenges and \nfuture directions,” Information Fusion, vol. 91, pp. 424–444, Mar. \n2023. doi: 10.1016/j.inffus.2022.09.025 \n[107] \nS. Zhang, S. Zhang, T. Huang, W. Gao, and Q. Tian, “Learning \naffective features with a hybrid deep model for audio–visual \nemotion recognition,” IEEE Transactions on Circuits and Systems \nfor Video Technology, vol. 28, no. 10, pp. 3030–3043, 2017. doi: \n10.1109/TCSVT.2017.2719043 \n[108] \nW. Neal Reilly, “Believable social and emotional agents,” PhD \nThesis, Ph. D Thesis CMU-CS-96-138. Carnegie Mellon Univ, \n1996. \n[109] \nA. Popescu, J. Broekens, and M. Van Someren, “GAMYGDALA: \nAn Emotion Engine for Games,” IEEE Trans. Affective Comput., \nvol. 5, no. 1, pp. 32–44, Jan. 2014. doi: 10.1109/T-AFFC.2013.24 \n[110] \nP. C. Ellsworth and K. R. Scherer, “Appraisal Processes In \nEmotion,” in Handbook of Affective Sciences, R. J. Davidson, K. R. \nScherer, and H. H. Goldsmith, Eds., Oxford University PressNew \nYork, NY, 2002, pp. 572–595. \ndoi:10.1093/oso/9780195126013.003.0029 \n[111] \nR. S. Lazarus, “On the Primacy of Cognition,” American \nPsychologist, vol. 39, no. 2, pp. 124–129, 1984. doi: 10.1037/0003-\n066X.39.2.124 \n[112] \nJ. Gratch and S. Marsella, “A domain-independent framework for \nmodeling emotion,” Cognitive Systems Research, vol. 5, no. 4, pp. \n269–306, Dec. 2004. doi: 10.1016/j.cogsys.2004.02.002 \n[113] \nS. D. Houlihan, D. Ong, M. Cusimano, and R. Saxe, “Reasoning \nabout the antecedents of emotions: Bayesian causal inference over \nan intuitive theory of Mind,” in Proceedings of the Annual Meeting \nof the Cognitive Science Society, 2022. \nhttps://escholarship.org/uc/item/7sn3w3n2 \n[114] \nS. D. Houlihan, M. Kleiman-Weiner, L. B. Hewitt, J. B. \nTenenbaum, and R. Saxe, “Emotion prediction as computation over \na generative theory of mind,” Phil. Trans. R. Soc. A., vol. 381, no. \n2251, p. 20220047, Jul. 2023. doi: 10.1098/rsta.2022.0047 \n[115] \nR. Saxe and S. D. Houlihan, “Formalizing emotion concepts within \na Bayesian model of theory of mind,” Current Opinion in \nPsychology, vol. 17, pp. 15–21, Oct. 2017. doi: \n10.1016/j.copsyc.2017.04.019 \n[116] \nM. Si, S. C. Marsella, and D. V. Pynadath, “Modeling appraisal in \ntheory of mind reasoning,” Autonomous Agents and Multi-Agent \nSystems, vol. 20, pp. 14–31, 2010. doi: 10.1007/s10458-009-9093-x \n[117] \nA. S. Rao, M. P. Georgeff, and others, “BDI agents: from theory to \npractice.,” in Icmas, vol. 95, pp. 312–319, 1995. \n\n22 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \n[118] \nB. Alfonso, E. Vivancos, and V. Botti, “Toward Formal Modeling \nof Affective Agents in a BDI Architecture,” ACM Trans. Internet \nTechnol., vol. 17, no. 1, pp. 1–23, Feb. 2017, doi: 10.1145/3001584 \n[119] \nJ. Gluz and P. Jaques, “A probabilistic implementation of emotional \nBDI agents,” in International Conference on Agents and Artificial \nIntelligence, SCITEPRESS, pp. 121–129, 2014. doi: \n10.5220/0004815501210129 \n[120] \nF. Peinado, M. Cavazza, and D. Pizzi, “Revisiting character-based \naffective storytelling under a narrative BDI framework,” in \nInteractive Storytelling: First Joint International Conference on \nInteractive Digital Storytelling, ICIDS 2008 Erfurt, Germany, \nNovember 26-29, 2008 Proceedings 1, pp. 83–88, Springer, 2008. \ndoi: 10.1007/978-3-540-89454-4_13 \n[121] \nY. Sánchez, T. Coma, A. Aguelo, and E. Cerezo, “ABC-EBDI: An \naffective framework for BDI agents,” Cognitive Systems Research, \nvol. 58, pp. 195–216, 2019. doi: 10.1016/j.cogsys.2019.07.002 \n[122] \nY. Sánchez-López and E. Cerezo, “Designing emotional BDI \nagents: good practices and open questions,” The Knowledge \nEngineering Review, vol. 34, p. e26, 2019, doi: \n10.1017/S0269888919000122 \n[123] \nA. Ortony, G. L. Clore, and A. Collins, The Cognitive Structure of \nEmotions. New York: NY: Cambridge University Press, 1988. \n[124] \nG. L. Clore and A. Ortony, “Psychological Construction in the OCC \nModel of Emotion,” Emotion Review, vol. 5, no. 4, pp. 335–343, \nOct. 2013. doi: 10.1177/1754073913489751 \n[125] \nJ. Dias, S. Mascarenhas, and A. Paiva, “FAtiMA Modular: Towards \nan Agent Architecture with a Generic Appraisal Framework,” in \nEmotion Modeling, vol. 8750, T. Bosse, J. Broekens, J. Dias, and J. \nVan Der Zwaan, Eds., in Lecture Notes in Computer Science, vol. \n8750. , Cham: Springer International Publishing, 2014, pp. 44–56. \ndoi: 10.1007/978-3-319-12973-0_3 \n[126] \nC. D. Elliott, “The affective reasoner: a process model of emotions \nin a multiagent system,” Northwestern University, 1992. \n[127] \nM. S. El-Nasr, J. Yen, and T. R. Ioerger, “Flame—fuzzy logic \nadaptive model of emotions,” Autonomous Agents and Multi-Agent \nSystems, vol. 3, pp. 219–257, 2000. doi: 10.1023/A:1010030809960 \n[128] \nP. Gebhard, “ALMA: a layered model of effect,” in Proceedings of \nthe Fourth International Joint Conference on Autonomous Agents \nand Multiagent Systems, 2005, pp. 29–36. doi: \n10.1145/1082473.1082478 \n[129] \nN. H. Frijda, The Emotions. Cambridge University Press, 1986. \n[130] \nI. J. Roseman, “Cognitive determinants of emotion: A structural \ntheory.,” Review of Personality & Social Psychology, vol. 5, pp. 11-\n36, 1984. \n[131] \nK. R. Scherer, “On the nature and function of emotion: A \ncomponent process approach,” in Approaches to Emotion, NJ: \nErlbaum, 1984. \n[132] \nC. A. Smith and P. C. Ellsworth, “Patterns of cognitive appraisal in \nemotion.,” Journal of Personality and Social Psychology, vol. 48, \nno. 4, p. 813-838, 1985. \n[133] \nP. C. Ellsworth, “Appraisal Theories of Emotions,” in Emotion \nTheory: The Routledge Comprehensive Guide, New York: \nRoutledge, 2024. \n[134] \nC. Becker-Asano, WASABI: Affect simulation for agents with \nbelievable interactivity, vol. 319. IOS Press, 2008. \n[135] \nR. P. Marinier III, J. E. Laird, and R. L. Lewis, “A computational \nunification of cognitive behavior and emotion,” Cognitive Systems \nResearch, vol. 10, no. 1, pp. 48–69, 2009. doi: \ndoi:10.1016/j.cogsys.2008.03.004 \n[136] \nE. Lotfi and M.-R. Akbarzadeh-T., “Practical emotional neural \nnetworks,” Neural Networks, vol. 59, pp. 61–72, Nov. 2014, doi: \n10.1016/j.neunet.2014.06.012 \n[137] \nS. Marsella, J. Gratch, P. Petta, and others, “Computational models \nof emotion,” in A Blueprint for Affective Computing-A sourcebook \nand manual, vol. 11, no. 1, New York, NY, USA: Oxford University \nPress, pp. 21–46, 2010. \n[138] \nY. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature, vol. \n521, no. 7553, pp. 436–444, 2015. doi: 10.1038/nature14539 \n[139] \nA. Khashman, “Modeling cognitive and emotional processes: A \nnovel neural network architecture,” Neural Networks, vol. 23, no. \n10, pp. 1155–1163, Dec. 2010, doi: 10.1016/j.neunet.2010.07.004 \n[140] \nD. C. Ong, H. Soh, J. Zaki, and N. D. Goodman, “Applying \nProbabilistic Programming to Affective Computing,” IEEE Trans \nAffect Comput, vol. 12, no. 2, pp. 306–317, 2021, doi: \n10.1109/taffc.2019.2905211 \n[141] \nD. Sander, D. Grandjean, and K. R. Scherer, “A systems approach to \nappraisal mechanisms in emotion,” Neural Networks, vol. 18, no. 4, \npp. 317–352, May 2005, doi: 10.1016/j.neunet.2005.03.001 \n[142] \nH.-W.-S. Bao, “The Fill-Mask Association Test (FMAT): \nMeasuring propositions in natural language.,” Journal of Personality \nand Social Psychology, 2024. doi: 10.1037/pspa0000396 \n[143] \nM. Binz and E. Schulz, “Using cognitive psychology to understand \nGPT-3,” Proceedings of the National Academy of Sciences, vol. 120, \nno. 6, p. e2218523120, 2023. doi: 10.1073/pnas.2218523120 \n[144] \nJ. Wei et al., “Chain-of-thought prompting elicits reasoning in large \nlanguage models,” Advances in Neural Information Processing \nSystems, vol. 35, pp. 24824–24837, 2022. \n[145] \nM. Croissant, M. Frister, G. Schofield, and C. McCall, “An \nAppraisal-Based Chain-Of-Emotion Architecture for Affective \nLanguage Model Game Agents,” Sep. 10, 2023, arXiv preprint: \narXiv:2309.05076. Accessed: Jul. 12, 2024. [Online]. Available: \nhttp://arxiv.org/abs/2309.05076 \n[146] \nJ. Berger and G. Packard, “Using natural language processing to \nunderstand people and culture.,” American Psychologist, vol. 77, no. \n4, p. 525, 2022. doi: 10.1037/amp0000882 \n[147] \nJ. Yang et al., “Harnessing the power of LLMs in practice: A survey \non ChatGPT and beyond,” ACM Transactions on Knowledge \nDiscovery from Data, vol. 18, no. 6, pp. 1–32, 2024. doi: \n10.1145/3649506 \n[148] \nA. Sobieszek and T. Price, “Playing games with AIs: the limits of \nGPT-3 and similar large language models,” Minds and Machines, \nvol. 32, no. 2, pp. 341–364, 2022. doi: 10.1007/s11023-022-09602-0 \n[149] \nS. D. Kreibig, “Autonomic nervous system activity in emotion: A \nreview,” Biological Psychology, vol. 84, no. 3, pp. 394–421, 2010. \ndoi: 10.1016/j.biopsycho.2010.03.010 \n[150] \nH. C. Lench, S. A. Flores, and S. W. Bench, “Discrete emotions \npredict changes in cognition, judgment, experience, behavior, and \nphysiology: a meta-analysis of experimental emotion elicitations.,” \nPsychological Bulletin, vol. 137, no. 5, p. 834, 2011. \ndoi:10.1037/a0024244.  \n[151] \nJ. L. Tracy and D. Randles, “Four models of basic emotions: A \nreview of Ekman and Cordaro, Izard, Levenson, and Panksepp and \nWatt,” Emotion Review, vol. 3, no. 4, pp. 397–405, 2011. doi: \n10.1177/1754073911410747 \n[152] \nL. Pessoa, “A network model of the emotional brain,” Trends in \nCognitive Sciences, vol. 21, no. 5, pp. 357–371, 2017. doi: \n10.1016/j.tics.2017.03.002. \n[153] \nA. Shenhav and W. B. Mendes, “Aiming for the stomach and hitting \nthe heart: dissociable triggers and sources for disgust reactions.,” \nEmotion, vol. 14, no. 2, p. 301, 2014. doi:10.1037/a0034644. \n[154] \nK. C. Berridge and M. L. Kringelbach, “Neuroscience of affect: \nbrain mechanisms of pleasure and displeasure,” Current Opinion in \nNeurobiology, vol. 23, no. 3, pp. 294–303, 2013. \ndoi:10.1016/j.conb.2013.01.017 \n[155] \nJ. LeDoux, “Rethinking the Emotional Brain,” Neuron, vol. 73, no. \n4, pp. 653–676, Feb. 2012, doi: 10.1016/j.neuron.2012.02.004 \n[156] \nS. W. Gilroy et al., “Pad-based multimodal affective fusion,” in \n2009 3rd International Conference on Affective Computing and \nIntelligent Interaction and Workshops, IEEE, 2009, pp. 1–8. doi: \n10.1109/ACII.2009.5349552 \n[157] \nJ. Jia, S. Zhang, F. Meng, Y. Wang, and L. Cai, “Emotional audio-\nvisual speech synthesis based on PAD,” IEEE Transactions on \nAudio, Speech, and Language Processing, vol. 19, no. 3, pp. 570–\n582, 2010. doi: 10.1109/TASL.2010.2052246 \n[158] \nV. Terzis, C. N. Moridis, and A. A. Economides, “The effect of \nemotional feedback on behavioral intention to use computer-based \nassessment,” Computers & Education, vol. 59, no. 2, pp. 710–721, \nSep. 2012. doi: 10.1016/j.compedu.2012.03.003 \n[159] \nW. Robinson, “Ecological Correlations and the Behavior of \nIndividuals*,” International Journal of Epidemiology, vol. 38, no. 2, \npp. 337–341, Apr. 2009. doi: 10.1093/ije/dyn357 \n[160] \nP. J. Curran and D. J. Bauer, “The Disaggregation of Within-Person \nand Between-Person Effects in Longitudinal Models of Change,” \nAnnu. Rev. Psychol., vol. 62, no. 1, pp. 583–619, Jan. 2011. doi: \n10.1146/annurev.psych.093008.100356 \n[161] \nH. R. Kirk, B. Vidgen, P. Röttger, and S. A. Hale, “The benefits, \nrisks and bounds of personalizing the alignment of large language \nmodels to individuals,” Nat Mach Intell, vol. 6, no. 4, pp. 383–392, \nApr. 2024. doi: 10.1038/s42256-024-00820-y \n\n23 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \n[162] \nJ. Li, A. Waleed, and H. Salam, “A Survey on Personalized \nAffective Computing in Human-Machine Interaction,” Apr. 01, \n2023, arXiv preprint: arXiv:2304.00377. Accessed: Aug. 04, 2024. \n[Online]. Available: http://arxiv.org/abs/2304.00377 \n[163] \nR. Alexander et al., “The neuroscience of positive emotions and \naffect: Implications for cultivating happiness and wellbeing,” \nNeuroscience & Biobehavioral Reviews, vol. 121, pp. 220–249, \n2021. doi: 10.1016/j.neubiorev.2020.12.002 \n[164] \nG. L. Clore and A. Ortony, “Cognition in emotion: Always, \nsometimes, or never,” In Cognitive Neuroscience of Emotion, New \nYork: Oxford University Press., pp. 24–61, 2000. \n[165] \nD. Becker and K. Bernecker, “The Role of Hedonic Goal Pursuit in \nSelf-Control and Self-Regulation: Is Pleasure the Problem or Part of \nthe Solution?,” Affec Sci, vol. 4, no. 3, pp. 470–474, Sep. 2023. doi: \n10.1007/s42761-023-00193-2 \n[166] \nS. Yu, “Between-Level Incongruences in Human Positivity,” \nPerspectives on Psychological Science, vol. 20, no. 1, pp. 3-19, \n2025. doi: 10.1177/17456916231190824 \n[167] \nM. Csikszentmihalyi, M. Csikszentmihalyi, S. Abuhamdeh, and J. \nNakamura, “Flow,” Flow and the Foundations of Positive \nPsychology: The Collected Works of Mihaly Csikszentmihalyi, \nSpringer Dordrecht, pp. 227–238, 2014. \n[168] \nJ. Nakamura, M. Csikszentmihalyi, and others, “The concept of \nflow,” Handbook of Positive Psychology, New York: University \nPress, pp. 89-105, 2002. \n[169] \nP. van Geert, “Nonlinear complex dynamical systems in \ndevelopmental psychology.,” in Chaos and Complexity in \nPsychology: The Theory of Nonlinear Dynamical Systems., New \nYork, NY: Cambridge University Press, pp. 242–281, 2009. \n[170] \nK. Friston, T. FitzGerald, F. Rigoli, P. Schwartenbeck, and G. \nPezzulo, “Active inference: a process theory,” Neural Computation, \nvol. 29, no. 1, pp. 1–49, 2017. doi: 10.1162/NECO_a_00912 \n[171] \nG. Pezzulo, T. Parr, and K. Friston, “Active inference as a theory of \nsentient behavior,” Biological Psychology, vol. 186, p. 108741, Feb. \n2024. doi: 10.1016/j.biopsycho.2023.108741 \n[172] \nC. Hesp, R. Smith, T. Parr, M. Allen, K. J. Friston, and M. J. D. \nRamstead, “Deeply Felt Affect: The Emergence of Valence in Deep \nActive Inference,” Neural Computation, vol. 33, no. 2, pp. 398–446, \nFeb. 2021, doi: 10.1162/neco_a_01341 \n[173] \nM. Joffily and G. Coricelli, “Emotional valence and the free-energy \nprinciple,” PLoS Computational Biology, vol. 9, no. 6, p. e1003094, \n2013. doi: 10.1371/journal.pcbi.1003094 \n[174] \nJ. Kiverstein, M. Miller, and E. Rietveld, “The feeling of grip: \nnovelty, error dynamics, and the predictive brain,” Synthese, vol. \n196, pp. 2847–2869, 2019. doi: 10.1007/s11229-017-1583-9 \n[175] \nM. Miller, J. Kiverstein, and E. Rietveld, “The Predictive Dynamics \nof Happiness and Well-Being,” Emotion Review, vol. 14, no. 1, pp. \n15–30, Jan. 2022. doi: 10.1177/17540739211063851 \n[176] \nP. Sandoval-Segura, V. Singla, J. Geiping, M. Goldblum, and T. \nGoldstein, “What can we learn from unlearnable datasets?,” \nAdvances in Neural Information Processing Systems, vol. 36, pp. \n75372-75391, 2024. \n[177] \nS. Oishi and J. Graham, “Social Ecology: Lost and Found in \nPsychological Science,” Perspect Psychol Sci, vol. 5, no. 4, pp. 356–\n377, Jul. 2010. doi: 10.1177/1745691610374588 \n[178] \nU. Bronfenbrenner, “Toward an experimental ecology of human \ndevelopment.” American Psychologist, vol. 32, no. 7, p. 513, 1977. \ndoi: 10.1037/0003-066X.32.7.513 \n[179] \nU. Bronfenbrenner, “Recent advances in research on the ecology of \nhuman development,” Development as Action in Context, Springer, \nBerlin, Heidelberg, pp. 287–309, 1986. doi: 10.1007/978-3-662-\n02475-1_15 \n[180] \nU. Bronfenbrenner and P. A. Morris, “The ecology of \ndevelopmental processes.,” In W. Damon & R. M. Lerner (Eds.), \nHandbook of Child Psychology: Theoretical Models of Human \nDevelopment (5th ed., pp. 993–1028). John Wiley & Sons, Inc.. \n1998. \n[181] \nC. S. Dweck, “From needs to goals and representations: Foundations \nfor a unified theory of motivation, personality, and development.,” \nPsychological Review, vol. 124, no. 6, pp. 689–719, Nov. 2017, doi: \n10.1037/rev0000082 \n[182] \nL. F. Barrett, “Context reconsidered: Complex signal ensembles, \nrelational meaning, and population thinking in psychological \nscience.,” American Psychologist, vol. 77, no. 8, pp. 894-920, 2022. \ndoi: 10.1037/amp0001054 \n[183] \nM. Saqr, R. Cheng, S. López-Pernas, and E. D. Beck, “Idiographic \nartificial intelligence to explain students’ self-regulation: Toward \nprecision education,” Learning and Individual Differences, vol. 114, \np. 102499, Aug. 2024. doi: 10.1016/j.lindif.2024.102499 \n[184] \nD. Urhahne and L. Wijnia, “Theories of Motivation in Education: an \nIntegrative Framework,” Educ Psychol Rev, vol. 35, no. 2, p. 45, \nJun. 2023, doi: 10.1007/s10648-023-09767-9 \n[185] \nE. L. Deci and R. M. Ryan, “The \"what\" and \"why\" of goal pursuits: \nHuman needs and the self-determination of behavior,” \nPsychological Inquiry, vol. 11, no. 4, pp. 227–268, 2000. \ndoi:10.1207/S15327965PLI1104_01 \n[186] \nA. S. Heller, A. S. Fox, E. K. Wing, K. M. McQuisition, N. J. Vack, \nand R. J. Davidson, “The Neurodynamics of Affect in the \nLaboratory Predicts Persistence of Real-World Emotional \nResponses,” J. Neurosci., vol. 35, no. 29, pp. 10503–10509, Jul. \n2015, doi: 10.1523/JNEUROSCI.0569-15.2015 \n[187] \nD. W. Grupe et al., “Behavioral and neural indices of affective \ncoloring for neutral social stimuli,” Social Cognitive and Affective \nNeuroscience, vol. 13, no. 3, pp. 310–320, 2018. \ndoi:10.1093/scan/nsy011 \n[188] \nA. Tambini, U. Rimmele, E. A. Phelps, and L. Davachi, “Emotional \nbrain states carry over and enhance future memory formation,” \nNature Neuroscience, vol. 20, no. 2, pp. 271–278, 2017. \ndoi:10.1038/nn.4468 \n[189] \nR. J. Davidson, “Well-being and affective style: neural substrates \nand biobehavioural correlates.,” Philos Trans R Soc Lond B Biol Sci, \nvol. 359, no. 1449, pp. 1395–1411, Sep. 2004, \ndoi:10.1098/rstb.2004.1510 \n[190] \nM. B. Brewer, “The psychology of prejudice: Ingroup love and \noutgroup hate?,” Journal of Social Issues, vol. 55, no. 3, pp. 429–\n444, 1999. doi: 10.1111/0022-4537.00126 \n[191] \nL. Muttenthaler, J. Dippel, L. Linhardt, R. A. Vandermeulen, and S. \nKornblith, “Human alignment of neural network representations,” \nApr. 03, 2023, arXiv preprint: arXiv:2211.01201. \ndoi:10.48550/arXiv.2211.01201 \n[192] \nJ. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, \n“Imagenet: A large-scale hierarchical image database,” in 2009 \nIEEE Conference on Computer Vision and Pattern Recognition, \nIEEE, 2009, pp. 248–255. doi: 10.1109/CVPR.2009.5206848. \n[193] \nM. Csikszentmihalyi, Handbook of Research Methods for Studying \nDaily Life. Guilford Press, 2011. \n[194] \nS. Shiffman, A. A. Stone, and M. R. Hufford, “Ecological \nmomentary assessment,” Annu. Rev. Clin. Psychol., vol. 4, no. 1, pp. \n1–32, 2008. doi: 10.1146/annurev.clinpsy.3.022806.091415 \n[195] \nT. J. Trull and U. Ebner-Priemer, “The role of ambulatory \nassessment in psychological science,” Current Directions in \nPsychological Science, vol. 23, no. 6, pp. 466–470, 2014. doi: \n10.1177/0963721414550706 \n[196] \nD. Kahneman, A. B. Krueger, D. A. Schkade, N. Schwarz, and A. \nA. Stone, “A survey method for characterizing daily life experience: \nThe day reconstruction method,” Science, vol. 306, no. 5702, pp. \n1776–1780, 2004. doi: 10.1126/science.1103572 \n[197] \nL. Hasenbein et al., “Learning with simulated virtual classmates: \nEffects of social-related configurations on students’ visual attention \nand learning experiences in an immersive virtual reality classroom,” \nComputers in Human Behavior, vol. 133, p. 107282, Aug. 2022. \ndoi:10.1016/j.chb.2022.107282 \n[198] \nR. Liu, L. Wang, J. Lei, Q. Wang, and Y. Ren, “Effects of an \nimmersive virtual reality‐based classroom on students’ learning \nperformance in science lessons,” Brit J Educational Tech, vol. 51, \nno. 6, pp. 2034–2049, Nov. 2020. doi: 10.1111/bjet.13028 \n[199] \nM. Mulders, J. Buchner, and M. Kerres, “A Framework for the Use \nof Immersive Virtual Reality in Learning Environments,” Int. J. \nEmerg. Technol. Learn., vol. 15, no. 24, p. 208, Dec. 2020. doi: \n10.3991/ijet.v15i24.16615 \n[200] \nÉ. Ouellet, B. Boller, N. Corriveau-Lecavalier, S. Cloutier, and S. \nBelleville, “The Virtual Shop: A new immersive virtual reality \nenvironment and scenario for the assessment of everyday memory,” \nJournal of Neuroscience Methods, vol. 303, pp. 126–135, Jun. 2018. \ndoi: 10.1016/j.jneumeth.2018.03.010 \n[201] \nM. C. Howard, “Virtual reality interventions for personal \ndevelopment: A meta-analysis of hardware and software,” Human-\nComputer Interaction, vol. 34, no. 3, pp. 205–239, 2019. \ndoi:10.1080/07370024.2018.1469408 \n\n24 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \n[202] \nE. Johnston, G. Olivas, P. Steele, C. Smith, and L. Bailey, \n“Exploring pedagogical foundations of existing virtual reality \neducational applications: A content analysis study,” Journal of \nEducational Technology Systems, vol. 46, no. 4, pp. 414–439, 2018. \ndoi: 10.1177/0047239517745560 \n[203] \nC. Zhang, Y. Xie, H. Bai, B. Yu, W. Li, and Y. Gao, “A survey on \nfederated learning,” Knowledge-Based Systems, vol. 216, p. 106775, \nMar. 2021, doi: 10.1016/j.knosys.2021.106775 \n[204] \nA. Gadotti, L. Rocher, F. Houssiau, M. Creţu, and A. de Montjoye, \n“Anonymization: The imperfect science of using data while \npreserving privacy,” Science Advances, 2024. \ndoi:10.1126/sciadv.adn7053 \n[205] \nT. Wilholt, “Bias and values in scientific research,” Studies in \nHistory and Philosophy of Science Part A, vol. 40, no. 1, pp. 92–\n101, Mar. 2009, doi: 10.1016/j.shpsa.2008.12.005 \n[206] \nE. Ntoutsi et al., “Bias in data-driven artificial intelligence \nsystems—An introductory survey,” Wiley Interdisciplinary Reviews: \nData Mining and Knowledge Discovery, vol. 10, no. 3, p. e1356, \n2020. doi: 10.1002/widm.1356 \n[207] \nB. Schölkopf et al., “Toward Causal Representation Learning,” \nProceedings of the IEEE, vol. 109, no. 5, pp. 612–634, May 2021, \ndoi: 10.1109/JPROC.2021.3058954 \n[208] \nJ. Peters, D. Janzing, and B. Schölkopf, Elements of Causal \nInference: Foundations and Learning Algorithms. The MIT Press, \n2017. http://library.oapen.org/handle/20.500.12657/26040 \n[209] \nB. Schölkopf, D. Janzing, J. Peters, E. Sgouritsa, K. Zhang, and J. \nMooij, “On causal and anticausal learning,” arXiv preprint \narXiv:1206.6471, 2012. https://doi.org/10.48550/arXiv.1206.6471 \n[210] \nP. Spirtes, C. Glymour, and R. Scheines, Causation, Prediction, and \nSearch. The MIT Press, 2001. \n[211] \nJ. Richens and T. Everitt, “Robust agents learn causal world \nmodels,” arXiv preprint arXiv:2402.10877, 2024. Available: \nhttps://doi.org/10.48550/arXiv.2402.10877 \n[212] \nJ. B. Tenenbaum, C. Kemp, T. L. Griffiths, and N. D. Goodman, \n“How to Grow a Mind: Statistics, Structure, and Abstraction,” \nScience, vol. 331, no. 6022, pp. 1279–1285, Mar. 2011. doi: \n10.1126/science.1192788 \n[213] \nL. D. Costa et al., “Possible principles for aligned structure learning \nagents,” Sep. 30, 2024, arXiv preprint arXiv:2410.00258. Accessed: \nOct. 22, 2024. [Online]. Available: http://arxiv.org/abs/2410.00258 \n[214] \nR. T. Lee, M. Ni, W. M. Fang, I. Ravreby, Y. Shoda, and V. Zayas, \n“An Integrative Framework for Capturing Emotion and Emotion \nRegulation in Daily Life,” Affective Science, vol. 5, no. 3, pp. 179–\n183, Sep. 2024. doi: 10.1007/s42761-024-00262-0 \n[215] \nK. D. Hoover, “Causality in economics and econometrics,” In New \nPalgrave Dictionary of Economics. (eds Durlauf, S. N., & Blume, L. \nE.) 2nd ed. 2008 (Palgrave Macmillan, Basingstoke, UK, 2006). \n[216] \nM. Otani, Y. Nakashima, E. Rahtu, J. Heikkilä, and N. Yokoya, \n“Learning Joint Representations of Videos and Sentences with Web \nImage Search,” Aug. 08, 2016, arXiv preprint arXiv:1608.02367. \nAvailable: http://arxiv.org/abs/1608.02367 \n[217] \nA. Farhadi et al., “Every picture tells a story: Generating sentences \nfrom images,” in Computer Vision–ECCV 2010: 11th European \nConference on Computer Vision, Heraklion, Crete, Greece, \nSeptember 5-11, 2010, Proceedings, Part IV 11, Springer, 2010, pp. \n15–29. doi: 10.1007/978-3-642-15561-1_2 \n[218] \nD. Lin, S. Fidler, C. Kong, and R. Urtasun, “Visual Semantic \nSearch: Retrieving Videos via Complex Textual Queries,” in 2014 \nIEEE Conference on Computer Vision and Pattern Recognition, \nColumbus, OH, USA: IEEE, Jun. 2014, pp. 2657–2664. doi: \n10.1109/CVPR.2014.340 \n[219] \nR. Socher, M. Ganjoo, C. D. Manning, and A. Ng, “Zero-Shot \nLearning Through Cross-Modal Transfer,” in Advances in Neural \nInformation Processing Systems, Curran Associates, Inc., 2013. \nAvailable: \nhttps://proceedings.neurips.cc/paper/2013/hash/2d6cc4b2d139a5351\n2fb8cbb3086ae2e-Abstract.html \n[220] \nY. Yu, J. Chen, T. Gao, and M. Yu, “DAG-GNN: DAG structure \nlearning with graph neural networks,” in International Conference \non Machine Learning, PMLR, 2019, pp. 7154–7163. Available: \nhttps://proceedings.mlr.press/v97/yu19a.html \n[221] \nX. Zheng, B. Aragam, P. K. Ravikumar, and E. P. Xing, “DAGs \nwith NO TEARS: Continuous Optimization for Structure Learning,” \nin Advances in Neural Information Processing Systems, Curran \nAssociates, Inc., 2018. Available: \nhttps://proceedings.neurips.cc/paper/2018/hash/e347c51419ffb23ca3\nfd5050202f9c3d-Abstract.html \n[222] \nJ. S. Park, L. Popowski, C. Cai, M. R. Morris, P. Liang, and M. S. \nBernstein, “Social Simulacra: Creating Populated Prototypes for \nSocial Computing Systems,” in Proceedings of the 35th Annual \nACM Symposium on User Interface Software and Technology, Bend \nOR USA: ACM, Oct. 2022, pp. 1–18. \ndoi:10.1145/3526113.3545616. \n[223] \nJ. S. Park et al., “Generative agent simulations of 1,000 people,” \narXiv preprint arXiv:2411.10109, 2024. Available: \nhttps://doi.org/10.48550/arXiv.2411.10109 \n[224] \nM. L. Littman, “Reinforcement learning improves behaviour from \nevaluative feedback,” Nature, vol. 521, no. 7553, pp. 445–451, May \n2015. doi: 10.1038/nature14540 \n[225] \nE. Bengio, J. Pineau, and D. Precup, “Interference and \nGeneralization in Temporal Difference Learning,” in Proceedings of \nthe 37th International Conference on Machine Learning, PMLR, \nNov. 2020, pp. 767–777. Available: \nhttps://proceedings.mlr.press/v119/bengio20a.html \n[226] \nL. Wang, X. Zhang, H. Su, and J. Zhu, “A Comprehensive Survey \nof Continual Learning: Theory, Method and Application,” Feb. 06, \n2024, arXiv preprint: arXiv:2302.00487. \ndoi:10.48550/arXiv.2302.00487. \n[227] \nJ. Piaget, The Construction of Reality in the Child (eBook). \nRoutledge, 2013. Available: https://doi.org/10.4324/9781315009650 \n[228] \nT. J. Morgan and M. W. Feldman, “Human culture is uniquely open-\nended rather than uniquely cumulative,” Nature Human Behaviour, \nvol. 9, pp. 28–42, 2024. doi: 10.1038/s41562-024-02035-y \n[229] \nA. Cossu, A. Carta, V. Lomonaco, and D. Bacciu, “Continual \nlearning for recurrent neural networks: An empirical evaluation,” \nNeural Networks, vol. 143, pp. 607–627, Nov. 2021. doi: \n10.1016/j.neunet.2021.07.021 \n[230] \nG. M. Van de Ven and A. S. Tolias, “Three scenarios for continual \nlearning,” arXiv preprint arXiv:1904.07734, 2019. Available: \nhttps://doi.org/10.48550/arXiv.1904.07734 \n[231] \nG. A. Carpenter and S. Grossberg, “A massively parallel \narchitecture for a self-organizing neural pattern recognition \nmachine,” Computer Vision, Graphics, and Image Processing, vol. \n37, no. 1, pp. 54–115, 1987. \n[232] \nK. Khetarpal, M. Riemer, I. Rish, and D. Precup, “Towards \nContinual Reinforcement Learning: A Review and Perspectives,” \nJournal of Artificial Intelligence Research, vol. 75, pp. 1401–1476, \nDec. 2022. doi: 10.1613/jair.1.13673 \n[233] \nM. Binz, I. Dasgupta, A. K. Jagadish, M. Botvinick, J. X. Wang, and \nE. Schulz, “Meta-learned models of cognition,” Behav Brain Sci, \nvol. 47, p. e147, 2024. doi: 10.1017/S0140525X23003266 \n[234] \nC. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning \nfor fast adaptation of deep networks,” in Proceedings of the 34th \nInternational Conference on Machine Learning, PMLR, vol. 70, pp. \n1126-1135, 2017. Available: \nhttps://proceedings.mlr.press/v70/finn17a.html \n[235] \nB. M. Lake and M. Baroni, “Human-like systematic generalization \nthrough a meta-learning neural network,” Nature, vol. 623, no. \n7985, pp. 115–121, 2023. doi: 10.1038/s41586-023-06668-3 \n[236] \nK. Nussenbaum and C. A. Hartley, “Understanding the development \nof reward learning through the lens of meta-learning,” Nat Rev \nPsychol, vol. 3, no. 6, pp. 424–438, Apr. 2024. doi: 10.1038/s44159-\n024-00304-1 \n[237] \nG. Berseth, Z. Zhang, G. Zhang, C. Finn, and S. Levine, “CoMPS: \nContinual Meta Policy Search,” Dec. 08, 2021, arXiv preprint \narXiv:2112.04467. Available: \nhttps://doi.org/10.48550/arXiv.2112.04467 \n[238] \nR. T. McCoy and T. L. Griffiths, “Meta-learning as a bridge \nbetween neural networks and symbolic Bayesian models,” \nBehavioral and Brain Sciences, vol. 47, p. e155, 2024. doi: \n10.1017/S0140525X24000116 \n[239] \nR. T. McCoy and T. L. Griffiths, “Modeling rapid language learning \nby distilling Bayesian priors into artificial neural networks,” May \n24, 2023, arXiv preprint: arXiv:2305.14701. Available: \nhttp://arxiv.org/abs/2305.14701 \n[240] \nW. Zhao, J. P. Queralta, and T. Westerlund, “Sim-to-real transfer in \ndeep reinforcement learning for robotics: a survey,” in 2020 IEEE \nsymposium series on computational intelligence (SSCI), IEEE, 2020, \npp. 737–744. doi: 10.1109/SSCI47803.2020.9308468 \n\n25 \nTeleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being \n[241] \nA. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V. Koltun, \n“CARLA: An open urban driving simulator,” in Proceedings of the \n1st Annual Conference on Robot Learning, PMLR, vol. 78, pp. 1–\n16, 2017. Available: \nhttps://proceedings.mlr.press/v78/dosovitskiy17a.html \n[242] \nS. Shah, D. Dey, C. Lovett, and A. Kapoor, “Airsim: High-fidelity \nvisual and physical simulation for autonomous vehicles,” In Hutter, \nM., Siegwart, R. (eds) Field and Service Robotics. Springer \nProceedings in Advanced Robotics, vol 5. Springer, Cham, 2018. \ndoi: 10.1007/978-3-319-67361-5_40 \n[243] \nE. Todorov, T. Erez, and Y. Tassa, “Mujoco: A physics engine for \nmodel-based control,” in 2012 IEEE/RSJ International Conference \non Intelligent Robots and Systems, Vilamoura-Algarve, Portugal, \n2012, pp. 5026–5033. doi: 10.1109/IROS.2012.6386109 \n[244] \nS. Qi et al., “CivRealm: A Learning and Reasoning Odyssey in \nCivilization for Decision-Making Agents,” Mar. 12, 2024, arXiv \npreprint: arXiv:2401.10568. Available: \nhttp://arxiv.org/abs/2401.10568 \n[245] \nJ. Bauer et al., “Human-timescale adaptation in an open-ended task \nspace,” in Proceedings of the 40th International Conference on \nMachine Learning, PMLR, vol. 202, pp. 1887–1935, 2023. \nAvailable: https://proceedings.mlr.press/v202/bauer23a.html \n[246] \nS. Reed et al., “A Generalist Agent,” Nov. 11, 2022, arXiv preprint \narXiv:2205.06175. doi: 10.48550/arXiv.2205.06175. \n[247] \nD. Silver, S. Singh, D. Precup, and R. S. Sutton, “Reward is \nenough,” Artificial Intelligence, vol. 299, p. 103535, Oct. 2021, doi: \n10.1016/j.artint.2021.103535 \n[248] \nD. Kahneman, A. B. Krueger, D. Schkade, N. Schwarz, and A. \nStone, “Toward National Well-Being Accounts,” American \nEconomic Review, vol. 94, no. 2, pp. 429–434, Apr. 2004, doi: \n10.1257/0002828041301713. \n[249] \nE. L. Deci and R. M. Ryan, “Hedonia, eudaimonia, and well-being: \nan introduction,” J Happiness Stud, vol. 9, no. 1, pp. 1–11, Jan. \n2008, doi: 10.1007/s10902-006-9018-1. \n[250] \nJ. E. Butner, K. T. Gagnon, M. N. Geuss, D. A. Lessard, and T. N. \nStory, “Utilizing topology to generate and test theories of change.,” \nPsychological Methods, vol. 20, no. 1, pp. 1–25, 2015, doi: \n10.1037/a0037802. \n[251] \nX. T. Wang and J. G. Johnson, “A tri-reference point theory of \ndecision making under risk.,” Journal of Experimental Psychology: \nGeneral, vol. 141, no. 4, p. 743-756, 2012. doi: 10.1037/a0027415 \n[252] \nC.-Y. Liu and B. Yin, “Affective Foundations in AI-Human \nInteractions: Insights from Evolutionary Continuity and Interspecies \nCommunications,” Computers in Human Behavior, p. 108406, Aug. \n2024. doi: 10.1016/j.chb.2024.108406 \n[253] \nL. Christov-Moore et al., “Preventing antisocial robots: A pathway \nto artificial empathy,” Science Robotics, vol. 8, no. 80, p. eabq3658, \nJul. 2023. doi: 10.1126/scirobotics.abq3658 \n[254] \nP. Bloom, “Empathy and its discontents,” Trends in Cognitive \nSciences, vol. 21, no. 1, pp. 24–31, 2017. \ndoi:10.1016/j.tics.2016.11.004 \n[255] \nJ. Prinz, “Against empathy,” The Southern Journal of Philosophy, \nvol. 49, pp. 214–233, 2011. doi: 10.1111/j.2041-6962.2011.00069.x \n[256] \nJ. Majdandžić, S. Amashaufer, A. Hummer, C. Windischberger, and \nC. Lamm, “The selfless mind: How prefrontal involvement in \nmentalizing with similar and dissimilar others shapes empathy and \nprosocial behavior,” Cognition, vol. 157, pp. 24–38, 2016. doi: \n10.1016/j.cognition.2016.08.003 \n[257] \nJ. Zaki, “Empathy: a motivated account.,” Psychological Bulletin, \nvol. 140, no. 6, p. 1608, 2014. doi: 10.1037/a0037679 \n[258] \nA. S. Cowen and D. Keltner, “Semantic Space Theory: A \nComputational Approach to Emotion,” Trends in Cognitive \nSciences, vol. 25, no. 2, pp. 124–136, Feb. 2021. doi: \n10.1016/j.tics.2020.11.004. \n[259] \nL. Nummenmaa, R. Hari, J. K. Hietanen, and E. Glerean, “Maps of \nsubjective feelings,” Proceedings of the National Academy of \nSciences, vol. 115, no. 37, pp. 9198–9203, Sep. 2018. doi: \n10.1073/pnas.1807390115 \n[260] \nJ. A. Russell, “Culture and the categorization of emotions.,” \nPsychological Bulletin, vol. 110, no. 3, pp. 426–450, 1991. doi: \n10.1037/0033-2909.110.3.426 \nDr. Bin Yin is an associate professor at \nFujian Normal University in Fuzhou, \nChina. He was born in China and \nearned dual Bachelor’s degrees in \nbiological sciences and psychology \nfrom Peking University in 2008. He \nlater earned his Ph.D. in psychology \nand \nneuroscience \nfrom \nDuke \nUniversity in 2016, where his research \nfocused \non \nanimal \nmodels \nand \ncomputational \nmethods \nfor \nunderstanding \nreward \nlearning, \nspatiotemporal cognition, and emotional processes. \n \nDr. Yin’s academic career has centered on affective and behavioral \nneuroscience and computational psychology, where he integrates \nexperimental approaches with computational modeling to address both \nfundamental and applied questions. He currently leads research \ninvestigating the relationship between preclinical studies and their \napplication to mental health and artificial intelligence. He has \npublished widely in areas such as emotional processing and responses, \naffective and behavioral development, and affective computing. Dr. \nYin is also committed to advancing interdisciplinary collaboration in \nwell-being sciences and is dedicated to contributing to global scientific \ndiscussions. \n \nDr. Yin is a member of the Society for Neuroscience, the American \nPsychological Association, and IEEE. He has been actively involved \nin promoting the development of the interdisciplinary research \ncommunity through various leadership roles. He has received several \nresearch grants and awards and has contributed to the editorial process \nfor affective and behavioral science-related publications. \n \nMs. Chong-Yi Liu and Ms. Liya Fu are master’s students mentored by \nDr. Yin. Dr. Jinkun Zhang is a colleague and collaborator whose main \nresearch interests lie in utilizing insights from basic cognitive research \nto inform multimedia learning by students. \n",
  "metadata": {
    "source_path": "papers/arxiv/Teleology-Driven_Affective_Computing_A_Causal_Framework_for_Sustained\n__Well-Being_f2dcc60ec42d61d6.pdf",
    "content_hash": "f2dcc60ec42d61d6bf1cad69ba9919c49795f34c264d37addc7c6d0ef9064902",
    "arxiv_id": null,
    "title": "Teleology-Driven_Affective_Computing_A_Causal_Framework_for_Sustained\n__Well-Being_f2dcc60ec42d61d6",
    "author": "Tiffany McKerahan",
    "creation_date": "D:20250222164324+08'00'",
    "published": "20250222164324+08'00'",
    "pages": 25,
    "size": 1467072,
    "file_mtime": 1740470174.4944096
  }
}