{
  "text": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n1\nDeep Learning-Powered Electrical Brain Signals\nAnalysis: Advancing Neurological Diagnostics\nJiahe Li, Xin Chen, Fanqi Shen, Junru Chen, Yuxin Liu, Daoze Zhang, Zhizhang Yuan, Fang Zhao, Meng Li† and\nYang Yang†\nAbstract—Neurological disorders represent significant global\nhealth challenges, driving the advancement of brain signal\nanalysis methods. Scalp electroencephalography (EEG) and in-\ntracranial electroencephalography (iEEG) are widely used to\ndiagnose and monitor neurological conditions. However, dataset\nheterogeneity and task variations pose challenges in developing\nrobust deep learning solutions. This review systematically exam-\nines recent advances in deep learning approaches for EEG/iEEG-\nbased neurological diagnostics, focusing on applications across\n7 neurological conditions using 46 datasets. We explore trends\nin data utilization, model design, and task-specific adaptations,\nhighlighting the importance of pre-trained multi-task models for\nscalable, generalizable solutions. To advance research, we propose\na standardized benchmark for evaluating models across diverse\ndatasets to enhance reproducibility. This survey emphasizes\nhow recent innovations can transform neurological diagnostics\nand enable the development of intelligent, adaptable healthcare\nsolutions.\nIndex Terms—Deep learning, Neural Signal Analysis, Elec-\ntroencephalography, Neurological Disorder Diagnosis\nI. INTRODUCTION\nNeurological disorders represent one of the most significant\nchallenges to global health today, with profound consequences\nfor both individuals and healthcare systems. According to\nthe World Health Organization (WHO), neurological disor-\nders affect over one-third of the global population, making\nthem a leading cause of illness and disability worldwide [1].\nDementia, which affects 47.5 million people worldwide, is\na primary concern, with Alzheimer’s disease being the most\ncommon form. Seizure impacts more than 50 million in-\ndividuals, while sleep disorders are widespread yet often\nunderdiagnosed. Other significant disorders, including Parkin-\nson’s disease, schizophrenia, depression, and ADHD, further\nexacerbate the global burden, placing additional strain on\nhealthcare systems [2]. In low- and middle-income countries,\n† Corresponding author.\nManuscript received 24 February 2025. This work is supported by NSFC\n(62322606) and Zhejiang NSF (LR22F020005).\nJiahe Li, Xin Chen, Fanqi Shen, Junru Chen, Yuxin Liu, Daoze Zhang,\nZhizhang Yuan and Yang Yang are with the College of Computer Science\nand Technology, Zhejiang University, Hangzhou, Zhejiang 310027, China (e-\nmail:\njiaheli@zju.edu.cn,\nxin.21@intl.zju.edu.cn,\nfanqishen@zju.edu.cn,\njrchen cali@zju.edu.cn,\nyuxin.liu@zju.edu.cn,\nzhangdz@zju.edu.cn,\nzhizhangyuan@zju.edu.cn, yangya@zju.edu.cn).\nFang Zhao is with the DiFint Technology (Shanghai) Co, Shanghai, 201210,\nChina (email: zhaofang@difint.cn).\nMeng Li is with the Shanghai Institute of Microsystem and Information\nTechnology, Chinese Academy of Sciences, Shanghai, China, the School of\nGraduate Study, University of Chinese Academy of Sciences, Beijing, 100049,\nChina, and The INSIDE Institute for Biological and Artificial Intelligence,\nShanghai, 201210, China (email: limeng.braindecoder@gmail.com).\nwhere limited resources constrain access to neurological care\nand treatment, the situation is particularly dire.\nPractical diagnostic tools are essential to alleviate the grow-\ning global burden of neurological disorders, and electrical\nbrain signals are indispensable among them. Electrical brain\nsignals, specifically electroencephalography, are critical for\nunderstanding and diagnosing neurological disorders. Elec-\ntroencephalography evaluates electrical activity in the brain\nand is categorized into scalp electroencephalography (EEG)\nand intracranial electroencephalography (iEEG). EEG is non-\ninvasive, recording brain activity from electrodes placed on the\nscalp. iEEG includes inserting electrodes into the brain (stereo-\nelectroencephalography, SEEG) or onto the brain’s surface\n(electrocorticography, ECoG), providing more detailed and\nlocalized information [3].\nThe analysis of brain signals such as EEG/iEEG poses\nsignificant challenges for traditional machine learning (ML)\napproaches. These methods typically rely on manually engi-\nneered features that may not fully capture the complex patterns\nin neurophysiological data, while their performance is often\ncompromised by inherent noise and artifacts in raw neural\nrecordings. Deep learning (DL) addresses these limitations by\nautomatically extracting features, modeling temporal depen-\ndencies, and improving robustness against signal variability.\nThe ability of DL methods to detect and classify neurological\ndisorders with high accuracy has driven widespread adoption\nin brain signal analysis. This survey systematically examines\nthe workflow of DL models in brain signal analysis, focusing\non their applications in diagnosing neurological disorders.\nA. General Workflow\nThe general workflow of electrical brain signal analysis in\nneurological diagnostics, as illustrated in Fig. 1, consists of\nthree main stages: signal collection, signal preprocessing, and\nanalysis and diagnosis.\nIn the signal collection stage, electrical brain activity is\nrecorded using EEG, ECoG, or SEEG systems (Fig. 1.a).\nThese signals are typically captured across multiple channels\nat specific sampling frequencies and are often accompanied\nby labeled tasks and corresponding labels.\nThe signal preprocessing stage (Fig. 1.b) involves a series\nof low-level techniques, including denoising, filtering, artifact\nremoval, and normalization. These steps are crucial for re-\nducing noise and artifacts, enhancing relevant patterns, and\nstructuring the data for effective feature extraction.\nIn the analysis and diagnosis stage (Fig. 1.c), the prepro-\ncessed signals undergo feature extraction and neurodiagnostic\narXiv:2502.17213v1  [q-bio.NC]  24 Feb 2025\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n2\nTraining\nDiagnosis\n2D. Feature Extraction\n2B. Signal Collection\n2C. Signal Preprocessing\n \n \n \nS\ni\ng\nn\na\nl \nC\no\nll\ne\nc\nt\ni\no\nn\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \nS\ni\ng\nn\na\nl \nP\nr\ne\np\nr\no\nc\ne\ns\ns\ni\nn\ng\nT\nchannels\nRNN\nCNN\nGNN\n2F. Architecture\nTransformer\nFiltering\nDownsampling\nArtifact Removal\nChannel Selection\nRaw Signal\nNormalization\nSegmentation\nsliding  window\n2D Spectrogram\nChannel-Correlation Network\nStatistical Features\na\nd\nb\nc\nmean\nmin\nmax\n#zero crossings =26\n219\n66\n59\n14\n16\n51\n3\n16\n4\n4\n16\n3\n8\n2\nADHD\nSeizure\nSleep\nMDD\nSZ\nAD\nPD\n#Related Works\n#Public Datasets\nS\nt\na\nt\ni\ns\nt\ni\nc\na\nl\n \nI\nn\nf\no\nr\nm\na\nt\ni\no\nn\nA\nn\na\nl\ny\ns\ni\ns\n \na\nn\nd\n \nD\ni\na\ng\nn\no\ns\nis\n (i)\n(ii)\n(iii)\nEEG\nECoG\nSEEG\n  (i)\n  (ii)\n  (iii)\nsupervised\nSubject-Specific\nCross-Subject\nMixed-Subject\nevent-level\nsample-level\nsemi-supervised\nunsupervised\n2G. Training Paradigm\n2E. Partitioning Strategy\nself-supervised\nFig. 1: General Workflow of Electrical Brain Signals Analysis in Neurological Diagnostics. a. Signal Collection:\nAcquisition of EEG/iEEG signals from patients using non-invasive scalp electrodes or invasive intracranial electrodes,\ncapturing brain electrical activity for clinical purposes. b. Signal Preprocessing: A feasible workflow to process raw signals,\nensuring their suitability for subsequent analysis. c. Analysis and Diagnosis: Extraction of features from the preprocessed\nsignals, followed by the application of deep learning techniques for model training and neurological classification.\nd. Statistical Information: A statistical summary of related work and publicly available datasets, illustrating their\ncontributions to the field and providing essential resources for future research, model development, and validation.\nclassification. Feature extraction transforms the signals into\nrepresentations suitable for diagnosis. Traditional methods\nextract spatial, temporal, and spectral features manually, while\ndeep learning approaches automatically learn complex, di-\nagnostically relevant patterns. These features are then fed\ninto classifiers for specific neurodiagnostic tasks. The training\nphase involves careful consideration of network backbones,\ntraining paradigms and data partitioning strategies.\nFinally, the extracted features are applied to downstream\ntasks. Fig. 1.d highlights the distribution of related research\nefforts and publicly available datasets across various neuro-\nlogical conditions, including seizure, sleep disorders, major\ndepressive disorder (MDD), schizophrenia (SZ), Alzheimer’s\ndisease (AD), Parkinson’s disease (PD), and attention deficit\nhyperactivity disorder (ADHD).\nB. Related Studies and Our Contributions\nExisting brain signal analysis surveys exhibit diverse scopes\nand focuses. Some focus specifically on EEG signals, em-\nphasizing their wide availability [4]–[6]. Others broaden the\nscope to include brain signals like magnetic resonance imag-\ning (MRI) [7], [8], which differ from EEG and iEEG in\nacquisition methods, temporal resolution, and preprocessing\nrequirements. From a task perspective, some reviews focus\nspecifically on diseases such as seizure [9], [10], providing in-\ndepth insights into disease-specific applications. Others take a\nbroader view, covering diverse brain-computer interface (BCI)\napplications [11], [12], which focus on interaction and control,\ndiffering fundamentally from neurological diagnostic tasks.\nOur work establishes three foundational contributions to ad-\nvance deep learning-driven neurodiagnosis: First, we systemat-\nically curate and analyze 46 public EEG/iEEG datasets across\nseven neurological conditions, establishing the most compre-\nhensive data landscape to date. We also unify fragmented\nmethodologies by standardizing data processing, model ar-\nchitectures, and evaluation protocols. Besides, we identify\nself-supervised learning as the optimal paradigm for devel-\noping multi-task diagnostic frameworks, offering a compre-\nhensive overview of pre-trained multi-task frameworks and\ntheir advancements. Additionally, we propose a benchmarking\nmethodology to evaluate brain signal models across tasks,\nproviding a foundation for scalable and versatile solutions in\nEEG/iEEG-based neurological diagnostics applications.\nII. METHODS\nA. Problem Definition\nIn this survey, we classify neurological diagnostic tasks into\nsample-level classification and event-level classification, both\nof which fall under the broader framework of classification\nproblems. Sample-level classification involves assigning a sin-\ngle label to an entire signal, which typically represents a spe-\ncific subject or sample (e.g., Alzheimer’s disease diagnosis).\nBy comparison, event-level classification focuses on identify-\ning and classifying distinct temporal segments within a more\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n3\nextended signal, thereby introducing an implicit segmentation\nprocess by associating each segment with a specific event or\nstate (e.g., seizure detection or sleep staging).\nElectrical brain signals, which capture the brain’s electrical\nactivity over time, can be modeled as multivariate time series.\nSpecifically, let X ∈RC×T represent the EEG/iEEG time\nseries, where C is the number of channels, and T is the number\nof sampling points. Each channel xc = {xc\n1, xc\n2, . . . , xc\nT }\ncorresponds to the measurements from a specific source, such\nas an EEG electrode or a contact of an iEEG electrode.\n1) Sample-Level Classification: In sample-level classifica-\ntion, the objective is to assign a single label y ∈Y to the\nentire signal X. This can be formulated as:\ny = Φsample(X; θ),\ny ∈Y,\nwhere Φsample represents the deep learning model parameter-\nized by θ, and Y denotes the set of possible classes. Here, X\nis treated as a unified entity, capturing sample-level or subject-\nlevel characteristics.\n2) Event-Level Classification: In event-level classification,\nthe goal is to classify smaller temporal segments of the signal.\nThe signal X is divided into K segments X1, X2, . . . , XK,\nwhere Xk ∈RC×Tk and Tk is the duration of the k-th\nsegment. A classification model is applied to each segment to\nproduce a sequence of labels Y = {y1, y2, . . . , yK}, yk ∈Y:\nyk = Φsegment(Xk; θ),\nY =\nK\n[\nk=1\n{yk},\nwhere Φsegment denotes the deep learning model parameterized\nby θ. This process associates each segment Xk with a specific\nlabel yk, allowing the temporal localization of events within\nthe signal. Event-level classification captures natural temporal\ndependencies between consecutive segments, reflecting the\ncontinuity of events in time [13].\nB. Signal Collection\nEEG have evolved significantly since Hans Berger first\nrecorded EEG signals from the human scalp in 1924 [14].\nWhile EEG signals are typically collected non-invasively using\nscalp electrodes placed according to the 10-20 system [15],\nmore recent studies employ higher-density EEG electrode con-\nfigurations for enhanced spatial resolution and detailed brain\nactivity mapping. EEG captures brain oscillations across fre-\nquency bands, each linked to specific neural states: delta (deep\nsleep), theta (light sleep), alpha (relaxation), beta (focus),\nand gamma (higher cognition) [16]. Depending on the study,\nparticipants may perform tasks or rest to elicit relevant brain\nactivity. Resting-state EEG evaluates baseline activity, while\nspecific tasks can highlight disease-related abnormalities [17].\niEEG involves implanting electrodes either within deep and\nsuperficial brain structures via burr holes (SEEG) or on the\nbrain’s surface by placing grids during craniotomy (ECoG).\nCompared to EEG, iEEG offers excellent spatial resolution and\nreduced susceptibility to artifacts from scalp muscle activity\nand eye movements. SEEG allows recording from deep and\ndistributed brain regions with minimal invasiveness, while\nECoG provides higher spatial resolution for cortical surface\nTABLE I: Signal Preprocessing Techniques\nTechniques\nDetails\nReference\nNoise Reduction &\nFiltering\nFIR Filter\n[18]\nIIR Filter\n[19]\nAdaptive Filters\n[20]\nManual & Custom\n[21]\nArtifact Removal\nBlind Source Separation\n[22]\nArtifact Correction\n[23]\nBaseline Correction &\nDetrending\nBaseline Correction\n[24]\nBaseline Removal\n[25]\nDetrending\n[26]\nChannel Processing\nChannel Selection\n[27]\nChannel Mapping\n[28]\nRe-Referencing\n[25]\nNormalization &\nScaling\nZ-Normalization\n[29]\nQuantile Normalization\n[30]\nScaling & Shifting\n[28]\nSampling Adjustment\nDownsampling\n[31]\nResampling\n[32]\nInterpolation\n[33]\nImputation\n[34]\nSegmentation\nWindowing\n[35]\nSignal Alignment &\nSynchronization\nTime Synchronization\n[36]\nTemporal Alignment\n[36]\nactivity due to its densely packed electrode grids. However,\niEEG can still be affected by cardiac artifacts, electrode shifts,\nand other forms of noise. Rigorous preprocessing techniques\nare essential to ensure the accuracy and reliability of EEG and\niEEG signals in clinical and research applications.\nC. Signal Preprocessing\nEEG/iEEG signals require low-level preprocessing to ad-\ndress challenges such as noise and artifact removal, normal-\nization for consistency, and segmentation into analyzable time\nwindows. These steps refine raw data, ensuring it accurately\nreflects brain activity and provides a robust foundation for\nanalysis. Representative methods are summarized in Table I,\nwith one key work per category highlighted.\n1) Noise Reduction and Filtering: Filtering techniques,\nsuch as Finite Impulse Response (FIR) and Infinite Impulse\nResponse (IIR) filters, are employed to isolate specific fre-\nquency components. Advanced methods like MSEC noise\nreduction and wavelet transforms [21] provide specialized\nsolutions for effective denoising and precise data refinement.\n2) Artifact Removal: Artifact removal strategies include\nBlind Source Separation techniques, such as Independent\nComponent Analysis (ICA), Principal Component Analysis\n(PCA), and Multiple Component Analysis (MCA) [37], along\nwith Artifact Correction methods, including Ocular Correction\nand Artifact Subspace Reconstruction. Wavelet decomposition\nis also commonly used mitigate artifacts.\n3) Baseline Correction and Detrending: Baseline correc-\ntion and detrending address baseline drift caused by eye\nmovements, breathing, and subject motion. Baseline correction\nstandardizes power data, baseline removal reduces subject-\nindependent noise, and detrending eliminates linear or non-\nlinear trends, enhancing signal reliability.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n4\nTABLE II: Feature Extraction Techniques\nTechniques\nDetails\nReference\nData Augmentation\nOversampling\n[32]\nELM-AE\n[39]\nSignal Decomposition\n& Transformation\nTime-Frequency Analysis\n[40]\nEmpirical Decomposition\n[41]\nSpectral & Power\nAnalysis\nPower Spectrum\n[42]\nSpectral Density\n[43]\nPartial Directed Coherence\n[44]\nTime-Domain Features\nExtraction\nStatistical Measures\n[45]\nAmplitude & Range\n[46]\nHjorth Parameters\n[47]\nFrequency-Domain\nFeatures Extraction\nBand Power Features\n[48]\nSpectral Measures\n[49]\nTime-Frequency\nFeatures Extraction\nWavelet Coefficients\n[50]\nSTFT Features\n[51]\nMultitaper Spectral\n[52]\nOther Features\nExtraction\nNonlinear Features\n[53]\nSpatial Features\n[54]\nTransform-Based Features\n[55]\nGraph Analysis\nClustering Coefficient\n[56]\nOther Graph Metrics\n[57]\n4) Channel Processing: Neurological disorders often affect\nspecific brain regions, making channel processing techniques,\nincluding selection, mapping, and re-referencing, essential for\nenhancing the specificity and interpretability of analyses.\n5) Normalization and Scaling: Normalization standardizes\nthe amplitude of raw EEG and iEEG signals, which often vary\nin voltage. Common methods include Z-score and quantile\nnormalization, while linear scaling and shifting minimize\nspurious amplitude variations across channels.\n6) Sampling Adjustment: Sampling adjustments optimize\ndata for analysis while reducing computational demands.\nDownsampling reduces memory and processing requirements,\nwhereas interpolation handles missing data, insufficient train-\ning samples, and pulse artifacts [38].\n7) Segmentation: Segmentation divides EEG and iEEG\ndata into smaller sections for localized information extraction\nand data augmentation to enhance sample diversity. Overlap\nwindows ensure continuity and capture transitional features,\nwhile non-overlapping segments prioritize computational effi-\nciency and maintain distinct temporal boundaries.\n8) Signal Alignment and Synchronization: Signal alignment\nensures temporal consistency across signals from different\nsources, improving the reliability of findings. Fine-grained\ntemporal alignment further corrects residual discrepancies\nafter initial synchronization, ensuring data precision.\nD. Feature Extraction\nFeature extraction techniques reconfigure data into alterna-\ntive representations by isolating key features or decomposing\nit into core components essential for modeling and analysis.\nThis process effectively primes the data for more sophisticated,\nabstract analytical tasks. Representative methods are summa-\nrized in Table II, with one key work per category highlighted.\n1) Data Augmentation: Data augmentation generates new\nsamples to increase dataset diversity and improve classification\naccuracy and stability. Oversampling is commonly used to ad-\ndress class imbalances, while the Extreme Learning Machine\nAutoencoder (ELM-AE) employs autoencoders to synthesize\ndata by reconstructing input features [39].\n2) Spectral and Power Analysis: Spectral and power anal-\nysis focuses on examining the frequency components and\nenergy distribution of signals. Key techniques include power\nspectrum calculation, frequency band energy analysis, and\npartial-directed coherence for evaluating signal causality.\n3) Time Domain Feature Extraction: Time domain features,\nsuch as statistical measures, Hjorth parameters, and Zero-\nCrossing Rate, effectively represent signal amplitude, time\nscale, and complexity. These features provide valuable insights\ninto signal distribution, intensity, and rate of change.\n4) Frequency Domain Feature Extraction: Frequency do-\nmain features, such as band power, band energy, median\nfrequency, spectral edge frequency, and power spectral density\n(PSD), provide insights into the spectral content of signals.\n5) Time-Frequency Feature Extraction:\nTime-frequency\nfeatures capture both temporal and spectral information,\nproviding a comprehensive signal representation. Short-time\nFourier Transform (STFT) analyzes frequency variations over\ntime, while Continuous and Discrete Wavelet Transforms\n(CWT, DWT) offer detailed time-frequency representations.\nAdvanced techniques like FBSE-EWT filter banks [58] and\nSmoothed Pseudo Wigner Ville Distribution (SPWVD) [59]\nenhance analysis precision.\n6) Other Feature Extraction: Nonlinear features, such as\nentropy measures, fractal dimensions, and Lyapunov expo-\nnents, capture complex patterns that linear methods may miss.\nSpatial features, including Common Spatial Patterns and con-\nnectivity measures like phase-locking value (PLV) and phase-\nlag index (PLI), represent spatial domain activities. Transform-\nbased features further enhance analysis by reconstructing\nsignals into more informative representations.\n7) Signal Decomposition and Transformation: Signal de-\ncomposition and transformation techniques decompose com-\nplex signals to facilitate detailed analysis, such as wavelet\ntransforms, Gabor Transform [40], Fast Fourier Transform,\nEmpirical Mode Decomposition, and Hilbert-Huang Trans-\nform.\n8) Graph Analysis: Graph analysis evaluates connectivity\nbetween channels. Metrics like degree measure connections\nand node importance, while the clustering coefficient quanti-\nfies local network density, revealing network structure.\nE. Data Partitioning Strategies\nBuilding on the detailed definition of X(i) ∈RC×T in\nSection II-A, where X(i) represents the EEG or iEEG signal\nof subject i, we further introduce additional notations to\nformalize the data partitioning strategies:\n• P = {1, 2, . . . , N}: The set of N subjects in the dataset.\n• Xtrain, Xval, Xtest: The training, validation, and testing sets,\nrespectively.\n• αtrain, αval, αtext ∈(0, 1): The proportion of data used for\ntraining, validation and test, and αtrain + αval + αtest = 1.\n• K(i): The total number of temporal segments or events\nderived from subject i’s data.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n5\nUsing these definitions, we classify data partitioning strate-\ngies into three categories: subject-specific methods, mixed-\nsubject methods, and cross-subject methods.\n1) Subject-Specific Methods: Subject-specific methods fo-\ncus on capturing individual characteristics by partitioning\neach subject’s data independently into training, validation, and\ntesting sets. Formally,\nXtrain ∪Xval ∪Xtest = {X(i)\nk }K(i)\nk=1 ,\nwhere i denotes a specific subject. This method is particularly\nuseful in the early stages of development, as it enables rapid\niteration on small datasets and captures individual patient\npatterns. It is commonly used in closed-loop seizure detection\nsystems, where personalization is critical.\n2) Mixed-Subject Methods: Mixed-subject methods lever-\nage signals from all subjects in P for training, validation, and\ntesting, aiming to create models with broad applicability. The\ndata partitioning method is as follows:\nXset ⊂\n[\ni∈P\nK(i)\n[\nk=1\n{X(i)\nk },\n|Xset| = αset\nN\nX\ni=1\nK(i),\nwhere set ∈{train, val, test}. By pooling data across subjects,\nthis approach maximizes training efficiency and improves the\nmodel’s robustness to inter-subject variability. However, it also\nintroduces the risk of data leakage, as segments from the same\nsubject may appear in different sets.\n3) Cross-Subject Methods: Clinical applications demand\nmodels that generalize across unseen patients. Cross-subject\nmethods explicitly enforce subject separation between training,\nvalidation, and testing by partitioning P into disjoint subsets:\n|Pset| = αset|P|,\nXset =\n[\ni∈Pset\nK(i)\n[\nk=1\n{X(i)\nk },\nwhere set ∈{train, val, test}. This ensures that models are\nevaluated on entirely unseen subjects.\nExtending subject-level partitioning strategies, dataset-level\npartitioning includes three approaches: dataset-specific (in-\ndependent partitioning per dataset), mixed-dataset (pooling\ndata across datasets), and cross-dataset (disjoint datasets for\ntraining, validation, and testing). Dataset-specific methods\ncapture individual dataset characteristics, while mixed-dataset\nmethods enhance robustness to inter-dataset variability. Cross-\ndataset partitioning is crucial for universal models, rigorously\nassessing generalization and closely aligning with real-world\nclinical deployment.\nF. Deep Learning Architectures\nNeurological data processing relies on several key architec-\ntures: Convolutional Neural Networks (CNNs) [60] excel at\nextracting spatial/spectral features through hierarchical convo-\nlutions. Recurrent Neural Networks (RNNs) [61] capture\ntemporal dependencies via recurrent connections. Transform-\ners [62] model long-range spatiotemporal relationships using\nself-attention. Graph Neural Networks (GNNs) [63] ana-\nlyze functional connectivity in graph-structured data. Autoen-\ncoders (AEs) [64] learn compressed representations through\nencoder-decoder structures. Generative Adversarial Net-\nworks (GANs) [65] synthesize signals through adversarial\ntraining. Spiking Neural Networks (SNNs) [66] leverage\nspike-based computation for temporal dynamics.\nG. Deep Learning Paradigms\nDeep learning applications in neurological diagnostics can\nbe categorized into four paradigms: supervised learning,\nself-supervised learning, unsupervised learning, and semi-\nsupervised learning. Each paradigm addresses specific chal-\nlenges in processing brain signals by leveraging architectures\ntailored to data availability and task requirements. These\nparadigms will be further discussed in detail in Section III.\n1) Supervised Learning: Supervised learning is the dom-\ninant paradigm for neurological diagnostics tasks, training\nmodels to map signals X ∈RC×T to labels y ∈Y.\n2) Unsupervised Learning: Unsupervised learning is es-\nsential for uncovering intrinsic data structures in signals X,\nenabling representation learning without relying on labels.\n3) Semi-Supervised Learning:\nSemi-supervised learning\ncombines a small set of labeled examples {(xi, ˆyi)}l\ni=1, where\nˆyi denotes the provided labels, with a larger set of unlabeled\nexamples {xj}l+u\nj=l+1 to learn a mapping from X to Y.\n4) Self-Supervised\nLearning:\nSelf-supervised\nlearning\n(SSL) leverages unlabeled EEG/iEEG data by constructing\npretext tasks that generate pseudo-labels ˆy from intrinsic\nproperties of the raw signals X. These tasks enable mod-\nels to learn robust representations, which can be fine-tuned\nfor downstream tasks. SSL methods fall into three main\ncategories: contrastive, predictive, and reconstruction-based\nlearning. Contrastive-based methods, such as Contrastive\nPredictive Coding (CPC) [18] and Transformation Contrastive\nLearning [67], learns by maximizing similarity between related\nviews while minimizing it between unrelated ones, capturing\ndistinguishing signal features. Predictive-based learning em-\nploys pretext tasks such as Relative Positioning and Temporal\nShuffling to extract structural patterns across temporal, fre-\nquency, and spatial domains [68], [69]. By predicting transfor-\nmations applied to the data, it enhances domain-specific fea-\nture learning. Reconstruction-based learning trains models\nto reconstruct masked signal segments. Methods like Masked\nAutoencoders (MAE) reconstruct temporal or spectral com-\nponents, learning intrinsic patterns in the process [28], [70].\nStudies have also explored hybrid methods, which combine el-\nements from contrastive, predictive, and reconstruction-based\napproaches [18], [71].\nIII. APPLICATIONS\nThis section systematically reviews neurological disease\ndiagnosis methodologies. Each subsection starts with an in-\ntroduction to the disease’s background, including its charac-\nteristics, diagnostic tasks, and relevant public datasets. We will\nthen review representative works for each disease, highlighting\ndisease-specific features in the context of deep learning-based\ndiagnosis, such as data types, frequency bands, brain regions,\nand methodological trends. Given their extensive research\nhistory, seizure detection and sleep staging receive dedicated\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n6\nTABLE III: Public EEG/iEEG datasets for seizure detection, with Seizures indicating the number of episodes, Length the\nduration of each record, and Size the total duration of recording.\nDataset\nType\nSubjects\nSeizures\nLength\nSize\nFrequency (Hz)\nChannels\nBonn [72]\nEEG\n10\n-\n23.6 sec\n≈3.3 hours\n173.61\n1\nFreiburg [73]\niEEG\n21\n87\n4 sec\n≈504 hours\n256\n128\nMayo-UPenn [74]\niEEG\n2\n48\n1 sec\n583 min\n500-5000\n16-76\nCHB-MIT [75]–[77]\nEEG\n22\n198\n1 hour\n≈686 hours\n256\n23 / 24 / 26\nBern-Barcelona [78]\niEEG\n5\n3750\n20 sec\n57 hours\n512\n64\nHauz Khas [79]\nEEG\n10\n-\n5.12 sec\n87 min\n200\n50\nMelbourne [80]\niEEG\n3\n-\n10 min\n81.25 hours\n400\n184\nTUSZ [81]\nEEG\n642\n3050\n-\n700 hours\n250\n19\nSWEC-ETHZ [82], [83]\niEEG\n18 / 16\n244 / 100\n1 hour / 3 min\n2656 hours / 48 min\n512 / 1024\n24-128 / 36-100\nZenodo [84]\nEEG\n79\n1379\n74 min\n≈97 hours\n256\n21\nMayo-Clinic [85]\niEEG\n25\n-\n3 sec\n50 hours\n5000\n1\nFNUSA [85]\niEEG\n14\n-\n3 sec\n7 hours\n5000\n1\nSiena [86]\nEEG\n14\n47\n145-1408 min\n≈128 hours\n512\n27\nBeirut [87]\nEEG\n6\n35\n1 sec\n130 min\n512\n19\nHUP [88]\niEEG\n58\n208\n300 sec\n≈27 hours\n500\n52-232\nCCEP [89]\niEEG\n74\n-\n-\n89 hours\n2048\n48-116\nsections, while other disorders are analyzed through focused\ncomparative discussions to eliminate redundancy. Technical\nimplementation details across studies (preprocessing pipelines,\nnetwork architectures, training protocols) are systematically\ncataloged in supplementary tables.\nA. Seizure Disorder\n1) Task Description: Epilepsy, a neurological disorder af-\nfecting 50 million people globally, is characterized by recur-\nrent seizures caused by abnormal brain activity. Seizures range\nfrom brief confusion or blanking out to severe convulsions\nand loss of consciousness. According to the World Health\nOrganization (WHO), up to 70% of epilepsy cases can be\neffectively treated with proper care. However, in low-income\nregions, limited resources and stigma often hinder access to\ntreatment, heightening the risk of premature death [90].\nSeizure\ndetection\nprimarily\nrelies\non\nstandardized\nEEG/iEEG datasets, summarized in Table III. The key\nchallenge is distinguishing seizure events from background\nactivity, typically framed as binary classification where\nyk ∈{0, 1}. Most approaches segment long EEG sequences\ninto\nsmaller\nwindows\nfor\nsample-level\nclassification,\naggregating segment predictions to form event-level outcomes\nas Y = SK\nk=1{yk} [91], [92]. Another approach detects\noptimal cut points within continuous recordings to identify\nthe boundaries of meaningful segments {Xk}K\nk=1, and each\nsegment is classified individually [56]. The final event-level\nprediction is obtained by combining these event-level labels\nY = SK\nk=1{Φsegment(Xk; θ)}.\nMore detailed classifications have also been explored, in-\ncluding three-class tasks, where yk ∈{A, D, E} represents\ninterictal (A, the period between seizures), preictal (D, the\ntime before seizure onset), and ictal (E, seizure) states [93].\nFive-class tasks refine this further by subdividing the preictal\nstate into early, middle, and late stages [94]. The Temple\nUniversity Seizure Corpus (TUSZ) [81] supports detailed\nepilepsy studies, classifying events into pathological patterns\nlike epileptiform discharges and seizure types (e.g., focal, gen-\neralized, tonic-clonic), as well as non-pathological signals such\nas background activity and artifacts (e.g., eye movements). A\ndetailed overview of all related works is provided in Appendix\nTable XI.\n2) Supervised Methods: Supervised seizure detection using\nEEG/iEEG data has advanced alongside growing datasets and\nimproved technology. Early studies relies on subject-specific\nor mixed-subject evaluations using short, pre-segmented EEG\nclips. For example, the Bonn dataset [72] consists of manu-\nally labeled seizure/non-seizure segments, leading to models\noptimized for fixed-length inputs. Approaches based on raw\nsignals employ CNNs or RNNs to automatically extract spa-\ntiotemporal features from these standardized segments [29],\n[95], while feature-based methods derive handcrafted or trans-\nformed representations, such as scalograms [94] and wavelet-\nbased features [96], which are more suited for shallow clas-\nsifiers. These techniques inherently assume limited temporal\ncontext and avoided segmentation challenges.\nWith the adoption of long-term recordings like CHB-\nMIT [76], the focus shifts toward cross-subject paradigms.\nThese datasets provide extensive seizure examples within\ncontinuous, long-term EEG streams, necessitating more flexi-\nble detection frameworks capable of handling variable-length\ninputs and identifying seizure boundaries in unsegmented\ndata. Approaches integrate temporal modeling through sliding\nwindows [91], sequence-aware architectures such as Trans-\nformers [97], or hybrid feature fusion techniques [98]. Con-\ncurrently, cross-subject validation becomes standard, reflecting\nclinical requirements that generalize across diverse conditions.\nThe necessity of cross-subject modeling in seizure detection\nstems from its critical role in ensuring clinical generalization.\nThe invasive nature of iEEG fundamentally differentiates its\nmodeling requirements from EEG through distinct acquisi-\ntion paradigms and neurophysiological characteristics, as its\npatient-specific recording conditions and electrode configura-\ntions lead to substantial inter-subject heterogeneity in tem-\nporal features and spatial sampling properties, unlike EEG’s\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n7\nstandardized scalp placement [99]. Balancing high-resolution\nspatiotemporal capture with robustness across patients, iEEG\nrequires specialized methodologies to enhance generalizabil-\nity while addressing its inherent complexities. Spatial mod-\neling is essential for capturing three-dimensional epilepto-\ngenic networks with depth electrodes. Graph-based methods\nmodel inter-channel dependencies via neuroanatomical [100]\nor dynamic functional connections [101], while Transformer\narchitectures use attention mechanisms to adapt to varying\nelectrode configurations [102]. DMNet [103] improves domain\ngeneralization through self-comparison mechanisms.\n3) Semi- and Unsupervised Methods: Semi-supervised and\nunsupervised learning techniques have become increasingly\napplied in deep learning for seizure detection, particularly\nwhen labeled data is limited. A common approach incorporates\nclustering paradigms for event-level segmentation, allowing\nthe model to identify and segment seizure events [56]. Another\nnotable application involves using models such as Autoen-\ncoders, DBNs and GANs to automatically extract relevant\nfeatures or augment the dataset, thereby enhancing the model’s\nrobustness and generalizability [104]–[106].\n4) Self-supervised Methods: Self-supervised learning has\nemerged as an effective approach for seizure detection. Con-\ntrastive learning captures seizure-related patterns by forming\npositive pairs through segment augmentation and negative\npairs based on feature differences. For example, SLAM [107]\ngenerates negative pairs by pairing the anchor with a ran-\ndomly selected window from a distant time point. SPP-\nEEGNET [108] calculates the absolute difference between\npairs to classify them as positive or negative. Wagh et al. [109]\nemploys cross-domain contrastive learning to mitigate individ-\nual differences by comparing subjects based on factors such\nas age. They use the delta/beta power ratio to estimate EEG-\nbased behavioral states and distinguish pre- and post-seizure\ncharacteristics. Zheng et al. [110] employ predictive-based\nSSL by designing classification pretext tasks that simulate key\nepileptic features, such as increased amplitude and abnormal\nfrequencies, enabling the model to recognize epilepsy-related\npatterns. Tang et al. [111] first combine graph-based modeling\nwith pre-training for EEGs, where the model predicts the next\nset of EEG signals for a given time period.\nEpilepsyNet [97] employs reconstruction-based SSL, us-\ning Pearson Correlation Coefficients to capture spatial-\ntemporal embeddings while preserving contextual features.\nWavelet2Vec [92] utilizes a frequency-aware masked autoen-\ncoder that reconstructs wavelet-transformed EEG patches in\nthe time-frequency domain. By leveraging seizure-specific\nabnormal discharge patterns across frequency bands, it en-\nhances feature extraction for seizure subtype classification.\nEEG-CGS [57] adopts a hybrid graph-based SSL approach,\nframing seizure detection as anomaly detection, integrating\nrandom walk-based subgraph sampling with contrastive and\nreconstruction-based learning.\nThe SSL paradigm is also commonly used in iEEG-based\nmodeling. BrainNet [112] employs bidirectional contrastive\npredictive coding to capture temporal correlation in SEEG\nsignals. MBrain [71] models time-varying propagation pat-\nterns and inter-channel phase delays characteristic of epileptic\nTABLE IV: Public Sleep EEG Datasets, where Recordings\ndenotes the number of whole-night PSG recordings.\nDataset\nRecordings\nFrequency (Hz)\nChannels\nSleep-EDF [77], [114]\n197\n100\n2\nMASS [115]\n200\n256\n4-20\nSHHS [116], [117]\n8362\n125\n2\nSVUH UCD [77], [118]\n25\n128\n3\nHMC [77], [119]\n151\n256\n4\nPC18 [77], [120]\n1985\n200\n6\nMIT-BIH [77], [121]\n16\n250\n1\nDOD-O [122]\n55\n250\n8\nDOD-H [122]\n25\n250\n12\nISRUC [123]\n126\n200\n6\nMGH [124]\n25941\n200\n6\nPiryatinska [125]\n37\n64\n1\nDRM-SUB [126]\n20\n200\n3\nSD-71 [127]\n142\n500\n61\nactivity through a multivariant contrastive-predictive learn-\ning framework, leveraging graph-based representations for\nspatial-temporal correlations across EEG and SEEG channels.\nPPi [113] accounts for regional seizure variability, employing\na channel discrimination task to ensure the model captures\ndistinct pathological patterns across brain regions rather than\ntreating all channels uniformly.\nB. Sleep Staging\n1) Task Description: Sleep staging is critical to understand-\ning sleep disorders like insomnia and sleep apnea, as well as\nthe impact on overall health. It is estimated that 20% to 41% of\nthe global population is affected by sleep disorders, which are\nlinked to an increased risk of obesity, cardiovascular diseases,\nand mental health issues [128]. Therefore, accurately identi-\nfying sleep stages is essential for addressing these concerns.\nSleep staging involves segmenting signals into 30-second\nepochs and classifying them into stages: awake (W), rapid\neye movement (REM), and three non-REM (NREM) stages\n(N1, N2, N3). Wake is characterized by high-frequency β and\nα waves. In N1, the transition from wakefulness to sleep,\nlow-amplitude θ waves appear. N2, the light sleep stage, is\nmarked by sleep spindles and K-complexes associated with\nsensory processing and memory consolidation. N3, or deep\nsleep, features slow-wave δ activity. REM sleep, essential for\nemotional regulation and dreaming, is characterized by rapid,\nlow-voltage brain activities.\nMultimodal modeling is fundamental for sleep analysis,\nas polysomnography (PSG) integrates EEG (e.g., Fpz-Cz,\nPz-Oz), Electrooculography (EOG), and Electromyography\n(EMG) to enhance staging accuracy. The public datasets listed\nin Table IV are frequently employed in sleep analysis. A\ndetailed overview of all related works is provided in Appendix\nTable XII.\n2) Supervised methods:\nSelecting biosignal modalities\nis critical for designing supervised learning frameworks\nin PSG-based sleep staging. Two primary paradigms are\nwidely used. Single-channel EEG methods, preferred in\nresource-constrained settings, offer hardware simplicity, re-\nduced cross-modal interference, and enhanced computational\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n8\nTABLE V: Public EEG Datasets for Depression Detection,\nwhere Exp (n) represents the number of depressed\nindividuals and Ctrl (n) represents the healthy control group.\nDataset\nExp (n)\nCtrl (n)\nFrequency (Hz)\nChannels\nHUSM [139]\n34\n30\n256\n22\nPRED+CT [140]\n46\n75\n500\n64\nEDRA [141]\n26\n24\n500\n63\nMODMA [142]\n24\n26\n29\n29\n250\n128\n3\nefficiency [129], [130]. However, relying solely on EEG limits\nthe detection of complementary cues—such as ocular and\nmuscular activities—essential for identifying ambiguous sleep\nstages like REM sleep. Multimodal architectures integrating\nEEG, EOG, and EMG signals emulate the integrative anal-\nysis performed by sleep experts [131], [132]. Chambon et\nal. [131] employs techniques like spatial filtering to mitigate\ncross-modal interference. These designs align with clinical\nscoring protocols and compensate for the limited contextual\ninformation of individual modalities. Beyond these dominant\napproaches, hybrid models, such as EEG-EOG, balance diag-\nnostic accuracy with computational efficiency [133].\n3) Self-supervised methods:\nSelf-supervised contrastive-\nbased methods enhance sleep representation by leveraging\ntemporal and contextual patterns in unlabeled EEG data. Early\nworks explore tasks such as relative positioning, temporal\nshuffling, and autoregressive latent feature predictions to ex-\ntract temporal structures from multivariate signals [68], [69].\nJiang and et al. [134] extends these efforts with augmentation-\nbased contrastive learning, generating positive and negative\npairs from augmented EEG segments. ContraWR [135] adopts\nconstructing contrastive pairs from distinct time windows, pri-\noritizing window-level temporal dependencies. mulEEG [136]\nand CoSleep [137] introduce multi-view contrastive strategies\nto integrate time-series and spectrogram representations of\nEEG data. mulEEG emphasizes cross-view consistency while\nencouraging modality-specific features, whereas CoSleep de-\nvelops a time-frequency dual-view contrastive learning frame-\nwork that implicitly captures sleep-staging-related temporal\ndynamics and spectral rhythmic patterns in EEG signals.\nMultimodal modeling improves sleep staging accuracy by\nintegrating complementary EEG, EOG, and EMG insights.\nBrant-X [138] address alignment challenges using EEG foun-\ndation models and contrastive learning. By aligning EEG and\nEXG signals at both the local and global levels, Brant-X\neffectively bridges the semantic gaps between modalities.\nC. Depression Identification\n1) Task Description: Depression, particularly Major De-\npressive Disorder (MDD), is a psychological condition affect-\ning 5% of individuals worldwide, with a higher prevalence\namong women. In low- and middle-income countries, up to\n75% of individuals lack adequate care due to limited resources\nand stigma, despite effective treatments being available [143].\nDepression severity is quantified using standardized scales\nlike the Beck Depression Inventory (BDI) to differentiate\nclinical depression from normal mood variations. Existing\nTABLE VI: Public EEG Datasets for Schizophrenia, where\nExp (n) represents the number of schizophrenia patients and\nCtrl (n) represents the control group.\nDataset\nExp (n)\nCtrl (n)\nFrequency (Hz)\nChannels\nCeonRepod [147]\n14\n14\n250\n19\nNIMH [148]\n49\n32\n1024\n64\nMHRC [149]\n45\n39\n128\n16\nstudies adopt heterogeneous classification criteria: some focus\non binary discrimination (e.g., patients vs. healthy controls),\nwhile others stratify cohorts by treatment status (medicated vs.\nnon-medicated) or severity levels (mild vs. moderate/severe).\nTable V summarizes datasets used in MDD research. A\ndetailed overview of all related works is provided in Appendix\nTable XIII.\n2) Approach overview: Depression impacts both superfi-\ncial and deeper brain structures, presenting challenges for\ntraditional handcrafted features. Acharya introduces the first\nend-to-end DL model for EEG-based depression detection,\nshowing that right-hemisphere signals are significantly more\ndistinctive than left-hemisphere ones, which aligns with clin-\nical findings [144]. This insight has driven further studies\nanalyzing hemispheric EEG separately, often confirming sim-\nilar patterns. For example, Ay et al. introduces a hybrid\nCNN-LSTM architecture, with experimental results revealing\na more pronounced performance improvement in the right\ncerebral hemisphere [21]. DeprNet [35] employs a CNN-based\narchitecture with visualizations highlighting prominent activity\nin right-hemisphere electrodes for depressed subjects.\nSpiking neural networks (SNNs) excel in EEG-based de-\npression diagnosis, capturing brain-inspired spatiotemporal\ndynamics with biologically interpretable insights. Shah et\nal. [145] employ the NeuCube SNN framework to encode EEG\nsignals into temporal spike trains, mapping them onto a 3D\nspiking neural network reservoir (SNNr) aligned with the Ta-\nlairach brain atlas. The SNNr models spatiotemporal relation-\nships between EEG channels using unsupervised spike-timing-\ndependent plasticity (STDP), offering interpretable brain con-\nnectivity visualizations. Sam et al. [146] integrates a 3D\nbrain-inspired SNN with an LSTM, leveraging SNN’s energy\nefficiency with LSTM’s temporal modeling capabilities.\nD. Schizophrenia Identification\n1) Task Description: Schizophrenia (SZ) is a psychiatric\ndisorder affecting 24 million people worldwide, character-\nized by cognitive impairments, including memory deficits,\ndelusions, and hallucinations [150]. SZ is associated with\ndisruptions in structural and functional brain connectivity,\nmarked by decreased global efficiency, weakened strength, and\nincreased clustering [151]. These abnormalities are detectable\nin EEG signals, making them useful for binary classification\nto distinguish SZ patients from healthy controls. Table VI\nsummarizes publicly available datasets for SZ research. A\ndetailed overview of all related works is provided in Appendix\nTable XIV.\n2) Approach overview: Transfer learning has emerged as\na powerful technique for fine-tuning pre-trained computer\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n9\nTABLE VII: Public EEG Datasets for Alzheimer’s Diagnosis,\nwhere AD (n) and MCI (n) represent the experimental\ngroups, and Ctrl (n) represents the control group.\nDataset\nAD\n(n)\nMCI\n(n)\nCtrl\n(n)\nFrequency\n(Hz)\nChannels\nFSA [155]\n160\n-\n24\n128\n21\nAD-65 [156]\n36\n-\n29\n250\n19\nFiscon [157]\n49\n37\n14\n1024\n19\nAD-59 [158]\n59\n7\n102\n128-256\n21\nvision (CV) models in EEG-based schizophrenia diagnosis,\nenhancing performance with minimal training. A common\napproach is converting EEG signals into 2D images for CNN-\nbased models. Aslan et al. [152] feed spectrograms into a\npre-trained VGG-16, applying Grad-CAM to highlight critical\nfrequency components. SchizoGoogLeNet [153] fine-tunes the\npre-trained GoogLeNet to process 2D EEG feature matrices,\nwhich are generated from preprocessed EEG signals through\naverage filtering and resizing to align with the model’s input\ndimensions. Shalbaf et al. [154] transform EEG into scalogram\nimages via CWT, using ResNet-18 and VGG-19 to extract\nspatial-temporal features for classification.\nE. Alzheimer’s Disease Diagnosis\n1) Task Description: Alzheimer’s disease (AD) is a pro-\ngressive neurodegenerative disorder that starts with mild mem-\nory loss and advances to severe cognitive impairment, affecting\ndaily life. While medical interventions can improve quality\nof life, a definitive cure remains elusive [159]. Alzheimer’s\ndisease (AD) progresses through three stages: preclinical,\nmild cognitive impairment (MCI), and Alzheimer’s dementia.\nClassification tasks typically distinguish MCI or Alzheimer’s\ndementia from healthy controls. EEG abnormalities, such\nas slowed brain rhythms and desynchronization, serve as\nbiomarkers for AD-related neurodegeneration [160]. Table VII\nsummarizes publicly available datasets. A detailed overview of\nall related works is provided in Appendix Table XV.\n2) Approach overview: EEG abnormalities in Alzheimer’s\ndisease, such as disrupted functional connectivity and altered\nbrain rhythms, provide critical insights into the neurolog-\nical changes. Brain connectivity modeling in AD can be\napproached from several angles. One approach, as seen in\nST-GCN [161], generates functional connectivity matrices that\nincorporate metrics like wavelet coherence and phase-locking\nvalue to simulate spatial and temporal dependencies in EEG\nsignals. Alves et al. [162] uses functional connectivity matrices\nderived from Granger causality and correlation measures to\nemphasize the spatial structure of brain networks. Additionally,\nsome studies focus on spectral analysis, such as Morabito et\nal. [163], who convert EEG data into 2D spectral images\nusing FFT and process these images with techniques like\ndiscriminative DCssCDBM to identify hybrid features that\nhighlight EEG patterns associated with AD.\nF. Parkinson’s Disease Diagnosis\n1) Task Description: Parkinson’s disease (PD) is a progres-\nsive neurodegenerative disorder marked by motor symptoms\nTABLE VIII: Public EEG Datasets for Parkinson’s Disease\nDiagnosis, where Exp (n) represents the number of patients\nand Ctrl (n) represents the healthy control group.\nDataset\nExp (n)\nCtrl (n)\nFrequency (Hz)\nChannels\nUCSD [164]\n15\n16\n512\n32\nUNM [165]\n27\n27\n500\n64\nUI [166]\n14\n14\n500\n59\n(tremors, rigidity, bradykinesia) and non-motor symptoms (de-\npression, sleep disturbances, cognitive decline). In 2019, over\n8.5 million people worldwide were living with PD [167]. EEG\nis widely used in PD research due to its noise resistance and\nsensitivity to neurological changes, such as slowing cortical\noscillations and increased low-frequency power [168]. Most\nstudies focus on supervised learning for binary classification,\nwith some incorporating transfer learning. Table VIII summa-\nrizes publicly available datasets. A detailed overview of all\nrelated works is provided in Appendix Table XVI.\n2) Approach overview:\nTransforming raw EEG signals\ninto 2D representations is a well-established approach for\nPD classification, with various techniques offering distinct\ninsights. Spectrograms, generated via Gabor Transform, as\nin GaborPDNet [40], preserve time-frequency characteristics\nwhile minimizing information loss. Scalograms, created using\nCWT, provide another effective representation [169]. Accord-\ning to Chu et al. [170], power spectral density (PSD) mapping\nis another method, where specific frequency bands like high-\nδ and low-α can serve as potential biomarkers for early\nPD diagnosis. Connectivity-based 2D representations can be\nobtained, like those applied by Arasteh et al. [171], compute\ndirectional connectivity and produce heatmaps that effectively\ncapture inter-channel relationships across frequency bands.\nG. ADHD Identification\n1) Task Description: Attention-deficit/hyperactivity disor-\nder (ADHD) is a neurodevelopmental disorder affecting\naround 3.1% of individuals aged 10–14 and 2.4% of those\naged 15–19 [174]. It is categorized into three subtypes:\nInattentive (ADHD-I), Hyperactive-Impulsive (ADHD-H), and\nCombined (ADHD-C) [175]. EEG is widely used alongside\nneuroimaging and physiological measures for ADHD diagno-\nsis. However, deep learning remains underexplored, with most\nexisting approaches relying on supervised learning and feature-\nbased classification. Research focuses on binary classification\ntasks, and Table IX lists two publicly available datasets. A\ndetailed overview of all related works is provided in Appendix\nTable XVII.\n2) Approach overview: Studies on ADHD diagnosis iden-\ntify distinct EEG neurophysiological markers, particularly\nTABLE IX: Public EEG Datasets for ADHD Identification,\nwhere Exp (n) represents the number of ADHD patients and\nCtrl (n) represents the healthy control group.\nDataset\nExp (n)\nCtrl (n)\nFrequency (Hz)\nChannels\nADHD-79 [172]\n37\n42\n256\n2\nADHD-121 [173]\n61\n60\n128\n19\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n10\nabnormalities in specific frequency bands. Chen et al. [176]\nand Dubreuil-Vall et al. [177] demonstrate the effectiveness\nof CNNs for ADHD detection. Chen et al. report θ and β\nabnormalities in children with ADHD, while Dubreuil-Vall et\nal. observe altered α and δ −θ in frontal electrodes during\nexecutive function tasks, aligning with medical findings. They\nalso find that EEG data from executive function tasks outper-\nform resting-state EEG for ADHD detection.\nIV. UNIVERSAL PRE-TRAINED MODELS\nIn recent years, SSL has revolutionized EEG/iEEG analysis\nin neurological diagnosis. Emerging methods focus on general-\nizable SSL frameworks that integrate heterogeneous datasets\nduring pre-training, overcoming the limitations of task- and\ndataset-specific models and enabling seamless adaptation to\nmultiple downstream tasks. These innovations bring us closer\nto the development of universal neurodiagnostic models capa-\nble of addressing challenges across diverse clinical settings.\nTable X summarizes pre-trained SSL frameworks for multi-\ntask neurodiagnosis, organized by the SSL paradigms to align\nwith their technical evolution analyzed in this section. While\nsome frameworks extend to broader time-series data, such as\nBCI signals and motion sensor data, we focus on datasets and\ntasks directly relevant to neurological applications. Below, we\nfurther explore these frameworks, examining their contribu-\ntions to unified pre-training strategies, multitask adaptability,\nand their potential to impact real-world applications.\nA. Contrastive- and Predictive- Based Learning\na) Contrastive Predictive Coding: Early SSL approaches\nin EEG/iEEG analysis are largely based on the Contrastive\nPredictive Coding (CPC) paradigm [18], [71], which learns\nrobust representations by predicting signal segments through\ncontrastive learning. While these models employed generic\narchitectures across neurophysiological tasks, they fail to\nachieve true cross-task generalization. As a result, they are\ntrained separately on specific datasets, limiting their clinical\napplicability across diverse neurodiagnostic applications. CPC\nvariants like TS-TCC [178] introduce a one-to-one feature\ntransfer mechanism. This framework enables feature migration\nacross tasks such as human activity recognition, sleep staging,\nand epileptic seizure detection, paving the way for broader\nmulti-domain diagnostic generalization.\nBuilding on the foundational principles of CPC, two dis-\ntinct approaches have emerged: contrastive learning (CL)\nand predictive-based variants. CL retains CPC’s contrastive\nframework but emphasizes explicit instance-level discrimina-\ntion through hand-crafted augmentations for positive/negative\npairs, instead of CPC’s autoregressive future state prediction.\nPredictive variants inherit CPC’s structure but replace its auto-\nlearned latent contexts with manually defined features.\nb) Contrastive-Based learning: SeqCLR [67], inspired\nby SimCLR, employs contrastive learning to EEG data, en-\nhancing similarity between augmented views of the same\nchannel through domain-specific transformations. Adopting\na mixed-dataset training approach, it unifies diverse EEG\ndatasets for robust representation learning. TF-C [179] in-\ncorporates dual time-frequency contrastive learning with a\ncross-domain consistency loss to align embeddings across\ntemporal and spectral representations. It further evaluates one-\nto-many paradigms, highlighting the potential of cross-task\nfeature sharing for universal neural signal models. BIOT [180]\nintegrates contrastive learning, unifying multimodal biosignals\n(e.g., EEG, ECG) via tokenization and linear attention to learn\ninvariant physiological patterns for cross-task generalization.\nc) Predictive-Based Learning: Jo et al. [181] proposes\na channel-aware predictive-based framework, which leverages\nstopped band prediction for spectral feature learning and\nemploys temporal trend identification to capture dynamic\npatterns. By integrating mix-dataset pretraining, it enhances\ngeneralization through cross-domain feature fusion. However,\nthe pretraining scale remains limited.\nB. Reconstruction-Based Learning\na) Masked Autoencoding: The paradigm shift from CPC\nto masked reconstruction in SSL aims for higher data effi-\nciency and scalability, inspired by cross-domain advances like\nmasked language modeling in NLP (e.g., BERT [189]), with\nMAE’s generative approach enhancing classification perfor-\nmance while avoiding complex negative sampling.\nNeuro2vec [70] extends masked reconstruction by integrat-\ning EEG-specific spatiotemporal recovery and spectral compo-\nnent prediction into a unified framework, utilizing a CNN-ViT\nhybrid architecture for patch embedding and reconstruction.\nCRT [182] further introduces multi-domain reconstruction\nthrough cross-domain synchronization of temporal and spec-\ntral features, replacing conventional masking with adaptive\ninput dropping to preserve data distribution integrity, thereby\nimproving robustness in physiological signal modeling. Neuro-\nBERT [183] introduces Fourier Inversion Prediction (FIP),\nreconstructing masked signals by predicting their Fourier am-\nplitude and phase, then applying an inverse Fourier transform.\nThe spectral-based prediction framework inherently matches\nthe physiological nature of EEG signals.\nb) Large-Scale\nContinuous-Reconstruction\nModels:\nTransformer architectures excel in neurodiagnostics due to\ntheir scalability and attention mechanisms, which adaptively\ncapture global dependencies in irregular neural signals. BERT-\nstyle pretraining, particularly masked reconstruction, enhances\nneurodiagnostic classification by enforcing robust contextual\nlearning of latent bioelectrical patterns, which is crucial for\ndistinguishing subtle neurological signatures. Their paralleliz-\nable training and tokenized time-frequency representations\npave the way for scalable foundation models, driving large-\nscale pretraining in neural signal analysis.\nInspired by Bert, BENDR [28] integrates CPC with MAE-\ninspired reconstruction for temporal feature learning. Pre-\ntrained on the Temple University Hospital EEG Corpus\n(TUEG)—a diverse dataset containing 1.5 TB of raw clinical\nEEG recordings from over 10,000 subjects—BENDR repre-\nsents the emergence of large-scale pretraining for neurodi-\nagnostics, showcasing the cross-subject scalability of trans-\nformers. It demonstrates how foundation models can unify\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n11\nTABLE X: Summary of pre-trained SSL frameworks for multi-task neurodiagnosis, focusing on relevant datasets and tasks,\nwith paradigms such as Contrastive Learning (CL), Contrastive Predictive Coding (CPC), and Masked Autoencoding (MAE)\nWork\nSSL Paradigm\nBackbone\nData Type\nPartitioning\npre-training Dataset\nDownstream Tasks\nBanville et al. [18]\nCPC\nCNN\nEEG\ndataset-specific\nTUSZ, PC18\nSeizure, Sleep\nMBrain [71]\nCPC\nCNN+LSTM+GNN\nEEG, iEEG\ndataset-specific\nTUSZ, private\nSeizure, etc.\nTS-TCC [178]\nCPC\nCNN+Transformer\nEEG\ncross-dataset\nBonn, Sleep-EDF, etc.\nSeizure, Sleep, etc.\nSeqCLR [67]\nCL\nCNN+GRU\nEEG\nmixed-dataset\nTUSZ, Sleep-EDF, ISRUC, etc.\nSeizure, Sleep, etc.\nTF-C [179]\nCL\nCNN\nEEG\ncross-dataset\nSleep-EDF, etc.\nSeizure, Sleep, etc.\nBIOT [180]\nCL\nTransformer\nEEG, etc.\ncross-dataset\nSHHS, etc.\nSeizure, etc\nJo et al. [181]\nPredictive\nCNN\nEEG\nmixed-dataset\nCHB-MIT, Sleep-EDF\nSeizure, Sleep\nneuro2vec [70]\nMAE\nCNN+Transformer\nEEG\ncross-dataset\nBonn, Sleep-EDF, etc.\nSeizure, Sleep\nCRT [182]\nMAE\nTransformer\nEEG\ndataset-specific\nSleep-EDF, etc.\nSleep, etc.\nNeuroBERT [183]\nMAE\nTransformer\nEEG, etc.\ndataset-specific\nBonn, SleepEDF, etc,\nSeizure, Sleep,etc.\nBENDR [28]\nCPC+MAE\nCNN+Transformer\nEEG\ncross-dataset\nTUEG\nSleep, etc.\nCBRAMOD [184]\nMAE\nTransformer\nEEG\ncross-dataset\nTUEG\nSeizure, Sleep, MDD\nBrant [99]\nMAE\nTransformer\niEEG\ncross-dataset\nprivate\nSeizure, etc.\nBrainwave [185]\nMAE\nTransformer\nEEG, iEEG\ncross-dataset\nTUEG,\nSiena,\nCCEP,\nSleep-\nEDF, NIMH, FSA, private, etc.\nSeizure, Sleep, MDD,\nSZ, AD, ADHD\nEEGFormer [186]\nVQ+MAE\nTransformer\nEEG\ncross-dataset\nTUEG\nSeizure, etc.\nLaBraM [187]\nVQ+MAE\nTransformer\nEEG\ncross-dataset\nTUEG, Siena, etc.\nSeizure, etc.\nNeuroLM [188]\nVQ+MAE\n+Predictive\nTransformer\nEEG\ncross-dataset\nTUEG, Siena, etc.\nSeizure, Sleep, etc.\nheterogeneous neural signal paradigms, advancing generalized\nand scalable EEG analysis. CBRAMOD [184] introduces a\ncriss-cross transformer framework to explicitly model EEG’s\nspatial-temporal heterogeneity. Using patch-based masked\nEEG reconstruction, it separately processes spatial and tempo-\nral patches through parallel attention mechanisms, preserving\nthe structural dependencies unique to EEG.\nBrant [99] and Brainwave [185] represent a unified effort to\nestablish foundation models for neural signal analysis. Brant\nfocuses on SEEG signals, employing a masked autoencoding\nframework with dual Transformer encoders to capture tempo-\nral dependencies and spatial correlations, enabling applications\nsuch as seizure detection and signal forecasting. Brainwave\npioneers large-scale pretraining with an unprecedented mul-\ntimodal corpus of over 40,000 hours of EEG and iEEG data\nfrom 16,000 subjects, marking a significant milestone in neural\nsignal foundation models. Its pre-training strategy follows\na masked modeling paradigm that randomly masks time-\nfrequency patches of neural signals, and the model is trained\nto reconstruct the missing regions. To enhance generalizability\nacross different types of neural data, Brainwave employs\na shared encoder for both EEG and iEEG, coupled with\nmodality-specific reconstruction decoders. These innovations\nposition Brainwave as the first comprehensive foundation\nmodel capable of unifying EEG and iEEG analysis, with\ntransformative implications for neuroscience research.\nc) Large-Scale Discrete-Reconstruction Models: Vector\nQuantized Variational Autoencoder (VQ-VAE) is a powerful\nframework for learning discrete representations of continuous\ndata by mapping inputs to a predefined codebook, which\nhas been widely adopted in domains like speech and image\nprocessing [190]. By tokenizing raw data into discrete codes,\nthis approach enhances cross-subject generalization while pre-\nserving interpretable spatiotemporal patterns.\nLaBraM [187] trains its discrete codebook by reconstructing\nboth Fourier spectral magnitudes and phases of EEG seg-\nments, then pretrains with a symmetric masking task that\npredicts masked code indices bidirectionally. NeuroLM [188]\nfurther extends this approach by introducing VQ Temporal-\nFrequency Prediction, aligning EEG tokens with textual rep-\nresentations through adversarial training. After tokenization,\nit employs multi-channel autoregressive modeling, enabling\nan LLM to predict the next EEG token in a manner anal-\nogous to language modeling. EEGFormer [186] focuses on\nreconstructing raw temporal waveforms for codebook training,\nfollowed by BERT-style masked signal reconstruction pretrain-\ning. These methods demonstrate how VQ-based tokenization\nadapts to EEG modeling—whether prioritizing spectral syn-\nchrony (LaBraM), fusing time-frequency features (NeuroLM),\nor preserving temporal fidelity (EEGFormer).\nC. BrainBenchmark\nThe development of universal pre-trained frameworks rep-\nresents a transformative advancement in healthcare, enabling\nthe integration of heterogeneous datasets and generalization\nacross diverse diagnostic tasks. To systematically evaluate and\nadvance this field, we have established an open benchmark,\ncurrently comprising 8 models and 9 public datasets focused\non neurological diagnostics, with ongoing expansions planned.\nThis benchmark supports comprehensive performance eval-\nuation, custom model integration, and dataset extensibility,\nfostering reproducible research and innovation. The imple-\nmentation is publicly available at https://github.com/ZJU-\nBrainNet/BrainBenchmark. Future work will include a detailed\nanalysis of benchmark results to further advance universal\nframeworks in EEG/iEEG analysis.\nV. CONCLUSION\nThis survey systematically reviews 448 studies and 46\npublic datasets to advance deep learning-driven analysis of\nEEG/iEEG signals across seven neurological diagnostic tasks:\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n12\nseizure detection, sleep staging and disorder, major depres-\nsive disorder, schizophrenia, Alzheimer’s disease, Parkinson’s\ndisease, and ADHD. Our work establishes three founda-\ntional contributions: First, we unify fragmented methodologies\nacross neurological conditions by standardizing data process-\ning, model architectures, and evaluation protocols. Second,\nwe identify self-supervised learning as the most promising\nparadigm for multi-task neurodiagnosis, providing a compre-\nhensive overview of pre-trained SSL frameworks and their\nadvancements. Third, we introduce BrainBenchmark to en-\nhance reproducibility by integrating neurological datasets and\nuniversal models under standardized evaluations.\nLooking back, the pursuit of universal models capable of\nlearning from diverse, multimodal data reflects the field’s\ngrowing ambition. It lays the groundwork for a new era of\nintelligent and adaptable healthcare systems. Over the past\ndecades, significant progress in traditional methods has estab-\nlished a strong foundation for neurological diagnostics based\non electrical brain signals. Key contributions include advances\nin signal preprocessing techniques, curating large-scale, well-\nannotated datasets, and developing deep learning architectures\nfor specific tasks. Building on this foundation, the integration\nof self-supervised pretraining marks a paradigm shift, enabling\nmodels to extract rich and meaningful representations from\nvast amounts of unlabeled, heterogeneous data.\nLooking forward, the ultimate goal is to develop genuinely\nuniversal and adaptable frameworks capable of transcending\nindividual tasks and datasets to address a broader range of neu-\nrological disorders. These advancements will pave the way for\nintelligent diagnostic tools that deliver precise, efficient, and\naccessible healthcare solutions globally, driving transformative\nprogress in biomedical research and clinical applications.\nACKNOWLEDGMENT\nThis work is supported by NSFC (62322606) and Zhejiang\nNSF (LR22F020005).\nIn this section, we provide summaries of deep learning-\nbased frameworks for the seven neurodiagnostic tasks men-\ntioned earlier. These summaries include details on prepro-\ncessing methods, extracted features, deep learning backbones,\ntraining paradigms, downstream task datasets, classification\ntasks, data partitioning strategies, and reported performances.\nThe relevant tables are as follows: seizure detection in Ta-\nble XI, sleep staging in Table XII, depression identification\nin Table XIII, schizophrenia identification in Table XIV,\nAlzheimer’s disease diagnosis in Table XV, Parkinson’s dis-\nease diagnosis in Table XVI, and ADHD identification in\nTable XVII.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n13\nTABLE XI: Summary of deep learning frameworks for seizure detection\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[191] Image generation\n2D Image\n2D-CNN\nsupervised\nBern-Barcelona,\nprivate\nbinary\nmixed-subject\n100%\n[93]\nFFT\nFrequency-\ndomain features\n2D-CNN\nsupervised\nFreiburg,\nCHB-MIT\nbinary\n3-class\nsubject-specific\n98.2%-\n99.4%\n95.3%\n[192] Filtering,Downsampling\nRaw\n2D-CNN\nsupervised\nprivate\nbinary\ncross-subject\nAUC=0.94\n[193] FSST,WSST\nTime-Frequency\nmatrix\n2D-CNN\nsupervised\nBern-Barcelona\nbinary\nmixed-subject\n99.94%\n[194] Filtering,EMD,FWT,FT\nRaw,IMFs,\nWavelet\nCoefficients,\nModule Values\n2D-CNN\nsupervised\nBern-Barcelona,\nprivate\nbinary\nmixed-subject\n98.9%\n[195] Z-norm,STFT\n2D Spectrograms\n2D-CNN\nsupervised\nBern-Barcelona,\nprivate\nbinary\nmixed-subject\n91.8%\n[46]\nFiltering\n2D Images\n2D-CNN\nsupervised\nBonn\nbinary\nmixed-subject\n99.6%\n[94]\nCWT\n2D Scalograms\n2D-CNN\nsupervised\nBonn\nbinary\n3-class\n5-class\nmixed-subject\n93.60%\n[196] Windowing\nRaw Segments\n2D-CNN\nsupervised\nCHB-MIT\nbinary\nmixed-subject\n99.07%\n[197] Image construction\nintensity Image\n2D-CNN\nsupervised\nCHB-MIT\nbinary\nmixed-subject\n99.48%\n[198] Windowing,Normalization Raw\n2D-CNN\nsupervised\nCHB-MIT\nbinary\ncross-subject\n98.05%\n[199] FFT,WPD\nTime-Frequency\nfeatures\n2D-CNN\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n98.33%\n[200] STFT,Filtering,\nMAS calculation\nMAS Map Image\n2D-CNN\nsupervised\nCHB-MIT,\nprivate\nbinary\n3-class\n5-class\nmixed-subject\n99.33%\n98.62%\n87.95%\n[201] MPS\n2D Spectrograms\n2D-CNN\nsupervised\nCHB-MIT,\nprivate\nbinary\nmixed-subject\nSEN>90%\n[202] Filtering,Segmentation\n2D Image\n2D-CNN\nsupervised\nprivate\nbinary\ncross-subject\nTPR=74%\n[203] Filtering,Normalization,\nImage generation\n2D Image\n2D-CNN\nsupervised\nprivate\nbinary\nmixed-subject\n87.65%\n[204] FFT\n2D Spectrograms\n2D-CNN\nsupervised\nTUSZ\nbinary\ncross-subject\nF1=59.2%\n[205] Segmentation,\nImage generation\nRPS Image\n2D-CNN\nsupervised\nBonn\nbinary\n3-class\nmixed-subject\n98.5%\n95%\n[206] CWT\nScalograms\n2D-CNN\nsupervised\nBonn\nbinary\nmixed-subject\n72.49%\n[207] Hilbert Transform,\nGASF,GADF\n2D Images\n2D-CNN\nsupervised\nBonn\nbinary\nmixed-subject\n98%\n[208] Filtering,DWT\n2D Image\n2D-CNN\nsupervised\nBonn\nbinary\nmixed-subject\n97.74%\n[209] Segmentation\nRaw Segments\n2D-CNN\nsupervised\nCHB-MIT\nbinary\ncross-subject\n99.72%\n[210] Segmentation,DWT\nPSDED\n2D-CNN\nsupervised\nCHB-MIT\n4-class\nmixed-subject\n92.6%\n[211] Channel selection,\nImage generation\n2D Image\n2D-CNN\nsupervised\nCHB-MIT\n3-class\nmixed-subject\n94.98%\n[212] Segmentation,STFT\n2D Spectrograms\n2D-CNN\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n95.65%\n[213] Filtering,Segmentation,\nSTFT\n2D Spectrograms\n2D-CNN\nsupervised\nCHB-MIT\nbinary\nsubject-specific\nSEN=92.7%\n[214] Segmentation,STFT\n2D Spectrograms\n2D-CNN\nsupervised\nCHB-MIT\nbinary\nmixed-subject\n98.26%\n[215] Filtering,FT,Welch’s,WPD Fusion\nfeature\nImage\n2D-CNN\nsupervised\nCHB-MIT,\nprivate\n5-class\nmixed-subject\n98.97%\n[216] Normalization,DWT,\nS-Transform\n2D Spectrograms\n2D-CNN\nsupervised\nFreiburg\nbinary\nsubject-specific\n98.12%\n[217] Segmentation,CWT\nscalograms\n2D-CNN\nsupervised\nMelbourne\nbinary\nmixed-subject\nAUC=0.928\n[218] Filtering,STFT\n2D Spectrograms\n2D-CNN\nsupervised\nTUSZ\nbinary\ncross-subject\n88.3%\n[219] Filtering,Segmentation\nRaw Segments\n2D-CNN\nsupervised\nTUSZ\nbinary\ncross-subject\n70.38%\n[220] Segmentation,STFT,CWT\n2D Spectrogram,\nScalogram\n2D-CNN\nsupervised\nBonn\nbinary\nmixed-subject\n99.21%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n14\n(Continued) Summary of deep learning frameworks for seizure detection\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[221] Segmentation, FNSW\n2D Image\n2D-CNN\nsupervised\nBonn\nbinary\n3-class\n5-class\nmixed-subject\n100%\n[222] Segmentation,EMD,WOG\nGraph\nrepresentation\n2D-CNN\nsupervised\nBonn,\nprivate\nbinary\nmixed-subject\n100%\n97.65%\n[223] Z-norm,Windowing\nRPS Image\n2D-CNN\nsupervised\nBonn\nbinary\nmixed-subject\n92.3%\n[224] Filtering,CWT\n2D Scalograms\n2D-CNN\nsupervised\nBonn\nbinary\nmixed-subject,\ncross-subject\n99.5%\n[225] STFT\n2D Spectrograms\n2D-CNN\n+Attention\nsupervised\nCHB-MIT\nbinary\nmixed-subject\n96.61%\n[226] Filtering,Z-norm\nRaw Segments\n2D-CNN\n+Attention\nsupervised\nSWEC-\nETHZ,private\nbinary\nsubject-specific\nAUC=0.92\nAUC=0.96\n[51]\nSTFT\nSpectrograms\n3D-CNN\nsupervised\nCHB-MIT,\nprivate\nbinary\ncross-subject\n99.4%\n[227] Segmentation,WT\nRelative\nEnergy\nmatrix\nBi-GRU\nsupervised\nCHB-MIT,\nprivate\nbinary\ncross-subject,\nsubject-specific\nSEN=95.49\n[228] Segmentation,\nTime-GAN\nEnhanced\nSegments\nBiLSTM\nsupervised\nprivate\nbinary\ncross-subject\n78.5%\n[229] Filtering,Frequency fea-\nture extraction\nLinear features\nBi-LSTM\nsupervised\nBonn\nbinary\nmixed-subject\n98.56%\n[230] Z-norm,Filtering,\nSegmentation\nRaw Segments\nBi-LSTM\nsupervised\nBern-Barcelona\nbinary\nmixed-subject\n99.6%\n[231] Segmentation,LMD\nStatistical\nfeatures\nBi-LSTM\nsupervised\nCHB-MIT\nbinary\nsubject-specific\nSEN=93.61%\n[232] Segmentation,\nS-transform\nSpectrogram\nBi-LSTM\nsupervised\nFreiburg\nbinary\nsubject-specific\n98.69%\n[233] Segmentation\nSegments\nBi-LSTM\nsupervised\nCHB-MIT\nbinary\nmixed-subject,\ncross-subject\n87.8%\n[234] Normalization,\nInstantaneous frequency\nSpectral entropy\nBi-LSTM\nsupervised\nBonn\nbinary\n5-class\nmixed-subject\n100%\n96%\n[26]\nBaseline Correction,\nWindowing,linear\ndetrending\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\ncross-subject\n87.51%\n[235] Downsampling,\nFiltering\nRaw\nCNN\nsupervised\nprivate\nbinary\ncross-subject\n97.1%\n[29]\nZ-norm\nRaw\nCNN\nsupervised\nBonn\nbinary\nmixed-subject\n88.67%\n[236] Segmentation,EMD\nIMFs of EMD\nCNN\nsupervised\nBonn\nbinary\n3-class\nmixed-subject\n100%\n98.6%\n[237] Segmentation\nRaw Segments\nCNN\nsupervised\nBonn\nbinary\nmixed-subject\n99.1%\n[238] Normalization\nRaw Segments\nCNN\nsupervised\nBonn\nbinary\n5-class\ncross-subject\n97.38%\n93.67%\n[239] Filtering,Segmentation\nRaw Segments\nCNN\nsupervised\nCHB-MIT\nbinary\ncross-subject\nSEN=86.29%\n[240] Filtering,Downsampling,\nCAR montage\nRaw\nCNN\nsupervised\nprivate\nbinary\ncross-subject\nAUC=93.5%\n[241] Segmentation,\nNormal-\nization, Standardization\nSegments\nCNN\nsupervised\nTUSZ\nbinary\ncross-subject\n79.34%\n[96]\nDWT\nWavelet\nCoefficients\nCNN\nsupervised\nBonn\nbinary\nmixed-subject\n100%\n[242] Filtering, Z-norm\nRaw\nCNN\nsupervised\nBonn\nbinary\nmixed-subject\n99%\n[243] Data Augmentation,\nfeature enhancement\nEnhanced\nSegments\nCNN\nsupervised\nCHB-MIT\nbinary\ncross-subject\nSEN=74.08%\n[244] Filtering,Windowing\nRaw Segments\nCNN\nsupervised\nCHB-MIT,\nprivate\nbinary\nmixed-subject\nAUC=0.8\n[245] Filtering,Windowing\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\ncross-subject\nAUC=0.83\n[246] Downsampling,Z-norm,\nWindowing,Data\nAugmentation\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\ncross-subject\nSEN=95.8%\n[247] Z-norm,Filtering,\nSegmentation\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\ncross-subject\nAUC=0.961\n[248] Normalization,\nSegmentation\nRaw Segments\nCNN\nsupervised\nBern-Barcelona\nbinary\nmixed-subject\n91.5%\n[249] Filtering,\nData Augmentation\nAugmented data\nCNN\nsupervised\nBern-Barcelona\nbinary\nmixed-subject\n89.28%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n15\n(Continued) Summary of deep learning frameworks for seizure detection\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[48]\nFiltering,DWT,\nPower Spectrum Band\nCalculation,Frequency\nBand Calculation\n2D Image\nCNN\nsupervised\nBonn\nbinary\ncross-subject\n99.99%\n[250] Segmentation,Filtering\nApEn and RQA\nvector\nCNN\nsupervised\nBonn\nbinary\nmixed-subject\n99.26%\n[251] Normalization,CWT\n2D Scalograms\nCNN\nsupervised\nBonn\nbinary\nmixed-subject\n98.78%\n[252] Filtering\nRaw\nCNN\nsupervised\nBonn\nbinary\n3-class\nmixed-subject\n100%\n99.8%\n[253] -\nRaw\nCNN\nsupervised\nBonn\n3-class\nmixed-subject\n98.67%\n[254] Segmentation,\nData Augmentation\nRaw Segments\nCNN\nsupervised\nBonn\nbinary\nmixed-subject\nAUC=0.92%\n[255] Z-norm\nRaw\nCNN\nsupervised\nBonn\nbinary\n5-class\nmixed-subject\n99.93%\n94.01%\n[256] Normalization\nRaw\nCNN\nsupervised\nBonn\nbinary\n3-class\n5-class\nmixed-subject\n98.5-100%\n[257] Segmentation,\nNormalization\nRaw Segments\nCNN\nsupervised\nBonn\nbinary\n3-class\n5-class\nmixed-subject\n97.63%-99.52%\n96.73%-98.06%\n93.55%\n[258] Z-norm\nRaw\nCNN\nsupervised\nBonn,\nCHB-MIT\nbinary\nmixed-subject\n98.67%\n[259] Segmentation,Baseline\nRemoval,Resampling,\nDetrending,Filtering\nRaw Segments\nCNN\nsupervised\nBonn,\nTUSZ,\nCHB-MIT\nbinary\nsubject-specific\n99.8%\n92%\n95.96%\n[260] Channel selection\nRaw\nCNN\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n96.1%\n[261] Filtering,Segmentation,\nSpectrogram generation\n2D Spectrograms\nCNN\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n77.57%\n[262] Segmentation\nRaw Segments\nCNN\nsupervised\nCHB-MIT\nbinary\nmixed-subject\n96.74%\n[263] Normalization,\nSegmentation\nRaw Segments\nCNN\nsupervised\nCHB-MIT\nbinary\ncross-subject\n97%\n[264] Segmentation,Filtering,\nFFT,WT\nspectral data\nCNN\nsupervised\nCHB-MIT\nbinary\nmixed-subject\n97.25%\n[265] Filtering,resampling,\nSegmentation\nRaw Segments\nCNN\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n84.1%\n[266] Segmentation\nRaw Segments\nCNN\nsupervised\nCHB-MIT,\nMayo-Upenn\nbinary\nsubject-specific\nAUC=0.970\nAUC=0.915\n[267] Downsampling,Filtering,\nArtifact Removal\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\ncross-subject,\nsubject-specific\n99.6%\n[268] Z-norm,Filtering\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\ncross-subject\n80%\n[269] Segmentation,Filtering,\nData Augmentation\nRaw\nCNN\nsupervised\nprivate\nbinary\ncross-subject,\nsubject-specific\n96.39%\n[270] Filtering,Segmentation\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\ncross-subject\n-\n[271] Filtering,Downsampling,\nSegmentation\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\nsubject-specific\nAUC=98.9\n[272] Windowing,Normalization Raw Segments\nCNN\nsupervised\nprivate\nbinary\ncross-subject\n77%\n[273] Downsampling,Windowing Raw,\nPeriodogram,\nSpectrograms,\nImage\nCNN\nsupervised\nMayo-Upenn\nbinary\ncross-subject,\nsubject-specific\n99.9%\n[274] Segmentation\nRaw Segments\nCNN\nsupervised\nMayo-UPenn,\nCHB-MIT\nbinary\nsubject-specific\nAUC=0.981\nAUC=0.988\n[275] Time-Frequency feature\nextraction\nPattern Matrices\nCNN\nsupervised\nTUSZ\nbinary\ncross-subject\nAUC=0.74\n[276] Segmentation\nRaw Segments\nCNN\nsupervised\nTUSZ\nbinary\ncross-subject\n80.5%\n[277] 1D-AaLBP,1D-AdLBP\nHistogram-based\nfeature\nCNN\nsupervised\nBonn,\nCHB-MIT\nbinary\n5-class\nmixed-subject\n98.8% - 99.65%\n99.11%\n[278] Filtering,Segmentation,\nFFT\nFrequency-\ndomain features\nCNN\nsupervised\nMayo-Upenn\nbinary\nsubject-specific\n94.74%\n[103] Normalization,Differencing Difference\nMatrix\nCNN\nsupervised\nMAYO,\nFNUSA, private\nbinary\ncross-subject\nF2=55.93-81.54\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n16\n(Continued) Summary of deep learning frameworks for seizure detection\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[279] Filtering,GPSO\nTime- & Freq-\ndomain featrues\nCNN\nsupervised\nBonn\nbinary\nmixed-subject\n99.65%\n[280] Z-norm,FFT\nRaw,features\nCNN\nsupervised\nBonn\nbinary\n3-class\nmixed-subject\n98.23%\n96.33%\n[281] Normalization,Filtering,\nSTFT\nRPSD,SampEn,SI\nCNN\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n94.5%\n[282] Normalization,\nSegmentation\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\nmixed-subject\n99.61%\n[283] Filtering,Segmentation\nFreq-features,\nTime-Freq Image\nCNN\n3D-CNN\nsupervised\nHelsinki\nbinary\ncross-subject\n90.06%\n[284] Filtering,Segmentation,\nArtifact rejection\nRaw Segments\nCNN\n2D-CNN\nsupervised\nprivate\nbinary\ncross-subject\n96.39%\n[285] Normalization\nRaw\nCNN\nCNN-LSTM\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n91.50%\n92.11%\n[286] Segmentation\nRaw\nCNN,LSTM\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n89.21%\n[287] Segmentation,\nNormalization\nNaN\nCNN\nLSTM\nGRU\nsupervised\nBonn\nbinary\nmixed-subject\n97.27%\n96.82%\n96.67%\n[288] STFT\n2D Spectrograms\nCNN+Attention supervised\nCHB-MIT\nbinary\ncross-subject\n96.22%\n[289] Filtering,Downsampling,\nSegmentation\nRaw Segments\nCNN+Attention supervised\nprivate\nbinary\ncross-subject\nAUC=0.97\n[290] Downsampling,\nSegmentation\nRaw Segments\nCNN-\nBiGRU\nsupervised\nCHB-MIT,\nBonn,\nMayo-Upenn\nbinary\nmixed-subject\n0.985\n[53]\nDWT\nStatistical,Freq-,\nNonlinear\nfeatures\nCNN-\nBiGRU\n+Attention\nsupervised\nFreiburg\nbinary\nmixed-subject\n98.35%\n[291] Filtering,Segmentation,\nNormalization\nRaw Segments\nCNN-\nBiLSTM\nsupervised\nprivate\nbinary\ncross-subject\nAUC=0.9042\n[292] Normalization,K-means\nSMOTE\nRaw Segments\nCNN-\nBiLSTM\nsupervised\nBonn\nbinary\n5-class\nmixed-subject\n99.41%\n84.10%\n[293] Downsampling,Bipolar\nReference,Segmentation\nRaw Segments\nCNN-\nBiLSTM\n+Attention\nsupervised\nMayo-UPenn,\nprivate\nbinary\ncross-subject\n94.12%\n[98]\nWindowing\nRaw Segments\nCNN-\nBiLSTM\n+Attention\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n96.61%\n[294] Filtering,S-transform\nAdjacency matrix\nCNN-GCN\nsupervised\nCHB-MIT\nbinary\ncross-subject\n98%\n[295] TCP\nRaw\nCNN-GRU\nsupervised\nTUSZ\nbinary\ncross-subject\n86.57%\n[296] Segmentation,WPT\nMulti-view\nfeature matrix\nCNN-GRU\nsupervised\nCHB-MIT\nbinary\nsubject-specific\nSEN=94.50%\n[297] Filtering,CWT\n2D Scalograms\nCNN-GRU\nsupervised\nBonn\nbinary\n3-class\n5-class\nmixed-subject\n100%\n100%\n99.4%\n[91]\nWindowing,Filtering,\nZ-norm\n-\nCNN-GRU\nsupervised\nCHB-MIT\nbinary\nsubject-specific\nAUC=0.88\n[298] Frequency\nDecomposi-\ntion,Image generation\n2D Image\nCNN-LSTM\nsupervised\nCHB-MIT\nbinary\ncross-subject,\nsubject-specific\nSEN=96%\n[299] Segmentation,PCA\nLFCCs\nCNN-LSTM\nsupervised\nTUSZ,private\n6-class\ncross-subject\nSEN=30%\n[300] -\nRaw\nCNN-LSTM\nsupervised\nBonn\nbinary\n3-class\nmixed-subject\n100%\n98.33%\n[301] Segmentation\nRaw Segments\nCNN-LSTM\nsupervised\nBonn\nbinary\nmixed-subject\n98.8%\n[302] Normalization\nRaw\nCNN-LSTM\nsupervised\nBonn\nbinary\n5-class\nmixed-subject\n99.39%\n82%\n[303] Filtering,Segmentation\nRaw Segments\nCNN-LSTM\nsupervised\nBonn,\nFreiburg,\nCHB-MIT\nbinary\nmixed-subject\n100%\n96.17%\n95.29%\n[304] Segmentation,\nImage generation\n2D Image\nCNN-LSTM\nsupervised\nCHB-MIT\n4-class\ncross-subject\n99%\n[305] Segmentation,FFT,DWT\nTime-Frequency\nfeatures\nCNN-LSTM\nsupervised\nFreiburg\nbinary\nmixed-subject\n99.27%\n[306] Segmentation,\nFormat Conversion\nEEG video\nCNN-LSTM\nsupervised\nprivate\nbinary\ncross-subject\nSEN=88%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n17\n(Continued) Summary of deep learning frameworks for seizure detection\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[307] Filtering,Segmentation,\nCWT,STFT\n2D Spectrogram,\nScalogram\nCNN-LSTM\nsupervised\nBonn\nCHB-MIT\nBern-Barcelona\nbinary\nmixed-subject\n99.94%\n93.77%\n95.08%\n[308] Filtering,STFT\n2D Spectrograms\nCNN-LSTM\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n94.5%\n[309] Filtering,Difference\nRaw,Differential\nsignal\nCNN-LSTM\n+Attention\nsupervised\nBonn\nbinary\n5-class\nmixed-subject\n98.87%\n90.17%\n[310] Filtering,Resampling,TCP\nSegments\nCNN-RNN\nsupervised\nTUSZ\nbinary\ncross-subject\n82.27%\n[311] Segmentation\nRaw Segments\nCNN-RNN\n+Attention\nsupervised\nCHB-MIT\nbinary\nmixed-subject\nSEN=92.88%\n[312] Normalization\nRaw Segments\nCNN-\nTransformer\nsupervised\nTUSZ\nvarious\ncross-subject\nAUC=0.72\n[313] Channel selection,\nWindowing\nRaw Segments\nCNN-\nTransformer\nsupervised\nCHB-MIT\nbinary\ncross-subject,\nsubject-specific\nSEN=65.5%\n[102] Filtering,resampling,\nWindowing\nRaw Segments\nCNN-\nTransformer\nsupervised\nSWEC-ETHZ,\nprivate\nbinary\nsubject-specific\nSEN=97.5%\n[314] Filtering,Z-norm,DWT\nRhythm Signals\nCNN-\nTransformer\nsupervised\nCHB-MIT\nbinary\ncross-subject\nSEN=91.7%\n[315] Filtering,Windowing\nRaw Segments\nCNN-\nTransformer\nsupervised\nCHB-MIT\nbinary\nsubject-specific\nAUC=0.937\n[316] Filtering,Downsampling,\nBipolar Reference\nRaw Segments\nCNN-\nTransformer\nsupervised\nTUSZ,\nCHB-MIT\nbinary\ncross-subject\n49.1%-\n85.8%\n[317] Filtering,Segmentation,\nSTFT\nTime-Frequency\nfeatures\nCNN-\nTransformer\nsupervised\nCHB-MIT\nbinary\ncross-subject\n94.75%\n[318] Bipolar referencing,\nFiltering,Z-norm\nRaw Segments\nCNN-\nTransformer\nsupervised\nSWEC-ETHZ\nHUP\nbinary\ncross-subject\n91.15%\n88.84%\n[319] DWT\nWavelet-based\nfeatures\nDBN\nsupervised\nprivate\nbinary\ncross-subject\n96.87%\n[320] Segmentation,GASF\nGASF Image\nPre-Trained\nNetworks,\nDeep ANN\nsupervised\nBern-Barcelona\nbinary\nmixed-subject\nAUC=0.92\n[321] Min-max Normalization\nRaw\nDNN\nsupervised\nBonn\nbinary\nmixed-subject\n97.17%\n[322] Normalization\nRaw\nDNN\nsupervised\nBonn\nbinary\nmixed-subject\n80%\n[323] Filtering,Segmentation,ToC SAE-based\nDNN\nsupervised\nBonn\nbinary\n3-class\n5-class\nmixed-subject\n100%\n99.6%\n97.2%\n[324] DWT,Normalization\nNonlinear\nand\nentropy features\nDNN\nsupervised\nBonn,\nBern-Barcelona,\nCHB-MIT\nbinary\n3-class\nmixed-subject\n93.61%(Bonn)\n[325] Filtering,Z-norm,DWT\nWavelet\nCoefficients\nDWT-Net\nsupervised\nTUSZ\nbinary\ncross-subject\nSEN=59.07%\n[326] Filtering,Z-norm,\nNetwork construction\nAdjacency matrix\nGAT\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n98.89%\n[327] Filtering,Network\nconstruction\nNode Feature\nmatrix,Adjacency\nmatrix\nGAT+GRU\nsupervised\nCHB-MIT,\nprivate\nbinary\ncross-subject,\nsubject-specific\n98.74%\n[328] Filtering,Z-norm,\nNetwork construction\nAdjacency\nmatrix,Raw\nGAT\n+Transformer\nsupervised\nCHB-MIT\nbinary\ncross-subject,\nsubject-specific\n98.3%\n[329] Filtering,Z-norm\nNode Feature\nmatrix,Adjacency\nmatrix\nGAT-\nBiLSTM\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n98.52%\n[330] ICA\nCorrelation\nmatrix\nGCN\nsupervised\nBonn,\nCHB-MIT\nbinary\n3-class\nmixed-subject\n99.8%\n99.2%\n[331] FFT,VG\nFrequency-\ndomain Network\nGCN\nsupervised\nBonn,\nprivate\nbinary\nmixed-subject\n100%\n[332] Filtering,Segmentation,\nNetwork construction\nRaw Segments,\nAdjacency matrix\nGCN\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n99.3%\n[333] Filtering,Z-norm,\nSegmentation,Network\nconstruction\nEEG Network\nGCN\nsupervised\nprivate\nbinary\nmixed-subject\nAUC=0.91\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n18\n(Continued) Summary of deep learning frameworks for seizure detection\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[334] Segmentation,Network\nconstruction\nAdjacency matrix\nGCN\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n98.38%\n[335] Filtering,Z-norm\nNode Feature\nmatrix,Adjacency\nmatrix\nGCN+Attention supervised\nCHB-MIT\nbinary\nsubject-specific\n98.7%\n[336] Filtering,Windowing\nRaw Segments\nGCN-\nTransformer\nsupervised\nCHB-MIT\nbinary\nsubject-specific\nAUC=0.935\n[101] Filtering,Segmentation,FFT Node Feature\nmatrix,Adjacency\nmatrix\nGNN\nsupervised\nTUSZ\nbinary\ncross-subject\n81.77%\n[337] Filtering,Segmentation,\nNetwork construction\nNaN\nGNN+\nTransformer\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n98.43%\n[338] Segmentation\nRaw Segments\nGRU\nsupervised\nBonn\n3-class\nmixed-subject\n98%\n[339] DWT\nWavelet\nCoefficients\nGRU\nsupervised\nBonn\nbinary\nsubject-specific\n98.5%\n[340] -\nRaw\nGRU\nsupervised\nBonn\nbinary\nmixed-subject\n97.5%\n[341] Segmentation\nRaw Segments\nLSTM\nsupervised\nBonn\n3-class\nmixed-subject\n100%\n[342] -\nRaw\nLSTM\nsupervised\nBonn\nbinary\nmixed-subject\n95.54%\n[343] Data Augmentation,\nSegmentation\nRaw Segments\nLSTM\nsupervised\nBonn\nbinary\nmixed-subject\n100%\n[344] Z-norm,DCT\nHurst & ARMA\nfeatures\nLSTM\nsupervised\nBonn\nbinary\n3-class\nmixed-subject\n99.17%\n94.81%\n[345] DWT\n20\nEigenvalue\nfeatures\nLSTM\nsupervised\nBonn\nbinary\nmixed-subject\n99%\n[346] Filtering,Segmentation,FFT Freq-domain\nfeatures\nLSTM\nsupervised\nCHB-MIT\nbinary\nsubject-specific\n98.14%\n[347] DWT,CFS\nTime-Frequency\nfeatures\nLSTM\nsupervised\nTUSZ\nbinary\n4-class\ncross-subject\n98.08%\n95.92%\n[348] Filtering,decomposition\nTime-\n&\nFreq-\ndomain featrues\nLSTM\nsupervised\nCHB-MIT,\nSiena,\nBeirut,\nBonn\nbinary\nmixed-subject,\ncross-subject\n94.69%\n[349] Filtering\nMontage grid\nRNN\nsupervised\nCHB-MIT\nbinary\nsubject-specific\nSEN=100%\n[350] Segmentation\nRaw Segments\nRNN\nsupervised\nCHB-MIT\nbinary\ncross-subject\n88.7%\n[351] Segmentation\nRaw Segments\nRNN\nsupervised\nCHB-MIT\nbinary\nmixed-subject\n87%\n[352] -\nRaw\nRNN\nsupervised\nBonn\nbinary\n3-class\n5-class\nmixed-subject\n99.33%\n98.2%\n81.33%\n[353] Filtering,Z-norm,\nWindowing\nRaw Segments\nRNN-\nTransformer\nsupervised\nBonn,\nCHB-MIT\nbinary\nsubject-specific\n95.06%\n[354] STFT\nSpectrogram\nRNN-\nTransformer\nsupervised\nBonn,\nCHB-MIT\nbinary\nsubject-specific\n99.75%\n[355] STFT\nSpectrograms\nTGCN\nsupervised\nprivate\nbinary\ncross-subject\nAUC=0.928\n[356] Resampling,Segmentation\nRaw Segments\nTransformer\nsupervised\nTUSZ\nbinary\ncross-subject\nSEN=9.03%\n[357] STFT,Bipolar Montage\nTime-Frequency\nGraph\nTransformer\nsupervised\nTUSZ\nbinary\ncross-subject\nAUC=0.921\n[20]\nSubspace Filtering,\nICLabel\nRaw,Subspace\nFiltering,ICLabel\nU-net\nsupervised\nTUSZ\nbinary\ncross-subject\n-\n[358] Filtering,PSD\nPSD\nDNN\nsupervised\nprivate\nbinary\nsubject-specific\n-\n[359] Filtering\nHypergraph-\nbased HSO\nDNN\nsupervised\nprivate\nbinary\nmixed-subject\n90.70%\n[109] Filtering,Downsampling,\nSegmentation\n2D Topomap\n2D-CNN\nself-supervised\nTUSZ\nbinary\ncross-subject\nAUC=0.92\n[110] -\nRaw Segments\nCNN\nself-supervised\nCHB-MIT,\nMayo-UPenn,\nprivate\nbinary\nmixed-subject,\ncross-subject\nAUC=0.92-0.95\n[112] Windowing\nRaw Segments\nCNN-GNN\nself-supervised\nprivate\nbinary\ncross-subject\nF2=76.87%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n19\n(Continued) Summary of deep learning frameworks for seizure detection\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[113] Downsampling,\nSegmentation\nTime-\n&\nFreq-\ndomain featrues,\nRaw\nCNN-LSTM\nself-supervised\nMayo-UPenn,\nFNUSA,\nprivate\nbinary\ncross-subject\nF1=85.6%\nF1=82.3%\nF1=87.1%\n[111] Z-norm,FFT\nAdjacency\nmatrix,Frequency-\ndomain features\nGNN\nself-supervised\nTUSZ\nbinary\ncross-subject\nAUC=0.875\n[57]\nFFT,graph construction\nEEG Network\nGNN\nself-supervised\nTUSZ\nbinary\ncross-subject\nF1=0.534%\n[97]\nSegmentation,PCC\nPCC matrix\nTransformer\nself-supervised\nTurkish\nbinary\ncross-subject\n85%\n[107] Filtering,Z-norm,\nWindowing\nRaw Segments\nTransformer\nself-supervised\nCHB-MIT\nbinary\ncross-subject\n97.07%\n[108] Filtering,Segmentation\nRaw Segments\nCNN\nself-supervised\nTUSZ\nbinary\ncross-subject\n-\n[92]\nDWPT\nWavelets\nTransformer\nself-supervised\nTUSZ\n4-class\ncross-subject\n73%\n[360] Normalization,\nData Enhancement\nAE-based\nAE\nsemi-supervised\nBonn\nbinary\n5-class\ncross-subject\n99.6%\n96.4%\n[361] Segmentation,Filtering,\nData Augmentation\nRaw Segments\nCNN\nsemi-supervised\nCHB-MIT,\nprivate\nbinary\nmixed-subject\n90.58%\n[362] Artifacts removal,FFT\n2D Spectrograms\nCNN\nsemi-supervised\nprivate\nbinary\ncross-subject\n95.70%\n[363] STFT\nSSDA-based\n2D-CNN\nunsupervised\nCHB-MIT\nbinary\ncross-subject\n94.37%\n[364] FFT\nBP-ASE-based\n2D-CNN\nunsupervised\nCHB-MIT\nbinary\ncross-subject\n99.4%\n[104] -\nAE-based\nCNN\nunsupervised\nBonn\nbinary\n3-class\ncross-subject\n100%\n99.33%\n[27]\nNormalization\nAE-based\nCNN\nunsupervised\nBonn,\nCHB-MIT\nbinary\ncross-subject\n100%\n92%\n[365] Segmentation,STFT\nGAN-based\nCNN\nunsupervised\nCHB-MIT,\nEPILEPSIAE,\nFreiburg\nbinary\nsubject-specific\n77.68%\n75.47%\n65.05%\n[56]\nFT,WT\nSpectrograms\nCNN\nunsupervised\nFreiburg\nclustering subject-specific\n97.38%\n[366] Filtering,Segmentation\nAE-based\nCNN\nunsupervised\nprivate\n3-class\nsubject-specific\n98.84%\n[367] Filtering,Segmentation\nAE-based\nCNN\nunsupervised\nBonn\nbinary\ncross-subject\n99.8%\n[368] Normalization\nRaw\nDBN\nunsupervised\nprivate\n5-class\ncross-subject\nF1=0.93%\n[105] Min-max Normalization\nTime-domain\nfeatures\nDBN\nunsupervised\nprivate\nbinary\ncross-subject,\nsubject-specific\nF1=90%\n[369] Filtering,Normalization\nDCAE-based\nDCAE\nunsupervised\nBonn,\nBern-Barcelona\nbinary\nmixed-subject\n96%\n93.21%\n[370] Segmentation,\nNormalization\nSSAE-based\nDNN\nunsupervised\nBonn\nbinary\nmixed-subject\n96%\n[371] Filtering\nSAE-based\nDNN\nunsupervised\nBonn\nbinary\n3-class\n5-class\nmixed-subject\n100%\n[372] STFT\nSSDA-based\nDNN\nunsupervised\nCHB-MIT\nbinary\nmixed-subject\n93.92%\n[373] Taguchi Method\nSSAE-based\nDNN\nunsupervised\nBonn\nbinary\nmixed-subject\n100%\n[374] Segmentation,Z-norm\nDSAE-based\nDNN\nunsupervised\nBonn\nbinary\nmixed-subject\n100%\n[375] Filtering,Segmentation,\nHWPT,FD\nAE-based\nDNN\nunsupervised\nBonn\nbinary\nmixed-subject\n98.67%\n[376] Segmentation,CWT\nSAE-based\nDNN\nunsupervised\nCHB-MIT\nbinary\nmixed-subject\n93.92%\n[377] Downsampling,Filtering,\nZ-norm\nAE-based\nDNN\nunsupervised\nprivate\nbinary\nsubject-specific\nSEN=100%\n[43]\nESD\nDSAE-based\nDNN\nunsupervised\nprivate\nbinary\nmixed-subject\n100%\n[58]\nFBSE-EWT\nSAE-based\nDNN\nunsupervised\nBern-Barcelona\nbinary\nmixed-subject\n100%\n[106] Filtering,Segmentation,\nZ-norm,STFT\n2D Spectrograms\nGAN\nunsupervised\nprivate\nbinary\nsubject-specific\nAUC=0.9393\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n20\nTABLE XII: Summary of deep learning frameworks for sleep staging\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[378] Filtering,Feature\nExtraction\nTime-\n&\nFreq-\nfeatures\n3D-CNN\nsupervised\nISRUC\n5-class\ncross-subject\n82%-83.2%\n[130] AFR\nRaw Segments\nCNN\nsupervised\nSleep-EDF,\nSHHS\n5-class\ncross-subject\n82.9%-86.6%\n[379] Filtering,Resampling\nRaw Segments\nCNN-\nTransformer\nsupervised\nSleep-EDF,\nISRUC,\nprivate\n5-class\ncross-subject\n84.76%-86.32%\n[380] Resampling,Segmentation\nRaw Segments\nCNN\nsupervised\nSleep-EDF,\nSHHS\n5-class\ncross-subject\n85.3%\n88.1%\n[381] DCT\nDCT Coefficients\nCNN-LSTM\nsupervised\nSleepEDF,\nDRM-SUB,\nISRUC\n5-class\ncross-subject\n85.47%-87.11%\n[382] Segmentation\nRaw Segments\nCNN-\nBiLSTM\nsupervised\nSleep-EDF,\nMASS\n5-class\ncross-subject\n82.0%\n86.2%\n[383] Filtering,Spectrogram\nGeneration\n2D Spectrogram\n2D-CNN\nsupervised\nSleep-EDF,\nSHHS\n5-class\nmixed-subject\n83.02%-94.17%\n[384] Filtering,Downsampling\nComplex Values\nCNN\nsupervised\nUCD,\nMIT-BIH\n5-class\ncross-subject\n92%\n[385] Filtering,DE Calculation\nDE matrix\nGCN\nsupervised\nMASS\n5-class\ncross-subject\n88.90%\n[386] Filtering,Segmentation,\nPCC,PLV\nEEG Network\nCNN+Attention supervised\nSleep-EDF\n5-class\ncross-subject\n81%-85.8%\n[387] -\nRaw Segments\nCNN-\nbiLSTM\nsupervised\nSleep-EDF,\nMASS,\nSHHS\n5-class\ncross-subject\n83.9%-86.7%\n[388] feature extraction\nFreq- features\nCNN\nsupervised\nSleep-EDF\n5-class\ncross-subject\n81.5%-86.6%\n[389] Segmentation\nRaw Segments\nCNN\nsupervised\nSleep-EDF,\nSHHS\n5-class\ncross-subject\n79.5%-83.3%\n[390] Segmentation,Network\nconstruction\nSpatial-Temporal\nfeatures\nGCN+Attention supervised\nMASS,\nISRUC\n5-class\ncross-subject\n88.1%\n90.5%\n[32]\nResampling,Filtering,HHT Time-Frequency\nImage\n2D-CNN\nsupervised\nSVU UCD,\nMIT-BIH\n5-class\ncross-subject\n88.4%\n87.6%\n[391] Filtering\nSpatial-Temporal\nfeatures\nCNN-GAT\nsupervised\nSleep-EDF\n5-class\ncross-subject\n81.6%-84.9%\n[392] Downsampling,STFT\nTime-Freq Image\nBiRNN\n+Attention\nsupervised\nMASS\n5-class\ncross-subject\n87.1%\n[393] Segmentation,\nNormalization\nRaw Segments\nCNN-\nBiRNN\nsupervised\nSleep-EDF\n5-class\ncross-subject\n80.03%-84.26%\n[394] Segmentation,Multitaper\nSpectral Analysis\nRaw,Spectrogram\nCNN\nsupervised\nMGH\n5-class\ncross-subject\n85.76%\n[395] Filtering,Segmentation\nRaw Segments\nCNN-CRF\nsupervised\nSleep-EDF\n5-class\ncross-subject\n86.81%\n[396] Segmentation\nRaw Segments\nCNN-LSTM\nsupervised\nSleep-EDF,\nMASS\n5-class\ncross-subject\n83.1%-87.5%\n[52]\nMultitaper Spectral\nEstimation,Image\nConstruction\nRGB Image\n2D-CNN\nsupervised\nSleep-EDF\n5-class\ncross-subject\n88%\n[397] Segmentation\nRaw Segments\nCNN-\nBiLSTM\nsupervised\nSleep-EDF\n5-class\ncross-subject\n85.07%-87.02%\n[398] Segmentation\nRaw Segments\nBiLSTM\n+Attention\nsupervised\nSleep-EDF,\nDRM-SUB\n5-class\ncross-subject\n83.78%\n81.72%\n[399] Filtering,Segmentation,\nNormalization,Hilbert\nStat. features,\nSpectrogram\nCNN\nsupervised\nSleep-EDF\n2-class\nmixed-subject\n96.94%\n[400] Downsampling,\nSegmentation\nTime-\n&\nFreq-\nfeatures\nCNN-\nBiLSTM\nsupervised\nMASS\n5-class\ncross-subject\n87.8%\n[133] Downsampling,\nSegmentation\nRaw Segments\nCNN-LSTM\nsupervised\nSleep-EDF\n5-class\ncross-subject\n83.7%\n[401] Standardization\nRaw Segments\nCNN-\nTransformer\nsupervised\nSleep-EDF\n5-class\ncross-subject\n79.5%\n[402] Filtering,Windowing,DFT\nSpectral\nCoefficients\nGRU+Attention supervised\nSleep-EDF\n5-class\ncross-subject\n82.5%\n[129] -\nRaw Segments\nCNN\nsupervised\nSleep-EDF\n5-class\ncross-subject\n74%\n[131] Filtering,Downsampling,\nNormalization\nRaw Segments\nCNN\nsupervised\nMASS\n5-class\ncross-subject\n82%\n[403] -\nRaw Segments\nCNN\nsupervised\nSHHS\n5-class\ncross-subject\n87%\n[404] Segmentation\nRaw Segments\nCNN\nsupervised\nSleep-EDF\n5-class\ncross-subject\n81%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n21\n(Continued) Summary of deep learning frameworks for sleep staging\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[132]\nDownsampling,\nNormalization,\nSegmentation\nRaw segments\nCNN-LSTM\nsupervised\nSHHS, ISRUC,\nDRM-SUB,\nSVUH UCD,\nHMC,\nSleep-\nEDF\n5-class\ncross-subject\nκ=0.8\n[405] Downsampling,STFT\nTime-Frequency\nImage\nCNN\nsupervised\nSleep-EDF,\nMASS\n5-class\ncross-subject\n82.3%\n83.6%\n[406] Segmentation\nRaw Segments\nCNN\nsupervised\nSleep-EDF\n5-class\ncross-subject\n92.67%\n[407] Z-norm\nRaw Segments\nCNN+Attention supervised\nSleep-EDF\n5-class\nmixed-subject\n82.8%-93.7%\n[408] DE Calculation\nDE matrix\nCNN-GCN\nsupervised\nSleep-EDF,\nISRUC\n5-class\ncross-subject\n91.0%\n87.4%\n[409] Windowing,STFT,PSD\nCalculation\nSpectral & Tem-\nporal features\nLSTM\nsupervised\nMASS\n5-class\ncross-subject\n89.4%\n[410] Filtering,Segmentation,\nNormalization\nRaw Segments\nCNN\nsupervised\nISRUC\n(2-5)-\nclass\nmixed-subject\n98.93%-99.24%\n[31]\nFiltering,Windowing\nRaw Segments\nCNN\nsupervised\nSleep-EDF\n(2-6)-\nclass\nmixed-subject\n92.95%-98.1%\n[135] Filtering,Segmentation,\nSTFT\nRaw Segments,\n2D Spectrogram\n2D-CNN\nself-supervised\nSleep-EDF,\nSHHS,\nMGH\n5-class\ncross-subject\n72.03%-86.90%\n[137] Filtering,Hilbert\nTransform\nRaw Segments,\n2D Spectrogram\nCNN\nself-supervised\nSleep-EDF,\nISRUC\n5-class\ncross-subject\n71.6%\n57.9%\n[411] Normalization\nRaw Segments\nCNN-RNN\nself-supervised\nSleep-EDF,\nISRUC\n5-class\nmixed-subject\n80.0%\n71.4%\n[412] Segmentation\nRaw Segments\nTransformer\nself-supervised\nSleep-EDF\n5-class\ncross-subject\n90%\n[136] Resampling,Filtering,STFT 2D Spectrogram\nCNN\nself-supervised\nSleep-EDF,\nSHHS\n5-class\ncross-subject\n78.06%\n81.21%\n[413] Segmentation,Channel\nSelection,Normalization\nRaw Segments\nCNN-RNN\nself-supervised\nSleep-EDF,\nISRUC\n5-class\nmixed-subject\n80.8%\n74.4%\n[414] Segmentation,\nNormalization\nRaw Segments\nCNN-RNN\nself-supervised\nSleep-EDF,\nISRUC\n5-class\ncross-subject\n70.1%\n53.6%\n[415] Normalization,\nSegmentation\nRaw Segments\nCNN-\nTransformer\nself-supervised\nSleep-EDF,\nMASS\n5-class\ncross-subject\n83.12%\n84.23%\n[416] Segmentation,\nAugmentation\nAugmented\nSegments\nCNN+Attention self-supervised\nSleep-EDF,\nISRUC\n5-class\ncross-subject\n82.0%\n79.9%\n[68]\nFiltering,Segmentation,\nNormalization\nRaw Segments\nCNN\nself-supervised\nSleep-EDF,\nMASS\n5-class\ncross-subject\n76-79%\n[134] Normalization,Filtering,\nSegmentation\nRaw Segments\nCNN\nself-supervised\nSleep-EDF\n5-class\nmixed-subject\n88.16%\n[30]\nFiltering,Normalization,\nSegmentation\nRaw Segments,\n2D Spectrogram\nCNN\nself-supervised\nSleep-EDF\n5-class\ncross-subject\n86.8%\n[417] Segmentation,\nNormalization\nRaw Segments\nCNN\nself-supervised\nSleep-EDF,\nPC18\n5-class\ncross-subject\n72.5%\n[418] Normalization,\nSegmentation\nRaw Segments\nCNN\nsemi-supervised\nSleep-EDF,\nprivate\n5-class\nmixed-subject\n91%\n[419] Filtering,STFT\n2D Spectrogram\nCNN\nsemi-supervised\nSleep-EDF,\nprivate\n5-class\nmixed-subject\n84%\n[420] Segmentation,FFT\n2D Spectrogram\n2D-CNN\nsemi-supervised\nSleep-EDF\n5-class\ncross-subject\n89%\n[421] Filtering,Normalization,\nSegmentation\nRaw Segments\nCNN-\nBiGRU\nsemi-supervised\nSleep-EDF,\nDRM-SUB\n5-class\nmixed-subject\n82.3%\n81.6%\n[422] Multi-tapered\nSpectrogram Generation\nTime-Frequency\nImage\nGMM\nsemi-supervised\nSleep-EDF\n4-class\nsubject-specific\n73%\n[423] Filtering\nRaw Segments\nCNN\nsemi-supervised\nSleep-EDF\n5-class\nmixed-subject\n80%\n[424] Filtering,Downsampling\nRaw Segments\nCNN\nunsupervised\nSleep-EDF,\nUCD\n5-class\ncross-subject\n83.4%\n77.2%\n[425] Segmentation,Filtering\nComplex Values\nCNN\nunsupervised\nUCD,\nMIT-BIH\n5-class\ncross-subject\n87%\n[426] Filtering,Segmentation,\nfeature extraction\nTime-Frequency\ndomain features\nAE\nunsupervised\nPiryatinska\n3-class\nmixed-subject\n80.4%\n[427] Filtering,Downsampling,\nSegmentation\nRaw Segments\nDBN\nunsupervised\nUCD\n5-class\ncross-subject\n91.31%\n[428] Morlet Calculation,\nNormalization\nSSAE-based\nDNN\nunsupervised\nSleep-EDF\n5-class\ncross-subject\n78%\n[429] Filtering,feature extrac-\ntion\nTime-\n&\nFreq-\nfeatures,Raw\nDBN\nunsupervised\nUCD\n5-class\ncross-subject\n67.4%-72.2%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n22\nTABLE XIII: Summary of deep learning frameworks for depression identification\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[430] Filtering,ICA,STFT\nConnectivity\nGraph\nGCN-LSTM\nsupervised\nPRED+CT,\nMODMA\nbinary\ncross-subject\n90.38%\n90.57%\n[431] ICA,DWT,Segmentation\nFrequency-\ndomain matrix\nCNN-LSTM\nsupervised\nHUSM\nbinary\nmixed-subject\n99.15%\n[432] Filtering,ICA,Z-norm,\nSTFT\n2D Spectrogram\nCNN-LSTM\nsupervised\nHUSM\nbinary\nmixed-subject\n99.9%\n[34]\nICA,FFT,Windowing\nTime-Frequency\nfeatures\nCNN-LSTM\nsupervised\nprivate\nbinary\nmixed-subject\n99.1%\n[35]\nFiltering,ICA,Segmentation Raw Segments\nCNN\nsupervised\nprivate\nbinary\nmixed-subject\n99.37%\n[433] Filtering,Segmentation\nRaw Segments\nCNN-\nTransformer\nsupervised\nHUSM,\nprivate\nbinary\ncross-subject\n93.7%\n96.2%\n[434] Filtering,ICA,Band\nFilter,CSP\nRaw Segments\nTransformer\nsupervised\nprivate\nbinary\nmixed-subject\n92.25%\n[435] Z-norm,Welch\nPsd features\nCNN-\nGRU+Attention\nsupervised\nMODMA,\nEDRA\nbinary\nmixed-subject\n97.56%\n98.33%\n[436] Downsampling,Z-norm,\nSegmentation\nRaw Segments\n2D-CNN\nsupervised\nprivate\n3-class\nmixed-subject\n79.08%\n[437] Filtering,Downsampling,\nNormalization\nRaw Segments\nCNN-LSTM\nsupervised\nprivate\nbinary\ncross-subject\n94.69%\n[438] Filtering,ICA,Wpt\nBrain Network\nGCN\nsupervised\nMODMA,\nEDRA,\nHUSM\nNaN\nmixed-subject\n91.11%-93.75%\n[439] Baseline Removal,\nDetrending,Filtering,STFT\nTime-Frequency\nImage\nGCN\nsupervised\nHUSM,\nMODMA\nbinary\ncross-subject\n99.19%\n95.53%\n[440] Normalization,\nSegmentation,Network\nconstruction\nNode Feature\nmatrix,Adjacency\nmatrix\nGNN\nsupervised\nMODMA\nbinary\ncross-subject\n84.91%\n[441] Filtering,DE Calculation\nDifferential\nEn-\ntropy,Adjacency\nmatrix\nGCN\nsupervised\nPRED+CT,\nMODMA\nbinary\ncross-subject\n83.17%\n92.87%\n[442] Filtering,ICA,CAR,\nU-NET\nMulti-scale\nSaliency-encoded\nSpectrogram\nCNN\nsupervised\nHUSM\nbinary\ncross-subject\n99.22%\n[443] Downsampling,Filtering,\nSegmentation\nRaw Segments\nCNN-RSE\nsupervised\nprivate\nbinary\nmixed-subject\n98.48%\n[444] Segmentation\nRaw Segments\n2D-CNN\nsupervised\nHUSM,\nprivate\n3-class\nmixed-subject\n98.59%\n[445] Filtering,Min-max\nNorm,Segmentation,\nWelch\nAsymmetry\nmatrix Images\n2D-CNN\nsupervised\nHUSM\nbinary\nmixed-subject\n98.85%\n[446] Filter,Image\nConstruction\n2D Image\nCNN-LSTM\nsupervised\nHUSM\nbinary\ncross-subject\n99.245%\n[447] Denoising,Filtering,STFT\n2D Spectrogram\n2D-CNN\nsupervised\nHUSM\nbinary\nmixed-subject\n99.58%\n[448] Band-pass Filter\nFrequency bands\n2D-CNN\nsupervised\nHUSM\nbinary\nmixed-subject\n96.97%\n[449] Filtering,MPWD,Network\nconstruction\nAdjacency matrix\nOf\nFdmb\nNet-\nwork\n2D-CNN\nsupervised\nHUSM\nbinary\nmixed-subject\n97.27%\n[450] MSEC,Segmentation\nRaw Segments\nCNN,CNN-\nLSTM\nsupervised\nHUSM\nbinary\nmixed-subject\n98.32%\n[451] Filtering,PLV,Welch\nMultilayer Brain\nNetwork\nGCN\nsupervised\nHUSM\nbinary\nmixed-subject\n99.29%\n[452] ICA,Rereferencing,Filtering2D Image\n2D-CNN\nsupervised\nHUSM\nbinary\nmixed-subject\n99.11%\n[453] Filtering,Z-norm,\nSegmentation\nConnectivity\nmatrix\n2D-\nCNN+Attention\nsupervised\nHUSM\nbinary\ncross-subject\n91.06%\n[454] ICA,Z-norm,Band Filter\nFrequency bands\nCNN\nsupervised\nHUSM\nbinary\ncross-subject\n99.6%\n[455] Filtering,ASR\nRaw Segments\nInception\nsupervised\nHUSM\nbinary\ncross-subject\n91.67%\n[456] Filtering,CWT,WCOH\nRGB Image\n2D-CNN\nsupervised\nHUSM\nbinary\nmixed-subject\n98.1%\n[457] Filtering,Windowing,\nSWC,PLV\nP-mSWC\n2D-CNN\nsupervised\nHUSM,\nPRED+CT\nbinary\nmixed-subject\n93.93%- 99.87%\n[144] Filtering,Z-norm\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\nmixed-subject\n95.96%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n23\n(Continued) Summary of deep learning frameworks for depression identification\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[458] Filtering,STFT\n2D Spectrogram\n2D-CNN\nsupervised\nprivate\nbinary\nmixed-subject\n96.43%\n[459] Filtering,ICA,Segmentation Mixed\nFeature\nmatrix\nCNN\nsupervised\nprivate\nbinary\nmixed-subject\n94.13%\n[47]\nICA,LMS,AR,Hjorth\n2D Image\nCNN\nsupervised\nprivate\nbinary\ncross-subject\n84.75%\n[460] Filtering,Segmentation\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\nmixed-subject\n75.29%\n[461] Filtering,Segmentation,\nPLV,PLI\nConnectivity\nmatrix\n2D-CNN\nsupervised\nprivate\nbinary\ncross-subject\n80.74%\n[462] Filtering,PLI\nConnectivity\nmatrix\n2D-CNN\nsupervised\nprivate\nbinary\nmixed-subject\n67.67%\n[44]\nDenoising,Segmentation,\nPDC matrix Calculation\n3D CPC\n3D-CNN\nsupervised\nprivate\nbinary\ncross-subject\n100%\n[21]\nManual Denoising,\nFiltering\nRaw Segments\nCNN-LSTM\nsupervised\nprivate\nbinary\nmixed-subject\n99.12%\n[463] Filtering,Segmentation\nRaw Segments\nCNN-RNN\nsupervised\nprivate\nbinary\nmixed-subject\n99.66%\n[464] Filtering,Image\nConstruction\nSpatial-Temporal\nImage\n2D-CNN\nsupervised\nprivate\nbinary\nmixed-subject\n92.66%\n[465] Filtering,DWT\nWavelet features\nBiLSTM\nsupervised\nprivate\nbinary\nmixed-subject\n99.66%\n[466] Band Filter,\nNormalization\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\nmixed-subject\n98.13%\n[467] Filtering,ICA,Hanning\n2D Frames\n2D-CNN\nsupervised\nprivate\nbinary\ncross-subject\n77.2%\n[468] Filtering,LMS\nRaw Segments\nCNN-LSTM\nsupervised\nMODMA\nbinary\ncross-subject\n95.1%\n[469] Filter,Image\nConstruction\n2D Image\nDAN\nsupervised\nMODMA\nbinary\ncross-subject\n77%\n[470] Filtering,Windowing,PLI\nTime- & Spatial-\ndomain features\nCNN-RNN\nsupervised\nMODMA\nbinary\nmixed-subject\n96.33%\n[471] Filtering,Z-norm\nTime-Frequency\nfeatures\n2D-CNN\nsupervised\nPRED+CT\nbinary\nmixed-subject\n93.33%\n[472] ICA,Z-norm\nRaw Segments\nCNN-LSTM\nsupervised\nPRED+CT\nbinary\nmixed-subject\n99.07%\n[42]\nFiltering,ICA,Power\nSpectrum Calculation\nTopographical\nActivity Map,\nFrequency bands\n2D-CNN\nsupervised\nprivate\nbinary\ncross-subject\n85.62%\n[146] Filtering,ICA\nSpike Trains\nSNN-LSTM\nsupervised\nPRED+CT\n4-class\ncross-subject\n98%\n[473] Filtering,downsampling\nFrequency bands\nCNN-LSTM\nsupervised\nprivate\nbinary\ncross-subject\n95%\n[474] Filtering,feature extrac-\ntion\nAdjacency\nmatrix,Node\nfeatures\nGCN\nsupervised\nprivate\nbinary\ncross-subject\n97%\n[475] Image construstion\n2D Image\n2D-CNN\nsupervised\nMODMA\nbinary\nmixed-subject\n74%\n[476] Filtering,ICA\nGraph\nGCN\nself-supervised\nMODMA,\nEDRA\nbinary\ncross-subject\n99.19%\n98.38%\n[477] ICA,Filtering,\nDE Calculation\nDifferential\nEntropy\nGCN\nsemi-supervised\nMODMA\nbinary\ncross-subject\n92.23%\n[45]\nICA,Filtering\nAE-based\nDNN\nunsupervised\nprivate\nbinary\ncross-subject\n83.42%\n[145] ICA,Segmentation\nSpike Trains\nSNN\nunsupervised\nprivate\nbinary\nmixed-subject\n72.13%\n[478] Filtering,DWT,PCC\nAdjacency matrix\nGCN\nunsupervised\nMODMA\nbinary\nmixed-subject\n97%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n24\nTABLE XIV: Summary of deep learning frameworks for schizophrenia identifiaction\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[54]\nConnectivity\nMeasures,Complex\nNetwork construction\nVAR,PDC,CN\nCNN\nsupervised\nMHRC\nbinary\ncross-subject\n91.69%\n[479] Z-norm,Segmentation\nRaw Segments\nCNN\nsupervised\nCeonRepod\nbinary\nmixed-subject\n98.07%\n[480] Segmentation,\nMargenau–Hill\nTime-Frequency\nImage\nCNN\nsupervised\nMHRC,\nCeonRepod,\nNIMH\nbinary\nmixed-subject\n96.35%-99.75%\n[481] Connectivity\nNetworks\nConstruction\nWOC-Based\nfeatures\nCNN\nsupervised\nMHRC\nbinary\ncross-subject\n90%\n[482] Filtering,Segmentation,\nWelch Method\nSpectrum matrix\nCNN\nsupervised\nprivate\nbinary\ncross-subject\n91.12%\n[483] Filtering\nRaw Segments\nCNN\nsupervised\nCeonRepod\nbinary\nmixed-subject\n98.05%\n[22]\nFiltering,Segmentation,\nASR,ICA\nConnectivity\nfeatures\nCNN\nsupervised\nCeonRepod\nbinary\nmixed-subject\n99.84%\n[484] CWT,STFT,SPWVD\nScalogram,TFR,\nSpectrogram\nCNN\nsupervised\nNIMH\nbinary\nmixed-subject\n93.36%\n[485] Filtering,Segmentation,\nZ-norm\nRaw Segments\nCNN\nsupervised\nCeonRepod\nbinary\nmixed-subject\n99.18%\n[486] Filtering,ICA\nTrend Time\nSeries\nCNN\nsupervised\nCeonRepod\nbinary\ncross-subject\n93%\n[487] Mspca,Filtering,Multitaper Frequency\nfeatures\nCNN\nsupervised\nCeonRepod\nbinary\nmixed-subject\n98.76%\n[488] Filtering,Segmentation,\nConnectivity Measures\nFC matrix\nCNN\nsupervised\nMHRC\nbinary\ncross-subject\n94.11%\n[489] Filtering,Windowing,\nZ-norm,CWT\n2D Scalogram\nCNN\nsupervised\nCeonRepod,\nNIMH\nbinary\nmixed-subject\n99%\n96%\n[490] Re-Referencing,\nFiltering,Segmentation\nRaw Segments\n2D-CNN\nsupervised\nprivate\n3-class\ncross-subject\n81.6%-99.2%\n[491] Filtering,Segmentation,FFT Spectral Power,\nVariance,Mobility,\nComplexity,Mean\nSpectral Amp.\n2D-CNN\nsupervised\nMHRC,\nCeonRepod\nbinary\nmixed-subject\n94.08%-98.56%\n[152] Segmentation,STFT\n2D Spectrogram\n2D-CNN\nsupervised\nMHRC,\nCeonRepod\nbinary\nmixed-subject\n95%\n97%\n[50]\nCWT\n2D Scalogram\n2D-CNN\nsupervised\nMHRC,\nCeonRepod\nbinary\nmixed-subject\n98%\n99.5%\n[41]\nSegmentation,EMD,HHT\nHilbert Spectrum\n2D-CNN\nsupervised\nMHRC,\nCeonRepod\nbinary\nmixed-subject\n96.02%\n98.2%\n[39]\nWT,1D-LBP,ELM-AE\nEEG Image\n2D-CNN\nsupervised\nMHRC\nbinary\nmixed-subject\n97.73%\n[55]\nZ-norm\nEEG Image\n2D-CNN\nsupervised\nNIMH\nbinary\nmixed-subject\n93.2%\n[153] Filtering\nImage matrix\n2D-CNN\nsupervised\nNIMH\nbinary\nmixed-subject\n98.84%\n[154] Filtering,CWT\n2D Scalogram\n2D-CNN\nsupervised\nCeonRepod\nbinary\nmixed-subject\n99%\n[492] Filtering,Segmentation\nRaw Segments\n2D-CNN\nsupervised\nNIMH,\nprivate\nbinary\ncross-subject\n80%\n[493] Baseline Correction,\nFiltering,Segmentation\nTime-Frequency\nfeatures\n2D-CNN\nsupervised\nNIMH\nbinary\nmixed-subject\n92%\n[494] Segmentation,PCC\nCorrelation\nmatrix\n2D-CNN\nsupervised\nMHRC\nbinary\nmixed-subject\n90%\n[495] Segmentation,Phase\nReconstruction\nRPS Portrait\n2D-CNN\nsupervised\nCeonRepod\nbinary\nmixed-subject\n99.37%\n[33]\nFiltering,Interpolation\nEEG Image\n2D-CNN\nsupervised\nNIMH\nbinary\nmixed-subject\n99.23%\n[496] Normalization,DSTFT\nDSTFT\nSpectrogram\n2D-CNN\nsupervised\nMHRC\nbinary\ncross-subject\n83%\n[497] LSDl\n2D Spectrogram,\nScalogram\n2D-CNN\nsupervised\nMHRC\nbinary\nmixed-subject\n98.3%\n[498] Segmentation,Feature\nSelection\nNonlinear\nfeatures\n2D-CNN\nsupervised\nCeonRepod\nbinary\nmixed-subject\n95.85%\n[499] Filtering,CWT,CMI\nConnectivity\nmatrix\n3D-CNN\nsupervised\nMHRC\nbinary\ncross-subject\n97.74%\n[500] Normalization,DAF\n2D Image\nCNN,\nTransformer\nsupervised\nCeonRepod\nbinary\nmixed-subject\n98.32%-99.04%\n[501] Filtering,Segmentation,\nZ-norm\nPSD features\nCNN\nCNN-LSTM\nsupervised\nprivate\nbinary\ncross-subject\n75.9%\n71.5%\n[502] Filtering,Min-Max\nNorm\nRaw\nCNN-LSTM\nsupervised\nprivate\nbinary\ncross-subject\n89.98%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n25\n(Continued) Summary of deep learning frameworks for schizophrenia identification\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[24]\nFiltering,Segmentation,\nBaseline Correction,\nOcular Correction\nFuzzyEn\nRGB\nImage\nCNN-LSTM\nsupervised\nprivate\nbinary\nmixed-subject\n99.22%\n[503] Filtering,Segmentation\nRaw Segments\nCNN-LSTM\nsupervised\nMHRC,\nCeonRepod\nbinary\ncross-subject\n91%\n96.1%\n[504] MSST\nTime-Frequency\nFeature Image\nCNN-LSTM\nsupervised\nCeonRepod\nbinary\nmixed-subject\n84.42%\n[505] Filtering,TE\n2D Image\nCNN-LSTM\nsupervised\nCeonRepod\nbinary\nmixed-subject\n99.9%\n[506] Artifact Removal,\nFiltering\nRaw\nCNN-LSTM\nsupervised\nNIMH\nbinary\ncross-subject\n98.2%\n[507] Segmentation,Z-norm\nRaw Segments\nCNN-LSTM\nsupervised\nCeonRepod\nbinary\nmixed-subject\n99.25%\n[508] Filtering,PCA,ICA\nRaw,features\nCNN-TCN\nsupervised\nCeonRepod\nbinary\nmixed-subject\n99.57%\n[509] Filtering, feature extrac-\ntion\nFrequency\nfeatures\nDNN\nsupervised\nprivate\nbinary\nmixed-subject\n97.5%\n[510] Connectivity\nMeasures,Complex\nNetwork construction\nDC,CN\nDNN-DBN\nSupervised\nMHRC\nbinary\ncross-subject\n95%\n[511] Filtering,ICA\nPLI,PCI\nGNN\nSupervised\nprivate\nbinary\ncross-subject\n84.17%\n[512] Filtering,TVD\nTime- and Non-\nlinear features\nLSTM\nSupervised\nCeonRepod\nbinary\nmixed-subject\n99%\n[513] Dimension Reduction\nEnd-to-end\nRNN-LSTM\nSupervised\nMHRC\nbinary\nmixed-subject\n98%\n[514] Filtering,Normalization\nSpatial\nFeature\nmatrix\nTransformer\nSupervised\nCeonRepod\nbinary\nmixed-subject\n98.99%\n[515] Filtering,Segmentation,\nConnections calculation\nConnection\nmatrix\n2D-CNN\nsupervised\nprivate\nbinary\nmixed-subject\n100%\n[516] Z-norm,Filtering\nAE-based\nCNN\nUnsupervised\nCeonRepod\nbinary\ncross-subject\n81.81%\n[517] Segmentation\nSAE-based\nDNN\nUnsupervised\nCeonRepod\nbinary\nmixed-subject\n97.95%\n[518] Filtering\nAE-based\nDNN\nUnsupervised\nMHRC,\nCeonRepod,\nNIMH\nbinary\nmixed-subject\n95.01%-99.99%\nTABLE XV: Summary of deep learning frameworks for Alzheimer’s Disease Diagnosis\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[162] Filtering,Segmentation,\nConnections Calculation\nConnection\nmatrix\n2D-CNN\nSupervised\nprivate\nbinary\nmixed-subject\n100%\n[519] Filtering,Segmentation\nRaw Segments\n2D-CNN\nSupervised\nFSA Alzheimer’s\nbinary\nmixed-subject\n97.9%\n[161] Filtering,Segmentation,\nNetwork construction\nAdjacency\nmatrix,Segments\nGCN\nSupervised\nprivate\nbinary\nmixed-subject\n92.3%\n[520] Filtering,Segmentation\nRaw Segments\n2D-CNN\nSupervised\nprivate\nbinary\nmixed-subject\n69.03%-85.78%\n[163] Filtering,Segmentation,\nCWT\nTime-Frequency\nfeatures\n2D-CNN\nSupervised\nprivate\nbinary\n3-class\ncross-subject\n85%\n82%\n[521] Filtering,FFT\n2D Spectrograms\n2D-CNN\nSupervised\nprivate\nbinary\n3-class\nmixed-subject\n97.11%\n95.04%\n[522] Filtering,FFT\nFrequency-\ndomain features\n2D-CNN\nSupervised\nprivate\nbinary\n-\n93.7%\n[523] Filtering,Segmentation,\nICA,CWT\nRGB Image\n2D-CNN\nSupervised\nprivate\n3-class\nmixed-subject\n98.9%\n[524] Filtering,Downsampling,\nICA\nFrequency-\ndomain features\nCNN\nSupervised\nFiscon\n3-class\nmixed-subject\n97.1%\n[525] Normalization,\nSegmentation,DWT\n2D Spectrograms\nCNN\nSupervised\nAD-59\n3-class\ncross-subject\n98.84%\n[526] Filtering,Segmentation,FT\nPSD Image\n2D-CNN\nSupervised\nprivate\nBinary\n3-class\nmixed-subject\n84.62%-92.95%\n83.33%\n[527] Filtering,EMD\nTime-Frequency\nfeatures\nCNN\nSupervised\nprivate\nBinary\n3-class\nmixed-subject\n99.3%-99.9%\n94.8%\n[528] Filtering,Segmentation,RP\nFrequency-\ndomain features\nDNN\nSupervised\nprivate\nbinary\ncross-subject\n75%\n[529] Denoising\nAE-Based\nRBM\nUnsupervised\nprivate\nbinary\nmixed-subject\n92%\n[530] Filtering,ICA,\nMorlet Wavelet\nVAE-Based\nVAE\nUnsupervised\nprivate\nbinary\ncross-subject\n98.1%\n[531] Filtering,Segmentation,\nCWT\nSAE-Based\nMLP-NN\nUnsupervised\nprivate\nbinary\ncross-subject\n88%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n26\nTABLE XVI: Summary of deep learning frameworks for Parkinson’s Disease Diagnosis\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[532] Segmentation,Embedding\nReconstruction\nReconstructed\nSegments\nCNN-LSTM\nsupervised\nUNM\nbinary\nmixed-subject\n99.22%\n[40]\nGabor Transform\n2D Spectrograms\n2D-CNN\nsupervised\nUCSD\n3-class\nmixed-subject\n92.6%-99.46%\n[533] SPWVD,Artifact\nRemoval,Segmentation\nTFR\n2D-CNN\nsupervised\nUCSD,\nprivate\nbinary\nmixed-subject\n99.84%-100%\n[534] Denoising,TQWT,WPT\nTime-Frequency\nfeatures\nCNN\nsupervised\nprivate\n3-class\nmixed-subject\n92.59%-99.92%\n[535] Artifact rejection,\nFiltering,Segmentation\nRaw Segments\nCNN-RNN\nsupervised\nprivate\nbinary\ncross-subject\n82.89%\n[169] CWT,Segmentation\n2D Image\nCNN\nsupervised\nUCSD\n3-class\nmixed-subject\n99.6%-99.9%\n[170] ICA,Filtering,P-Welch\nPSD Image\n2D-CNN\nsupervised\nprivate\nbinary\nmixed-subject\n99.87%\n[171] Artifacts Removal,\nFiltering,Segmentation\nDC Image\n2D-CNN\nsupervised\nprivate\nbinary\nmixed-subject\n99.62%\n[536] CWT,VMD\nTime-Frequency\nfeatures\n2D-CNN\nsupervised\nprivate\nbinary\nmixed-subject\n92%-96%\n[537] Filtering,Segmentation\nRaw Segments\nANN\nsupervised\nUCSD\nbinary\nmixed-subject\n98%\n[19]\nArtifact Removal,\nFiltering\nRaw Segments\nCNN\nsupervised\nprivate\nbinary\nmixed-subject\n88.25%\n[538] Filtering,Z-norm\nRaw Segments\nCNN\nsupervised\nUNM,\nUI\nbinary\ncross-subject\n82.8%\n[539] Artifact rejection,\nFiltering,Normalization,\nSegmentation\nRaw Segments\nCNN-GRU\nsupervised\nprivate\nbinary\nmixed-subject\n99.2%\n[540] Segmentation\nRaw Segments\nCNN-LSTM\nsupervised\nprivate\nbinary\nmixed-subject\n96.9%\n[541] FFT\n2D Spectrograms\nCNN-LSTM\nsupervised\nprivate\nbinary\nmixed-subject\n99.7%\n[542] Artifact rejection,\nFiltering,Segmentation\nFunctional\nconnectivity\nmatrix\nGCN\nsupervised\nprivate\nbinary\nmixed-subject\n90.2%\nTABLE XVII: Summary of deep learning frameworks for ADHD identification\nRef.\nPreprocessing\nFeature\nBackbone\nTraining\nDataset\nTask\nPartitioning\nAccuracy\n[176] segment screening\nPSD\nCNN\nSupervised\nprivate\nBinary\nmixed-subject\n90.29%\n[177] Filtering,Segmentation,\nwavelet transform\nSpectrogram\nCNN\nSupervised\nprivate\nBinary\ncross-subject\n88%\n[23]\nResampling,filtering,\nASR,windowing,\nFreq. bands separation\nFrequency bands,\nRGB Images\nCNN\nSupervised\nADHD-Child\nBinary\ncross-subject\n98.48%\n[49]\nPSD\nPSD,SE\nLSTM\nSupervised\nprivate\nBinary\nmixed-subject\n92.15%\n[543] Filtering,Segmentation,\nICA,segment screening\nEnd-to-end\nCNN\nSupervised\nprivate\n3-class\nmixed-subject\n99.46%\n[544] FIR,filtering,ICA,\nSegmentation\nDynamic\nconnectivity\ntensor (DCT)\nConvLSTM\n+Attention\nSupervised\nADHD-Child\nBinary\nmixed-subject\n99.75%\n[25]\nRe-referencing,filtering,\nBaseline rejection,\ndownsampling,Segmentation\nPSD\nCNN\nSupervised\nADHD-Child\nBinary\nmixed-subject\n94.52%\n[545] Filtering,Segmentation,\nCWT\nTime-Frequency\nImage\nConvMixer,\nResNet50,\nResNet18\nSupervised\nADHD-Child\nBinary\nmixed-subject\n72.58%\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n27\nREFERENCES\n[1] World Health Organization, “Over 1 in 3 people affected by neurolog-\nical conditions, the leading cause of illness and disability worldwide,”\n2024.\n[2] ——, “Mental health: Neurological disorders.”\n[3] G. Ramantani and et al., “Correlation of invasive eeg and scalp eeg,”\nSeizure, vol. 41, pp. 196–200, 2016.\n[4] Y. Roy and et al., “Deep learning-based electroencephalography analy-\nsis: a systematic review,” Journal of neural engineering, vol. 16, no. 5,\np. 051001, 2019.\n[5] G. Amrani and et al., “Eeg signal analysis using deep learning: A\nsystematic literature review,” in 2021 Fifth International Conference\nOn Intelligent Computing in Data Sciences (ICDS), 2021, pp. 1–8.\n[6] N. S. Amer and S. B. Belhaouari, “Eeg signal processing for medical\ndiagnosis, healthcare, and monitoring: A comprehensive review,” IEEE\nAccess, 2023.\n[7] X. Zhang and et al., “A survey on deep learning-based non-invasive\nbrain signals: recent advances and new frontiers,” Journal of neural\nengineering, vol. 18, no. 3, p. 031002, 2021.\n[8] P. Khan and et al., “Machine learning and deep learning approaches for\nbrain disease diagnosis: principles and recent advances,” Ieee Access,\nvol. 9, pp. 37 622–37 655, 2021.\n[9] A. Shoeibi and et al., “Epileptic seizures detection using deep learning\ntechniques: a review,” International journal of environmental research\nand public health, vol. 18, no. 11, p. 5780, 2021.\n[10] J. Rahul and et al., “A systematic review of eeg based automated\nschizophrenia classification through machine learning and deep learn-\ning,” Frontiers in Human Neuroscience, vol. 18, p. 1347082, 2024.\n[11] K. M. Hossain and et al., “Status of deep learning for eeg-based\nbrain–computer interface applications,” Frontiers in computational\nneuroscience, vol. 16, p. 1006763, 2023.\n[12] W. Weng and et al., “Self-supervised learning for electroencephalo-\ngram: A systematic survey,” arXiv preprint arXiv:2401.05446, 2024.\n[13] J. Chen and et al., “Con4m: Context-aware consistency learning\nframework for segmented time series classification,” The Thirty-Eighth\nAnnual Conference on Neural Information Processing Systems, 2024.\n[14] H. Berger, “ ¨Uber das elektroenkephalogramm des menschen,” Archiv\nf¨ur psychiatrie und nervenkrankheiten, vol. 87, no. 1, pp. 527–570,\n1929.\n[15] H. H. Jasper, “Ten-twenty electrode system of the international fed-\neration,” Electroencephalogr Clin Neurophysiol, vol. 10, pp. 371–375,\n1958.\n[16] G. Buzsaki and A. Draguhn, “Neuronal oscillations in cortical net-\nworks,” science, vol. 304, no. 5679, pp. 1926–1929, 2004.\n[17] J. Jeong, “Eeg dynamics in patients with alzheimer’s disease,” Clinical\nneurophysiology, vol. 115, no. 7, pp. 1490–1505, 2004.\n[18] H. Banville and et al., “Uncovering the structure of clinical eeg signals\nwith self-supervised learning,” Journal of Neural Engineering, vol. 18,\nno. 4, p. 046020, 2021.\n[19] S. L. Oh and et al., “A deep learning approach for parkinson’s disease\ndiagnosis from eeg signals,” Neural Computing and Applications,\nvol. 32, pp. 10 927–10 933, 2020.\n[20] C. Chatzichristos and et al., “Epileptic seizure detection in eeg via\nfusion of multi-view attention-gated u-net deep neural networks,” in\n2020 IEEE Signal Processing in Medicine and Biology Symposium\n(SPMB), 2020, pp. 1–7.\n[21] B. Ay and et al., “Automated depression detection using deep repre-\nsentation and sequence learning with eeg signals,” Journal of medical\nsystems, vol. 43, pp. 1–12, 2019.\n[22] N. Grover and et al., “Schizo-net: A novel schizophrenia diag-\nnosis framework using late fusion multimodal deep learning on\nelectroencephalogram-based brain connectivity indices,” IEEE Trans-\nactions on Neural Systems and Rehabilitation Engineering, vol. 31, pp.\n464–473, 2023.\n[23] M. Moghaddari and et al., “Diagnose adhd disorder in children using\nconvolutional neural network based on continuous mental task eeg,”\nComputer Methods and Programs in Biomedicine, vol. 197, p. 105738,\n2020.\n[24] J. Sun and et al., “A hybrid deep neural network for classification of\nschizophrenia using eeg data,” Scientific Reports, vol. 11, no. 1, p.\n4706, 2021.\n[25] A. Nouri and Z. Tabanfar, “Detection of adhd disorder in children using\nlayer-wise relevance propagation and convolutional neural network: An\neeg analysis,” Frontiers in Biomedical Technologies, vol. 11, no. 1, pp.\n14–21, 2024.\n[26] A. Antoniades and et al., “Deep learning for epileptic intracranial eeg\ndata,” in 2016 IEEE 26th International Workshop on Machine Learning\nfor Signal Processing (MLSP).\nIEEE, 2016, pp. 1–6.\n[27] T. Wen and Z. Zhang, “Deep convolution neural network and\nautoencoders-based unsupervised feature learning of eeg signals,” IEEE\nAccess, vol. 6, pp. 25 399–25 410, 2018.\n[28] D. Kostas and et al., “Bendr: Using transformers and a contrastive self-\nsupervised learning task to learn from massive amounts of eeg data,”\nFrontiers in Human Neuroscience, vol. 15, p. 653659, 2021.\n[29] U. R. Acharya and et al., “Deep convolutional neural network for\nthe automated detection and diagnosis of seizure using eeg signals,”\nComputers in Biology and Medicine, vol. 100, pp. 270–278, 2018.\n[30] W. Ko and H.-I. Suk, “Eeg-oriented self-supervised learning and\ncluster-aware adaptation,” in Proceedings of the 31st ACM Interna-\ntional Conference on Information & Knowledge Management, 2022,\npp. 4143–4147.\n[31] Z. Mousavi and et al., “Deep convolutional neural network for clas-\nsification of sleep stages from single-channel eeg signals,” Journal of\nneuroscience methods, vol. 324, p. 108312, 2019.\n[32] J. Zhang and et al., “Orthogonal convolutional neural networks for\nautomatic sleep stage classification based on single-channel eeg,”\nComputer Methods and Programs in Biomedicine, vol. 183, p. 105089,\n2020.\n[33] S. Siuly and et al., “Exploring deep residual network based features for\nautomatic schizophrenia detection from eeg,” Physics in Engineering\nand Science Medicine, vol. 46, pp. 561–574, 2023.\n[34] G. Sharma and et al., “Dephnn: a novel hybrid neural network for\nelectroencephalogram (eeg)-based screening of depression,” Biomedi-\ncal signal processing and control, vol. 66, p. 102393, 2021.\n[35] A. Seal and et al., “Deprnet: A deep convolution neural network\nframework for detecting depression using eeg,” IEEE Transactions on\nInstrumentation and Measurement, vol. 70, pp. 1–13, 2021.\n[36] S. Iwama and et al., “Two common issues in synchronized multimodal\nrecordings with eeg: Jitter and latency,” Neuroscience Research, 2023.\n[37] K. A. Robbins and et al., “How sensitive are eeg results to preprocess-\ning methods: A benchmarking study,” IEEE Transactions on Neural\nSystems and Rehabilitation Engineering, vol. 28, no. 5, pp. 1081–1090,\n2020.\n[38] T. Tuncer and et al., “A novel ensemble local graph structure based\nfeature extraction network for eeg signal analysis,” Biomed. Signal\nProcess. Control., vol. 61, p. 102006, 2020.\n[39] N. Sobahi and et al., “A new signal to image mapping procedure and\nconvolutional neural networks for efficient schizophrenia detection in\neeg recordings,” IEEE Sensors Journal, vol. 22, no. 8, pp. 7913–7919,\n2022.\n[40] H. W. Loh and et al., “Gaborpdnet: Gabor transformation and deep\nneural network for parkinson’s disease detection using eeg signals,”\nElectronics, vol. 10, no. 14, p. 1740, 2021.\n[41] A. Z¨ulfikar and A. Mehmet, “Empirical mode decomposition and\nconvolutional neural network-based approach for diagnosing psychotic\ndisorders from eeg signals,” Applied Intelligence, vol. 52, no. 11, pp.\n12 103–12 115, 2022.\n[42] X. Li and et al., “Eeg-based mild depression recognition using convolu-\ntional neural network,” Medical & biological engineering & computing,\nvol. 57, pp. 1341–1352, 2019.\n[43] A. M. Karim and et al., “A new framework using deep auto-encoder\nand energy spectral density for medical waveform data classification\nand processing,” Biocybernetics and Biomedical Engineering, vol. 39,\nno. 1, pp. 148–159, 2019.\n[44] D. M. Khan and et al., “Automated diagnosis of major depressive\ndisorder using brain effective connectivity and 3d convolutional neural\nnetwork,” Ieee Access, vol. 9, pp. 8835–8846, 2021.\n[45] J. Zhu and et al., “Multimodal mild depression recognition based on\neeg-em synchronization acquisition network,” IEEE Access, vol. 7, pp.\n28 196–28 210, 2019.\n[46] J. Liu and B. Woodson, “Deep learning classification for epilepsy\ndetection using a single channel electroencephalography (eeg),” in Pro-\nceedings of the 2019 3rd International Conference on Deep Learning\nTechnologies, 2019, pp. 23–26.\n[47] X. Li and et al., “Depression recognition using machine learning meth-\nods with different feature generation strategies,” Artificial intelligence\nin medicine, vol. 99, p. 101696, 2019.\n[48] I. Bhattacherjee, “Epileptic seizure detection using multicolumn con-\nvolutional neural network,” in 2020 7th International Conference on\nComputing for Sustainable Global Development (INDIACom).\nIEEE,\n2020, pp. 58–63.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n28\n[49] M. Tosun, “Effects of spectral features of eeg signals recorded with\ndifferent channels and recording statuses on adhd classification with\ndeep learning,” Physical and Engineering Sciences in Medicine, vol. 44,\nno. 3, pp. 693–702, 2021.\n[50] Z. Aslan and M. Akin, “A deep learning approach in automated\ndetection of schizophrenia using scalogram images of eeg signals,”\nPhysical and Engineering Sciences in Medicine, vol. 45, no. 1, pp.\n83–96, 2022.\n[51] G. Choi and et al., “A novel multi-scale 3d cnn with deep neural\nnetwork for epileptic seizure detection,” in 2019 IEEE International\nConference on Consumer Electronics (ICCE), 2019, pp. 1–2.\n[52] A. Vilamala and et al., “Deep convolutional neural networks for\ninterpretable analysis of eeg sleep stage scoring,” in 2017 IEEE 27th\ninternational workshop on machine learning for signal processing\n(MLSP), 2017, pp. 1–6.\n[53] J. Xu and et al., “Epileptic seizure detection based on feature extraction\nand cnn- bigru network with attention mechanism,” in International\nConference on Intelligent Computing.\nSpringer, 2023, pp. 308–319.\n[54] C.-R. Phang and et al., “A multi-domain connectome convolutional\nneural network for identifying schizophrenia from eeg connectivity\npatterns,” IEEE journal of biomedical and health informatics, vol. 24,\nno. 5, pp. 1333–1343, 2019.\n[55] D.-W. Ko and J.-J. Yang, “Eeg-based schizophrenia diagnosis through\ntime series image conversion and deep learning,” Electronics, vol. 11,\nno. 14, 2022.\n[56] Q. Zhan and W. Hu, “An epilepsy detection method using multiview\nclustering algorithm and deep features,” Computational and Mathemat-\nical Methods in Medicine, vol. 2020, p. 5128729, 2020.\n[57] T. K. K. Ho and N. Armanfard, “Self-supervised learning for anoma-\nlous channel detection in eeg graphs: Application to seizure analysis,”\nin Proceedings of the AAAI conference on artificial intelligence, vol. 37,\nno. 7, 2023, pp. 7866–7874.\n[58] T. Siddharth and et al., “Eeg-based detection of focal seizure area using\nfbse-ewt rhythm and sae-svm network,” IEEE Sensors Journal, vol. 20,\nno. 19, pp. 11 421–11 428, 2020.\n[59] E. Ebrahimzadeh and et al., “A novel approach for detection of\ndeception using smoothed pseudo wigner-ville distribution (spwvd),”\nJournal of Biomedical Science and Engineering, vol. 2013, pp. 8–18,\n2013.\n[60] Y. LeCun and et al., “Convolutional networks for images, speech, and\ntime series,” The handbook of brain theory and neural networks, vol.\n3361, no. 10, p. 1995, 1995.\n[61] J. L. Elman, “Finding structure in time,” Cognitive science, vol. 14,\nno. 2, pp. 179–211, 1990.\n[62] A. Vaswani and et al., “Attention is all you need,” Advances in neural\ninformation processing systems, vol. 30, 2017.\n[63] F. Scarselli and et al., “The graph neural network model,” IEEE\nTransactions on Neural Networks, vol. 20, no. 1, pp. 61–80, 2009.\n[64] G. E. Hinton and R. Zemel, “Autoencoders, minimum description\nlength and helmholtz free energy,” Advances in neural information\nprocessing systems, vol. 6, 1993.\n[65] I. Goodfellow and et al., “Generative adversarial nets,” Advances in\nneural information processing systems, vol. 27, 2014.\n[66] W. Maass, “Networks of spiking neurons: the third generation of neural\nnetwork models,” Neural networks, vol. 10, no. 9, pp. 1659–1671,\n1997.\n[67] M. N. Mohsenvand and et al., “Contrastive representation learning for\nelectroencephalogram classification,” in Machine Learning for Health,\n2020, pp. 238–253.\n[68] H. Banville and et al., “Self-supervised representation learning from\nelectroencephalography signals,” in 2019 IEEE 29th International\nWorkshop on Machine Learning for Signal Processing (MLSP), 2019,\npp. 1–6.\n[69] A. v. d. Oord and et al., “Representation learning with contrastive\npredictive coding,” arXiv preprint arXiv:1807.03748, 2018.\n[70] D. Wu and et al., “neuro2vec: Masked fourier spectrum predic-\ntion for neurophysiological representation learning,” arXiv preprint\narXiv:2204.12440, 2022.\n[71] D. Cai and et al., “Mbrain: A multi-channel self-supervised learning\nframework for brain signals,” in Proceedings of the 29th ACM SIGKDD\nConference on Knowledge Discovery and Data Mining, 2023, pp. 130–\n141.\n[72] R. G. Andrzejak and et al., “Indications of nonlinear deterministic and\nfinite-dimensional structures in time series of brain electrical activity:\nDependence on recording region and brain state,” Physical Review E,\nvol. 64, no. 6, p. 061907, 2001.\n[73] M. Ihle and et al., “Epilepsiae – A European epilepsy database,”\nComputer Methods and Programs in Biomedicine, vol. 106, no. 3, pp.\n127–138, 2012.\n[74] bbrinkm and et al., “Upenn and mayo clinic’s seizure detection\nchallenge,” 2014.\n[75] J. Guttag, “CHB-MIT Scalp EEG Database (version 1.0.0),” 2010.\n[76] A. Shoeb, “Application of Machine Learning to Epileptic Seizure Onset\nDetection and Treatment,” Ph.D. dissertation, Massachusetts Institute\nof Technology, September 2009.\n[77] A. Goldberger and et al., “PhysioBank, PhysioToolkit, and PhysioNet:\nComponents of a new research resource for complex physiologic\nsignals,” Circulation, vol. 101, no. 23, pp. e215–e220, 2000.\n[78] R. G. Andrzejak and et al., “Nonrandomness, nonlinear depen-\ndence, and nonstationarity of electroencephalographic recordings from\nepilepsy patients,” Physical Review E, vol. 86, p. 046206, 2012.\n[79] P. Swami and et al., “Eeg epilepsy datasets,” 09 2016.\n[80] L. Kuhlmann and et al., “Melbourne university aes/mathworks/nih\nseizure prediction,” 2016.\n[81] V. Shah and et al., “The Temple University Hospital Seizure Detection\nCorpus,” Frontiers in Neuroinformatics, vol. 12, p. 83, 2018.\n[82] A. Burrello and et al., “One-shot learning for ieeg seizure detection\nusing end-to-end binary operations: Local binary patterns with hyperdi-\nmensional computing,” in Proceedings of the IEEE Biomedical Circuits\nand Systems Conference (BioCAS), October 17-19 2018.\n[83] ——, “Hyperdimensional computing with local binary patterns: One-\nshot learning of seizure onset and identification of ictogenic brain\nregions using short-time ieeg recordings,” IEEE Transactions on\nBiomedical Engineering (TBME), 2019.\n[84] N. Stevenson and et al., “A dataset of neonatal EEG recordings with\nseizure annotations,” Scientific Data, vol. 6, p. 190039, 2019.\n[85] P. Nejedly and et al., “Multicenter intracranial eeg dataset for clas-\nsification of graphoelements and artifactual signals,” Scientific Data,\nvol. 7, no. 1, p. 179, June 2020.\n[86] P. Detti and et al., “Eeg synchronization analysis for seizure prediction:\nA study on data of noninvasive recordings,” Processes, vol. 8, no. 7,\np. 846, 2020.\n[87] W. Nasreddine, “Epileptic eeg dataset,” 2021.\n[88] J. M. Bernabei and et al., “”hup ieeg epilepsy dataset”,” 2022.\n[89] D. van Blooijs, M. van den Boom, J. van der Aar, G. Huiskamp,\nG. Castegnaro, M. Demuru, W. Zweiphenning, P. van Eijsden, K. J.\nMiller, F. Leijten, and D. Hermes, “”ccep ecog dataset across age 4-\n51”,” 2023.\n[90] World Health Organization, “Epilepsy,” 2024.\n[91] X. Xu and et al., “Patient-specific method for predicting epileptic\nseizures based on drsn-gru,” Biomedical Signal Processing and Control,\nvol. 81, p. 104449, 2023.\n[92] R. Peng and et al., “Wavelet2vec: a filter bank masked autoencoder for\neeg-based seizure subtype classification,” in ICASSP 2023-2023 IEEE\nInternational Conference on Acoustics, Speech and Signal Processing\n(ICASSP), 2023, pp. 1–5.\n[93] M. Zhou and et al., “Epileptic seizure detection based on eeg signals\nand cnn,” Frontiers in neuroinformatics, vol. 12, p. 95, 2018.\n[94]\n¨O. T¨urk and M. S. ¨Ozerdem, “Epilepsy detection by using scalogram\nbased convolutional neural network from eeg signals,” Brain sciences,\nvol. 9, no. 5, p. 115, 2019.\n[95] I. Ullah and et al., “An automated system for epilepsy detection using\neeg brain signals based on deep learning approach,” Expert Systems\nwith Applications, vol. 107, pp. 61–71, 2018.\n[96] R. Akut, “Wavelet based deep learning approach for epilepsy detec-\ntion,” Health Information Science and Systems, vol. 7, no. 1, pp. 1–9,\n2019.\n[97] O. S. Lih and et al., “Epilepsynet: Novel automated detection of\nepilepsy using transformer model with eeg signals from 121 patient\npopulation,” Computers in Biology and Medicine, vol. 164, p. 107312,\n2023.\n[98] A. K. Dutta and et al., “Deep learning-based multi-head self-attention\nmodel for human epilepsy identification from eeg signal for biomedical\ntraits,” Multimedia Tools and Applications, pp. 1–23, 2024.\n[99] D. Zhang and et al., “Brant: Foundation model for intracranial neural\nsignal,” Advances in Neural Information Processing Systems, vol. 36,\n2024.\n[100] J. Guo and et al., “Detecting high frequency oscillations for stereoelec-\ntroencephalography in epilepsy via hypergraph learning,” IEEE Trans-\nactions on Neural Systems and Rehabilitation Engineering, vol. 29, pp.\n587–596, 2021.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n29\n[101] A. Rahmani and et al., “A meta-gnn approach to personalized seizure\ndetection and classification,” in ICASSP 2023-2023 IEEE International\nConference on Acoustics, Speech and Signal Processing (ICASSP).\nIEEE, 2023, pp. 1–5.\n[102] Y. Sun and et al., “Continuous seizure detection based on transformer\nand long-term ieeg,” IEEE Journal of Biomedical and Health Infor-\nmatics, vol. 26, no. 11, pp. 5418–5427, 2022.\n[103] S. Tu and et al., “Dmnet: Self-comparison driven model for subject-\nindependent seizure detection,” in The Thirty-eighth Annual Conference\non Neural Information Processing Systems.\n[104] A. M. Abdelhameed and et al., “Epileptic seizure detection using deep\nconvolutional autoencoder,” in 2018 IEEE international workshop on\nsignal processing systems (SiPS), 2018, pp. 223–228.\n[105] J. Turner and et al., “Deep belief networks used on high resolution\nmultichannel electroencephalography data for seizure detection,” in\n2014 aaai spring symposium series, 2014.\n[106] S. You and et al., “Unsupervised automatic seizure detection for focal-\nonset seizures recorded with behind-the-ear eeg using an anomaly-\ndetecting generative adversarial network,” Computer Methods and\nPrograms in Biomedicine, vol. 193, p. 105472, 2020.\n[107] T. Xiao and et al., “Self-supervised learning with attention mechanism\nfor eeg-based seizure detection,” Biomedical Signal Processing and\nControl, vol. 87, p. 105464, 2024.\n[108] X. Li and V. Metsis, “Spp-eegnet: An input-agnostic self-supervised\neeg representation model for inter-dataset transfer learning,” in Inter-\nnational Conference on Computing and Information Technology, 2022,\npp. 173–182.\n[109] N. Wagh and et al., “Domain-guided self-supervision of eeg data\nimproves downstream classification performance and generalizability,”\nin Machine Learning for Health, 2021, pp. 130–142.\n[110] Y. Zheng and et al., “Task-oriented self-supervised learning for\nanomaly detection in electroencephalography,” in International Con-\nference on Medical Image Computing and Computer-Assisted Inter-\nvention.\nSpringer, 2022, pp. 193–203.\n[111] S. Tang and et al., “Self-supervised graph neural networks for improved\nelectroencephalographic seizure analysis,” 10th International Confer-\nence on Learning Representations (ICLR’22), 2022.\n[112] J. Chen and et al., “Brainnet: Epileptic wave detection from seeg with\nhierarchical graph diffusion learning,” pp. 2741–2751, 2022.\n[113] Z. Yuan and et al., “Ppi: Pretraining brain signal model for patient-\nindependent seizure detection,” Advances in Neural Information Pro-\ncessing Systems, vol. 36, 2024.\n[114] B. Kemp and et al., “Analysis of a sleep-dependent neuronal feedback\nloop: The slow-wave microcontinuity of the EEG,” IEEE Transactions\non Biomedical Engineering, vol. 47, no. 9, pp. 1185–1194, 2000.\n[115] C. O’Reilly and et al., “Montreal Archive of Sleep Studies: An\nopen-access resource for instrument benchmarking and exploratory\nresearch,” Journal of Sleep Research, vol. 23, no. 6, pp. 628–635, 2014.\n[116] S. F. Quan and et al., “The Sleep Heart Health Study: Design, rationale,\nand methods,” Sleep, vol. 20, no. 12, pp. 1077–1085, 1997.\n[117] G. Q. Zhang and et al., “The National Sleep Research Resource:\nTowards a sleep data commons,” Journal of the American Medical\nInformatics Association, vol. 25, no. 10, pp. 1351–1358, October 2018.\n[118] “St. Vincent’s University Hospital / University College Dublin Sleep\nApnea Database,” 2007.\n[119] D. Alvarez-Estevez and R. Rijsman, “Haaglanden medisch centrum\nsleep staging database (version 1.1),” 2022.\n[120] M. M. Ghassemi and et al., “You Snooze, You Win: The Phys-\nioNet/Computing in Cardiology Challenge 2018,” in 2018 Computing\nin Cardiology Conference (CinC), 2018, pp. 1–4.\n[121] Y. Ichimaru and G. B. Moody, “Development of the polysomnographic\ndatabase on CD-ROM,” Psychiatry and Clinical Neurosciences, vol. 53,\npp. 175–177, April 1999.\n[122] A. Guillot and et al., “Dreem open datasets: Multi-scored sleep datasets\nto compare human and automated sleep staging,” IEEE Transactions\non Neural Systems and Rehabilitation Engineering, vol. PP, pp. 1–1,\n07 2020.\n[123] S. Khalighi and et al., “ISRUC-Sleep: A comprehensive public\ndataset for sleep researchers,” Computer Methods and Programs in\nBiomedicine, vol. 124, pp. 180–192, 2016.\n[124] S. Biswal and et al., “Expert-level sleep scoring with deep neural\nnetworks,” Journal of the American Medical Informatics Association,\nvol. 25, no. 12, pp. 1643–1650, 2018.\n[125] A. Piryatinska and et al., “Automated detection of neonate eeg sleep\nstages,” Computer methods and programs in biomedicine, vol. 95, no. 1,\npp. 31–46, 2009.\n[126] S. Devuyst, “The dreams databases and assessment algorithm,” 2005.\n[127] C.\nXiang\nand\net\nal.,\n“A\nresting-state\neeg\ndataset\nfor\nsleep\ndeprivation,”\nhttps://doi.org/10.18112/openneuro.ds004902.v1.0.5,\nhttps://doi.org/10.18112/openneuro.ds004902.v1.0.5.\n[128] The Recovery Village, “Sleep disorders statistics,” 2023.\n[129] O. Tsinalis and et al., “Automatic sleep stage scoring with single-\nchannel eeg using convolutional neural networks,” arXiv preprint\narXiv:1610.01683, 2016.\n[130] E. Eldele and et al., “An attention-based deep learning approach for\nsleep stage classification with single-channel eeg,” IEEE Transactions\non Neural Systems and Rehabilitation Engineering, vol. 29, pp. 809–\n818, 2021.\n[131] S. Chambon and et al., “A deep learning architecture for temporal sleep\nstage classification using multivariate and multimodal time series,”\nIEEE Transactions on Neural Systems and Rehabilitation Engineering,\nvol. 26, no. 4, pp. 758–769, 2018.\n[132] D. Alvarez-Estevez and R. M. Rijsman, “Inter-database validation of a\ndeep learning approach for automatic sleep scoring,” PloS one, vol. 16,\nno. 8, p. e0256111, 2021.\n[133] K. H and et al., “Accurate deep learning-based sleep staging in a clinical\npopulation with suspected obstructive sleep apnea,” IEEE journal of\nbiomedical and health informatics, vol. 24(7), pp. 2073–2081, 2019.\n[134] X. Jiang and et al., “Self-supervised contrastive learning for eeg-\nbased sleep staging,” in 2021 International Joint Conference on Neural\nNetworks (IJCNN), 2021, pp. 1–8.\n[135] C. Yang and et al., “Self-supervised electroencephalogram represen-\ntation learning for automatic sleep staging: model development and\nevaluation study,” JMIR AI, vol. 2, no. 1, p. e46769, 2023.\n[136] V. Kumar and et al., “muleeg: a multi-view representation learning on\neeg signals,” in International Conference on Medical Image Computing\nand Computer-Assisted Intervention, 2022, pp. 398–407.\n[137] J. Ye and et al., “Cosleep: A multi-view representation learning\nframework for self-supervised learning of sleep stage classification,”\nIEEE Signal Processing Letters, vol. 29, pp. 189–193, 2021.\n[138] D. Zhang and et al., “Brant-x: A unified physiological signal alignment\nframework,” in Proceedings of the 30th ACM SIGKDD Conference on\nKnowledge Discovery and Data Mining, 2024, pp. 4155–4166.\n[139] W. Mumtaz, “MDD Patients and Healthy Controls EEG Data (New),”\n11 2016.\n[140] J. Cavanagh and et al., “The patient repository for eeg data + compu-\ntational tools (pred+ct),” Frontiers in Neuroinformatics, vol. 11, p. 67,\nNov 2017.\n[141] L. Yang and et al., “Automatic feature learning model combining\nfunctional connectivity network and graph regularization for depression\ndetection,” Biomedical Signal Processing and Control, vol. 82, p.\n104520, 2023.\n[142] H. Cai and et al., “A multi-modal open dataset for mental-disorder\nanalysis,” Scientific Data, vol. 9, no. 1, p. 178, 2022.\n[143] World Health Organization. (2024) Depression.\n[144] U. R. Acharya and et al., “Automated eeg-based screening of depression\nusing deep convolutional neural network,” Computer methods and\nprograms in biomedicine, vol. 161, pp. 103–113, 2018.\n[145] D. Shah and et al., “Deep learning of eeg data in the neucube brain-\ninspired spiking neural network architecture for a better understanding\nof depression,” in Neural Information Processing: 26th International\nConference, ICONIP 2019, Sydney, NSW, Australia, December 12–15,\n2019, Proceedings, Part III 26, 2019, pp. 195–206.\n[146] A. Sam and et al., “Depression identification using eeg signals via a\nhybrid of lstm and spiking neural networks,” IEEE Transactions on\nNeural Systems and Rehabilitation Engineering, vol. 31, pp. 4725–\n4737, 2023.\n[147] E. Olejarczyk and W. Jernajczyk, “Graph-based analysis of brain\nconnectivity in schizophrenia,” PloS one, vol. 12, no. 11, p. e0188629,\n2017.\n[148] J. M. Ford and et al., “Did i do that? abnormal predictive processes in\nschizophrenia when button pressing to deliver a tone,” Schizophrenia\nbulletin, vol. 40, no. 4, pp. 804–812, 2014.\n[149] S. Borisov and et al., “Analysis of eeg structural synchrony in adoles-\ncents with schizophrenic disorders,” Human Physiology, vol. 31, pp.\n255–261, 2005.\n[150] World Health Organization. (2024) Schizophrenia.\n[151] A. Zalesky and et al., “Disrupted axonal fiber connectivity in\nschizophrenia,” Biological psychiatry, vol. 69, no. 1, pp. 80–89, 2011.\n[152] Z. Aslan and M. Akin, “Automatic detection of schizophrenia by\napplying deep learning over spectrogram images of eeg signals.”\nTraitement du Signal, vol. 37, no. 2, 2020.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n30\n[153] S. Siuly and et al., “Schizogooglenet: The googlenet-based deep\nfeature extraction design for automatic detection of schizophrenia,”\nComputational Intelligence and Neuroscience, vol. 2022, no. 1, p.\n1992596, 2022.\n[154] A. Shalbaf and et al., “Transfer learning with deep convolutional neural\nnetwork for automated detection of schizophrenia from eeg signals,”\nPhysical and Engineering Sciences in Medicine, vol. 43, pp. 1229–\n1239, 2020.\n[155] M. L. Vicchietti and et al., “Data from: Computational methods of eeg\nsignals analysis for alzheimer’s disease classification,” Feb 2023.\n[156] A. Miltiadous and et al., “”a dataset of 88 eeg recordings from:\nAlzheimer’s disease, frontotemporal dementia and healthy subjects”,”\n2023.\n[157] G. Fiscon and et al., “In alzheimer’s disease patients classification\nthrough eeg signals processing,” in Computational Intelligence & Data\nMining, 2014, pp. 105–112.\n[158] M.\nCejnek\nand\net\nal.,\n“Novelty\ndetection-based\napproach\nfor\nalzheimer’s disease and mild cognitive impairment diagnosis from eeg,”\nMedical & Biological Engineering & Computing, vol. 59, no. 11, pp.\n2287–2296, 2021.\n[159] M. A. BETTER, “Alzheimer’s disease facts and figures,” Alzheimer’s\nDement, vol. 20, pp. 3708–3821, 2024.\n[160] D. Labate and et al., “Eeg complexity modifications and altered\ncompressibility in mild cognitive impairment and alzheimer’s disease,”\nin Recent Advances of Neural Network Models and Applications:\nProceedings of the 23rd Workshop of the Italian Neural Networks\nSociety (SIREN), 2014, pp. 163–173.\n[161] X. Shan and et al., “Spatial–temporal graph convolutional network for\nalzheimer classification based on brain functional connectivity imaging\nof electroencephalogram,” Human Brain Mapping, vol. 43, no. 17, pp.\n5194–5209, 2022.\n[162] A. C. L and et al., “Eeg functional connectivity and deep learning\nfor automatic diagnosis of brain disorders: Alzheimer’s disease and\nschizophrenia,” Journal of Physics: complexity, vol. 3(2), p. 025001,\n2022.\n[163] F. C. Morabito and et al., “Deep convolutional neural networks for clas-\nsification of mild cognitive impaired and alzheimer’s disease patients\nfrom scalp eeg recordings,” in 2016 IEEE 2nd International Forum\non Research and Technologies for Society and Industry Leveraging a\nbetter tomorrow (RTSI).\nIEEE, 2016, pp. 1–6.\n[164] A. P. Rockhill and et al., “”uc san diego resting state eeg data from\npatients with parkinson’s disease”,” 2021.\n[165] J. F. Cavanagh and et al., “Diminished eeg habituation to novel events\neffectively classifies parkinson’s patients,” Clinical Neurophysiology,\nvol. 129, no. 2, pp. 409–418, Feb 2018.\n[166] A. Singh and et al., “Frontal theta and beta oscillations during lower-\nlimb movement in parkinson’s disease,” Clinical Neurophysiology, vol.\n131, pp. 694–702, 2020.\n[167] World Health Organization, “Parkinson disease,” 2023.\n[168] A. Morita and et al., “Relationship between slowing of the eeg\nand cognitive impairment in parkinson disease,” Journal of Clinical\nNeurophysiology, vol. 28, no. 4, pp. 384–387, 2011.\n[169] M. Shaban and A. W. Amara, “Resting-state electroencephalography\nbased deep-learning for the detection of parkinson’s disease,” Plos one,\nvol. 17, no. 2, p. e0263159, 2022.\n[170] C. Chu and et al., “Deep learning reveals personalized spatial spectral\nabnormalities of high delta and low alpha bands in eeg of patients\nwith early parkinson’s disease,” Journal of Neural Engineering, vol. 18,\nno. 6, p. 066036, 2021.\n[171] E. Arasteh and et al., “Deep transfer learning for parkinson’s disease\nmonitoring by image-based representation of resting-state eeg using\ndirectional connectivity,” Algorithms, vol. 15, no. 1, p. 5, 2021.\n[172] G. S. Bajestani and et al., “A dataset of eeg signals from adults with\nadhd and healthy controls: Resting state, cognitive function, and sound\nlistening paradigm,” 2023.\n[173] M. Nasrabadi and et al., “Eeg data for adhd / control children,” 2020.\n[174] World Health Organization. (2021) Adolescent mental health.\n[175] National\nInstitute\nof\nMental\nHealth.\n(2023)\nAttention-\ndeficit/hyperactivity disorder (adhd). U.S. Department of Health\nand Human Services.\n[176] H. Chen and et al., “Use of deep learning to detect personalized spatial-\nfrequency abnormalities in eegs of children with adhd,” Journal of\nneural engineering, vol. 16, no. 6, p. 066046, 2019.\n[177] L. Dubreuil-Vall and et al., “Deep learning convolutional neural net-\nworks discriminate adult adhd from healthy individuals on the basis of\nevent-related spectral eeg,” Frontiers in neuroscience, vol. 14, p. 251,\n2020.\n[178] E. Eldele and et al., “Time-series representation learning via temporal\nand contextual contrasting,” Proceedings of the Thirtieth International\nJoint Conference on Artificial Intelligence, IJCAI-21, 2021.\n[179] X. Zhang and et al., “Self-supervised contrastive pre-training for time\nseries via time-frequency consistency,” Advances in Neural Information\nProcessing Systems, vol. 35, pp. 3988–4003, 2022.\n[180] C. Yang and et al., “Biot: Biosignal transformer for cross-data learning\nin the wild.”\n[181] S. Jo and et al., “Channel-aware self-supervised learning for eeg-based\nbci,” in 2023 11th International Winter Conference on Brain-Computer\nInterface (BCI).\nIEEE, 2023, pp. 1–4.\n[182] W. Zhang and et al., “Self-supervised time series representation learn-\ning via cross reconstruction transformer,” IEEE Transactions on Neural\nNetworks and Learning Systems, 2023.\n[183] D. Wu and et al., “Neuro-bert: Rethinking masked autoencoding for\nself-supervised neurological pretraining,” IEEE Journal of Biomedical\nand Health Informatics, 2024.\n[184] J. Wang and et al., “Cbramod: A criss-cross brain foundation model for\neeg decoding,” The Thirteenth International Conference on Learning\nRepresentations, 2025.\n[185] Z. Yuan and et al., “Brainwave: A brain signal foundation model for\nclinical applications,” 2024.\n[186] Y. Chen and et al., “Eegformer: Towards transferable and interpretable\nlarge-scale eeg foundation model,” in AAAI 2024 Spring Symposium\non Clinical Foundation Models, 2024.\n[187] W.-B. Jiang and et al., “Large brain model for learning generic repre-\nsentations with tremendous eeg data in bci,” The Twelfth International\nConference on Learning Representations, 2024.\n[188] W. Jiang and et al., “Neurolm: A universal multi-task foundation model\nfor bridging the gap between language and eeg signals,” The Thirteenth\nInternational Conference on Learning Representations, 2025.\n[189] J. Devlin, “Bert: Pre-training of deep bidirectional transformers for\nlanguage understanding,” arXiv preprint arXiv:1810.04805, 2018.\n[190] A. Van Den Oord and et al., “Neural discrete representation learning,”\nAdvances in neural information processing systems, vol. 30, 2017.\n[191] A. M. Taqi and et al., “Classification and discrimination of focal\nand non-focal eeg signals based on deep neural network,” in 2017\nInternational Conference on Current Research in Computer Science\nand Information Technology (ICCIT).\nIEEE, 2017, pp. 86–92.\n[192] M. C. Tjepkema-Cloostermans and et al., “Deep learning for detection\nof focal epileptiform discharges from scalp eeg recordings,” Clinical\nNeurophysiology, vol. 129, no. 10, pp. 2191–2196, 2018.\n[193] S. Madhavan and et al., “Time-frequency domain deep convolutional\nneural network for the classification of focal and non-focal eeg signals,”\nIEEE Sensors Journal, vol. 20, no. 6, pp. 3078–3086, 2019.\n[194] R. San-Segundo and et al., “Classification of epileptic eeg recordings\nusing signal transforms and convolutional neural networks,” Computers\nin Biology and Medicine, vol. 109, pp. 148–158, 2019.\n[195] L. Sui and et al., “Localization of epileptic foci by using convolutional\nneural network based on ieeg,” in IFIP International Conference on\nArtificial Intelligence Applications and Innovations.\nSpringer, 2019,\npp. 331–339.\n[196] P. Boonyakitanont and et al., “A comparison of deep neural networks\nfor seizure detection in eeg signals,” bioRxiv, p. 702654, 2019.\n[197] B. Bouaziz and et al., “Epileptic seizure detection using a convolutional\nneural network,” in Digital Health Approach for Predictive, Preventive,\nPersonalised and Participatory Medicine.\nSpringer, 2019, pp. 79–86.\n[198] M. S. Hossain and et al., “Applying deep learning for epilepsy seizure\ndetection and brain mapping visualization,” ACM Transactions on\nMultimedia Computing, Communications, and Applications (TOMM),\nvol. 15, no. 1s, pp. 1–17, 2019.\n[199] X. Tian and et al., “Deep multi-view feature learning for eeg-based\nepileptic seizure detection,” IEEE Transactions on Neural Systems and\nRehabilitation Engineering, vol. 27, no. 10, pp. 1962–1972, 2019.\n[200] J. Cao and et al., “Epileptic signal classification with deep eeg features\nby stacked cnns,” IEEE Transactions on Cognitive and Developmental\nSystems, vol. 12, no. 4, pp. 709–722, 2019.\n[201] P. Z. Yan and et al., “Automated spectrographic seizure detection using\nconvolutional neural networks,” Seizure, vol. 71, pp. 124–131, 2019.\n[202] A. Emami and et al., “Seizure detection by convolutional neural\nnetwork-based analysis of scalp electroencephalography plot images,”\nNeuroImage: Clinical, vol. 22, p. 101684, 2019.\n[203] R. Zuo and et al., “Automated detection of high-frequency oscillations\nin epilepsy based on a convolutional neural network,” Frontiers in\nComputational Neuroscience, vol. 13, p. 6, 2019.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n31\n[204] U. Asif and et al., “Seizurenet: A deep convolutional neural network\nfor accurate seizure type classification and seizure detection,” arXiv\npreprint arXiv:1903.03232, 2019.\n[205] N. Ilakiyaselvan and et al., “Deep learning approach to detect seizure\nusing reconstructed phase space images,” Journal of Biomedical Re-\nsearch, vol. 34, no. 3, p. 240, 2020.\n[206] W. Mao and et al., “Eeg dataset classification using cnn method,” in\nJournal of Physics: Conference Series, vol. 1456.\nIOP Publishing,\n2020, p. 012017.\n[207] A. Shankar and et al., “Epileptic seizure classification based on gramian\nangular field transformation and deep learning,” in 2020 IEEE Applied\nSignal Processing Conference (ASPCON).\nIEEE, 2020, pp. 147–151.\n[208] A. Singh and et al., “Cnn-based epilepsy detection using image like\nfeatures of eeg signals,” in 2020 International Conference on Electrical\nand Electronics Engineering (ICE3).\nIEEE, 2020, pp. 280–284.\n[209] P. Boonyakitanont and et al., “Automatic epileptic seizure onset-offset\ndetection based on cnn in scalp eeg,” in ICASSP 2020-2020 IEEE\nInternational Conference on Acoustics, Speech and Signal Processing\n(ICASSP).\nIEEE, 2020, pp. 1225–1229.\n[210] Y. Gao and et al., “Deep convolutional neural network-based epileptic\nelectroencephalogram (eeg) signal classification,” Frontiers in Neurol-\nogy, vol. 11, 2020.\n[211] F. George and et al., “Epileptic seizure prediction using eeg images,”\nin 2020 International Conference on Communication and Signal Pro-\ncessing (ICCSP).\nIEEE, 2020, pp. 1595–1598.\n[212] Y. Qin and et al., “Patient-specific seizure prediction with scalp eeg\nusing convolutional neural network and extreme learning machine,”\nin 2020 39th Chinese Control Conference (CCC).\nIEEE, 2020, pp.\n7622–7625.\n[213] S. M. Usman and et al., “Epileptic seizures prediction using deep\nlearning techniques,” IEEE Access, vol. 8, pp. 39 998–40 007, 2020.\n[214] B. Zhang and et al., “Cross-subject seizure detection in eegs using\ndeep transfer learning,” Computational and Mathematical Methods in\nMedicine, vol. 2020, 2020.\n[215] D. Hu and et al., “Epileptic state classification by fusing hand-crafted\nand deep learning eeg features,” IEEE Transactions on Circuits and\nSystems II: Express Briefs, 2020.\n[216] G. Liu and et al., “Automatic seizure detection based on s-transform and\ndeep convolutional neural network,” International Journal of Neural\nSystems, vol. 30, no. 04, p. 1950024, 2020.\n[217] R. Hussein and et al., “Epileptic seizure prediction: A semi-\ndilated convolutional neural network architecture,” arXiv preprint\narXiv:2007.11716, 2020.\n[218] S. Raghu and et al., “Eeg based multi-class seizure type classification\nusing convolutional neural network and transfer learning,” in Neural\nNetworks, vol. 124, 2020, pp. 202–212.\n[219] T. Uyttenhove and et al., “Interpretable epilepsy detection in routine,\ninterictal eeg data using deep learning,” in Machine Learning for\nHealth.\nPMLR, 2020, pp. 355–366.\n[220] M. Rashed-Al-Mahfuz and et al., “A deep convolutional neural network\nmethod to detect seizures and characteristic frequencies using epilep-\ntic electroencephalogram (eeg) data,” IEEE Journal of Translational\nEngineering in Health and Medicine, vol. 9, pp. 1–12, 2021.\n[221] M. Zeng and et al., “Grp-dnet: A gray recurrence plot-based densely\nconnected convolutional network for classification of epileptiform eeg,”\nJournal of Neuroscience Methods, vol. 347, p. 108953, 2021.\n[222] T. Luo and et al., “Emd-wog-2dcnn based eeg signal processing for\nrolandic seizure classification,” Comput. Methods Biomech. Biomed.\nEng., vol. 25, no. 14, pp. 1565–1575, 2022.\n[223] T. Jagadesh and et al., “Early prediction of epileptic seizure using deep\nlearning algorithm,” in Brain-Computer Interface.\nWiley, 2023, pp.\n157–177.\n[224] T. Kaur and T. K. Gandhi, “Automated diagnosis of epileptic seizures\nusing eeg image representations and deep learning,” Neuroscience\nInformatics, vol. 3, no. 3, p. 100139, 2023.\n[225] Y. Yuan and et al., “A novel channel-aware attention framework for\nmulti-channel eeg seizure detection via multi-view deep learning,” in\n2018 IEEE EMBS international conference on biomedical & health\ninformatics (BHI), 2018, pp. 206–209.\n[226] X. Si and et al., “Patient-independent seizure detection based on long-\nterm ieeg and a novel lightweight cnn,” J. Neural Eng., vol. 20, no. 1,\np. 016037, 2023.\n[227] Y. Zhang and et al., “Epileptic seizure detection based on bidirectional\ngated recurrent unit network,” IEEE Transactions on Neural Systems\nand Rehabilitation Engineering, vol. 30, pp. 135–145, 2022.\n[228] B. Ganti and et al., “Time-series generative adversarial network ap-\nproach of deep learning improves seizure detection from the human\nthalamic seeg,” Frontiers in Neurology, vol. 13, p. 755094, 2022.\n[229] X. Hu and Q. Yuan, “Epileptic eeg identification based on deep bi-lstm\nnetwork,” in 2019 IEEE 11th International Conference on Advanced\nInfocomm Technology (ICAIT).\nIEEE, 2019, pp. 63–66.\n[230] L. Fraiwan and M. Alkhodari, “Classification of focal and non-focal\nepileptic patients using single channel eeg and long short-term memory\nlearning system,” IEEE Access, vol. 8, pp. 77 255–77 262, 2020.\n[231] X. Hu and et al., “Scalp eeg classification using deep bi-lstm network\nfor seizure detection,” Computers in Biology and Medicine, vol. 124,\np. 103919, 2020.\n[232] M. Geng and et al., “Epileptic seizure detection based on stockwell\ntransform and bidirectional long short-term memory,” IEEE Transac-\ntions on Neural Systems and Rehabilitation Engineering, vol. 28, no. 3,\npp. 573–580, 2020.\n[233] X. Yao and et al., “A robust deep learning approach for automatic\nclassification of seizures against non-seizures,” Biomedical Signal\nProcessing and Control, vol. 64, p. 102215, 2021.\n[234] E. Tuncer and E. Bolat, “Classification of epileptic seizures from elec-\ntroencephalogram (eeg) data using bidirectional short-term memory (bi-\nlstm) network architecture,” Biomed. Signal Process. Control, vol. 73,\np. 103462, 2022.\n[235] A. O’Shea and et al., “Neonatal seizure detection using convolutional\nneural networks,” in 2017 IEEE 27th International Workshop on\nMachine Learning for Signal Processing (MLSP).\nIEEE, 2017, pp.\n1–6.\n[236] H. G. Daoud and et al., “Automatic epileptic seizure detection based on\nempirical mode decomposition and deep neural network,” in 2018 IEEE\n14th international colloquium on signal processing & its applications\n(CSPA).\nIEEE, 2018, pp. 182–186.\n[237] I. Ullah and et al., “An automated system for epilepsy detection using\neeg brain signals based on deep learning approach,” Expert Systems\nwith Applications, vol. 107, pp. 61–71, 2018.\n[238] J. Zhang and et al., “A new approach for classification of epilepsy eeg\nsignals based on temporal convolutional neural networks,” in 2018 11th\nInternational Symposium on Computational Intelligence and Design\n(ISCID), vol. 2.\nIEEE, 2018, pp. 80–84.\n[239] R. Yuvaraj and et al., “A deep learning scheme for automatic seizure\ndetection from long-term scalp eeg,” in 2018 52nd Asilomar Conference\non Signals, Systems, and Computers.\nIEEE, 2018, pp. 368–372.\n[240] J. Thomas and et al., “Eeg classification via convolutional neural\nnetwork-based interictal epileptiform event detection,” in 2018 40th\nAnnual International Conference of the IEEE Engineering in Medicine\nand Biology Society (EMBC).\nIEEE, 2018, pp. 3148–3151.\n[241] O. Yıldırım and et al., “A deep convolutional neural network model for\nautomated identification of abnormal eeg signals,” Neural Computing\nand Applications, pp. 1–12, 2018.\n[242] D. Lu and J. Triesch, “Residual deep convolutional neural network for\neeg signal classification in epilepsy,” arXiv preprint arXiv:1903.08100,\n2019.\n[243] Z. Wei and et al., “Automatic epileptic eeg detection using convolu-\ntional neural network with improvements in time-domain,” Biomedical\nSignal Processing and Control, vol. 53, p. 101551, 2019.\n[244] J. Craley and et al., “Integrating convolutional neural networks and\nprobabilistic graphical modeling for epileptic seizure detection in mul-\ntichannel eeg,” in International Conference on Information Processing\nin Medical Imaging.\nSpringer, 2019, pp. 291–303.\n[245] A. H. Ansari and et al., “Neonatal seizure detection using deep con-\nvolutional neural networks,” International Journal of Neural Systems,\nvol. 29, no. 04, p. 1850011, 2019.\n[246] M. T. Avcu and et al., “Seizure detection using least eeg channels\nby deep convolutional neural network,” in 2019 IEEE International\nConference on Acoustics, Speech and Signal Processing (ICASSP).\nIEEE, 2019, pp. 1120–1124.\n[247] K. Fukumori and et al., “Fully data-driven convolutional filters with\ndeep learning models for epileptic spike detection,” in 2019 IEEE\nInternational Conference on Acoustics, Speech and Signal Processing\n(ICASSP).\nIEEE, 2019, pp. 2772–2776.\n[248] S. Wang and et al., “Time-resnext for epilepsy recognition based\non eeg signals in wireless networks,” EURASIP Journal on Wireless\nCommunications and Networking, vol. 2020, no. 1, pp. 1–12, 2020.\n[249] X. Zhao and et al., “Classification of epileptic ieeg signals by cnn\nand data augmentation,” in 2020 IEEE International Conference on\nAcoustics, Speech and Signal Processing (ICASSP).\nIEEE, 2020, pp.\n926–930.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n32\n[250] X. Gao and et al., “Automatic detection of epileptic seizure based on\napproximate entropy, recurrence quantification analysis and convolu-\ntional neural networks,” Artificial Intelligence in Medicine, vol. 102, p.\n101711, 2020.\n[251] D. Kaya, “The mrmr-cnn based influential support decision system\napproach to classify eeg signals,” Measurement, vol. 156, p. 107602,\n2020.\n[252] J. Lian and et al., “Pair-wise matching of eeg signals for epileptic\nidentification via convolutional neural network,” IEEE Access, vol. 8,\npp. 40 008–40 017, 2020.\n[253] H. Qin and et al., “Deep multi-scale feature fusion convolutional neural\nnetwork for automatic epilepsy detection using eeg signals,” in 2020\n39th Chinese Control Conference (CCC). IEEE, 2020, pp. 7061–7066.\n[254] A. Torfi and E. A. Fox, “Corgan: Correlation-capturing convolutional\ngenerative adversarial networks for generating synthetic healthcare\nrecords,” arXiv e-prints, pp. arXiv–2001, 2020.\n[255] G. Zhang and et al., “Mnl-network: A multi-scale non-local network\nfor epilepsy detection from eeg signals,” Frontiers in Neuroscience,\nvol. 14, 2020.\n[256] W. Zhao and et al., “Seizurenet: A model for robust detection of\nepileptic seizures based on convolutional neural network,” Cognitive\nComputation and Systems, vol. 2, no. 3, pp. 119–124, 2020.\n[257] ——, “A novel deep neural network for robust detection of seizures\nusing eeg signals,” Computational and Mathematical Methods in\nMedicine, vol. 2020, p. Article 2020, 2020.\n[258] R. Abiyev and et al., “Identification of epileptic eeg signals using\nconvolutional neural networks,” Applied Sciences, vol. 10, no. 12, p.\n4089, 2020.\n[259] Y. Li and et al., “Epileptic seizure detection in eeg signals using a uni-\nfied temporal-spectral squeeze-and-excitation network,” IEEE Transac-\ntions on Neural Systems and Rehabilitation Engineering, vol. 28, no. 4,\npp. 782–794, 2020.\n[260] H. Daoud and et al., “Iot based efficient epileptic seizure prediction\nsystem using deep learning,” in 2020 IEEE 6th World Forum on Internet\nof Things (WF-IoT).\nIEEE, 2020, pp. 1–6.\n[261] G. C. Jana and et al., “A cnn-spectrogram based approach for seizure\ndetection from eeg signal,” Procedia Computer Science, vol. 167, pp.\n403–412, 2020.\n[262] O. Kaziha and T. Bonny, “A convolutional neural network for seizure\ndetection,” in 2020 Advances in Science and Engineering Technology\nInternational Conferences (ASET).\nIEEE, 2020, pp. 1–5.\n[263] S. Khalilpour and et al., “Application of 1-d cnn to predict epileptic\nseizures using eeg records,” in 2020 6th International Conference on\nWeb Research (ICWR).\nIEEE, 2020, pp. 314–318.\n[264] R. V. Sharan and S. Berkovsky, “Epileptic seizure detection using\nmultichannel eeg wavelet power spectra and 1-d convolutional neural\nnetworks,” in 2020 42nd Annual International Conference of the IEEE\nEngineering in Medicine & Biology Society (EMBC).\nIEEE, 2020,\npp. 545–548.\n[265] A. H. Thomas and et al., “Noise-resilient and interpretable epileptic\nseizure detection,” in 2020 IEEE International Symposium on Circuits\nand Systems (ISCAS).\nIEEE, 2020, pp. 1–5.\n[266] S. Zhao and et al., “Binary single-dimensional convolutional neural\nnetwork for seizure prediction,” in 2020 IEEE International Symposium\non Circuits and Systems (ISCAS).\nIEEE, 2020, pp. 1–5.\n[267] M. Abou Jaoude and et al., “Detection of mesial temporal lobe\nepileptiform discharges on intracranial electrodes using deep learning,”\nClinical Neurophysiology, vol. 131, no. 1, pp. 133–141, 2020.\n[268] L.-C. Lin and et al., “Alternative diagnosis of epilepsy in children with-\nout epileptiform discharges using deep convolutional neural networks,”\nInternational Journal of Neural Systems, vol. 30, no. 05, p. 1850060,\n2020.\n[269] F. Pisano and et al., “Convolutional neural network for seizure detection\nof nocturnal frontal lobe epilepsy,” Complexity, 2020.\n[270] T. Sakai and et al., “Scalpnet: Detection of spatiotemporal abnormal in-\ntervals in epileptic eeg using convolutional neural networks,” in ICASSP\n2020-2020 IEEE International Conference on Acoustics, Speech and\nSignal Processing (ICASSP).\nIEEE, 2020, pp. 1244–1248.\n[271] J. Thomas and et al., “Automated detection of interictal epileptiform\ndischarges from scalp electroencephalograms by convolutional neural\nnetworks,” International Journal of Neural Systems, vol. 30, no. 11, p.\n2050030, 2020.\n[272] C. Vance and et al., “Learning to detect the onset of slow activity\nafter a generalized tonic–clonic seizure,” BMC Medical Informatics\nand Decision Making, vol. 20, no. 12, pp. 1–8, 2020.\n[273] K.-O. Cho and H.-J. Jang, “Comparison of different input modalities\nand network structures for deep learning-based seizure detection,”\nScientific Reports, vol. 10, no. 1, pp. 1–11, 2020.\n[274] Y. Xu and et al., “An end-to-end deep learning approach for epileptic\nseizure prediction,” in 2020 2nd IEEE International Conference on\nArtificial Intelligence Circuits and Systems (AICAS).\nIEEE, 2020, pp.\n266–270.\n[275] T. Ieˇsmantas and R. Alzbutas, “Convolutional neural network for\ndetection and classification of seizures in clinical data,” Medical &\nBiological Engineering & Computing, vol. 58, no. 9, pp. 1919–1932,\n2020.\n[276] X. Zhang and et al., “Adversarial representation learning for ro-\nbust patient-independent epileptic seizure detection,” IEEE Journal of\nBiomedical and Health Informatics, vol. 24, no. 10, pp. 2852–2859,\n2020.\n[277] S. Ramakrishnan and et al., “Seizure detection with local binary pattern\nand cnn classifier,” in Journal of Physics: Conference Series, vol. 1767.\nIOP Publishing, 2021, p. 012029.\n[278] K. Singh and J. Malhotra, “Prediction of epileptic seizures from\nspectral features of intracranial eeg recordings using deep learning\napproach,” Multimed. Tools Appl., vol. 81, no. 20, pp. 28 875–28 898,\nAug 2022.\n[279] D. K. Atal and M. Singh, “Effectual seizure detection using mbbf-gpso\nwith cnn network,” Cogn. Neurodyn, pp. 1–12, 2023.\n[280] Y. Zaid, M. Sah, and C. Direkoglu, “Pre-processed and combined eeg\ndata for epileptic seizure classification using deep learning,” Biomedical\nSignal Processing and Control, vol. 84, p. 104738, 2023.\n[281] I. Assali and et al., “Cnn-based classification of epileptic states for\nseizure prediction using combined temporal and spectral features,”\nBiomedical Signal Processing and Control, vol. 82, p. 104519, 2023.\n[282] S. Mekruksavanich and A. Jitpattanakul, “Deep learning approaches\nfor epileptic seizures recognition based on eeg signal,” in 46th In-\nternational Conference on Telecommunications and Signal Processing\n(TSP).\nIEEE, 2023, pp. 33–36.\n[283] D. Raab, A. Theissler, and M. Spiliopoulou, “Xai4eeg: Spectral and\nspatio-temporal explanation of deep learning-based seizure detection\nin eeg time series,” Neural Comput. Appl., vol. 35, no. 14, pp. 10 051–\n10 068, May 2023.\n[284] T. Prasanth and et al., “Deep learning for interictal epileptiform spike\ndetection from scalp eeg frequency sub bands,” in Annual International\nConference of the IEEE Engineering in Medicine & Biology Society\n(EMBC).\nIEEE, 2020, pp. 3703–3706.\n[285] S. Poorani and P. Balasubramanie, “Deep learning based epileptic\nseizure detection with eeg data,” Int. J. Syst. Assur. Eng. Manag., pp.\n1–10, 2023.\n[286] X. Liu and A. G. Richardson, “Embedded deep learning for neural\nimplants,” arXiv preprint arXiv:2012.00307, 2020.\n[287] X. Chen, J. Ji, T. Ji, and P. Li, “Cost-sensitive deep active learning\nfor epileptic seizure detection,” in ACM International Conference on\nBioinformatics, Computational Biology, and Health Informatics, 2018,\npp. 226–235.\n[288] Y. Yuan and K. Jia, “Fusionatt: Deep fusional attention networks for\nmulti-channel biomedical signals,” Sensors, vol. 19, no. 11, p. 2429,\n2019.\n[289] D. Y. Isaev and et al., “Attention-based network for weak labels in\nneonatal seizure detection,” in Proc. Mach. Learn. Res., vol. 126, 2020,\np. 479.\n[290] M. Natu and et al., “Hcla cbigru: Hybrid convolutional bidirectional\ngru based model for epileptic seizure detection,” Neurosci. Inform., p.\n100135, 2023.\n[291] J. Craley, E. Johnson, C. Jouny, and A. Venkataraman, “Automated\ninter-patient seizure detection using multichannel convolutional and\nrecurrent neural networks,” Biomed. Signal Process. Control, vol. 64,\np. 102360, 2021.\n[292] I. Ahmad and et al., “A hybrid deep learning approach for epileptic\nseizure detection in eeg signals,” IEEE Journal of Biomedical and\nHealth Informatics, 2023.\n[293] Y. Wang and et al., “Seeg-net: An explainable and deep learning-based\ncross-subject pathological activity detection method for drug-resistant\nepilepsy,” Computers in Biology and Medicine, vol. 148, p. 105703,\n2022.\n[294] F. A. Jibon and et al., “Epileptic seizure detection from electroen-\ncephalogram (eeg) signals using linear graph convolutional network and\ndensenet based hybrid framework,” J. Radiat. Res. Appl. Sci., vol. 16,\nno. 3, p. 100607, 2023.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n33\n[295] S. Roy and et al., “Chrononet: A deep recurrent neural network for\nabnormal eeg identification,” in Conference on Artificial Intelligence\nin Medicine in Europe.\nSpringer, 2019, pp. 47–56.\n[296] L. Tang and et al., “Seizure prediction using multiview features and\nimproved convolutional gated recurrent network,” IEEE Access, vol. 8,\npp. 172 352–172 361, 2020.\n[297] S. P. Kumar and et al., “Automatic detection of epilepsy using cnn-\ngru hybrid model,” in Biomed. Signals Based Comput.-Aided Diagn.\nNeurol. Disord.\nSpringer, 2022, pp. 165–186.\n[298] P. Thodoroff and et al., “Learning robust features using deep learning\nfor automatic seizure detection,” in Machine Learning for Healthcare\nConference.\nPMLR, 2016, pp. 178–190.\n[299] M. Golmohammadi and et al., “Deep architectures for automated\nseizure detection in scalp eegs,” arXiv preprint arXiv:1712.09776,\n2017.\n[300] U. B. Baloglu and et al., “Convolutional long-short term memory\nnetworks model for long duration eeg signal classification,” J. Mech.\nMed. Biol., vol. 19, no. 01, p. 1940005, 2019.\n[301] Y. Liu and et al., “Deep c-lstm neural network for epileptic seizure\nand tumor detection using high-dimension eeg signals,” IEEE Access,\nvol. 8, pp. 37 495–37 504, 2020.\n[302] G. Xu and et al., “A one-dimensional cnn-lstm model for epileptic\nseizure recognition using eeg signal analysis,” Frontiers in Neuro-\nscience, vol. 14, p. 1253, 2020.\n[303] Y. Li and et al., “Automatic seizure detection using fully convolutional\nnested lstm,” International Journal of Neural Systems, vol. 30, no. 04,\np. 2050019, 2020.\n[304] W. Liang and et al., “Scalp eeg epileptogenic zone recognition and\nlocalization based on long-term recurrent convolutional network,” Neu-\nrocomputing, vol. 396, pp. 569–576, 2020.\n[305] W. Hussain and et al., “Epileptic seizure detection using 1d-\nconvolutional long short-term memory neural networks,” Appl. Acoust.,\nvol. 177, p. 107941, 2021.\n[306] Y. Yang and et al., “Video-based detection of generalized tonic-clonic\nseizures using deep learning,” IEEE Journal of Biomedical and Health\nInformatics, 2021.\n[307] M. Varlı and et al., “Multiple classification of eeg signals and epileptic\nseizure diagnosis with combined deep learning,” J. Comput. Sci.,\nvol. 67, p. 101943, 2023.\n[308] Y. P. Singh and et al., “Automatic prediction of epileptic seizure using\nhybrid deep resnet-lstm model,” AI Commun., vol. 36, no. 1, pp. 57–72,\nFeb 2023.\n[309] X. Qiu and et al., “A difference attention resnet-lstm network for\nepileptic seizure detection using eeg signal,” Biomed. Signal Process.\nControl, vol. 83, p. 104652, 2023.\n[310] S. Roy and et al., “Deep learning enabled automatic abnormal eeg\nidentification,” in 2018 40th Annual International Conference of the\nIEEE Engineering in Medicine and Biology Society (EMBC).\nIEEE,\n2018, pp. 2756–2759.\n[311] C. Huang and et al., “Automatic epileptic seizure detection via\nattention-based cnn-birnn,” in 2019 IEEE International Conference on\nBioinformatics and Biomedicine (BIBM).\nIEEE, 2019, pp. 660–663.\n[312] D. Kostas and et al., “Bendr: Using transformers and a contrastive self-\nsupervised learning task to learn from massive amounts of eeg data,”\nFrontiers in Human Neuroscience, vol. 15, p. 653659, 2021.\n[313] P. Busia and et al., “Eegformer: Transformer-based epilepsy detec-\ntion on raw eeg traces for low-channel-count wearable continuous\nmonitoring devices,” in 2022 IEEE Biomedical Circuits and Systems\nConference (BioCAS).\nIEEE, 2022, pp. 640–644.\n[314] S. Hu and et al., “Exploring the applicability of transfer learning and\nfeature engineering in epilepsy prediction using hybrid transformer\nmodel,” IEEE Transactions on Neural Systems and Rehabilitation\nEngineering, vol. 31, pp. 1321–1332, 2023.\n[315] Z. Deng and et al., “Eeg-based seizure prediction via hybrid vision\ntransformer and data uncertainty learning,” Engineering Applications\nof Artificial Intelligence, vol. 123, p. 106401, 2023.\n[316] W. Y. Peh and et al., “Six-center assessment of cnn-transformer with\nbelief matching loss for patient-independent seizure detection in eeg,”\nInternational Journal of Neural Systems, vol. 33, no. 03, p. 2350012,\n2023.\n[317] C. Dong and et al., “Eeg-based patient-specific seizure prediction based\non spatial–temporal hypergraph attention transformer,” Biomedical Sig-\nnal Processing and Control, vol. 100, p. 107075, 2025.\n[318] Y. Sun and et al., “Multi-task transformer network for subject-\nindependent ieeg seizure detection,” Expert Systems with Applications,\np. 126282, 2024.\n[319] T. X. Le and et al., “Deep learning for epileptic spike detection,” VNU\nJournal of Science: Computer Science and Communication Engineer-\ning, vol. 33, no. 2, pp. 1–13, 2018.\n[320] K. P. Thanaraj and et al., “Implementation of deep neural networks to\nclassify eeg signals using gramian angular summation field for epilepsy\ndiagnosis,” arXiv preprint arXiv:2003.04534, 2020.\n[321] K. Akyol, “Stacking ensemble based deep neural networks modeling\nfor effective epileptic seizure detection,” Expert Systems with Applica-\ntions, vol. 148, p. 113239, 2020.\n[322] A. Guha and et al., “Epileptic seizure recognition using deep neural net-\nwork,” in Emerging Technology in Modelling and Graphics. Springer,\n2020, pp. 21–28.\n[323] R. Sharma and et al., “Seizures classification based on higher order\nstatistics and deep neural network,” Biomedical Signal Processing and\nControl, vol. 59, p. 101921, 2020.\n[324] H. A. Glory and et al., “Ahw-bgoa-dnn: A novel deep learning model\nfor epileptic seizure detection,” Neural Computing and Applications,\npp. 1–29, 2020.\n[325] Z. Zhang and et al., “Dwt-net: Seizure detection system with structured\neeg montage and multiple feature extractor in convolution neural\nnetwork,” Journal of Sensors, 2020.\n[326] Y. Zhao and et al., “Graph attention network with focal loss for seizure\ndetection on electroencephalography signals,” International Journal of\nNeural Systems, vol. 31, no. 07, p. 2150027, 2021.\n[327] Y. Wang and et al., “A spatiotemporal graph attention network based\non synchronization for epileptic seizure prediction,” IEEE Journal of\nBiomedical and Health Informatics, vol. 27, no. 2, pp. 900–911, 2023.\n[328] Y. Zhao and et al., “Hybrid attention network for epileptic eeg\nclassification,” International Journal of Neural Systems, vol. 33, no. 06,\np. 2350031, 2023.\n[329] J. He and et al., “Spatial–temporal seizure detection with graph atten-\ntion network and bi-directional lstm architecture,” Biomedical Signal\nProcessing and Control, vol. 78, p. 103908, 2022.\n[330] X. Chen and et al., “Epilepsy classification for mining deeper rela-\ntionships between eeg channels based on gcn,” in 2020 International\nConference on Computer Vision, Image and Deep Learning (CVIDL).\nIEEE, 2020, pp. 701–706.\n[331] J. Wang and et al., “A sequential graph convolutional network with\nfrequency-domain complex network of eeg signals for epilepsy detec-\ntion,” in 2020 IEEE International Conference on Bioinformatics and\nBiomedicine (BIBM).\nIEEE, 2020, pp. 785–792.\n[332] Y. Zhao and et al., “Eeg-based seizure detection using linear graph\nconvolution network with focal loss,” Computer methods and programs\nin biomedicine, vol. 208, p. 106277, 2021.\n[333] D. Nhu and et al., “Graph convolutional network for generalized\nepileptiform abnormality detection on eeg,” in 2021 IEEE Signal\nProcessing in Medicine and Biology Symposium (SPMB). IEEE, 2021,\npp. 1–6.\n[334] J. Lian and F. Xu, “Spatial enhanced pattern through graph convo-\nlutional neural network for epileptic eeg identification,” International\nJournal of Neural Systems, vol. 32, no. 09, p. 2250033, 2022.\n[335] C. Dong and et al., “Attention-based graph resnet with focal loss for\nepileptic seizure detection,” Journal of Ambient Intelligence and Smart\nEnvironments, vol. 14, no. 1, pp. 61–73, 2022.\n[336] Y. Wang and et al., “Dynamic multi-graph convolution based channel-\nweighted transformer feature fusion network for epileptic seizure\nprediction,” IEEE Transactions on Neural Systems and Rehabilitation\nEngineering, 2023.\n[337] J. Lian and F. Xu, “Epileptic eeg classification via graph transformer\nnetwork,” International Journal of Neural Systems, vol. 33, no. 8, p.\n2350042, 2023.\n[338] S. S. Talathi, “Deep recurrent neural networks for seizure detection\nand early seizure detection systems,” arXiv preprint arXiv:1706.03283,\n2017.\n[339] A. Verma and R. R. Janghel, “Epileptic seizure detection using deep\nrecurrent neural networks in eeg signals,” in Advances in Biomedical\nEngineering and Technology.\nSpringer, 2021, pp. 189–198.\n[340] O. Ramwala and et al., “Gru-based parameter-efficient epileptic seizure\ndetection,” Biomedical Signal Processing and Artificial Intelligence, pp.\n73–86, 2023.\n[341] R. Hussein and et al., “Robust detection of epileptic seizures using deep\nneural networks,” in 2018 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP). IEEE, 2018, pp. 2546–2550.\n[342] D. Ahmedt-Aristizabal and et al., “Deep classification of epileptic\nsignals,” in 2018 40th Annual International Conference of the IEEE,\n2018.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n34\n[343] R. Hussein and et al., “Optimized deep neural network architecture\nfor robust detection of epileptic seizures using eeg signals,” Clinical\nNeurophysiology, vol. 130, no. 1, pp. 25–37, 2019.\n[344] M. U. Abbasi and et al., “Detection of epilepsy seizures in neo-natal\neeg using lstm architecture,” IEEE Access, vol. 7, pp. 179 074–179 085,\n2019.\n[345] I. Aliyu and C. Lim, “Selection of optimal wavelet features for\nepileptic eeg signal classification with lstm,” Neural Computing and\nApplications, pp. 1–21, 2021.\n[346] K. Singh and J. Malhotra, “Two-layer lstm network-based prediction\nof epileptic seizures using eeg spectral features,” Complex Intelligence\nSystems, vol. 8, no. 3, pp. 2405–2418, Jun 2022.\n[347] E. Tuncer and E. Bolat, “Channel based epilepsy seizure type detection\nfrom electroencephalography (eeg) signals with machine learning tech-\nniques,” Biocybernetics and Biomedical Engineering, vol. 42, no. 2, pp.\n575–595, 2022.\n[348] A. Pandey and et al., “An intelligent optimized deep learning model\nto achieve early prediction of epileptic seizures,” Biomedical Signal\nProcessing and Control, vol. 84, p. 104798, Jul 2023.\n[349] L. Vidyaratne and et al., “Deep recurrent neural network for seizure\ndetection,” in 2016 International Joint Conference on Neural Networks\n(IJCNN).\nIEEE, 2016, pp. 1202–1207.\n[350] X. Yao, Q. Cheng, and G.-Q. Zhang, “Automated classification of\nseizures against nonseizures: A deep learning approach,” arXiv preprint\narXiv:1906.02745, 2019.\n[351] X. Yao and et al., “A novel independent rnn approach to classification of\nseizures against non-seizures,” arXiv preprint arXiv:1903.09326, 2019.\n[352] Y. Singh and D. Lobiyal, “A comparative study of deep learning\nalgorithms for epileptic seizure classification,” in 2022 International\nConference on Computing, Communication Security and Intelligent\nSystems (IC3SIS).\nIEEE, 2022, pp. 1–6.\n[353] R. Chiranjeevi and et al., “Identification of epileptic seizures using\nrecurrent neural networks and time series transformer,” in 2024 7th In-\nternational Conference on Circuit Power and Computing Technologies\n(ICCPCT).\nIEEE, 2024, pp. 1546–1553.\n[354] R. Zhu and et al., “Epileptic seizure prediction via multidimensional\ntransformer and recurrent neural network fusion,” Journal of Transla-\ntional Medicine, vol. 22, no. 1, p. 895, 2024.\n[355] I. C. Covert and et al., “Temporal graph convolutional networks for\nautomatic seizure detection,” in Machine Learning for Healthcare\nConference.\nPMLR, 2019, pp. 160–180.\n[356] J. Pedoeem and et al., Tabs: Transformer based Seizure Detection.\nCham: Springer International Publishing, 2022.\n[357] Y. Ma and et al., “Tsd: Transformers for seizure detection,” bioRxiv,\np. 2023.01.24.525308, 2023.\n[358] C. Meisel and K. A. Bailey, “Identifying signal-dependent information\nabout the preictal state: A comparison across ecog, eeg and ekg using\ndeep learning,” EBioMedicine, vol. 45, pp. 422–431, 2019.\n[359] J. Guo and et al., “Detecting high frequency oscillations for stereoelec-\ntroencephalography in epilepsy via hypergraph learning,” IEEE Trans-\nactions on Neural Systems and Rehabilitation Engineering, vol. 29, pp.\n587–596, 2021.\n[360] A. Gogna and et al., “Semi-supervised stacked label consistent au-\ntoencoder for reconstruction and analysis of biomedical signals,” IEEE\nTransactions on Biomedical Engineering, vol. 64, no. 9, pp. 2196–\n2205, 2016.\n[361] C. Park and et al., “Epileptic seizure detection for multi-channel\neeg with deep convolutional neural network,” in 2018 International\nConference on Electronics, Information, and Communication (ICEIC).\nIEEE, 2018, pp. 1–5.\n[362] W. Barry, S. Arcot Desai, T. K. Tcheng, and M. J. Morrell, “A\nhigh accuracy electrographic seizure classifier trained using semi-\nsupervised labeling applied to a large spectrogram dataset,” Frontiers\nin neuroscience, vol. 15, p. 667373, 2021.\n[363] Y. Yuan and et al., “A multi-view deep learning framework for eeg\nseizure detection,” IEEE Journal of Biomedical and Health Informatics,\nvol. 23, no. 1, pp. 83–94, 2018.\n[364] P. N. Bhagat and et al., “Robust prior stage epileptic seizure diagnosis\nsystem using resnet and backpropagation techniques,” International\nJournal, vol. 8, no. 5, 2020.\n[365] N. D. Truong and et al., “Epileptic seizure forecasting with generative\nadversarial networks,” IEEE Access, vol. 7, pp. 143 999–144 009, 2019.\n[366] H.\nTakahashi\nand\net\nal.,\n“Convolutional\nneural\nnetwork\nwith\nautoencoder-assisted multiclass labelling for seizure detection based\non scalp electroencephalography,” Computers in Biology and Medicine,\nvol. 125, p. 104016, 2020.\n[367] A. Shoeibi and et al., “A comprehensive comparison of handcrafted\nfeatures and convolutional autoencoders for epileptic seizures detection\nin eeg signals,” Expert Systems with Applications, vol. 163, p. 113788,\n2021.\n[368] D. Wulsin and et al., “Modeling electroencephalography waveforms\nwith semi-supervised deep belief nets: Fast classification and anomaly\nmeasurement,” J. Neural Eng., vol. 8, no. 3, p. 036015, 2011.\n[369] H. Daoud and M. Bayoumi, “Deep learning approach for epileptic\nfocus localization,” IEEE Transactions on Biomedical Circuits and\nSystems, vol. 14, no. 2, pp. 209–220, 2019.\n[370] Q. Lin and et al., “Classification of epileptic eeg signals with stacked\nsparse autoencoder based on deep learning,” in International Confer-\nence on Intelligent Computing.\nSpringer, 2016, pp. 802–810.\n[371] B. Yan and et al., “An eeg signal classification method based on\nsparse auto-encoders and support vector machine,” in 2016 IEEE/CIC\nInternational Conference on Communications in China (ICCC). IEEE,\n2016, pp. 1–6.\n[372] Y. Yuan and et al., “A multi-view deep learning method for epileptic\nseizure detection using short-time fourier transform,” in Proceedings\nof the 8th ACM International Conference on Bioinformatics, Compu-\ntational Biology, and Health Informatics, 2017, pp. 213–222.\n[373] A. M. Karim and et al., “A new generalized deep learning framework\ncombining sparse autoencoder and taguchi method for novel data\nclassification and processing,” Mathematical Problems in Engineering,\nvol. 2018, 2018.\n[374] Y. Qiu and et al., “Denoising sparse autoencoder-based ictal eeg clas-\nsification,” IEEE Transactions on Neural Systems and Rehabilitation\nEngineering, vol. 26, no. 9, pp. 1717–1726, 2018.\n[375] V. Sharathappriyaa and et al., “Auto-encoder based automated epilepsy\ndiagnosis,” in 2018 International Conference on Advances in Comput-\ning, Communications and Informatics (ICACCI).\nIEEE, 2018, pp.\n976–982.\n[376] Y. Yuan and et al., “Wave2vec: Deep representation learning for clinical\ntemporal data,” Neurocomputing, vol. 324, pp. 31–42, 2019.\n[377] A. Emami and et al., “Autoencoding of long-term scalp electroen-\ncephalogram to detect epileptic seizure for diagnosis support system,”\nComputers in Biology and Medicine, vol. 110, pp. 227–233, 2019.\n[378] J. X and et al., “3dsleepnet: A multi-channel bio-signal based sleep\nstages classification method using deep learning,” IEEE Transactions\non Neural Systems and Rehabilitation Engineering, 2023.\n[379] W. J and et al., “Caresleepnet: a hybrid deep learning network for\nautomatic sleep staging,” IEEE Journal of Biomedical and Health\nInformatics, 2024.\n[380] L. F and et al., “End-to-end sleep staging using convolutional neural\nnetwork in raw single-channel eeg,” Biomedical Signal Processing and\nControl, vol. 63, p. 102203, 2021.\n[381] E. E and O. S, “Cosleepnet: Automated sleep staging using a hybrid\ncnn-lstm network on imbalanced eeg-eog datasets,” Biomedical Signal\nProcessing and Control, vol. 80, p. 104299, 2023.\n[382] S. A and et al., “Deepsleepnet: A model for automatic sleep stage\nscoring based on raw single-channel eeg,” IEEE transactions on neural\nsystems and rehabilitation engineering, vol. 25(11), pp. 1998–2008,\n2017.\n[383] L. C and et al., “A deep learning method approach for sleep stage\nclassification with eeg spectrogram,” International Journal of Environ-\nmental Research and Public Health, vol. 19(10), p. 6322, 2022.\n[384] Z. J and W. Y, “A new method for automatic sleep stage classification,”\nIEEE transactions on biomedical circuits and systems, vol. 11(5), pp.\n1097–1110, 2017.\n[385] Z. Jia and et al., “Graphsleepnet: Adaptive spatial-temporal graph\nconvolutional networks for sleep stage classification.” in Ijcai, vol.\n2021, 2020, pp. 1324–1330.\n[386] F. Y and et al., “A dual-stream deep neural network integrated with\nadaptive boosting for sleep staging,” Biomedical Signal Processing and\nControl, vol. 79, p. 104150, 2023.\n[387] S. H and et al., “Intra-and inter-epoch temporal context network (iitnet)\nusing sub-epoch features for automatic sleep scoring on raw single-\nchannel eeg,” Biomedical signal processing and control, vol. 61, p.\n102037, 2020.\n[388] Y. C and et al., “Lwsleepnet: A lightweight attention-based deep\nlearning model for sleep staging with singlechannel eeg,” Digital\nHealth, vol. 9, p. 20552076231188206, 2023.\n[389] L. G and et al., “Micro sleepnet: efficient deep learning model for\nmobile terminal real-time sleep staging,” Frontiers in Neuroscience,\nvol. 17, p. 1218072, 2023.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n35\n[390] J. Z and et al., “Multi-view spatial-temporal graph convolutional\nnetworks with domain generalization for sleep stage classification,”\nIEEE Transactions on Neural Systems and Rehabilitation Engineering,\nvol. 29, pp. 1977–1986, 2021.\n[391] J. Lu and et al., “Pearnet: A pearson correlation-based graph attention\nnetwork for sleep stage recognition,” in 2022 IEEE 9th International\nConference on Data Science and Advanced Analytics (DSAA).\nIEEE,\n2022, pp. 1–8.\n[392] H. Phan and et al., “Seqsleepnet: end-to-end hierarchical recurrent\nneural network for sequence-to-sequence automatic sleep staging,”\nIEEE Transactions on Neural Systems and Rehabilitation Engineering,\nvol. 27, no. 3, pp. 400–410, 2019.\n[393] M. S and et al., “Sleepeegnet: Automated sleep stage scoring with\nsequence to sequence deep learning approach,” PloS one, vol. 14(5),\np. e0216456, 2019.\n[394] B. S and et al., “Sleepnet: automated sleep staging system via deep\nlearning,” arXiv preprint arXiv:1707.08262, 2017.\n[395] D. M and et al., “Sleepxai: An explainable deep learning approach for\nmulti-class sleep stage identification,” Applied Intelligence, vol. 53(13),\npp. 16 830–16 843, 2023.\n[396] A. Supratak and Y. Guo, “Tinysleepnet: An efficient deep learning\nmodel for sleep stage scoring based on raw single-channel eeg,” in\n2020 42nd Annual International Conference of the IEEE Engineering\nin Medicine & Biology Society (EMBC).\nIEEE, 2020, pp. 641–644.\n[397] J. N and et al., “Zleepanlystnet: a novel deep learning model for\nautomatic sleep stage scoring based on single-channel raw eeg data\nusing separating training,” Scientific Reports, vol. 14(1), p. 9859, 2024.\n[398] F. M and et al., “Deep learning in automatic sleep staging with a single\nchannel electroencephalography,” Frontiers in Physiology, vol. 12, p.\n628502, 2021.\n[399] H. M. N and K. I, “Mixed-input deep learning approach to sleep/wake\nstate classification by using eeg signals,” Diagnostics, vol. 13(14), p.\n2358, 2023.\n[400] S. C and et al., “A hierarchical neural network for sleep stage\nclassification based on comprehensive feature learning and multi-flow\nsequence learning,” IEEE journal of biomedical and health informatics,\nvol. 24(5), pp. 1351–1366, 2019.\n[401] Z. Yao and X. Liu, “A cnn-transformer deep learning model for\nreal-time sleep stage classification in an energy-constrained wireless\ndevice,” in 2023 11th International IEEE/EMBS Conference on Neural\nEngineering (NER).\nIEEE, 2023, pp. 1–4.\n[402] H. Phan and et al., “Automatic sleep stage classification using single-\nchannel eeg: Learning sequential features with attention-based recurrent\nneural networks,” in 2018 40th annual international conference of the\nIEEE engineering in medicine and biology society (EMBC), 2018, pp.\n1452–1455.\n[403] S. A and et al., “A convolutional neural network for sleep stage\nscoring from raw single-channel eeg,” Biomedical Signal Processing\nand Control, vol. 42, pp. 107–114, 2018.\n[404] S. M and et al., “Deep learning for automated feature discovery and\nclassification of sleep stages,” IEEE/ACM transactions on computa-\ntional biology and bioinformatics, vol. 17(6), pp. 1835–1845, 2019.\n[405] P. H and et al., “Joint classification and prediction cnn framework for\nautomatic sleep stage classification,” IEEE Transactions on Biomedical\nEngineering, vol. 66(5), pp. 1285–1296, 2018.\n[406] F.-B. E and et al., “Convolutional neural networks for sleep stage\nscoring on a two-channel eeg signal,” Soft Computing, vol. 24, pp.\n4067–4079, 2020.\n[407] Z. T and et al., “Convolution-and attention-based neural network\nfor automated sleep stage classification,” International Journal of\nEnvironmental Research and Public Health, vol. 17(11), p. 4152, 2020.\n[408] L. M and et al., “An attention-guided spatiotemporal graph convolu-\ntional network for sleep stage classification,” Life, vol. 12(5), p. 622,\n2022.\n[409] D. H and et al., “Mixed neural network approach for temporal sleep\nstage classification,” IEEE Transactions on Neural Systems and Reha-\nbilitation Engineering, vol. 26(2), pp. 324–333, 2017.\n[410] S. S. K and L. D, “Automated classification of multi-class sleep\nstages classification using polysomnography signals: a nine-layer 1d-\nconvolution neural network approach,” Multimedia Tools and Applica-\ntions, vol. 82(6), pp. 8049–8091, 2023.\n[411] C. S and et al., “Dssnet: a deep sequential sleep network for self-\nsupervised representation learning based on single-channel eeg,” IEEE\nSignal Processing Letters, vol. 29, pp. 2143–2147, 2022.\n[412] C. H. Y. S and et al., “Maeeg: Masked auto-encoder for eeg represen-\ntation learning,” arXiv preprint arXiv:2211.02625, 2022.\n[413] Y. Y and et al., “Psnsleep: a self-supervised learning method for sleep\nstaging based on siamese networks with only positive sample pairs,”\nFrontiers in Neuroscience, vol. 17, p. 1167723, 2023.\n[414] Q. Xiao and et al., “Self-supervised learning for sleep stage classifica-\ntion with predictive and discriminative contrastive coding,” in ICASSP\n2021-2021 IEEE International Conference on Acoustics, Speech and\nSignal Processing (ICASSP).\nIEEE, 2021, pp. 1290–1294.\n[415] H. Zhang and et al., “Expert knowledge inspired contrastive learning\nfor sleep staging,” in 2022 International Joint Conference on Neural\nNetworks (IJCNN).\nIEEE, 2022, pp. 1–6.\n[416] H. Lee, E. Seong, and D. K. Chae, “Self-supervised learning with\nattention-based latent signal augmentation for sleep staging with lim-\nited labeled data,” in IJCAI, 2022, pp. 3868–3876.\n[417] T. Br¨usch and et al., “Multi-view self-supervised learning for multi-\nvariate variable-channel time series,” in 2023 IEEE 33rd International\nWorkshop on Machine Learning for Signal Processing (MLSP). IEEE,\n2023, pp. 1–6.\n[418] L. Y and et al., “Adversarial learning for semi-supervised pediatric\nsleep staging with single-eeg channel,” Methods, vol. 204, pp. 84–91,\n2022.\n[419] L. Y. and et al., “Mtclss: Multi-task contrastive learning for semi-\nsupervised pediatric sleep staging,” IEEE Journal of Biomedical and\nHealth Informatics, vol. 27(6), pp. 2647–2655, 2022.\n[420] Z. C and et al., “Hybrid manifold-deep convolutional neural network\nfor sleep staging,” Methods, vol. 202, pp. 164–172, 2022.\n[421] Z. Y and et al., “Shnn: A single-channel eeg sleep staging model based\non semi-supervised learning,” Expert Systems with Applications, vol.\n213, p. 119288, 2023.\n[422] A. M. Munk and et al., “Semi-supervised sleep-stage scoring based\non single channel eeg,” in 2018 IEEE International Conference on\nAcoustics, Speech and Signal Processing (ICASSP).\nIEEE, 2018, pp.\n2551–2555.\n[423] B. Haoran and L. Guanze, “Semi-supervised end-to-end automatic\nsleep stage classification based on pseudo-label,” in 2021 IEEE In-\nternational Conference on Power Electronics, Computer Applications\n(ICPECA).\nIEEE, 2021, pp. 83–87.\n[424] Z. J and W. Y, “Competition convolutional neural network for\nsleep stage classification,” Biomedical Signal Processing and Control,\nvol. 64, p. 102318, 2021.\n[425] Z. J. and W. Y., “Complex-valued unsupervised convolutional neural\nnetworks for sleep stage classification,” Computer methods and pro-\ngrams in biomedicine, vol. 164, pp. 181–191, 2018.\n[426] L. Fraiwan and K. Lweesy, “Neonatal sleep state identification using\ndeep learning autoencoders,” in 2017 IEEE 13th International Collo-\nquium on Signal Processing & its Applications (CSPA).\nIEEE, 2017,\npp. 228–231.\n[427] Z. J and et al., “Automatic sleep stage classification based on sparse\ndeep belief net and combination of multiple classifiers,” Transactions\nof the Institute of Measurement and Control, vol. 38(4), pp. 435–451,\n2016.\n[428] T. O and et al., “Automatic sleep stage scoring using time-frequency\nanalysis and stacked sparse autoencoders,” Annals of biomedical engi-\nneering, vol. 44, pp. 1587–1597, 2016.\n[429] L. M and et al., “Sleep stage classification using unsupervised feature\nlearning,” Advances in Artificial Neural Systems, vol. 2012(1), p.\n107046, 2012.\n[430] H.-G. Wang and et al., “Amgcn-l: an adaptive multi-time-window graph\nconvolutional network with long-short-term memory for depression\ndetection,” Journal of Neural Engineering, vol. 20, no. 5, p. 056038,\n2023.\n[431] C. Y and et al., “Dctnet: hybrid deep neural network-based eeg signal\nfor detecting depression,” Multimedia Tools and Applications, vol.\n82(26), pp. 41 307–41 321, 2023.\n[432] S. G and et al., “Depcap: a smart healthcare framework for eeg based\ndepression detection using time-frequency response and deep neural\nnetwork,” IEEE Access, vol. 11, pp. 52 327–52 338, 2023.\n[433] Y. Wang and et al., “Diffmdd: A diffusion-based deep learning frame-\nwork for mdd diagnosis using eeg,” IEEE Transactions on Neural\nSystems and Rehabilitation Engineering, 2024.\n[434] Y. M and et al., “Edt: An eeg-based attention model for feature\nlearning and depression recognition,” Biomedical Signal Processing\nand Control, vol. 93, p. 106182, 2024.\n[435] L. Yang and et al., “A gated temporal-separable attention network\nfor eeg-based depression recognition,” Computers in Biology and\nMedicine, vol. 157, p. 106782, 2023.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n36\n[436] W. Z and et al., “Hybrideegnet: A convolutional neural network for eeg\nfeature learning and depression discrimination,” IEEE Access, vol. 8,\npp. 30 332–30 342, 2020.\n[437] X. Song and et al., “Lsdd-eegnet: An efficient end-to-end framework\nfor eeg-based depression detection,” Biomedical Signal Processing and\nControl, vol. 75, p. 103612, 2022.\n[438] X. Sun and et al., “Multi-granularity graph convolution network for\nmajor depressive disorder recognition,” IEEE Transactions on Neural\nSystems and Rehabilitation Engineering, vol. 32, pp. 559–569, 2023.\n[439] W. Cui and et al., “A multiview sparse dynamic graph convolution-\nbased region-attention feature fusion network for major depressive dis-\norder detection,” IEEE Transactions on Computational Social Systems,\nvol. 11, pp. 2691–2702, 2023.\n[440] C. T and et al., “Exploring self-attention graph pooling with eeg-based\ntopological structure and soft label for depression detection,” IEEE\ntransactions on affective computing, vol. 13(4), pp. 2106–2118, 2022.\n[441] Z. Z and et al., “A novel eeg-based graph convolution network for\ndepression detection: incorporating secondary subject partitioning and\nattention mechanism,” Expert Systems with Applications, vol. 239, p.\n122356, 2024.\n[442] C. Yang and et al., “Tsunet-cc: Temporal spectrogram unet embedding\ncross channel-wise attention mechanism for mdd identification,” in\n2023 45th Annual International Conference of the IEEE Engineering\nin Medicine & Biology Society (EMBC).\nIEEE, 2023, pp. 1–4.\n[443] X. Y and et al., “Depressive disorder recognition based on frontal eeg\nsignals and deep learning,” Sensors, vol. 23(20), p. 8639, 2023.\n[444] K. H and et al., “Cloud-aided online eeg classification system for brain\nhealthcare: A case study of depression evaluation with a lightweight\ncnn,” Software: Practice and Experience, vol. 50(5), pp. 596–610,\n2020.\n[445] K. M and et al., “Deep-asymmetry: Asymmetry matrix image for deep\nlearning method in pre-screening depression,” Sensors, vol. 20(22), p.\n6526, 2020.\n[446] S. A and et al., “Major depressive disorder diagnosis based on effective\nconnectivity in eeg signals: a convolutional neural network and long\nshort-term memory approach,” Cognitive Neurodynamics, vol. 15(2),\npp. 239–252, 2021.\n[447] L. H. W and et al., “Decision support system for major depression\ndetection using spectrogram and convolution neural network with eeg\nsignals,” Expert Systems, vol. 39(3), p. e12773, 2022.\n[448] M. Kang and et al., “Low channel electroencephalogram based deep\nlearning method to pre-screening depression,” in 2020 International\nConference on Information and Communication Technology Conver-\ngence (ICTC).\nIEEE, 2020, pp. 449–451.\n[449] D. W and et al., “Multilayer brain network combined with deep\nconvolutional neural network for detecting major depressive disorder,”\nNonlinear Dynamics, vol. 102(2), pp. 667–677, 2020.\n[450] M. W and Q. A, “A deep learning framework for automatic diagnosis\nof unipolar depression,” International journal of medical informatics,\nvol. 132, p. 103983, 2019.\n[451] S. X and et al., “A novel complex network-based graph convolutional\nnetwork in major depressive disorder detection,” IEEE Transactions on\nInstrumentation and Measurement, vol. 71, pp. 1–8, 2022.\n[452] A. A and et al., “Automated major depressive disorder diagnosis using a\ndual-input deep learning model and image generation from eeg signals,”\nWaves in Random and Complex Media, 2023: 1-16.\n[453] X. M and et al., “An end-to-end deep learning model for eeg-based\nmajor depressive disorder classification,” IEEE Access, vol. 11, pp.\n41 337–41 347, 2023.\n[454] A. I. A and et al., “A robust deep-learning model to detect major de-\npressive disorder utilising eeg signals,” IEEE Transactions on Artificial\nIntelligence, 2024.\n[455] A. Rafiei and et al., “Automated detection of major depressive disorder\nwith eeg signals: A time series classification using deep learning,” IEEE\nAccess, vol. 10, pp. 73 804–73 817, 2022.\n[456] D. M. Khan and et al., “Development of wavelet coherence eeg as a\nbiomarker for diagnosis of major depressive disorder,” IEEE Sensors\nJournal, vol. 22, pp. 4315–4325, 2022.\n[457] L. Li and et al., “An eeg-based marker of functional connectivity:\nDetection of major depressive disorder,” Cognitive Neurodynamics,\nvol. 18, pp. 1671–1687, 2024.\n[458] P. Sandheep and et al., “Performance analysis of deep learning cnn in\nclassification of depression eeg signals,” in TENCON 2019-2019 IEEE\nRegion 10 Conference.\nIEEE, 2019, pp. 1339–1344.\n[459] L. Duan and et al., “Machine learning approaches for mdd detection\nand emotion decoding using eeg signals,” Frontiers in Human Neuro-\nscience, vol. 14, 2020.\n[460] X. Zhang and et al., “Eeg-based depression detection using convo-\nlutional neural network with demographic attention mechanism,” in\n2020 42nd annual international conference of the IEEE Engineering\nin Medicine & Biology Society (EMBC).\nIEEE, 2020, pp. 128–133.\n[461] L. X and et al., “A deep learning approach for mild depression recog-\nnition based on functional connectivity using electroencephalography,”\nFrontiers in neuroscience, vol. 14, p. 192, 2020.\n[462] Y. Xie and et al., “Anxiety and depression diagnosis method based\non brain networks and convolutional neural networks,” in 2020 42nd\nAnnual International Conference of the IEEE Engineering in Medicine\n& Biology Society (EMBC).\nIEEE, 2020, pp. 1503–1506.\n[463] A. Qayyum and et al., “Hybrid deep shallow network for assessment of\ndepression using electroencephalogram signals,” in Neural Information\nProcessing: 27th International Conference, ICONIP 2020, Bangkok,\nThailand, November 23–27, 2020, Proceedings, Part III 27.\nSpringer,\n2020, pp. 245–257.\n[464] U. C and et al., “Major depressive disorder classification based on dif-\nferent convolutional neural network models: deep learning approach,”\nClinical EEG and neuroscience, vol. 52(1), pp. 38–51, 2021.\n[465] H. D. S. B. A and et al., “Integration of deep learning for improved\ndiagnosis of depression using eeg and facial features,” Materials Today:\nProceedings, vol. 80, pp. 1965–1969, 2023.\n[466] A. O. Khadidos and et al., “Machine learning and electroencephalo-\ngram signal based diagnosis of dipression,” Neuroscience Letters, vol.\n809, p. 137313, 2023.\n[467] W. Mao and et al., “Resting state eeg based depression recognition re-\nsearch using deep learning method,” in Proceedings of the International\nConference on Brain Informatics (BI), Arlington, TX, USA, December\n2018, pp. 329–338.\n[468] J. Zhang and et al., “Depression screening using hybrid neural net-\nwork,” Multimedia Tools and Applications, vol. 82, pp. 26 955–26 970,\n2023.\n[469] W. Wu and et al., “Few-electrode eeg from the wearable devices using\ndomain adaptation for depression detection,” Biosensors, vol. 12, p.\n1087, 2022.\n[470] B. Zhang and et al., “Spatial–temporal eeg fusion based on neural\nnetwork for major depressive disorder detection,” Interdisciplinary\nScience: Computational Life Sciences, vol. 15, pp. 542–559, 2023.\n[471] D. A and et al., “Deep learning in computer aided diagnosis of mdd,”\nInt J In-novat Technol Explor Eng, vol. 8(6), pp. 464–468, 2019.\n[472] T. P. P and et al., “Eeg-based deep learning model for the automatic\ndetection of clinical depression,” Physical and Engineering Sciences\nin Medicine, vol. 43, pp. 1349–1360, 2020.\n[473] X. Song, D. Yan, L. Zhao, and L. Yang, “Lsdd-eegnet: An efficient\nend-to-end framework for eeg-based depression detection,” Biomedical\nSignal Processing and Control, vol. 75, p. 103612, 2022.\n[474] J. Zhu and et al., “Eeg based depression recognition using im-\nproved graph convolutional neural network,” Computers in Biology and\nMedicine, vol. 148, p. 105815, 2022.\n[475] B. Wang, Y. Kang, D. Huo, D. Chen, W. Song, and F. Zhang, “De-\npression signal correlation identification from different eeg channels\nbased on cnn feature extraction,” Psychiatry Research: Neuroimaging,\nvol. 328, p. 111582, 2023.\n[476] S. Zhang and et al., “Multi-view graph contrastive learning via adaptive\nchannel optimization for depression detection in eeg signals,” Interna-\ntional Journal of Neural Systems, vol. 33, p. 2350055, 2023.\n[477] D. Wang and et al., “Identification of depression with a semi-supervised\ngcn based on eeg data,” in 2021 IEEE International Conference on\nBioinformatics and Biomedicine (BIBM). IEEE, 2021, pp. 2338–2345.\n[478] W. Li and et al., “Gcns–fsmi: Eeg recognition of mental illness\nbased on fine-grained signal features and graph mutual information\nmaximization,” Expert Systems With Applications, vol. 228, p. 120227,\n2023.\n[479] O. S. L and et al., “Deep convolutional neural network model for\nautomated diagnosis of schizophrenia using eeg signals,” Applied\nSciences, vol. 9(14), p. 2870, 2019.\n[480] K. S. K and et al., “Schizonet: a robust and accurate margenau–hill\ntime-frequency distribution based deep neural network model for\nschizophrenia detection using eeg signals,” Physiological Measurement,\nvol. 44(3), p. 035005, 2023.\n[481] K. M. R and et al., “Weighted ordinal connection based functional\nnetwork classification for schizophrenia disease detection using eeg\nsignal,” Physical and Engineering Sciences in Medicine, vol. 46(3),\npp. 1055–1070, 2023.\n[482] W. Z and et al., “Automated rest eeg-based diagnosis of depression\nand schizophrenia using a deep convolutional neural network,” IEEE\nAccess, vol. 10, pp. 104 472–104 485, 2022.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n37\n[483] H. F and et al., “Fusion of multivariate eeg signals for schizophrenia\ndetection using cnn and machine learning techniques,” Information\nFusion, vol. 92, pp. 466–478, 2023.\n[484] K. S. K and et al., “Spwvd-cnn for automated detection of schizophre-\nnia patients using eeg signals,” IEEE Transactions on Instrumentation\nand Measurement, vol. 70, pp. 1–9, 2021.\n[485] L. I and et al., “Identification and diagnosis of schizophrenia based\non multichannel eeg and cnn deep learning model,” Schizophrenia\nResearch, vol. 271, pp. 28–35, 2024.\n[486] E. Lillo and et al., “Automated diagnosis of schizophrenia using eeg\nmicrostates and deep convolutional neural network,” Expert Systems\nwith Applications, vol. 209, p. 118236, 2022.\n[487] H. G¨oker, “1d-convolutional neural network approach and feature\nextraction methods for automatic detection of schizophrenia,” Signal,\nImage and Video Processing, vol. 17, no. 5, pp. 2627–2636, 2023.\n[488] A. Khodabakhsh and et al., “U-net based estimation of functional\nconnectivity from time series multi-channel eeg from schizophrenia\npatients,” in 2021 IEEE Nuclear Science Symposium and Medical\nImaging Conference (NSS/MIC), 2021.\n[489] G. Sahu and et al., “Scz-scan: an automated schizophrenia detection\nsystem from electroencephalogram signals,” Biomedical Signal Pro-\ncessing and Control, vol. 86, p. 105206, 2023.\n[490] L. Chu and et al., “Individual recognition in schizophrenia using deep\nlearning methods with random forest and voting classifiers: insights\nfrom resting state eeg streams,” arXiv preprint arXiv:1707.03467, 2017.\n[491] S. K and et al., “Spectral features based convolutional neural network\nfor accurate and prompt identification of schizophrenic patients,”\nProceedings of the Institution of Mechanical Engineers, vol. 2021, Part\nH: Journal of Engineering in Medicine.\n[492] B. C and et al., “From sound perception to automatic detection of\nschizophrenia: an eeg-based deep learning approach,” Frontiers in\nPsychiatry, vol. 12, p. 813460, 2022.\n[493] Z. Guo and et al., “Deep neural network classification of eeg data in\nschizophrenia,” in Proc 2021 IEEE 10th Data Driven Control Learn\nSyst Conf (DDCLS), 2021, pp. 1322–1327.\n[494] C. A. T. Naira and et al., “Classification of people who suffer\nschizophrenia and healthy people by eeg signals using deep learning,”\nInternational Journal of Advanced Computer Science and Applications,\nvol. 10, pp. 511–516, 2019.\n[495] N. Ilakiyaselvan and et al., “Reconstructed phase space portraits\nfor detecting brain diseases using deep learning,” Biomedical Signal\nProcessing and Control, vol. 71, p. 103278, 2022.\n[496] D. Calhas and et al., “On the use of pairwise distance learning for brain\nsignal classification with limited observations,” Artificial Intelligence in\nMedicine, vol. 105, p. 101852, 2020.\n[497] E. Nsugbe and et al., “Intelligence combiner: a combination of deep\nlearning and handcrafted features for an adolescent psychosis predic-\ntion using eeg signals,” in 2022 IEEE Int Work Metrol Ind 4.0 IoT\n(MetroInd4.0IoT), 2022, pp. 92–97.\n[498] V. Divya and et al., “Signal conducting system with effective optimiza-\ntion using deep learning for schizophrenia classification,” Computer\nSystems Science and Engineering, vol. 45, pp. 1869–1886, 2023.\n[499] M. Shen and et al., “Automatic identification of schizophrenia based\non eeg signals using dynamic functional connectivity analysis and 3d\nconvolutional neural network,” Computers in Biology and Medicine,\nvol. 160, p. 107022, 2023.\n[500] M. Saeedi and et al., “Schizophrenia diagnosis via fft and wavelet\nconvolutional neural networks utilizing eeg signals,” 2022.\n[501] C. A. Ellis and et al., “Examining effects of schizophrenia on eeg\nwith explainable deep learning models,” in 2022 IEEE 22nd Int Conf\nBioinformatics Bioengineering (BIBE), 2022, pp. 301–304.\n[502] A.-A. D and et al., “Identification of children at risk of schizophrenia\nvia deep learning and eeg responses,” IEEE Journal of biomedical and\nhealth informatics, vol. 25(1), pp. 69–76, 2020.\n[503] S. G and J. A. M, “Szhnn: a novel and scalable deep convolution\nhybrid neural network framework for schizophrenia detection using\nmultichannel eeg,” IEEE Transactions on Instrumentation and Mea-\nsurement, vol. 71, pp. 1–9, 2022.\n[504] K. Jindal and et al., “Bi-lstm-deep cnn for schizophrenia detection\nusing msst-spectral images of eeg signals,” in Artificial Intelligence-\nBased Brain-Computer Interface.\nElsevier, 2022, pp. 145–162.\n[505] B. S and et al., “Detection of schizophrenia using hybrid of deep learn-\ning and brain effective connectivity image from electroencephalogram\nsignal,” Computers in Biology and Medicine, vol. 146, p. 105570, 2022.\n[506] S. S and J. S. D, “A novel approach to schizophrenia detection:\nOptimized preprocessing and deep learning analysis of multichannel\neeg data,” Expert Systems with Applications, vol. 246, p. 122937, 2024.\n[507] A. Shoeibi and et al., “Automatic diagnosis of schizophrenia in eeg\nsignals using cnn-lstm models,” Frontiers in Neuroinformatics, vol. 15,\npp. 1–16, 2021.\n[508] G. Sharma and et al., “A smart healthcare framework for accurate\ndetection of schizophrenia using multichannel eeg,” IEEE Transactions\non Instrumentation and Measurement, vol. 72, pp. 1–9, 2023.\n[509] S. Guhan and et al., “Eeg based classification of children with learning\ndisabilities using shallow and deep neural network,” Biomedical Signal\nProcessing and Control, vol. 82, p. 104553, 2023.\n[510] C. R. Phang and et al., “Classification of eeg-based effective brain\nconnectivity in schizophrenia using deep neural networks,” in Int\nIEEE/EMBS Conf Neural Engineering (NER), 2019, pp. 401–406.\n[511] Q. Chang and et al., “Classification of first-episode schizophrenia,\nchronic schizophrenia and healthy control based on brain network of\nmismatch negativity by graph neural network,” IEEE Transactions on\nNeural Systems and Rehabilitation Engineering, vol. 29, pp. 1784–\n1794, 2021.\n[512] A. Nikhil Chandran and et al., “Eeg-based automated detection of\nschizophrenia using long short-term memory (lstm) network,” in Ad-\nvances in Machine Learning and Computational Intelligence: Proceed-\nings of ICMLCI 2019.\nSpringer Singapore, 2021, pp. 229–236.\n[513] S. R and et al., “A deep learning based model using rnn-lstm for the\ndetection of schizophrenia from eeg data,” Computers in Biology and\nMedicine, vol. 151, p. 106225, 2022.\n[514] L. B and et al., “Automatic detection of schizophrenia based on\nspatial–temporal feature mapping and levit with eeg signals,” Expert\nSystems with Applications, vol. 224, p. 119969, 2023.\n[515] C. L. Alves and et al., “Eeg functional connectivity and deep learning\nfor automatic diagnosis of brain disorders: Alzheimer’s disease and\nschizophrenia,” Journal of Physics: complexity, vol. 3, no. 2, p. 025001,\n2022.\n[516] Y. Wu and et al., “Schizophrenia detection based on eeg using recur-\nrent auto-encoder framework,” in International Conference on Neural\nInformation Processing.\nSpringer, 2022, pp. 62–73.\n[517] P. S. K and L. S. W, “Sasdl and rbatq: sparse autoencoder with\nswarm based deep learning and reinforcement based q-learning for\neeg classification,” IEEE open journal of engineering in medicine and\nbiology, vol. 3, pp. 58–68, 2022.\n[518] S. Parija and et al., “Autoencoder-based improved deep learning\napproach for schizophrenic eeg signal classification,” Pattern Analysis\nand Applications, vol. 26, no. 2, pp. 403–435, 2023.\n[519] N. M and et al., “A novel hybrid model in the diagnosis and classifica-\ntion of alzheimer’s disease using eeg signals: Deep ensemble learning\n(del) approach,” Biomedical Signal Processing and Control, vol. 89, p.\n105751, 2024.\n[520] Ieracitano and et al., “A convolutional neural network based self-\nlearning approach for classifying neurodegenerative states from eeg\nsignals in dementia,” in 2020 International Joint Conference on Neural\nNetworks (IJCNN).\nIEEE, 2020, pp. 1–8.\n[521] B. X and W. H, “Early alzheimer’s disease diagnosis based on eeg\nspectral images using deep learning,” Neural Networks, vol. 114, pp.\n119–135, 2019.\n[522] D. L. D and et al., “An intelligent alzheimer’s disease prediction using\nconvolutional neural network (cnn),” International Journal of Advanced\nResearch in Engineering and Technology (IJARET), vol. 11(4), pp. 12–\n22, 2020.\n[523] Huggins and et al., “Deep learning of resting-state electroencephalo-\ngram signals for three-class classification of alzheimer’s disease, mild\ncognitive impairment and healthy ageing,” Journal of Neural Engineer-\ning, vol. 18, no. 4, p. 046087, 2021.\n[524] X. W and et al., “A novel method for diagnosing alzheimer’s disease\nusing deep pyramid cnn based on eeg signals,” Heliyon, vol. 9(4), 2023.\n[525] R. K and Z. M, “Diagnose alzheimer’s disease and mild cognitive\nimpairment using deep cascadenet and handcrafted features from eeg\nsignals,” Biomedical Signal Processing and Control, vol. 99, p. 106895,\n2025.\n[526] I. C and et al., “A convolutional neural network approach for classi-\nfication of dementia stages based on 2d-spectral representation of eeg\nrecordings,” Neurocomputing, vol. 323, pp. 96–107, 2019.\n[527] A. K and et al., “Eeg-based clinical decision support system for\nalzheimer’s disorders diagnosis using emd and deep learning tech-\nniques,” Frontiers in Human Neuroscience, vol. 17, p. 1190203, 2023.\n[528] D. Kim and K. Kim, “Detection of early stage alzheimer’s disease using\neeg relative power with deep neural network,” in 2018 40th Annual\nInternational Conference of the IEEE Engineering in Medicine and\nBiology Society (EMBC).\nIEEE, 2018, pp. 352–355.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n38\n[529] Y. Zhao and L. He, “Deep learning in the eeg diagnosis of alzheimer’s\ndisease,” in Computer Vision-ACCV 2014 Workshops: Singapore, Sin-\ngapore, November 1-2, 2014, Revised Selected Papers, Part I 12.\nSpringer, 2015, pp. 340–353.\n[530] L. K and et al., “Feature extraction and identification of alzheimer’s\ndisease based on latent factor of multi-channel eeg,” IEEE Transactions\non Neural Systems and Rehabilitation Engineering, vol. 29, pp. 1557–\n1567, 2021.\n[531] M. F. C and et al., “Deep learning representation from electroen-\ncephalography of early-stage creutzfeldt-jakob disease and features\nfor differentiation from rapidly progressive dementia,” International\njournal of neural systems, vol. 27(02), p. 1650039, 2017.\n[532] S. S. A. A and et al., “Dynamical system based compact deep hybrid\nnetwork for classification of parkinson disease related eeg signals,”\nNeural Networks, vol. 130, pp. 75–84, 2020.\n[533] K. S. K and et al., “Pdcnnet: An automatic framework for the detection\nof parkinson’s disease using eeg signals,” IEEE Sensors Journal, vol.\n21(15), pp. 17 017–17 024, 2021.\n[534] Z.\nR\nand\net\nal.,\n“Eeg\nanalysis\nof\nparkinson’s\ndisease\nusing\ntime–frequency analysis and deep learning,” Biomedical Signal Pro-\ncessing and Control, vol. 78, p. 103883, 2022.\n[535] X. Shi, T. Wang, L. Wang, H. Liu, and N. Yan, “Hybrid convolutional\nrecurrent neural networks outperform cnn and rnn in task-state eeg\ndetection for parkinson’s disease,” in 2019 Asia-Pacific signal and\ninformation processing association annual summit and conference\n(APSIPA ASC).\nIEEE, 2019, pp. 939–944.\n[536] P. M and et al., “Deep-learning detection of mild cognitive impair-\nment from sleep electroencephalography for patients with parkinson’s\ndisease,” Plos one, vol. 18(8), p. e0286506, 2023.\n[537] M. Shaban, “Automated screening of parkinson’s disease using deep\nlearning based electroencephalography,” in 2021 10th international\nIEEE/EMBS conference on neural engineering (NER).\nIEEE, 2021,\npp. 158–161.\n[538] S. R. J and D. P, “Generalizable electroencephalographic classification\nof parkinson’s disease using deep learning,” Informatics in Medicine\nUnlocked, vol. 42, p. 101352, 2023.\n[539] L. S and et al., “A convolutional-recurrent neural network approach\nto resting-state eeg classification in parkinson’s disease,” Journal of\nneuroscience methods, vol. 361, p. 109282, 2021.\n[540] S. Lee, R. Hussein, and M. J. McKeown, “A deep convolutional-\nrecurrent neural network architecture for parkinson’s disease eeg clas-\nsification,” in 2019 IEEE global conference on signal and information\nprocessing (GlobalSIP).\nIEEE, 2019, pp. 1–4.\n[541] L. K and et al., “Parkinson’s disease detection and classification\nusing eeg based on deep cnn-lstm model,” Biotechnology and Genetic\nEngineering Reviews, vol. 40(3), pp. 2577–2596, 2024.\n[542] Z. S and et al., “An interpretable model based on graph learning for\ndiagnosis of parkinson’s disease with voice-related eeg,” NPJ Digital\nMedicine, vol. 7(1), p. 3, 2024.\n[543] A. Ahmadi and et al., “Computer aided diagnosis system using deep\nconvolutional neural networks for adhd subtypes,” Biomedical Signal\nProcessing and Control, vol. 63, p. 102227, 2021.\n[544] M. Bakhtyari and S. Mirzaei, “Adhd detection using dynamic connec-\ntivity patterns of eeg data and convlstm with attention framework,”\nBiomedical Signal Processing and Control, vol. 76, p. 103708, 2022.\n[545] B. Karakas¸ and et al., “Convmixer ve sdd kullanılarak dehb hastalı˘gının\neeg sinyalleri ile otomatik olarak tespit edilmesi,” T¨urk Do˘ga ve Fen\nDergisi, vol. 13, no. 1, p. 19–25, 2024.\n",
  "metadata": {
    "source_path": "papers/arxiv/Deep_Learning-Powered_Electrical_Brain_Signals_Analysis_Advancing\n__Neurological_Diagnostics_ace6631e504ec3cf.pdf",
    "content_hash": "ace6631e504ec3cf07e1c3c34369d1843a81d9c3267739154d42766c2d5fd695",
    "arxiv_id": null,
    "title": "Deep_Learning-Powered_Electrical_Brain_Signals_Analysis_Advancing\n__Neurological_Diagnostics_ace6631e504ec3cf",
    "author": "",
    "creation_date": "D:20250225025245Z",
    "published": "2025-02-25T02:52:45",
    "pages": 38,
    "size": 1527946,
    "file_mtime": 1740470168.1499867
  }
}