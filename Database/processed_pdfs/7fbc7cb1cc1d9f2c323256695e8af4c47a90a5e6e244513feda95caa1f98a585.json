{
  "text": "Evaluating the Effectiveness of Large Language\nModels in Automated News Article\nSummarization\nLionel Richy Panlap Houamegni1 and Fatih Gedikli1[0000−0001−6190−0449]\nInstitute of Computer Science\nUniversity of Applied Sciences Ruhr West\nMülheim an der Ruhr, Germany\nlionel.panlaphouamegni@stud.hs-ruhrwest.de, fatih.gedikli@hs-ruhrwest.de\nAbstract. The automation of news analysis and summarization pre-\nsents a promising solution to the challenge of processing and analyzing\nvast amounts of information prevalent in today’s information society.\nLarge Language Models (LLMs) have demonstrated the capability to\ntransform vast amounts of textual data into concise and easily compre-\nhensible summaries, offering an effective solution to the problem of in-\nformation overload and providing users with a quick overview of relevant\ninformation. A particularly significant application of this technology lies\nin supply chain risk analysis. Companies must monitor the news about\ntheir suppliers and respond to incidents for several critical reasons, in-\ncluding compliance with laws and regulations, risk management, and\nmaintaining supply chain resilience. This paper develops an automated\nnews summarization system for supply chain risk analysis using LLMs.\nThe proposed solution aggregates news from various sources, summa-\nrizes them using LLMs, and presents the condensed information to users\nin a clear and concise format. This approach enables companies to op-\ntimize their information processing and make informed decisions. Our\nstudy addresses two main research questions: (1) Are LLMs effective\nin automating news summarization, particularly in the context of sup-\nply chain risk analysis? (2) How effective are various LLMs in terms of\nreadability, duplicate detection, and risk identification in their summari-\nzation quality? In this paper, we conducted an offline study using a range\nof publicly available LLMs at the time and complemented it with a user\nstudy focused on the top performing systems of the offline experiments to\nevaluate their effectiveness further. Our results demonstrate that LLMs,\nparticularly Few-Shot GPT-4o mini, offer significant improvements in\nsummary quality and risk identification.\nKeywords: News Summarization · Large Language Models · Automated\nNews Analysis · Supply Chain Risk Analysis.\n1\nIntroduction\nIn an increasingly interconnected and globalized economy, companies must ef-\nficiently manage complex supply chains while identifying potential risks early.\narXiv:2502.17136v1  [cs.AI]  24 Feb 2025\n\n2\nPanlap Houamegni and Gedikli\nRecent events, such as the COVID-19 pandemic and geopolitical tensions, have\nhighlighted the vulnerabilities of global supply chains and underscored the need\nfor proactive risk analysis [8,5]. In this context, automated processing and anal-\nysis of news information are becoming essential to help companies identify and\nassess supply chain risks in real time. Automated news summarization helps\nreduce information overload, speed decision making, and improve awareness of\nimportant events. It can identify global events and trends that affect the supply\nchain, highlight early warning signals for potential risks, and improve supplier\nand market monitoring through continuous news analysis.\nThis study explores how modern LLMs can revolutionize automated news\nsummarization for supply chain risk analysis. LLMs such as GPT-4, Mistral, and\nLLaMA have made remarkable advancements in natural language processing,\nopening new possibilities for efficiently analyzing and summarizing large volumes\nof text.\nThe objective of this research is to evaluate and compare the performance\nof various LLMs in the context of automated news summarization for supply\nchain risk analysis. Both quantitative and qualitative metrics are used to provide\na comprehensive evaluation of model performance. A key focus is on various\nprompting techniques, including zero-shot, few-shot, and fine-tuning approaches,\nto evaluate their impact on summary quality.\nThe significance of this research arises from the growing demand for efficient\nand reliable risk analysis methods in supply chains [6,8]. Integrating LLMs into\nexisting risk management frameworks could enable companies to respond more\nquickly to potential disruptions and enhance supply chain resilience. Further-\nmore, this work contributes to the broader scientific discourse on the applicabil-\nity and limitations of LLMs in domain-specific tasks.\nMethodologically, this study employs an experimental design in which various\nLLMs are evaluated using a carefully curated dataset of news articles. The as-\nsessment utilizes established metrics such as ROUGE, BLEU, and BERTScore,\nalongside qualitative analyses leveraging G-Eval and human evaluators. This\ncombination of quantitative and qualitative methods provides a nuanced under-\nstanding of model performance, considering factors such as accuracy, efficiency,\nscalability, and cost.\nResearch on news summarization and its applications in risk analysis re-\nmains an evolving field with ongoing challenges. Key issues, including factual\naccuracy, the tendency of models to hallucinate, and inherent biases, remain at\nthe forefront of current discussions and constitute essential aspects of this study.\nThe findings of this investigation aim not only to advance research in AI and\nsupply chain management, but also to provide practical insights for companies\nlooking to integrate LLMs into their risk analysis workflows.\n2\nRelated Work\nThe field of automated text summarization, particularly in the context of supply\nchain risk analysis, has evolved significantly with the advent of LLMs. This\n\nEvaluating Large Language Models for News Summarization\n3\nsection provides an overview of prior research, highlighting key advancements,\nmethodologies, and persisting challenges.\n2.1\nAdvancements in Automated News Summarization\nLiu and Lapata (2019) demonstrated that pretrained transformer models offer\nsubstantial improvements in news summarization. By integrating extractive and\nabstractive techniques, they improved summary coherence and informativeness,\nparticularly when fine-tuned for domain-specific applications [9].\nStiennon et al. (2020) explored human feedback-driven training for summa-\nrization. They developed a reward model based on human preference alignment,\nwhich significantly improved model performance compared to traditional super-\nvised learning techniques [15].\nGoyal et al. (2022) assessed GPT-3’s capabilities in news summarization.\nThey found that GPT-3 could generate high-quality summaries without explicit\nfine-tuning, often outperforming human-generated summaries in coherence and\nfluency [3].\nWei et al. (2022) introduced chain-of-thought prompting, demonstrating how\nstructured reasoning prompts enable LLMs to perform complex summarization\ntasks with greater contextual awareness [18].\nLiu et al. (2023) proposed using LLM-generated summaries as reference train-\ning data for smaller models. Their approach enhanced the efficiency of smaller-\nscale summarization models, presenting a cost-effective alternative to fine-tuning\nlarge models [11].\nZhang et al. (2024) studied the impact of instruction tuning on zero-shot sum-\nmarization. They found that aligning models with high-quality reference summa-\nries significantly improved performance, often rivaling human-written summaries\n[20].\nFurther, Zhang et al. (2024) provided a systematic review of text summariza-\ntion. They examined the transition from extractive to abstractive techniques and\nhighlighted key challenges, such as factual accuracy, handling long documents,\nand mitigating biases in generated content [19].\nAn underexplored aspect of summarization is identifying related news arti-\ncles—also known as news story chains. Gedikli et al. (2021) addressed this chal-\nlenge in [2] by leveraging clustering and Named Entity Recognition (NER) to cre-\nate datasets for automated story chain detection, significantly reducing manual\nlabeling efforts while maintaining high-quality outputs. Similarly, Stockem Novo\nand Gedikli (2023) [16] investigate BERT-based methods for near-duplicate news\narticle detection, highlighting the importance of NER in identifying duplicate\ncontent. Accurate duplicate detection is essential for risk news summarization,\nas redundant information can distort risk assessments and lead to inefficiencies\nin decision-making.\n\n4\nPanlap Houamegni and Gedikli\n2.2\nResearch Gaps and Contributions of This Work\nDespite significant progress, several challenges remain unaddressed in the field\nof automated news summarization, particularly in the context of supply chain\nrisk analysis. This study aims to bridge the following gaps:\n– Domain-Specific Adaptation: Most existing LLMs are not optimized for\nsupply chain risk analysis. This study explores methods to tailor LLMs for\nindustry-specific summarization.\n– Factual Accuracy and Bias Mitigation: Ensuring the reliability of gener-\nated summaries remains a critical issue. We investigate strategies to enhance\nfactual accuracy and mitigate biases [20].\n– Real-Time Integration: The deployment of LLMs for real-time news anal-\nysis and early risk detection has been insufficiently explored. This work ex-\namines the feasibility of integrating LLMs into dynamic monitoring systems.\n– Evaluation of Readability and Duplicate Detection: While some mod-\nels produce coherent summaries, their effectiveness in detecting duplicate\ninformation and maintaining readability in large-scale analysis remains un-\nclear.\n– Fine-Tuning for Risk Identification: There is a lack of research on opti-\nmizing LLMs specifically for identifying and categorizing risk-related infor-\nmation in news articles relevant to supply chain disruptions.\nBy addressing these gaps, our work contributes to the ongoing development\nof AI-driven risk analysis solutions, demonstrating how LLMs can be effectively\nleveraged to enhance supply chain monitoring and resilience.\n3\nMethodology\nThis study adopts a mixed-methods approach, combining qualitative and quan-\ntitative techniques to ensure a comprehensive and nuanced analysis. Data will\nbe collected from a diverse range of news sources, including local, regional, and\ninternational news agencies, as well as digital magazines. When news articles\nwere not originally in English, they were translated using state-of-the-art trans-\nlation models from Hugging Face1 to ensure consistency in analysis. However,\ndue to copyright restrictions, the original news articles used in this study cannot\nbe publicly shared.\nTo develop the news summarization system, a variety of large language mod-\nels (LLMs) will be employed, including GPT-4o, GPT-4o mini, GPT-3.5 Turbo,\nMistral Large 2, Mistral 8x22b, Mistral 7b, Llama-3.2 90b, Llama-3.1 70b, Llama\n3.1 8b, Llama 3 70b, Llama 3 8b, Gemma 2-9b, Gemma 7b, and two fine-tuned\nmodels (one based on GPT-4o mini and another on GPT-3.5 Turbo). These\nmodels will be evaluated under different learning paradigms—zero-shot learn-\ning, few-shot learning, and fine-tuning—to optimize their performance and the\naccuracy of the generated summaries.\n1 https://huggingface.co\n\nEvaluating Large Language Models for News Summarization\n5\n3.1\nExperimental Design\n– Input: News articles from local, regional, and international sources, includ-\ning digital magazines, translated to English when needed.\n– Output: Summarized, duplication-free news articles that highlight potential\nrisks in supply chains, enabling informed decision-making.\n– Model Comparison: A thorough comparison of the performance of var-\nious LLMs will be conducted. The evaluation will focus on the quality of\nthe summaries and the models’ ability to identify risks. Different learning\nstrategies—zero-shot learning, few-shot learning, and fine-tuning—will be\nemployed to optimize the models’ effectiveness.\n– Hypothesis: The latest LLMs will produce higher-quality summaries and\nmore accurate risk identification compared to older models.\n– Independent Variable: The specific language model used.\n– Dependent Variables: The quality of the summaries and the accuracy of\nrisk identification.\n– Procedure: News articles will be input into the various language models,\nand the resulting summaries will be evaluated based on precision, relevance,\nand the ability to identify risks. Additional metrics such as price, speed,\nlatency, and context windows will also be considered. The results will be\nsubjected to statistical analysis to compare the performance of the models.\n– Expected Results: It is anticipated that newer models, such as GPT-4o for\nproprietary models and LLaMA-3.2 90b for open-source models, will deliver\nsuperior summary quality and more precise risk identification.2 This im-\nprovement is expected to provide a stronger foundation for decision-making\nin supply chain management.\nIt is important to emphasize that these models represent the state of the art\nin LLMs at the time of our study (October 2024).\n3.2\nWorkflow\nThe workflow for this study is designed to systematically address the challenges\nof supply chain risk analysis using computational intelligence techniques. The\nprocess is divided into seven key stages, as illustrated in Figure 1, and described\nbelow:\n(1) Data Import and Exploratory Data Analysis (EDA):\nThe raw dataset consists of 1,535 press articles, each enriched with meta-\ndata, including URLs, publication dates, headlines, abstracts, and sentiment\nratings. Additional attributes capture industry classifications, risk categories,\nand references to key entities such as people, organizations, and locations. The\ndataset, provided by graphworks.ai3—an AI-powered platform for real-time\nnews monitoring—spans 28 industries, with Industrial Manufacturing and Ser-\nvices, Transportation, and Energy being the most prevalent. This distribution\n2 See https://artificialanalysis.ai for a broad comparison of AI models and API\nproviders.\n3 https://graphworks.ai\n\n6\nPanlap Houamegni and Gedikli\nFig. 1. Evaluation Workflow\naligns with key focus areas in supply chain risk analysis. Risk classifications en-\ncompass broad categories such as Interruption and Shutdown, as well as more\nspecific concerns like Cybersecurity and Data Privacy. Initial data cleaning in-\nvolved removing irrelevant columns, correcting inconsistent values, and ensuring\ndata integrity for downstream tasks.\n(2) Separation of Training and Test Data: To ensure a robust eval-\nuation, the dataset was divided into distinct training and test subsets using\nan 80/20 split. Specifically, 1,228 articles (80%) were allocated for training,\nwhile 307 articles (20%) were reserved for testing. This division ensures a bal-\nanced evaluation of model performance, allowing for an unbiased assessment of\ngeneralizability on unseen data.\n(3) Metadata Extraction: A computational pipeline is implemented to\nextract metadata, including article titles, original links, industry classifications,\nand risk perceptions. This metadata is integrated into the input parameters\nfor summarization models to enhance contextual understanding and mitigate\nhallucinations, ensuring consistency across different LLMs.\n(4) Prompt Engineering: Effective prompt design is crucial for guid-\ning LLMs in generating high-quality summaries. Drawing on best practices in\nprompt engineering4, we employ few-shot prompting techniques [1] to improve\nperformance. Key parameters are carefully configured:\n– Maximum Token Count: 4096 (total length of input and output)\n– Temperature: 0.3 (optimized through iterative experimentation)\n– Top P (nucleus sampling): 0.5 (determined via systematic testing)\n4 OpenAI, Prompt Engineering - Enhance Results with Prompt Engineering Strate-\ngies. https://platform.openai.com/docs/guides/prompt-engineering\n\nEvaluating Large Language Models for News Summarization\n7\n(5) Fine-Tuning: In addition to evaluating the base models, we fine-tune\nGPT-4o mini and GPT-3.5 Turbo for the specific task of news summarization in\nsupply chain risk analysis using our domain-specific dataset. This step leverages\ncomputation techniques such as LoRA [7] to adapt the models to the unique\ncharacteristics of the dataset, enhancing their ability to capture nuanced risk-\nrelated information. Both fine-tuned and non-fine-tuned variants are tested to\ncompare their performance.\nIt should be noted that due to cost, time, and resource constraints, we could\nnot utilize the entire training dataset during fine-tuning. Additionally, OpenAI’s\nfine-tuning framework imposes a token limit of ≤4096 tokens per training exam-\nple. As a result, in some cases, not all 10 articles for a given summary fit within\nthe context window, requiring truncation to meet the token limit constraint.\nHowever, each training example contained at least 7–10 news articles along with\na corresponding summary.\n(6) Evaluation: A comprehensive evaluation framework is employed to com-\npare model performance across zero-shot, few-shot, and fine-tuned settings. Key\nevaluation criteria include:\n– Summary Quality: Assessed using metrics such as coherence, relevance,\nand informativeness.\n– Computational Efficiency: Measured in terms of cost (USD per million\ntokens), output speed (tokens per second), latency (time to first token), and\ncontext window size.\n– G-Eval: A novel evaluation framework that provides deeper insights into\nmodel strengths and weaknesses, enhancing the accuracy of performance\nassessments.This method follows best practices as described by Anadkat and\nFishman.5\n– Human Evaluation: Essential for validating machine-generated summa-\nries, human evaluation ensures alignment with domain-specific requirements\nand user expectations [13,10,14].\n(7) Results and Discussion: The final results are presented, showcasing\nthe effectiveness of the proposed workflow in generating high-quality summa-\nries for supply chain risk analysis. The findings are analyzed in detail, with a\ndiscussion on their implications and potential applications. Additionally, future\nresearch directions are identified, particularly the integration of advanced LLM-\nbased approaches (e.g., retrieval-augmented generation, reinforcement learning\nwith human feedback) to further enhance model performance.\n5 Shyamal\nAnadkat\nand\nSimón\nFishman.\nHow\nto\nevaluate\na\nsummariza-\ntion\ntask.\nhttps://cookbook.openai.com/examples/evaluation/how_to_eval_\nabstractive_summarization\n\n8\nPanlap Houamegni and Gedikli\n4\nResults\n4.1\nInference with different LLMs\nThis section presents the experimental results of employing multiple LLMs to\ngenerate summaries for news articles. In the context of LLMs, inference refers to\nthe process of utilizing a trained model to generate predictions or derive insights\nfrom new, unseen data. Inference can be conducted using various approaches,\nincluding zero-shot, few-shot, and fine-tuning. This study evaluates the perfor-\nmance of several state-of-the-art language models6 to address the central research\nquestion: Can zero-shot prompting, few-shot prompting, and fine-tuning provide\neffective solutions for summarizing news articles in the context of supply chain\nrisk analysis?\nIn light of recent research findings demonstrating that few-shot learning con-\nsistently outperforms zero-shot approaches and significantly enhances model per-\nformance [1], GPT-4o is employed as the reference model in a few-shot learning\ncontext. As part of the latest GPT-4 generation, GPT-4o strikes an optimal bal-\nance between performance and accessibility, making it particularly suitable for\nresearch applications. The model has demonstrated exceptional capabilities in\ncomplex language understanding tasks, including reasoning and knowledge-based\nbenchmarks such as the Massive Multitask Language Understanding (MMLU)\n[4], MMLU-Pro [17], and General Purpose Question Answering (GPQA) [12].\nThese achievements underscore GPT-4o’s robustness and versatility, solidifying\nits position as a reliable choice for this study. Additionally, a human expert has\nreviewed and modified the GPT-4o reference summary where necessary, ensuring\nthe accuracy and comprehensiveness of the information presented.\n4.2\nQuantitative Evaluation\nAutomatic Analysis Using Similarity Metrics This analysis 1 compares\nvarious LLMs under different configurations (zero-shot, few-shot, fine-tuning).\nNote that R-1, R-2, and R-L represent ROUGE-1, ROUGE-2, and ROUGE-L\nscores, respectively. Tests were conducted by having each LLM summarize 10 ar-\nticles in each summarization step. Key findings from the quantitative evaluation\nof automated summaries using similarity metrics include:\n– Model Performance: GPT-4o (zero-shot) achieved the best performance\nwith an average score of 0.7402 across all metrics. Mistral Large 2 (zero-shot)\nand GPT-4o mini (few-shot) followed in 2nd and 3rd place.\n– Comparison of Prompting Methods: Zero-shot prompting showed sur-\nprisingly good results, especially with advanced models like GPT-4o and\n6 GPT-4o, GPT-4o mini, GPT-4o mini Fine-Tuned, GPT-3.5 Turbo, GPT-3.5 Turbo\nFine-Tuned, Mistral Large 2, Mistral 8x22b, Mistral 7b, Llama-3.2 90b, Llama-3.1\n70b, Llama 3.1 8b, Llama 3 70b, Llama 3 8b, Gemma 2-9b, and Gemma 7b. These\nmodels represent the state of the art available at the time the experiments were\nconducted.\n\nEvaluating Large Language Models for News Summarization\n9\nTable 1. Evaluation Metrics Using Reference Summaries (Sorted by Average)\nModel\nR-1 R-2 R-L BLEU BERTScore\n∅\nZero-Shot GPT-4o\n0.781 0.601 0.774 0.595\n0.950\n0.7402\nZero-Shot Mistral Large 2 0.719 0.494 0.701 0.449\n0.941\n0.6608\nFew-Shot GPT-4o mini\n0.734 0.480 0.720 0.389\n0.935\n0.6516\nZero-Shot GPT-3.5\n0.708 0.469 0.703 0.406\n0.932\n0.6436\nFew-Shot LLaMA3 70B\n0.717 0.464 0.706 0.330\n0.948\n0.6330\nFew-Shot Mistral Large 2 0.676 0.464 0.663 0.398\n0.945\n0.6292\nFine-Tuned GPT-4o mini 0.677 0.448 0.659 0.374\n0.934\n0.6184\nZero-Shot LLaMA3 70B 0.662 0.422 0.652 0.376\n0.920\n0.6064\nZero-Shot GPT-4o mini\n0.683 0.411 0.660 0.354\n0.918\n0.6052\nFew-Shot Gemma2 9B\n0.649 0.409 0.624 0.374\n0.945\n0.6002\nFew-Shot GPT-3.5\n0.682 0.371 0.662 0.316\n0.943\n0.5948\nFine-Tuned with GPT-3.5 0.645 0.403 0.631 0.351\n0.923\n0.5906\nFew-Shot LLaMA3-1 70B 0.645 0.409 0.629 0.335\n0.935\n0.5906\nFew-Shot LLaMA3-2 90B 0.659 0.398 0.648 0.283\n0.922\n0.5820\nFew-Shot LLaMA3-1 8B 0.631 0.401 0.618 0.316\n0.939\n0.5810\nZero-Shot Mistral 7B\n0.622 0.385 0.601 0.356\n0.925\n0.5778\nZero-Shot Mistral 822B\n0.638 0.390 0.626 0.309\n0.910\n0.5746\nFew-Shot Mistral 7B\n0.649 0.403 0.627 0.289\n0.903\n0.5742\nZero-Shot Gemma2 9B\n0.636 0.394 0.627 0.305\n0.908\n0.5740\nFew-Shot LLaMA3 8B\n0.632 0.395 0.613 0.295\n0.934\n0.5738\nZero-Shot LLaMA3 8B\n0.632 0.391 0.621 0.264\n0.924\n0.5664\nZero-Shot LLaMA3-1 8B 0.626 0.383 0.615 0.276\n0.915\n0.5630\nZero-Shot LLaMA3-2 90B 0.626 0.368 0.611 0.293\n0.903\n0.5602\nZero-Shot LLaMA3-1 70B 0.624 0.366 0.611 0.290\n0.906\n0.5594\nFew-Shot Mistral 822B\n0.577 0.330 0.559 0.273\n0.905\n0.5288\nZero-Shot Gemma 7B\n0.476 0.225 0.454 0.163\n0.877\n0.4390\nFew-Shot Gemma 7B\n0.227 0.059 0.197 0.004\n0.813\n0.2600\n\n10\nPanlap Houamegni and Gedikli\nMistral Large 2. Few-shot prompting improved performance for some mod-\nels but was not consistently superior. Fine-tuning (e.g., with GPT-4o mini)\nyielded strong results but did not achieve top performance.\n– Model Sizes and Performance: Larger models (e.g., GPT-4o, Mistral\nLarge 2) tended to perform better, while smaller models like Gemma 7B\nshowed significantly weaker performance.\n– Metrics Comparison: BERTScore consistently showed high values, indi-\ncating good semantic similarity. Similarly, ROUGE-1 and ROUGE-L pro-\nvided consistent results for evaluating summary quality.\nMulti-criteria comparative analysis The multi-criteria comparative analysis\nincludes metrics such as context window, output speed, latency, costs, and token\nprocessing. Key findings include:\n– Summary Quality and Context Window: Models like GPT-4o, GPT-\n4o mini, LLaMA 3.1 (70B), LLaMA 3.2, and Mistral Large 2 achieve out-\nstanding results in summarization and risk identification. They offer a large\ncontext window of 128,000 tokens, enabling detailed analyses.\n– Efficiency in Speed and Cost: LLaMA models, especially LLaMA3-8B,\nare leaders in token processing rate, offering an ideal combination of efficiency\nand value for money. Open-source models like Gemma 2, Mistral 7B, Mistral\n8x22B, and the LLaMA series generally have lower costs per token.\n– Prompting Methods: Few-shot prompting proved more effective for many\nmodels, especially in complex tasks. However, zero-shot prompting showed\nsurprisingly strong results with models like GPT-4o, Mistral Large 2, and\nLLaMA 3 70B.\n– Cost Analysis and Efficiency: Proprietary models like GPT-4o and Mis-\ntral Large 2 guarantee high quality but are more cost-intensive. Open-source\nmodels (e.g., LLaMA, Gemma, Mistral 8x22B, and Mistral 7B) offer more\ncost-effective token and processing times.\n– Recommended Models and Configurations: Models with large context\nwindows (e.g., GPT-4o, GPT4o-mini, Mistral Large 2, and LLaMA 3.1 70B)\nare particularly recommended for high-quality summaries and precise risk\nanalyses.\nThis analysis shows that model selection strongly depends on the specific appli-\ncation requirements. The decision between proprietary and open-source models\nshould be based on budget, quality requirements, and efficiency needs.\n4.3\nQualitative Evaluation\nEvaluation with G-Eval The qualitative evaluation of models using G-Eval\nreveals interesting differences and similarities in terms of coherence, consistency,\n\nEvaluating Large Language Models for News Summarization\n11\nTable 2. Evaluation Metrics Using Reference Summaries (Sorted by Average)\nEvaluation Type\nCoherence Consistency Fluency Potential Impact Relevance ∅\nFew-Shot Mistral 822B\n10\n10\n10\n9\n10\n9.8\nFew-Shot GPT-4o mini\n10\n10\n10\n9\n10\n9.8\nZero-Shot Gemma2 9B\n10\n10\n10\n9\n10\n9.8\nZero-Shot GPT-4o mini\n10\n10\n10\n9\n10\n9.8\nFew-Shot GPT-3.5 Turbo\n10\n10\n10\n8\n10\n9.6\nZero-Shot LLaMA3-2 90B\n10\n10\n9\n9\n10\n9.6\nZero-Shot Mistral 822B\n9\n10\n10\n9\n10\n9.6\nZero-Shot LLaMA3-1 8B\n10\n10\n10\n8\n10\n9.6\nZero-Shot Gemma 7B\n9\n10\n9\n9\n10\n9.4\nZero-Shot LLaMA3 70B\n9\n10\n10\n8\n10\n9.4\nZero-Shot LLaMA3-1 70B\n9\n10\n9\n10\n9\n9.4\nFew-Shot LLaMA3 8B\n9\n10\n9\n8\n10\n9.2\nFew-Shot Mistral 7B\n9\n10\n9\n8\n10\n9.2\nFine-Tuned GPT-4o mini 2024\n8\n10\n9\n9\n10\n9.2\nFine-Tuned with GPT-3.5\n8\n10\n9\n9\n10\n9.2\nZero-Shot GPT-4o\n9\n10\n10\n9\n8\n9.2\nZero-Shot Mistral 7B\n9\n10\n9\n8\n10\n9.2\nFew-Shot LLaMA3 70B\n9\n10\n9\n8\n9\n9.0\nFew-Shot Mistral Large 2\n9\n9\n9\n8\n10\n9.0\nFew-Shot LLaMA3-1 70B\n9\n10\n9\n8\n9\n9.0\nZero-Shot Mistral Large 2\n9\n10\n9\n8\n9\n9.0\nFew-Shot LLaMA3-2 90B\n9\n10\n9\n8\n8\n8.8\nFew-Shot Gemma2 9B\n8\n9\n9\n8\n9\n8.6\nFew-Shot LLaMA3-1 8B\n8\n10\n9\n8\n8\n8.6\nZero-Shot LLaMA3 8B\n8\n8\n9\n8\n10\n8.6\nZero-Shot GPT-3.5 Turbo\n9\n8\n9\n8\n8\n8.4\nFew-Shot Gemma 7B\n8\n0\n8\n8\n0\n4.8\n\n12\nPanlap Houamegni and Gedikli\nfluency, relevance, and potential impact. This analysis provides insights into the\nstrengths of the models and their suitability for specific applications in supply\nchain management.\n– Top-Performing Models: Zero-Shot and Few-Shot GPT-4o mini, Zero-\nShot Gemma2 9B, and Few-Shot Mistral 822B achieved the highest average\nscore of 9.8. These models excel in generating coherent and consistent con-\ntent, making them well-suited for applications where accuracy and precision\nare crucial.\n– Potential Impact: Some models received lower scores (8) in potential im-\npact. This could indicate difficulties in precisely capturing the context of\nsupply chain management, potentially limiting their practical applicability\nin decision-intensive areas.\n– Few-Shot vs. Zero-Shot Configurations: Interestingly, some Zero-Shot\nmodels (like Gemma2 9B and GPT-4o mini) performed as well as or better\nthan their Few-Shot counterparts. This suggests these models can handle\ncomplex tasks well without specific training.\n– Fine-Tuned Models: While achieving high scores in coherence and con-\nsistency, fine-tuned models lagged behind the best Few-Shot and Zero-Shot\nmodels in potential impact and relevance. Fine-tuning may meet specific re-\nquirements but shows less flexibility and generalization ability in processing\nnew content.\n– Weaknesses of Individual Models: The Few-Shot Gemma 7B model,\nwith an average score of 4.8, showed clear weaknesses in coherence and rel-\nevance. These low values suggest limitations in architecture or training that\ncould hinder reliable application.\n– Open-Source Models and Consistency: Open-source models like Gem-\nma2, Mistral 8x22B, Mistral 7B, and LLaMA consistently achieved high\nscores, often competing with proprietary models. This consistency demon-\nstrates that open-source approaches can offer a valid alternative for high-\nquality, automated text generation.\nHuman Evaluation To complement the quantitative analyses, a human eval-\nuation was conducted to assess the quality of summaries generated by large lan-\nguage models (LLMs). Initially, the evaluation was designed to include 27 models\nwith 10 articles each. However, due to the significant workload for participants,\nthe methodology was refined to optimize efficiency while maintaining relevance.\nThe final approach involved evaluating three articles per model. The models were\nselected based on their performance in quantitative metrics (ROUGE, BLEU,\nand BERTScore) and vendor diversity to ensure balanced representation.\nThe evaluation focused on five key criteria: coherence, consistency, fluency,\npotential impact, and relevance. Feedback was collected from 31 participants\n\nEvaluating Large Language Models for News Summarization\n13\nover a month-long period, providing valuable insights into the strengths and\nlimitations of the models. The participant group consisted of 11 men (35.5%)\nand 20 women (64.5%), with an average age of 29 years. The study took place\nfrom October 1 to October 30, 2024.\nThe eight models selected for evaluation were: Zero-shot GPT-4o, Few-shot\nGPT-4o mini, Zero-shot Mistral Large 2, Few-shot Open-Mistral-8x22b, Few-\nshot LLaMA 3.1 70B, Zero-shot LLaMA 3 70B, Few-shot Gemma2-9b, and Fine-\nTuned GPT-3.5.\nA systematic analysis of the results was conducted, compiling participant\nratings into a table (see Table 3). For each model, average scores were calculated\nacross all evaluation criteria, with an overall average determined from the three\nassessed articles. These results were then compared with G-Eval ratings and\nquantitative metrics to derive meaningful insights.\nTable 3. Statistical Analysis of the Human Evaluation (Sorted by Average)\nEvaluation Type\nCoherence Consistency Fluency Potential Impact Relevance\n∅\nFew-Shot Gemma2 9B\n6.91\n6.67\n7.28\n7.17\n6.59\n6.92\nZero-Shot Mistral Large 2\n6.96\n6.70\n7.35\n6.88\n6.58\n6.89\nFew-Shot GPT-4o mini\n6.92\n6.54\n7.24\n6.99\n6.70\n6.88\nFew-Shot Mistral 822B\n6.89\n6.40\n7.29\n7.08\n6.42\n6.82\nZero-Shot GPT-4o\n6.88\n6.51\n7.27\n6.74\n6.46\n6.77\nZero-Shot LLaMA3 70B\n6.56\n6.30\n6.99\n7.02\n6.30\n6.63\nFew-Shot LLaMA3-1 70B\n6.52\n6.11\n7.03\n7.03\n6.29\n6.60\nFine-Tuned with GPT-3.5\n6.43\n6.13\n6.91\n6.35\n5.91\n6.35\nKey Findings\n– Coherence and Consistency: Discrepancies were observed between hu-\nman evaluation and G-Eval. For instance, Few-Shot Gemma2 9B ranked\nfirst in human evaluation despite its lower rank (23) in G-Eval. This sug-\ngests that human evaluators prioritize narrative structure and natural flow,\nwhich may not be fully captured by algorithmic metrics.\n– Fluency and Potential Impact: Human evaluators consistently rated flu-\nency lower than G-Eval, indicating that LLMs may not fully meet human\nexpectations for natural expression and readability. This highlights the need\nfor model optimization to improve language patterns and persuasiveness.\n– Relevance: Models like Few-Shot Gemma2 9B and Zero-Shot Mistral Large\n2 were highly rated for relevance, suggesting they provide useful information\ntailored to reader needs, even if their formal G-Eval scores were lower.\n– Discrepancy Between Human Evaluation and G-Eval: Human ratings\nwere consistently lower than G-Eval scores, indicating that human evaluators\nare more critical and may capture nuances that automated systems overlook.\n\n14\nPanlap Houamegni and Gedikli\n– Performance of Open-Source Models: Open models such as Gemma2\n9B and Mistral 8x22B performed well in human evaluation, demonstrating\ntheir potential for practical applications.\n– Influence of Prompting Approach: No consistent superiority was ob-\nserved between Few-Shot and Zero-Shot configurations in human evaluation,\ncontrasting with G-Eval, where Few-Shot models generally performed better.\nThe human evaluation process faced several challenges. Participants reported\nfatigue due to the volume of text, leading some to abandon the evaluation or\ncomplete it over multiple days. Additionally, the technical language and sophis-\nticated style of the articles posed barriers for some evaluators. Furthermore, the\nmodels exhibited a tendency to generalize, often replacing specific place names\nwith higher-level regions, which resulted in inaccuracies in location information.\nThe results of the human evaluation underscore the importance of comple-\nmenting automated metrics with human judgment. The discrepancies between\nhuman and G-Eval assessments highlight the need for further research to de-\nvelop evaluation methods that better align with human perceptions. This study\nemphasizes the value of human evaluation in refining LLMs for more precise and\ninformative news analysis, particularly in applications requiring high readability\nand relevance.\n5\nDiscussion\n5.1\nAnswering the Research Questions\nThe study addressed several key research questions, yielding the following in-\nsights:\n– Suitability for News Summarization in Risk Analysis: Modern LLMs,\nparticularly GPT-4o mini, GPT-4o, and Mistral Large 2, show strong ef-\nfectiveness for automated risk analysis. Statistical analyses confirm their\nconsistent high performance across multiple metrics, including coherence,\nrelevance, and fluency.\n– Summary Quality: The models exhibit strong readability and coherence,\nwith their responses implicitly incorporating duplicate detection and risk\nidentification. This validates their ability to generate high-quality summaries\ntailored to supply chain risk analysis.\n– Comparison of Zero-Shot, Few-Shot, and Fine-Tuning: Zero-shot\nconfigurations prove highly efficient when using powerful models, while few-\nshot approaches often enhance qualitative outcomes. Few-shot prompting,\nespecially with GPT-4o mini, demonstrated strong performance. Fine-tuning\nyielded mixed results, suggesting that its effectiveness depends on the specific\ncontext.\nThe study confirms the potential of modern LLMs for automated news sum-\nmarization in supply chain risk analysis. Few-shot GPT-4o mini excels across\nmultiple evaluation dimensions. The discrepancy between automated metrics\n\nEvaluating Large Language Models for News Summarization\n15\nand human evaluation underscores the necessity of combined quantitative and\nqualitative assessments.\n5.2\nPractical Implications\nThe findings have significant practical implications for organizations leveraging\nLLMs in supply chain risk analysis:\n– Efficiency Gains: Models like Few-Shot GPT-4o mini, Zero-Shot GPT-\n4o, and Zero-Shot Mistral Large 2 accelerate risk monitoring through rapid\nanalysis and summarization, enabling timely decision-making.\n– Cost Efficiency: Budget-friendly models such as Gemma2 9B (Few-Shot),\nLlama 3 70B (Zero-Shot), and Mistral 822B (Few-Shot) offer strong per-\nformance for resource-constrained organizations, making advanced AI tools\nmore accessible.\n– Real-Time Capability: LLaMA models’ high processing speeds enable\nreal-time analysis, critical for proactive risk management and dynamic sup-\nply chain environments.\n5.3\nModel-Specific Recommendations\nBased on the evaluation results, the following model-specific recommendations\nare proposed:\n– GPT-4o mini (Few-Shot): The top performer in both human and quanti-\ntative evaluations, offering good cost-efficiency. Regression analysis confirms\nthat it consistently maintains low latency and cost while delivering strong\nperformance. This makes it an ideal choice for organizations seeking an op-\ntimal balance between accuracy, speed, and resource utilization.\n– GPT-4o (Zero-Shot): Exceptional quantitative performance, but at a\nhigher cost. Its strong accuracy makes it suitable for high-stakes applica-\ntions where precision is critical.\n– Mistral Large 2 (Zero-Shot): Correlation analysis indicates that Mistral\nLarge 2 (Zero-Shot) achieves an effective balance between cost and perfor-\nmance. This model is recommended for organizations seeking a reliable, yet\ncost-effective solution.\n– LLaMA 3.1 70B (Few-Shot): Optimal performance-efficiency balance,\nideal for time-sensitive applications requiring rapid analysis.\n– Gemma2 9B (Few-Shot): Strong human evaluation results and cost-\nefficiency, suitable for budget-limited projects or smaller-scale implemen-\ntations.\n6\nSummary and Conclusion\nThis study comprehensively investigated the potential of modern large language\nmodels (LLMs) for automated news summarization in supply chain risk analysis.\n\n16\nPanlap Houamegni and Gedikli\nThe central research questions aimed to evaluate the models’ ability to accurately\nsummarize relevant content and analyze their performance in terms of readabil-\nity, duplicate detection, and risk identification. The results demonstrate that\nLLMs provide valuable support for risk analysis by enabling companies to effi-\nciently identify critical news content and respond swiftly to potential disruptions\nin their supply chains.\nQuantitative and qualitative analyses revealed that the Few-Shot GPT-4o\nmini model delivered outstanding performance, excelling in both automated\nmetrics and human evaluations while offering excellent cost-effectiveness. Mod-\nels like Zero-Shot GPT-4o and Mistral Large 2 also demonstrated impressive\nresults across various evaluation dimensions. Few-Shot GPT-4o mini, in partic-\nular, showed exceptional performance.\nA key insight from this study is the importance of a combined evaluation\nmethodology. Integrating quantitative metrics, LLM-based evaluators like G-\nEval, and human assessments provided a comprehensive and nuanced under-\nstanding of model performance. This multidimensional evaluation also revealed\ndiscrepancies between automated and human assessments, underscoring the ne-\ncessity of holistic evaluation approaches.\nThe results highlight that LLMs, through targeted prompting techniques\nsuch as Zero-Shot and Few-Shot, can generate precise and consistent summaries.\nThese summaries form a robust decision-making foundation for risk managers in\nglobal supply chains. At the same time, the study emphasized challenges related\nto model biases, factual accuracy, and ethical considerations.\nRegression analysis identified total costs and output speed as the primary fac-\ntors influencing latency, highlighting the importance of balancing performance\nand efficiency. These findings are particularly relevant for corporate settings,\nwhere practical implementation requires optimizing these trade-offs. From a\nbusiness perspective, this study provides companies with actionable insights for\nselecting and adapting LLMs based on specific needs. The results emphasize that\nmodel choice should consider factors such as accuracy, speed, and cost.\n6.1\nLimitations\nWhile the study provides valuable insights, several limitations must be acknowl-\nedged:\n– Dataset Constraints: The limited dataset size may affect the generaliz-\nability of the results. Future work should incorporate larger, more diverse\ndatasets to validate findings across different contexts.\n– Model Bias: Potential biases in LLMs may impact objectivity, requiring\ndeeper investigation [20]. Addressing these biases is critical for ensuring fair\nand accurate risk analysis.\n– Long-Term Performance: The stability of model performance over time\nremains unverified. Longitudinal studies are needed to assess how models\nadapt to evolving risks and data patterns.\n\nEvaluating Large Language Models for News Summarization\n17\n– Fine-Tuning Limitations: Resource constraints prevented evaluation of\nalternative models like LLaMA 3.1/3.2. Future research should explore fine-\ntuning with a broader range of models and datasets.\n6.2\nConclusion and Outlook\nIn summary, LLMs like GPT-4o mini and Mistral Large 2 represent promising\ntools for automated news summarization in risk management. However, the se-\nlection of models should align with the specific requirements for accuracy, speed,\nand cost efficiency. This study contributes significantly to the scientific discourse\non AI in supply chain management and establishes a solid foundation for future\nresearch and applications in supply chain risk analysis.\nFuture research should explore advanced fine-tuning techniques, domain-\nspecific customizations, and diverse datasets to enhance model robustness and\nreliability. Expanding experimental studies to a wider range of news sources and\nrisk scenarios will strengthen the generalizability of the findings. Furthermore, a\ndeeper investigation of the ethical implications of automated AI systems, along\nwith the development of clear guidelines for large language model (LLM) ap-\nplications in risk management, will help foster corporate confidence in adopting\nthese technologies.\nBy addressing these limitations and following the research directions de-\nscribed, the field can advance toward more reliable, efficient, and ethical AI-\ndriven solutions for supply chain risk analysis, ultimately enabling organizations\nto navigate complex global challenges with greater agility, accuracy, and re-\nsilience.\nReferences\n1. Brown, T., Mann, B., Ryder, N., et al.: Language Models are Few-Shot Learners.\nIn: Advances in Neural Information Processing Systems. vol. 33, pp. 1877–1901.\nCurran Associates, Inc. (2020)\n2. Gedikli, F., Novo, A.S., Jannach, D.: Semi-Automated Identification of News Story\nChains. In: Proc. of the 9th Int. Workshop on News Recommendation and Analytics\n(INRA 2021). CEUR Workshop Proceedings, vol. 3143, pp. 29–42 (2021)\n3. Goyal, T., Li, J.J., Durrett, G.: News Summarization and Evaluation in the Era\nof GPT-3 (2022), https://arxiv.org/abs/2209.12356\n4. Hendrycks, D., Burns, C., Basart, S., et al.: Measuring Massive Multitask Language\nUnderstanding. In: International Conference on Learning Representations (2021)\n5. Hohenstein, N.O.: Supply chain risk management in the COVID-19 pandemic:\nStrategies and empirical lessons for improving global logistics service providers’\nperformance. The International Journal of Logistics Management 33(4), 1336–1365\n(01 2022)\n6. Holgado, M., Blome, C., Schleper, M.C., Subramanian, N.: Brilliance in resilience:\noperations and supply chain management’s role in achieving a sustainable future.\nInternational Journal of Operations & Production Management 44(5), 877–899 (3\n2024)\n\n18\nPanlap Houamegni and Gedikli\n7. Hu, E.J., yelong shen, Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., Chen,\nW.: LoRA: Low-rank adaptation of large language models. In: Int. Conf. on Learn-\ning Representations (2022)\n8. Ivanov, D.: Supply chain viability and the covid-19 pandemic: a conceptual and\nformal generalisation of four major adaptation strategies. International Journal of\nProduction Research 59(12), 3535–3552 (2021)\n9. Liu, Y., Lapata, M.: Text Summarization with Pretrained Encoders. In: Proceed-\nings of the 2019 Conf. on Empirical Methods in Natural Language Processing and\nthe 9th Int. Joint Conf. on Natural Language Processing (EMNLP-IJCNLP). pp.\n3730–3740. Acl, Hong Kong, China (2019)\n10. Liu, Y., Fabbri, A.R., Liu, P., et al.: Revisiting the Gold Standard: Grounding\nSummarization Evaluation with Robust Human Evaluation. In: Proceedings of the\n61th Annual Meeting of the Association for Computational Linguistics (2023)\n11. Liu, Y., Shi, K., He, K., et al.: On Learning to Summarize with Large Language\nModels as References. In: Proceedings of the 2024 Conference of the North Amer-\nican Chapter of the Association for Computational Linguistics: Human Language\nTechnologies (Volume 1: Long Papers). pp. 8647–8664. Acl, Mexico City, Mexico\n(Jun 2024)\n12. Rein, D., Hou, B.L., Stickland, A.C., et al.: GPQA: A Graduate-Level Google-Proof\nQ&A Benchmark. In: First Conference on Language Modeling (2024)\n13. Reiter, E., Belz, A.: An investigation into the validity of some metrics for automat-\nically evaluating natural language generation systems. Computational Linguistics\n35(4), 529–558 (2009)\n14. Schuff, H., Vanderlyn, L., Adel, H., et al.: How to do human evaluation: A brief\nintroduction to user studies in NLP. Natural Language Engineering 29(5), 1199–\n1222 (2023)\n15. Stiennon, N., Ouyang, L., Wu, J., et al.: Learning to summarize from human feed-\nback. In: Proceedings of the 34th International Conference on Neural Information\nProcessing Systems. Nips ’20, Curran Associates Inc., Ny, Usa (2020)\n16. Stockem Novo, A., Gedikli, F.: Explaining bert model decisions for near-duplicate\nnews article detection based on named entity recognition. In: 2023 IEEE 17th\nInternational Conference on Semantic Computing (ICSC). pp. 278–281 (2023)\n17. Wang, Y., Ma, X., Zhang, G., et al.: MMLU-Pro: A More Robust and Challenging\nMulti-Task Language Understanding Benchmark. In: Advances in Neural Informa-\ntion Processing Systems 38 (NeurIPS 2024, Vancouver, Canada) (2024)\n18. Wei, J., Wang, X., Schuurmans, D., et al.: Chain-of-thought prompting elicits rea-\nsoning in large language models. Advances in neural information processing systems\n35, 24824–24837 (2022)\n19. Zhang, H., Yu, P.S., Zhang, J.: A Systematic Survey of Text Summarization: From\nStatistical Methods to Large Language Models. arXiv preprint arXiv:2406.11289\n(2024), https://arxiv.org/abs/2406.11289\n20. Zhang, T., Ladhak, F., Durmus, E., et al.: Benchmarking large language models\nfor news summarization. Transactions of the ACL 12, 39–57 (2024)\n",
  "metadata": {
    "source_path": "papers/arxiv/Evaluating_the_Effectiveness_of_Large_Language_Models_in_Automated_News\n__Article_Summarization_7fbc7cb1cc1d9f2c.pdf",
    "content_hash": "7fbc7cb1cc1d9f2c323256695e8af4c47a90a5e6e244513feda95caa1f98a585",
    "arxiv_id": null,
    "title": "Evaluating_the_Effectiveness_of_Large_Language_Models_in_Automated_News\n__Article_Summarization_7fbc7cb1cc1d9f2c",
    "author": "",
    "creation_date": "D:20250225024802Z",
    "published": "2025-02-25T02:48:02",
    "pages": 18,
    "size": 395415,
    "file_mtime": 1740470179.1587205
  }
}