{
  "text": "Characterizing Structured versus Unstructured Environments based on\nPedestrians’ and Vehicles’ Motion Trajectories*\nMahsa Golchoubian1†, Moojan Ghafurian2, Nasser Lashgarian Azad1, Kerstin Dautenhahn1,2\nAbstract— Trajectory behaviours of pedestrians and vehicles\noperating close to each other can be different in unstructured\ncompared to structured environments. These differences in the\nmotion behaviour are valuable to be considered in the trajectory\nprediction algorithm of an autonomous vehicle. However, the\navailable datasets on pedestrians’ and vehicles’ trajectories\nthat are commonly used as benchmarks for trajectory pre-\ndiction have not been classified based on the nature of their\nenvironment. On the other hand, the definitions provided for\nunstructured and structured environments are rather quali-\ntative and hard to be used for justifying the type of a given\nenvironment. In this paper, we have compared different existing\ndatasets based on a couple of extracted trajectory features,\nsuch as mean speed and trajectory variability. Through K-\nmeans clustering and generalized linear models, we propose\nmore quantitative measures for distinguishing the two different\ntypes of environments. Our results show that features such as\ntrajectory variability, stop fraction and density of pedestrians\nare different among the two environmental types and can be\nused to classify the existing datasets.\nI. INTRODUCTION\nMany researchers in the area of motion prediction and\nplanning are using the terms structured and unstructured\nenvironments for addressing two distinct application areas\nfor their automated systems [1], [2], [3], [4], [5]. Different\ndefinitions have been proposed in the literature for classi-\nfying these environments into structured and unstructured.\nIn one type of definition that is focused on vehicular traffic\nenvironments, the distinction is made based on the existence\nof lane marks and strict traffic rules (e.g., see [6], [7],\n[8], [9]). Within this definition, a structured environment\nis believed to be a place with clear lane marks and road\ndividers, and where traffic participants adhere to strict traffic\nrules [6]. On the other hand, in an unstructured environment,\nsuch marked lanes or road dividers do not exist and no strict\ntraffic rules are followed by drivers and pedestrians. In un-\nstructured environments, all traffic participants are required\nto pay more attention due to the reduced traffic rules [6].\nPedestrianized spaces and parking lots are considered as\nunstructured environments under this definition [6], [7].\nIn another definition, the coherency of the movement\npattern has been introduced as the aspect that distinguishes\nstructured from unstructured environments [10], [11], [12].\n* This research was undertaken, in part, thanks to funding from the\nCanada 150 Research Chairs Program and NSERC.\n†Corresponding\nAuthor:\nMahsa\nGolchoubian\nmahsa.golchoubian@uwaterloo.ca\n1Department of Systems Design Engineering, University of Waterloo,\nCanada\n2Department of Electrical and Computer Engineering, University of\nWaterloo, Canada\nIn this definition, an environments is called structured when\na main motion track can be identified which is usually\ncaused by a condition in the environment, such as the\npedestrian crosswalks on roads. In contrast, in unstructured\nenvironments, pedestrians can move freely in different di-\nrections [10]. In this definition, unlike the previous one,\na pedestrianized environment can be either structured or\nunstructured based on the existing motion patterns.\nAlthough there are some overlaps between these two\ndefinitions, there are also some differences that make it\nhard to specify whether an environment is structured or\nunstructured solely based on these qualitative definitions.\nDespite the differences in the two definitions provided\nabove, it is agreed in the literature that the behaviours of\ntraffic participants in these two types of environments are\ndifferent. This becomes important for an autonomous vehicle\nthat needs to predict the future motions of other traffic\nparticipants [13], [14], as this prediction will differ based on\nthe type of the environment in which the vehicle is operating.\nMany data-driven trajectory prediction models have been\nproposed for the use of autonomous transportation systems.\nThese models are usually trained on datasets that contain\nreal-world trajectories of pedestrians and vehicles in an\nenvironment. Depending on the type of the environment\nthese datasets have been captured from, the trained predictive\nmodel will also learn the motion behaviour of traffic partici-\npants within the same type of environment. Paying attention\nto this point is crucial when it comes to generalizing the\ntrained motion predictor to other similar environments.\nTherefore, while it is valuable to classify the datasets\nbased on the type of the environment (i.e., unstructured\nversus structured), it is hard to do this classification based on\nthe different qualitative definitions provided in the literature.\nTherefore, the present work investigates how to quantitatively\ndefine the type of environments through evaluating quantita-\ntive features for classifying environments to unstructured and\nstructured, by focusing on the traffic participants’ behaviours\nembedded in the trajectories. We use two methods, (a) clus-\ntering, to see if the existing datasets can be divided into two\nclusters showing structured vs. non-structured environments,\nand (b) regression to investigate if our assumptions about\nthe effect of features on identifying the type of environment\nis hold. Based on the existing literature, we assume that\ntraffic participants have similar behaviours in each type of\nenvironment, and based on this similarity we will suggest a\nrelationship between the extracted quantitative features and\nthe structured/unstructured nature of the environment. To the\nbest of our knowledge, this is the first work that proposes a\n© 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media,\nincluding reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution\nto servers or lists, or reuse of any copyrighted component of this work in other works.\narXiv:2502.16847v1  [cs.RO]  24 Feb 2025\n\nquantitative characterization for a structured vs. unstructured\nenvironment based on the trajectory data.\nAs we are interested in classifying environments that\ninclude both pedestrians and vehicles into structured and\nunstructured environments, we only analyze the datasets that\nhave both of these agents present.\nIn this paper, we address two main questions: (1) How\ncan we quantify the definition of structured and unstructured\nenvironments that include both pedestrians and vehicles\naccording to trajectory data. (2) How the existing datasets\non agents’ (i.e., pedestrians and vehicles) trajectories will\nget categorized based on these quantitative measures. Con-\nsidering these two research questions, our contribution is\ntwo-fold: (1) We suggest practical quantitative features that\ncan be used for classifying environments as structured and\nunstructured. (2) We group some of the well-known datasets\nin two classes based on these features.\nOur proposed quantitative features can be used to identify\nthe type of a new target environment, in order to use\nexisting pedestrian trajectory datasets classified within the\nsame environmental type for training a trajectory prediction\nalgorithm. This might be particularly beneficial for designing\nautonomous vehicles operating in different environments, so\nthat they can improve the trajectory prediction of different\ntraffic participants by considering their behaviour in that\nspecific environmental type.\nII. RELATED WORK\nPedestrian trajectory prediction is an active field of re-\nsearch with different application areas in autonomous driving\nand social robotics [15]. Various approaches have been used\nfor this trajectory prediction from physics-based models such\nas social force model [16], [17], [18] to data-driven models\nespecially deep learning ones [19], [20], [21]. Corresponding\nto this line of research, many real-world datasets have\nbeen collected from different environments to be used as a\nbenchmark for these trajectory prediction algorithms. While\nthe nature of the environment and vehicles’ presence can\nhave a considerable influence on the trajectory profile of\npedestrians, no clear classification has been made between\nthe different datasets based on quantitative measures such as\nthe pedestrians’ and vehicles’ trajectory features.\nDifferent datasets have been compared in terms of the\ncomplexity of the human trajectories for the prediction task\nby introducing some indicators in [22]. However, the focus\nof this comparison was only on pedestrians’ behaviour and\ntherefore mostly included datasets in which pedestrians are\nthe only agent present without being influenced by vehicles.\nRobicquet et al. have detected different classes of naviga-\ntion styles for pedestrians in a dataset based on the different\nways pedestrians handle their interaction in a collision avoid-\nance situation [23]. But it is still unclear how these navigation\nstyles can also be affected by the type of the environment.\nFurthermore, traffic participants’ spatial and movement\nbehaviour in different shared space layouts is studied in [24],\nconsidering both vehicles and pedestrians. But the number\nof behavioural features studied was limited to mean speed,\nnumber of interactions, and yield ratio.\nAlso, in another study focusing on pedestrians, pedes-\ntrians’ behaviour in a shopping mall was classified into\nthree categories of “walking straight”, “finding a way”, and\n“walking around” in [25], showing that roaming around is a\ncommon trajectory behaviour that can be seen in a shopping\nmall environment. However, the analysis was restricted to\none dataset with only pedestrians moving in a mall. Nev-\nertheless, we get inspiration from some of the behavioural\nmeasures used in these papers (e.g., path efficiency [22],\nstop ratio [25]) for building the quantitative features that can\ndescribe unstructured vs. structured environments.\nIII. DATASETS\nThere are a few datasets that include both pedestrians and\nvehicles which are analyzed in this paper, discussed below.\nStanford Drone Dataset (SDD) is a dataset that has been\ncaptured from the campus of Stanford university and con-\nsists of eight different scenes [23]. The dataset includes\ntrajectories of around 19k agents in different classes from\npedestrians, bicyclists, skateboarders to cars, carts, and buses.\nIn this paper, we have analyzed the trajectories of only\npedestrians, cars and carts within four scenes of this dataset\n(hyang, coupa, nexus, death circle) that include a relatively\nhigher percentage of car/cart compared to the other scenes. In\nthis dataset, we filtered out the annotations with “lost” value\nof 1 which indicates annotations outside the view screen.\ninD dataset contains trajectories of more than 11K traffic\nparticipants including pedestrians, vehicles, and bicycles\n[26]. The dataset was recorded from four different German\nintersections with two of these intersections being used in\nthe analysis of the current article.\nDUT dataset contains trajectories of pedestrians and ve-\nhicles interacting with each other in two locations on the\ncampus of Dalian University of Technology in China with\nclose to 2K pedestrian and 65 vehicle trajectory data [27].\nOne of the locations is an intersection without a traffic light.\nThe other location is a shared space near a roundabout where\nagents can move freely.\nHamburg Bergedorf Station (HBS) dataset is captured\nfrom a shared space street in Germany near a busy railway\nstation [28]. It includes trajectory data of 1115 pedestrians,\n331 cars and 29 cyclists.\nHC dataset was captured from a shared street in a university\ncampus in Germany [29]. It contains trajectory data of 282\npedestrians, 15 vehicles and 40 cyclists.\nAll the above datasets have been captured from stationary\ncameras or drones. In each of these datasets, the position\ntrack of different agents is provided frame by frame. These\npositions were all transformed to a world cartesian coordinate\nbefore being used for analysis.\nThree of the above datasets (i.e. HBS, HC and the\nroundabout scene of the DUT dataset) are collected from\nshared spaces environments which are defined as urban\nenvironments where the curbs, road surface markings and\ntraffic signs have been removed to encourage different traffic\n\nparticipants to share the same space and negotiate the priority\nbased on social rules [30]. However, it is not clear whether\nshared spaces should be categorized as unstructured or\nstructured environments according to the motion behaviour.\nThis would be further investigated during our analysis.\nThe secondary use of the above datasets for this study has\nreceived ethics clearance from the University of Waterloo\nResearch Ethics Committee.\nIV. METHOD\nFor each dataset and for all of its different scenes, we\nextracted thirteen features from the traffic participants’ tra-\njectories that could be helpful in distinguishing a structured\nenvironment from an unstructured one. We have categorized\nour extracted features into three sets of pedestrian motion\nfeatures, vehicle motion features, and pedestrian-vehicle in-\nteraction features that are described in order.\nA. Extracted trajectory features\nPedestrian motion features: The features that we ex-\ntracted from each individual pedestrian’s trajectory were: (a)\nmean speed of pedestrian, (b) stop fraction of pedestrian,\n(c) variability of pedestrian’s trajectory, (d) path efficiency\nof pedestrian, (e) pedestrians’ path orientation entropy, (f)\ndensity of pedestrians, and (g) density of standing pedestrian.\nThe first three features are related to the speed profile of\nthe pedestrian. We calculated the velocity vector from the\npedestrian’s position vector in consecutive frames knowing\nthe frame rate through which the dataset was captured. For\nthe mean speed feature, we calculated the average speed\nof the pedestrian during its whole trajectory. For the stop\nfraction, we computed the percentage of time the pedestrian\nis in a stop along its whole trajectory. We have considered a\npedestrian to be in a stopping position when their speed gets\nlower than 0.5 m/s [25]. Variability of trajectory is defined\nas the trace of the covariance matrix of the speed [25] and\nis calculated according to the equation below:\ntr(cov(−→\nV )) = 1\nn\nX\nt\n(vt −¯v)2\n(1)\nIn this equation, −→\nV is a vector of speeds in different time\nsteps t, (−→\nV = [v1, v2, ..., vn]), ¯v is the average speed and n is\nthe total number of time steps that the pedestrian is present\nin the scene.\nWe calculated path efficiency as the ratio of the distance\nbetween the endpoints of the trajectory over the trajectory\nlength and indicates how close the path is to a straight\nFig. 1.\nApproach angle definition in a pedestrian-vehicle interaction\nline [22]. Some of the datasets have a wider perspective\nof the capturing scene and therefore in those scenes, the\npedestrians’ trajectories can deviate from a straight line\ndue to some geometrical constraints in the scene such as\nthe buildings. To compensate for that in the calculation of\nthe path efficiency, we divide the trajectories into smaller\nsections each lasting 4.8 seconds and the path efficiency is\ncalculated using the cumulative value of the smaller sections\nof the trajectory within the formulation. These smaller pieces\nof the trajectory that last 4.8 seconds are called trajlet in\n[22] and are commonly used in trajectory prediction as the\nobservation interval of each agents’ trajectory for future\nposition prediction.\nFor the path orientation feature, we calculate the angle\nof the straight line connecting the start and endpoint of each\ntrajlet relative to a global horizon. However, the exact number\nof the path orientation is not important and cannot be com-\npared between the different datasets due to the inconsistency\nof the orientation of their global Cartesian frame. In fact,\nwhat is important is the diversity of the path orientation\nwithin each environment that could represent the pedestrians’\nlevel of freedom in selecting their movement direction. For\nmeasuring this diversity, we calculate the entropy of the path\norientation for each dataset and keep it as a feature.\nAll the above features are calculated for the pedestri-\nans that are not stationary throughout the whole dataset.\nStationary pedestrians are considered as those with a stop\nfraction of more than 90% and are excluded from the above\nfeature calculations as those features are not meaningful for\nstationary pedestrians and the calculations are prone to high\nerror for pedestrians that have a speed of more than 0.5\nm/s only at 10% of their whole trajectory. However, for\ncalculating the density of the pedestrians, all the moving\nand standing pedestrians are being considered and their total\nnumber is divided by the area of the scene from which the\ndataset is being captured. As the stationary pedestrians were\nignored in the first 5 features, we added a last feature that\nspecifies the density of standing pedestrians in the dataset.\nThese two density features are calculated for each pedestrian\nas the average density while the pedestrian is present in\nthe scene since the density of the crowd could affect each\nindividual’s motion behaviour.\nVehicle motion features: From the vehicle trajectory data\nwe extracted: (a) mean speed of the vehicle, (b) stop fraction\nof the vehicle, and (c) variability of vehicle’s trajectory.\nWe defined and calculated these features in the same way\nas in the pedestrian features. The only difference is in the\nstop fraction feature, where a vehicle is considered to be in\na stop when its speed is less than 1 m/s. Same as in the\npedestrians feature, here we also exclude vehicles that have\na means speed of less than 0.5 m/s throughout their whole\npresence which is used as an indication for a parked vehicle.\nPedestrian-vehicle interaction features: The way pedes-\ntrians and vehicles interact in a structured vs. unstructured\nenvironment can also be very different. In an unstructured\nenvironment as there are no pre-specified paths or lane\nmarks present [7], pedestrians and vehicles can approach one\n\nanother from different directions and since no strict rules\napply in unstructured environments [6], different behaviours\ncan be observed in terms of which class of agent (pedestrians\nor vehicles) gets the priority when their paths cross one\nanother. Therefore, (a) entropy of approach angle, (b) priority\n(percentage of pedestrian priority), and (c) ratio of vehicles\nto pedestrians were the three features that we defined for\ncapturing these differences.\nFor extracting these behaviours as interaction features, we\nfirst focus on those pairs of pedestrian-vehicle that get closer\nto each other than a threshold that we have selected to be\n4 meters here. Based on the speed and size of the vehicles,\nthis four meters was a rational distance choice below which\ncalculating approach angle was justifiable.\nFor each pair of pedestrian-vehicle, we then calculate their\napproach angle as the angle between the straight line con-\nnecting the endpoints of each of the two agent’s trajectories\nwhile they are in interaction (Fig. 1). We will then calculate\nthe entropy of the approach angle distribution within each\ndataset as a measure of the approach angle diversity. As\nanother feature we calculate the ratio of pedestrians gaining\npriority over vehicles to the total number of times a path\ncrossing situation happened between a vehicle and pedes-\ntrians during their interaction. We defined priority in terms\nof who got to first cross the intersection point of the two\ncrossing trajectories. We also include the ratio of vehicles to\npedestrians in each frame as a feature, with the average of\nthis ratio being calculated over all the frames of the dataset.\nB. Data Analysis Approach\nHaving the above-extracted features for each dataset, we\napply k-means clustering to find two clusters that could rep-\nresent structured vs. unstructured environments for the data\nin the combined datasets. By using the k-means clustering\ntechnique we have the flexibility of choosing the number\nof clusters to be two, for representing the two types of\nenvironments that we wanted to distinguish between. To have\nall features together, we used the average of the vehicle\nfeatures for each dataset and added them to the interaction\nand pedestrians features.\nWe have eliminated the outliers by using the 1.5 × IQR\n(Interquartile range) method. Therefore, the data points that\nare 1.5 × IQR below the 25% percentile or above the 75%\npercentile are excluded.\nAs the next step we evaluate each feature for its significant\neffect on the clustering result. For that we fit a generalized\nlinear model to the data, using the pedestrian features as\nthe fixed effect and the label of the environment from the\nclustering result as the output. This was done using the glm\nfunction in RStudio. The result of these analyses is presented\nin the next section.\nV. RESULTS AND DISCUSSION\nThe mean and 95% confidence intervals for each feature\nare shown in Figs. 2, 3, and 4. Note that the different scenes\nof each dataset are plotted separately. According to Fig. 2,\npedestrians in the SDD dataset have higher stop fraction and\ntrajectory variability with a lower path efficiency compared\nto the other datasets. In Fig. 2f, it is observed that the DUT\ndataset has the highest pedestrian density as it has been\ncaptured from a small congested area, but the density of\nstanding pedestrians is higher in SDD according to Fig 2g.\nThe highest vehicle mean speed is from the inD dataset as\nit is being captured from a typical road environment (Fig 3).\n(a) Pedestrian mean speed\n(b) Pedestrian stop fraction\n(c) Variability of pedestrian’s trajectory\n(d) Pedestrian path efficiency\n(e) Entropy of path orientation\n(f) Pedestrian Density\n(g) Standing Pedestrian Density\nFig. 2.\nThe value of features extracted from pedestrians’ trajectories in each dataset with 95 % confidence interval\n\n(a) Vehicle mean speed\n(b) Vehicle stop fraction\n(c) Variability of Vehicle ’s trajectory\nFig. 3.\nThe value of features extracted from vehicles’ trajectories in each dataset with 95 % confidence interval\n(a) Entropy of approach angle\n(b) Priority in path crossing\n(c) Ratio of vehicles to pedestrians\nFig. 4.\nThe value of features extracted from pedestrian-vehicle interaction in each data\nThe inD dataset also has the highest ration of vehicles to\npedestrians among all the datasets (Fig. 4c) and also the\nhighest percentage of vehicle priority (Fig. 4b).\nThe clustering results for each dataset based on these\nthirteen defined trajectory features is shown in Fig. 5. This\nfigure shows the percentage of the dataset that goes into each\nof the two clusters, A and B. For majority of the dataset, all\nthe data points stand unanimously within one cluster.\nAccording to this clustering result, cluster A which con-\ntains the four different scenes of the SDD dataset represents\ntrajectory behaviours that happen in a campus environment\nand mainly off the road. All the other datasets fall into\nthe second cluster, cluster B, which contains mostly road\nenvironments having either a conventional structure with\ndesignated operational areas for pedestrians and vehicles or\nhaving the design of a shared street.\nBy assigning all the points in a dataset to a label that\nrepresents the label of the majority of the points in that\ndataset from the k-means clustering, we have then compared\nthe values of each feature between the two clusters in Figs.\n6-8. In these figures, the mean value of each feature is shown\nwith the 95% confidence interval. The statistical analysis\nusing linear mixed-effects models (LMMs) [31] for each\nfeature separately while considering the dataset as a random\neffect shows that pedestrians’ stop fraction (se = 0.005, t =\n−91.06, p < 0.001), the variability of pedestrians’ trajectory\n(se = 0.069, t = −30.11, p < 0.001), and the pedestrians’\npath efficiency (se = 0.023, t = 4.731, p < 0.05) are signif-\nicantly different among the two clusters. The path efficiency\nis significantly lower in cluster A compared to cluster B. In\naddition, the density of standing pedestrians has significantly\ndifferent values in the two clusters (se = 1.82e −5, t =\n−30.86, p < 0.001). Among the vehicle-related features, the\nstop fraction of the vehicle (se = 0.051, t = −4.157, p <\n0.05) is significantly different between the two clusters.\nFor considering the effect of pedestrians’ features all\ntogether, we fitted a generalized linear model (GLM, using\nmaximum likelihood estimation) for predicting the label\nof clusters. All the features were centred to have a mean\nof zero for this analysis. To avoid collinearity, pedestrian\nfeatures that only had no or low correlation (< 0.3) with\neach other were selected as fixed effects, and to improve\nmodel fit, the combination resulting in the least AIC was\nconsidered, which is reported in Table I. The result of the\nGLM shows that all the three fixed effects of mean speed,\nvariability, and average pedestrian density had a significant\neffect on the clustering result. Using other combinations\nof non-correlating features, other pedestrian features not\nconsidered in the model of Table I also had significant effects\non predicting the clustering result. We also added the dataset\nTABLE I\nTHE GENERALIZED LINEAR MODEL LEADING TO BEST MODEL FIT\nACCORDING TO THE AIC CRITERIA (AIC=72.83). PED: PEDESTRIAN.\nFixed effects\nEstimate\nStd. Error\nz value\nPr(> |z|)\nPed mean speed\n2.897\n1.129\n2.567\n0.01 (*)\nPed variability\n-11.288\n1.778\n-6.349\n<0.001 (***)\nPed average density\n-0.736\n0.323\n-2.279\n0.023 (*)\n\nFig. 5.\nDatasets clustered in two groups based on the defined features. For\neach dataset the portion of its data points in each cluster is reported.\nas a random effect to the model (to take the effect of specific\nlocations/datasets into account) and fit a generalized linear\nmixed-effect model (GLMM). This led to pedestrian path\nefficiency being the only significant fixed effect.\nThis difference may be because we only have one dataset\nrepresenting cluster A, so, by including the dataset as a\nrandom effect, we are also accounting for the differences\nbetween the two environments. As we were not able to\nfind more datasets representing an unstructured environment\nsimilar to SDD, future work is needed to further investigate\nthe differences between the two environments.\nGeneral Comparison of Environmental Features: The\nenvironments in cluster A, overall are more dominated by\npedestrians than vehicles as it can be seen from their lower\nvehicle over pedestrian ratios compared to cluster B (Fig. 7).\nThe higher stop fraction in pedestrians’ trajectory profile in\ncluster A, can be a usual behaviour observed on-campus\nwhere people might linger in the environment or regularly\ncome to a stop along the path when meeting a friend. These\nbehaviours will also cause high variability in the speed\nprofile. The lower path efficiency of pedestrians in cluster A\nis equivalent to more deviations from a straight path which\ncan be the trajectory behaviour of a pedestrian that is roaming\naround without having an exact destination point in mind.\nThis behaviour is unlikely to happen for pedestrians that are\ncrossing the road or are walking on the sidewalk of an urban\narea towards their destination.\nTherefore, based on our results, We can point out some\nsimilarities between the trajectory features observed in clus-\nter A and the characteristics of an unstructured environment.\nSlightly higher entropy of path orientations in cluster A\n(Fig. 8), is an indication of higher diversity in the path\ndirections which happens when pedestrians are not restricted\nto follow designated paths under strict rules and are free to\nmove anywhere. This was one of the main elements of the\nqualitative description of an unstructured environment.\nWe can also describe an unstructured environment by the\nlower speed and higher variability of vehicles trajectory in\nthose environments (Fig. 6), as there are no strict rules\nspecifying the priorities or rights of way, and vehicles should\npay more attention as pedestrians can be present everywhere.\nThis could cause regular stops for the vehicles, resulting in\nslightly higher numbers for the stop fraction feature.\nThe effect of having no strict traffic rule in cluster A\nas an example of an unstructured environment can also be\nobserved in the higher percentage of times that the vehicle\nyields and gives priority to pedestrians in the interactions\nhappening in cluster A compared to cluster B (Fig. 7). The\npedestrian’s dominance in the scenes of cluster A and their\nenvironment not having a road structure could have affected\nthese priority behaviours in interaction which could be a\ncommon behaviour seen in unstructured environments.\nThe number of standing pedestrians per unit area in cluster\nA is higher than in cluster B, showing that we should\nexpect more standing pedestrians in environments similar\nto the ones in cluster A or in other words in unstructured\nenvironments. This is somehow also connected to having\nhigher stop fraction within these environments.\nOther features that could be added to the definition of\nan unstructured environment, suggested by our results, are\nmoving pedestrians having slightly lower speed with a higher\nprobability of coming to a stop along the path. This means\nthat we should expect more variability in the pedestrians’\ntrajectory in an unstructured environment. These behavioural\nfeatures are important to consider when predicting a pedes-\ntrian’s trajectory in different environments.\nVI. LIMITATIONS AND FUTURE WORK\nOur work had limitations. The number of existing datasets\nthat include both pedestrians and vehicles is limited espe-\ncially when it takes place outside the road structure, which\nis closer to the definition of an unstructured environment.\nAn unstructured environment similar to the SDD dataset can\nbe also found in other areas, such as in airport terminals\nand shopping malls, for which we could not find any data.\nTherefore, cluster A in our results only contains one major\ndataset (SDD) with its different scenes. Although having\nmore datasets that could have fallen under cluster A would\nhave strengthened our argument about the clusters represent-\ning unstructured vs. structured environments, there is still a\nclear difference between the SDD dataset and all the other\ndatasets which are believed to be a result of the different\nnature of the environments.\nThe other limitation comes from the differences between\nthe field of view and the geometry of the environments where\nthe data were captured from, with some datasets (e.g. DUT)\nbeing more focused on a small area as opposed to the others\nthat have covered a wider region (e.g. in, SDD). This would\naffect the length of the trajectory for each agent present in\nthe dataset with shorter trajectories probably showing fewer\nvariations in the trajectory profile due to limited information\navailable from them. Further analysis on a larger set of\ndatasets from various environments in which both pedestrians\nand vehicles are present could help address these limitations.\nAlthough we tried to be comprehensive in the list of\nfeatures extracted based on agents’ trajectories, there could\nbe other features that have not been considered which could\nreveal other differences between the two environment types.\nMore features can be investigated in the future, as well as\nusing a larger dataset that contains more examples of unstruc-\ntured environments, which, to the best of our knowledge, is\n\nFig. 6.\nThe mean of the vehicle features within each cluster along with the 95% confidence intervals\nFig. 7.\nThe mean of the interaction features within each cluster along with the 95% confidence intervals\nFig. 8.\nThe mean of the pedestrian features within each cluster along with the 95% confidence intervals\nFig. 9.\nThe process through which the results of this study can be used for developing trajectory prediction modules for autonomous vehicles (AVs)\n\nnot presently available. Also, we propose investigating how a\ntrajectory predictor trained on one dataset can be generalized\nto other environments of the same class. Fig 9 shows how this\nwork can be used in the process of developing a trajectory\npredictor for an autonomous vehicle in future work.\nVII. CONCLUSION\nWe studied the differences in the trajectory features of five\nexisting datasets that contain both pedestrians and vehicles.\nAfter dividing the datasets into two clusters based on 13\ndifferent features related to agents’ motion trajectories, we\nstudied the effect of trajectory features on distinguishing\nbetween unstructured or structured nature of the captured\nenvironment. Among the resulting two clusters, one included\nmainly road-like environments which we named structured\nenvironment and the other class that contained scenes from\na campus environment happening mainly outside of a road\nstructure, was interpreted to be the unstructured environment\nclass. We discussed the differences between the motion\nbehaviours of vehicles and agents in structured and un-\nstructured environments and provided a quantitative measure\nfor distinguishing between these environments. Considering\nthese features, one can then use the related dataset for the\nsimilar type of environment to train a pedestrian trajectory\npredictor for learning the behavioural elements that are\nprobable to be seen in the same type of environment.\nREFERENCES\n[1] J. Chen, Y. Wang, R. Wu, and M. Campbell, “Spatial-temporal graph\nneural network for interaction-aware vehicle trajectory prediction,” in\n2021 IEEE 17th International Conference on Automation Science and\nEngineering (CASE).\nIEEE, 2021, pp. 2119–2125.\n[2] S. Su, C. Peng, J. Shi, and C. Choi, “Potential field: Interpretable\nand unified representation for trajectory prediction,” arXiv preprint\narXiv:1911.07414, 2019.\n[3] J. Cai, Y. Zhang, L. Yang, H. Cai, and S. Li, “A context-augmented\ndeep learning approach for worker trajectory prediction on unstruc-\ntured and dynamic construction sites,” Advanced Engineering Infor-\nmatics, vol. 46, p. 101173, 2020.\n[4] D. C. Guastella and G. Muscato, “Learning-based methods of percep-\ntion and navigation for ground vehicles in unstructured environments:\nA review,” Sensors, vol. 21, no. 1, p. 73, 2021.\n[5] M. J. Procopio, J. Mulligan, and G. Grudic, “Learning terrain segmen-\ntation with classifier ensembles for autonomous robot navigation in\nunstructured environments,” Journal of Field Robotics, vol. 26, no. 2,\npp. 145–175, 2009.\n[6] R. Jyothi, K. Mahalakshmi, C. Vaishnavi, U. Apoorva, and S. Nitya,\n“Driver assistance for safe navigation under unstructured traffic envi-\nronment,” in 2019 Global Conference for Advancement in Technology\n(GCAT).\nIEEE, 2019, pp. 1–5.\n[7] S. Kerscher, N. Balbierer, S. Kraust, A. Hartmannsgruber, N. M¨uller,\nand B. Ludwig, “Intention-based prediction for pedestrians and vehi-\ncles in unstructured environments.” in VEHITS, 2018, pp. 307–314.\n[8] S. Kolski, D. Ferguson, M. Bellino, and R. Siegwart, “Autonomous\ndriving in structured and unstructured environments,” in 2006 IEEE\nIntelligent Vehicles Symposium.\nIEEE, 2006, pp. 558–563.\n[9] A. H. Ibrahim, C. Pegard, and E.-M. Mouaddib, “Collision prediction\nbetween vehicles in an unstructured environment,” in 14th Interna-\ntional Conference on Sciences and Techniques of Automatic Control\n& Computer Engineering-STA’2013.\nIEEE, 2013, pp. 509–514.\n[10] O. Ozturk, T. Yamasaki, and K. Aizawa, “Detecting dominant motion\nflows in unstructured/structured crowd scenes,” in 2010 20th Interna-\ntional Conference on Pattern Recognition.\nIEEE, 2010, pp. 3533–\n3536.\n[11] A. C. Jim´enez, J. Anzola, and A. Jimenez-Triana, “Pedestrian counting\nestimation based on fractal dimension,” Heliyon, vol. 5, no. 4, p.\ne01449, 2019.\n[12] M. Rodriguez, S. Ali, and T. Kanade, “Tracking in unstructured\ncrowded scenes,” in 2009 IEEE 12th International Conference on\nComputer Vision.\nIEEE, 2009, pp. 1389–1396.\n[13] F. Leon and M. Gavrilescu, “A review of tracking and trajectory\nprediction methods for autonomous driving,” Mathematics, vol. 9,\nno. 6, p. 660, 2021.\n[14] M. Z. Abnili and N. L. Azad, “Short term predictions of preceding\nvehicle speeds for connected and automated vehicles,” Controls,\nDynamic Systems and Robotics (CDSR), 2019.\n[15] A. Rudenko, L. Palmieri, M. Herman, K. M. Kitani, D. M. Gavrila,\nand K. O. Arras, “Human motion trajectory prediction: A survey,”\nThe International Journal of Robotics Research, vol. 39, no. 8, pp.\n895–935, 2020.\n[16] A. Rudenko, L. Palmieri, and K. O. Arras, “Joint long-term prediction\nof human motion using a planning-based social force approach,” in\n2018 IEEE International Conference on Robotics and Automation\n(ICRA).\nIEEE, 2018, pp. 4571–4577.\n[17] N. Rinke, C. Schiermeyer, F. Pascucci, V. Berkhahn, and B. Friedrich,\n“A multi-layer social force approach to model interactions in shared\nspaces using collision prediction,” Transportation research procedia,\nvol. 25, pp. 1249–1267, 2017.\n[18] M. Pr´edhumeau, L. Mancheva, J. Dugdale, and A. Spalanzani, “An\nagent-based model to predict pedestrians trajectories with an au-\ntonomous vehicle in shared spaces,” in AAMAS 2021-20th Interna-\ntional Conference on Autonomous Agents and Multiagent Systems,\n2021, pp. 1–9.\n[19] T. Salzmann, B. Ivanovic, P. Chakravarty, and M. Pavone, “Tra-\njectron++: Dynamically-feasible trajectory forecasting with heteroge-\nneous data,” in European Conference on Computer Vision.\nSpringer,\n2020, pp. 683–700.\n[20] R. Chandra, U. Bhattacharya, A. Bera, and D. Manocha, “Traphic: Tra-\njectory prediction in dense and heterogeneous traffic using weighted\ninteractions,” in Proceedings of the IEEE/CVF Conference on Com-\nputer Vision and Pattern Recognition, 2019, pp. 8483–8492.\n[21] H. Cheng, W. Liao, M. Y. Yang, M. Sester, and B. Rosenhahn,\n“Mcenet: multi-context encoder network for homogeneous agent tra-\njectory prediction in mixed traffic,” in 2020 IEEE 23rd International\nConference on Intelligent Transportation Systems (ITSC).\nIEEE,\n2020, pp. 1–8.\n[22] J. Amirian, B. Zhang, F. V. Castro, J. J. Baldelomar, J.-B. Hayet,\nand J. Pettr´e, “Opentraj: Assessing prediction complexity in human\ntrajectories datasets,” in Proceedings of the Asian Conference on\nComputer Vision, 2020.\n[23] A. Robicquet, A. Sadeghian, A. Alahi, and S. Savarese, “Learning\nsocial etiquette: Human trajectory understanding in crowded scenes,”\nin European conference on computer vision.\nSpringer, 2016, pp.\n549–565.\n[24] M. Batista and B. Friedrich, “Investigating spatial behaviour in differ-\nent types of shared space,” Transportation Research Procedia, vol. 60,\npp. 44–51, 2022.\n[25] K. Okamoto, A. Utsumi, H. Yamazoe, T. Miyashita, S. Abe, K. Taka-\nhashi, and N. Hagita, “Classification of pedestrian behavior in a\nshopping mall based on lrf and camera observations.” in MVA, 2011,\npp. 1–5.\n[26] J. Bock, R. Krajewski, T. Moers, S. Runde, L. Vater, and L. Eckstein,\n“The ind dataset: A drone dataset of naturalistic road user trajectories\nat german intersections,” in 2020 IEEE Intelligent Vehicles Symposium\n(IV).\nIEEE, 2020, pp. 1929–1934.\n[27] D. Yang, L. Li, K. Redmill, and ¨U. ¨Ozg¨uner, “Top-view trajectories:\nA pedestrian dataset of vehicle-crowd interaction from controlled\nexperiments and crowded campus,” in 2019 IEEE Intelligent Vehicles\nSymposium (IV).\nIEEE, 2019, pp. 899–904.\n[28] F. Pascucci, N. Rinke, C. Schiermeyer, V. Berkhahn, and B. Friedrich,\n“A discrete choice model for solving conflict situations between pedes-\ntrians and vehicles in shared space,” arXiv preprint arXiv:1709.09412,\n2017.\n[29] H. Cheng, Y. Li, and M. Sester, “Pedestrian group detection in shared\nspace,” in 2019 IEEE Intelligent Vehicles Symposium (IV).\nIEEE,\n2019, pp. 1707–1714.\n[30] M. Pr´edhumeau, A. Spalanzani, and J. Dugdale, “Pedestrian behavior\nin shared spaces with autonomous vehicles: An integrated framework\nand review,” IEEE Transactions on Intelligent Vehicles, 2021.\n[31] D. Bates, M. M¨achler, B. Bolker, and S. Walker, “Fitting linear mixed-\neffects models using lme4,” arXiv preprint arXiv:1406.5823, 2014.\n",
  "metadata": {
    "source_path": "papers/arxiv/Characterizing_Structured_versus_Unstructured_Environments_based_on\n__Pedestrians_and_Vehicles_Motion_Trajectories_a01216f41596437b.pdf",
    "content_hash": "a01216f41596437b53b171760f07374a5129d3bc7eb4d8c2badd6e2fc1f47955",
    "arxiv_id": null,
    "title": "Characterizing_Structured_versus_Unstructured_Environments_based_on\n__Pedestrians_and_Vehicles_Motion_Trajectories_a01216f41596437b",
    "author": "",
    "creation_date": "D:20250225022354Z",
    "published": "2025-02-25T02:23:54",
    "pages": 8,
    "size": 578507,
    "file_mtime": 1740470219.217394
  }
}