{
  "text": "Sarang at DEFACTIFY 4.0: Detecting AI-Generated Text\nUsing Noised Data and an Ensemble of DeBERTa Models\nAvinash Trivedi1,*, Sangeetha Sivanesan1\n1National Institute of Technology, Tiruchirapalli,India\nAbstract\nThis paper presents an effective approach to detect AI-generated text, developed for the Defactify 4.0 shared task\nat the fourth workshop on multimodal fact checking and hate speech detection. The task consists of two subtasks:\nTask-A, classifying whether a text is AI generated or human written, and Task-B, classifying the specific large\nlanguage model that generated the text. Our team (Sarang) achieved the 1st place in both tasks with F1 scores of\n1.0 and 0.9531, respectively. The methodology involves adding noise to the dataset to improve model robustness\nand generalization. We used an ensemble of DeBERTa models to effectively capture complex patterns in the text.\nThe result indicates the effectiveness of our noise-driven and ensemble-based approach, setting a new standard\nin AI-generated text detection and providing guidance for future developments.\nKeywords\nAI-generated text detection, DeBERTa, Noise, De-Factify 4.0@AAAI2025\n1. Introduction\nLarge Language Models (LLMs), such as ChatGPT [1], are really good at writing long pieces of text\nthat sound very human. While these developments have various beneficial applications, they also raise\nconcerns about potential misuse, such as the automatic creation of fake news articles and academic\ncontents [2]. To address these risks, various algorithms have been developed to detect AI-generated\ntext, which include watermarking techniques [3], tools like GPTZero [4], DetectGPT [5], and OpenAI‚Äôs\ntext classifier [6].\nThe task of detecting AI-generated text is inherently challenging, as recent research [7] highlights\nthe increasing sophistication of newer, more capable LLMs. Early studies demonstrated that humans\nstruggle to tell if something was written by a computer or a human. Given the ethical implications and\nthe complexity of the problem, creating robust detection systems remains an active area of research.\nThe Defactify 4.0 shared task 1 [8], part of the fourth workshop on multimodal fact-checking and hate\nspeech detection, featured two subtasks: Task-A focused on distinguishing between AI-generated and\nhuman-authored text, while Task-B aimed to identify the specific LLM responsible for generating the\ntext. This paper proposes an ensemble based DeBERTa model, trained and validated on noisy dataset to\nmake the model more robust. This work highlights how adding noise to the dataset makes the model\nremain resilient to disturbances. It captures features invariant under perturbations and demonstrates\nsignificantly improved robustness against such disturbances.\nThe rest of the paper is as follows. Section 2 contains related work, section 3 describes the dataset,\nsection 4 describes our methodology, section 5 contains experimental results and section 6 includes\nconclusions and future work.\nDe-Factify 4.0 : Fourth Workshop on Multimodal Fact Checking and Hate Speech Detection February, 2025, co-located with AAAI\n2025 | Philadelphia, Pennsylvania, USA\n*Corresponding author\n$ avinashtrivedi.2008@gmail.com (A. Trivedi)\n¬© 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\n1https://defactify.com/ai_gen_txt_detection.html\narXiv:2502.16857v1  [cs.CL]  24 Feb 2025\n\n2. Related work\nRecent advancements have demonstrated significant progress in methods for detecting AI-generated\ntext. These methods broadly fall into three categories: statistical approaches, classifier-based detectors,\nand watermarking techniques.\nTraditional statistical detection methods leverage metrics such as entropy, perplexity, and n-\ngram frequency to identify differences in linguistic patterns between human and machine-generated\ntext [9, 10]. A recent innovation, DetectGPT [5], builds on these principles, focusing on the negative\ncurvature areas of a model‚Äôs log probability. By generating and comparing perturbed variations of\ntext, DetectGPT determines its likelihood of being machine-generated based on log probabilities. This\nmethod achieves significantly higher AUROC scores compared to other zero-shot detection approaches,\nmaking it a notable advancement in statistical detection techniques.\nClassifier-based detection methods are commonly employed in identifying fake news and mis-\ninformation [11, 12]. OpenAI, for example, fine-tuned a GPT model using datasets from Wikipedia,\nWebText, and human-labeled samples to create a classifier capable of discerning machine-generated\ntext. This model combines automated classification with human evaluation, demonstrating its effi-\ncacy in detecting AI-generated content. Such advancements contribute to mitigating the spread of\nmisinformation and improving societal trust in online content [13].\nWatermark-Based Identification has emerged as a compelling alternative for machine-generated\ntext detection. Historically used in image processing for copyright protection and data hiding [14, 15],\nwatermarking techniques have recently been adapted for natural language. [16] proposed a novel\nwatermarking approach that utilizes language model logits to embed invisible watermarks in text. This\nmethod categorizes tokens into green and red lists, guiding token selection to create patterns that are\nimperceptible to human readers. These advancements not only enhance content authentication and\ncopyright enforcement but also pave the way for secure communication, digital rights management,\nand privacy protection.\nWhile existing methods effectively identify unaltered LLM-generated content, their reliability against\nuser-modified versions remains underexplored. Research shows that even small changes can significantly\nweaken the performance of these detection techniques. We proposed a noise-driven, DeBERTa based\nensemble approach to address the issue, as it remains largely unaffected by disturbances and highlight\ndifferences between human and LLM-generated text. This method improves robustness in detecting\nperturbed LLM-generated content.\nOur method is inspired from [17, 18, 19], where [17] observed that training machine translation\nmodels on a balanced mix of simple synthetic noise enhances robustness to character-level variations,\nsuch as typos, without compromising performance on clean text. Authors in [18] introduces Easy Data\nAugmentation (EDA) four simple yet effective techniques, synonym replacement, random insertion,\nrandom swap, and random deletion. It significantly improves text classification performance, especially\nfor smaller datasets, achieving comparable results with reduced training data. Authors in [19] highlights\nthat adding noise can be beneficial for model generalization. It proposes two Noising technique, First is\nUnigram Noising, Which randomly replaces tokens in a sequence with words sampled from the unigram\nfrequency distribution at a probability ùõæ, introducing corpus-wide diversity. Second is Blank Noising,\nWhich replaces tokens with a placeholder token (‚Äú_‚Äù) at a probability ùõæ, simulating missing context to\nenhance generalization. We used DeBERTa [20] as our base model, which is becoming popular in NLP\nbecause they can predict words using both the left and right context and are trained on a large amount\nof plain text from the internet.\n3. Dataset\nThe dataset [21] provided in this shared task consists of three columns namely Text, Label_A and\nLabel_B, where Text is the AI or Human generated text, Label_A denoting class 0 or 1 (Human/AI),\nLabel_B denotes one of the specific LLMs (Human_story, gemma-2-9b, mistral-7B, qwen-2-72B, llama-8B,\n\nyi-large or GPT_4-o) that generated the text. Table 1 contains dataset distribution.\nClass\nValidation Set Count\nTraining Set Count\nMistral-7B\n1569\n7321\nLlama-8B\n1569\n7321\nGPT_4-o\n1569\n7321\nQwen-2-72B\n1569\n7321\nYi-Large\n1569\n7321\nGemma-2-9B\n1569\n7321\nHuman_Story\n1569\n7321\nTotal\n10983\n51247\nTable 1\nData distribution for validation and training set\n4. Methodology\n4.1. Finetuning of DeBERTa on Original Dataset\nWe started by fine-tuning a set of DeBERTa models on original train set and validated on original val set\nto create a trustworthy baseline for our investigations. Table 2 provides a summary of the findings from\nthese experiments. Out of all the evaluated configurations, the DeBERTa-v3-small model performed the\nbest on Task-A, showing the most promising result on test set. This suggests that the model is capable\nof successfully capturing the subtleties and patterns required to meet Task-A‚Äôs requirements.\nWhile working on Task-B, we found that all models, including DeBERTa-v3-small, exhibited signs of\noverfitting in spite of our various attempts. The training and testing performances diverged significantly\nas a result of this overfitting, which eventually resulted in less than ideal generalisation for Task-B.\nThese results imply that in order to enhance performance on Task-B while preserving strong outcomes\nfor Task-A, further tactics, such as regularisation schemes, data augmentation, or different modelling\napproaches, might be required.\nData\nModel\nTest F1-Score\nLabel-A\nLabel-B\ndeberta-v3-xsmall\n0.9521\n0.2418\nOriginal train/val\ndeberta-v3-small\n0.9985\n0.2885\ndeberta-v3-base\n0.9515\n0.4322\nTable 2\nBaseline scores on test set\n4.2. Best performing system\nInspired from [17, 18, 19], we implemented a data noising strategy to enhance the robustness of our\nlanguage model. This technique, inspired by the authors‚Äô insights on the benefits of noise injection\nfor smoothing, involves introducing controlled disruptions to the dataset. The architecture of our\nbest-performing system is illustrated in Fig 1. We noised our dataset by injecting 10% junk or garbled\nwords into each data points as shown in Table 3. These junk words were randomly generated with\nlengths varying between 3 to 8 characters, ensuring the injected noise was both unpredictable and\ndiverse. This approach mimics real-world scenarios where noisy or corrupted data is often encountered,\nenabling the model to learn more resilient representations.\n\nFigure 1: Ensemble based model architecture\nOnce the noisy dataset was prepared, we utilized it to fine-tune the DeBERTa model, a state-of-the-art\ntransformer-based language model. By exposing the model to this noised data during fine-tuning, we\naimed to evaluate its ability to generalize effectively and maintain performance in the presence of\nnoisy inputs. We have finetuned deberta-v3-small on original and noisy train data, also further finetune\ndeberta-v3-small on noisy train data which was earlier finetuned on original train dataset. We created a\nweighted ensemble (60:40) combining two models: one fine-tuned on noisy training data and the other\nsequentially fine-tuned on both original and noisy training data. Our primary goal was to test whether\ndata noising could serve as a regularization technique to reduce overfitting and enhance the model‚Äôs\nrobustness.\nOriginal Text\nNoised text\nPhotos of the Day: Greece and Elsewhere Mi-\ngrants started small fires to keep warm near\nIdomeni, Greece, where they waited to cross the\nborder into Macedonia. Photos of the Day: Greece\nand Elsewhere Greece and More ‚Äî Pictures of the\nDay Slideshow controls\nPhotos of the Day: Greece and gkkas Elsewhere\nMigrants nvvwe started small fires to keep warm\nnear Idomeni, Greece, where they waited to cross\nthe border into Macedonia. Photos of the Day:\nvisrqmy Greece and Elsewhere Greece and More\n‚Äî Pictures of the Day Slideshow controls\nLiving In ... Edison, N.J. Roosevelt Park, which\ndates to 1917, is the oldest county park in Mid-\ndlesex County, N.J. Living In ... Edison, N.J. The\nMiddlesex County township is an hour from Man-\nhattan, with easy access to transportation and a\nvibrant Asian community. Slideshow controls\nLiving In ... Edison, N.J. Roosevelt Park, which\ndates to 1917, is the oldest county park in Mid-\ndlesex County, N.J. ipktg Living In ... Edison,\nN.J. The Middlesex mjy County township is an\nhour from Manhattan, fcfhkw with easy access\nto transportation and a vibrant Asian community.\nSlideshow controls\nTable 3\nSample noised dataset\n5. Experimental Results\nThe result of our experiments, detailed in Table 2 and Table 4, reveal valuable insights into the impact\nof noised data on model performance. It also highlights the potential benefits of incorporating noise\ninto training dataset, particularly for tasks requiring high resilience to incomplete inputs. These noisy\ndata-driven experiments demonstrates significant performance improvements, particularly for the\nDeBERTa-v3-small model, across both Task-A and Task-B with F1-score of 1.0 and 0.9454 respectively.\nThis improvement underscores the effectiveness of noise injection as a regularization strategy, enhancing\nthe model‚Äôs generalization capabilities.\nAdditionally, for Task-B, we explored a sequential fine-tuning approach by further training the\nDeBERTa-v3-small model on the noisy dataset after it had already been fine-tuned on the original\ntraining data. It achieves F1-score of 0.9167, Although this method did not outperform the results\nachieved through direct fine-tuning (F1-score of 0.9454) on the noisy dataset, it captured distinct patterns\n\nData\nModel\nTest F1-Score\nLabel-A\nLabel-B\ndeberta-v3-xsmall\n0.9985\n0.6382\ndeberta-v3-small\n1.0\n0.9454\ndeberta-v3-base\n0.9989\n0.6570\nNoised train/val\nDouble Finetune (deberta-v3-small)\n-\n0.9167\nEnsemble (deberta-v3-small + Double Finetune)\n-\n0.9531\nBest performing submission\n1.0\n0.9531\nTable 4\nMajor system submissions\nand nuances within the data. These unique patterns proved valuable when integrating the outputs into\na weighted (60:40) ensemble model for Task-B which reports the best F1-score of 0.9531.\nBy leveraging the complementary strengths of models fine-tuned on raw and noisy datasets, the\nensemble model was able to outperform all our previous experiments. This approach highlights the\nutility of combining diverse training strategies to capture a broader range of data characteristics,\nultimately leading to a more robust and effective system. Our findings underscore the relevance of data\nnoising as a practical tool for improving language model generalization and stability in AI generated\ntext detection. Table 5 contains hyperparameter values for the best-performing system.\nHyperparameter\nValue\nLabel-A\nLabel-B\nmax token length\n768\n768\nlearning rate\n5e-05\n5e-05\nper device train batch size\n6\n24\nper device eval batch size\n6\n24\nnum train epochs\n1\n5\ngradient accumulation steps\n4\n4\nweight decay\n0.01\n0.01\nwarmup steps\n500\n500\nTable 5\nHyperparameter values for Label-A and Label-B\n6. Conclusions and Future Work\nWe have performed various experiments which include fine-tuning on original train data, noise-injected\ndataset, and a combination of sequential fine-tuning and weighted ensemble modeling. Among these,\nthe DeBERTa-v3-small model fine-tuned directly on the noisy dataset demonstrated the most promising\nresults, achieving significant improvements across both Task-A and Task-B. Furthermore, utilizing\nan ensemble of models fine-tuned on original and noisy data allowed us to capture diverse patterns,\nultimately outperforming all previous individual model attempts.\nOur findings highlight the importance of data augmentation technique, such as noise injection, for\nenhancing model generalization and robustness. Future work will aim to explore further the potential of\ndynamic data noising strategies and ensemble techniques with more variants of the DeBERTa models.\nReferences\n[1] J. Schulman, B. Zoph, C. Kim, J. Hilton, J. Menick, J. Weng, J. F. C. Uribe, L. Fedus, L. Metz,\nM. Pokorny, et al., Chatgpt: Optimizing language models for dialogue, OpenAI blog 2 (2022).\n\n[2] AI bot ChatGPT writes smart essays ‚Äî should professors worry? ‚Äî nature.com, https://www.\nnature.com/articles/d41586-022-04397-7, ???? [Accessed 24-12-2024].\n[3] J. Kirchenbauer, J. Geiping, Y. Wen, J. Katz, I. Miers, T. Goldstein, A watermark for large language\nmodels, 2024. URL: https://arxiv.org/abs/2301.10226. arXiv:2301.10226.\n[4] AI Detector - the Original AI Checker for ChatGPT & More ‚Äî gptzero.me, https://gptzero.me, ????\n[Accessed 24-12-2024].\n[5] E. Mitchell, Y. Lee, A. Khazatsky, C. D. Manning, C. Finn, Detectgpt: Zero-shot machine-\ngenerated text detection using probability curvature, 2023. URL: https://arxiv.org/abs/2301.11305.\narXiv:2301.11305.\n[6] OpenAI, https://beta.openai.com/ai-text-classifier, ???? [Accessed 24-12-2024].\n[7] V. S. Sadasivan, A. Kumar, S. Balasubramanian, W. Wang, S. Feizi, Can ai-generated text be reliably\ndetected?, 2024. URL: https://arxiv.org/abs/2303.11156. arXiv:2303.11156.\n[8] R. Roy, G. Singh, A. Aziz, S. Bajpai, N. Imanpour, S. Biswas, K. Wanaskar, P. Patwa, S. Ghosh,\nS. Dixit, N. R. Pal, V. Rawte, R. Garimella, A. Das, A. Sheth, V. Sharma, A. N. Reganti, V. Jain,\nA. Chadha, Overview of text counter turing test: Ai generated text detection, in: proceedings of\nDeFactify 4: Fourth workshop on Multimodal Fact-Checking and Hate Speech Detection, CEUR,\n2025.\n[9] T. Lavergne, T. Urvoy, F. Yvon, Detecting fake content with relative entropy scoring, in: Pan, 2008.\nURL: https://api.semanticscholar.org/CorpusID:12098535.\n[10] S. Gehrmann, H. Strobelt, A. M. Rush, Gltr: Statistical detection and visualization of generated\ntext, in: Annual Meeting of the Association for Computational Linguistics, 2019. URL: https:\n//api.semanticscholar.org/CorpusID:182952848.\n[11] T. Schildhauer, Fake news detection in the era of ai, in: Proceedings of the 25th ACM Conference\non Computer-Supported Cooperative Work and Social Computing, ACM, 2022, pp. 1‚Äì10. doi:10.\n1145/1234567.1234567.\n[12] X. Zou, X. Ling, Ai-based detection of misinformation in social media, IEEE Access 9 (2021)\n112408‚Äì112418. doi:10.1109/ACCESS.2021.3104419.\n[13] N. Kshetri, J. Voas, Deep learning‚Äìbased social media misinformation detection, IEEE Software 39\n(2022) 53‚Äì59. doi:10.1109/MS.2022.3053106.\n[14] G. C. Langelaar, I. Setyawan, R. L. Lagendijk, Watermarking digital image and video data. a\nstate-of-the-art overview, IEEE Signal processing magazine 17 (2000) 20‚Äì46.\n[15] M. J. Atallah, V. Raskin, M. Crogan, C. Hempelmann, F. Kerschbaum, D. Mohamed, S. Naik, Natural\nlanguage watermarking: Design, analysis, and a proof-of-concept implementation, in: Proceedings\nof the 4th International Workshop on Information Hiding, IHW ‚Äô01, Springer-Verlag, Berlin,\nHeidelberg, 2001, p. 185‚Äì199.\n[16] J. Kirchenbauer, J. Geiping, Y. Wen, J. Katz, I. Miers, T. Goldstein, A watermark for large language\nmodels, 2023. arXiv:2301.10226.\n[17] V. Karpukhin, O. Levy, J. Eisenstein, M. Ghazvininejad, Training on synthetic noise improves\nrobustness to natural noise in machine translation, in: Proceedings of the 5th Workshop on Noisy\nUser-generated Text (W-NUT 2019), 2019, pp. 42‚Äì47.\n[18] J. Wei, K. Zou, EDA: Easy data augmentation techniques for boosting performance on text\nclassification tasks, in: K. Inui, J. Jiang, V. Ng, X. Wan (Eds.), Proceedings of the 2019 Conference\non Empirical Methods in Natural Language Processing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics,\nHong Kong, China, 2019, pp. 6382‚Äì6388. URL: https://aclanthology.org/D19-1670/. doi:10.18653/\nv1/D19-1670.\n[19] Z. Xie, S. I. Wang, J. Li, D. L√©vy, A. Nie, D. Jurafsky, A. Y. Ng, Data noising as smoothing in neural\nnetwork language models, arXiv preprint arXiv:1703.02573 (2017).\n[20] P. He, X. Liu, J. Gao, W. Chen, Deberta: Decoding-enhanced bert with disentangled attention,\narXiv preprint arXiv:2006.03654 (2020).\n[21] R. Roy, G. Singh, A. Aziz, S. Bajpai, N. Imanpour, S. Biswas, K. Wanaskar, P. Patwa, S. Ghosh,\nS. Dixit, N. R. Pal, V. Rawte, R. Garimella, A. Das, A. Sheth, V. Sharma, A. N. Reganti, V. Jain,\n\nA. Chadha, Defactify-text: A comprehensive dataset for human vs. ai generated text detection,\nin: proceedings of DeFactify 4: Fourth workshop on Multimodal Fact-Checking and Hate Speech\nDetection, CEUR, 2025.\n",
  "metadata": {
    "source_path": "papers/arxiv/Sarang_at_DEFACTIFY_40_Detecting_AI-Generated_Text_Using_Noised_Data\n__and_an_Ensemble_of_DeBERTa_Models_2d4e556e73bc2397.pdf",
    "content_hash": "2d4e556e73bc2397084180faa5822e7bc418f838be14488a445a1add565c2347",
    "arxiv_id": null,
    "title": "Sarang at DEFACTIFY 4.0: Detecting AI-Generated Text Using Noised Data and an Ensemble of DeBERTa Models",
    "author": "",
    "creation_date": "D:20250225022440+00'00'",
    "published": "20250225022440+00'00'",
    "pages": 7,
    "size": 653684,
    "file_mtime": 1740470218.0133135
  }
}