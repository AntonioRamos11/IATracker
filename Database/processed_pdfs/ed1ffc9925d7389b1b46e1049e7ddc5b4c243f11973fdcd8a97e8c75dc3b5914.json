{
  "text": "Culture-TRIP: Culturally-Aware Text-to-Image Generation\nwith Iterative Prompt Refinement\nSuchae Jeong1*, Inseong Choi1*, Youngsik Yun2, Jihie Kim2†,\n1Department of Computer Science and Engineering, Dongguk University,\n2Department of Computer Science and Artificial Intelligence, Dongguk University\nyys3606@dgu.ac.kr, jihie.kim@dgu.edu\nAbstract\nText-to-Image models, including Stable Diffu-\nsion, have significantly improved in generat-\ning images that are highly semantically aligned\nwith the given prompts.\nHowever, existing\nmodels may fail to produce appropriate im-\nages for the cultural concepts or objects that\nare not well known or underrepresented in west-\nern cultures, such as ‘hangari’ (Korean utensil).\nIn this paper, we propose a novel approach,\nCulturally-Aware Text-to-Image Generation\nwith Iterative Prompt Refinement (Culture-\nTRIP), which refines the prompt in order to\nimprove the alignment of the image with such\nculture nouns in text-to-image models. Our\napproach (1) retrieves cultural contexts and\nvisual details related to the culture nouns in\nthe prompt and (2) iteratively refines and eval-\nuates the prompt based on a set of cultural\ncriteria and large language models. The re-\nfinement process utilizes the information re-\ntrieved from Wikipedia and the Web. Our user\nsurvey, conducted with 66 participants from\neight different countries demonstrates that our\nproposed approach enhances the alignment be-\ntween the images and the prompts. In particu-\nlar, C-TRIP demonstrates improved alignment\nbetween the generated images and underrepre-\nsented culture nouns. Resource can be found at\nhttps://shane3606.github.io/Culture-TRIP.\n1\nIntroduction\nTo date, many Text-to-Image Models (Ramesh\net al., 2022; Rombach et al., 2022a; Ruiz et al.,\n2023) have demonstrated remarkable improve-\nments. Despite the outstanding performance in the\ntext-to-image models, the models fail to align the\nimages with the culture nouns in the prompts, such\nas ‘ao dai’(a Vietnamese clothing) or ‘hangari’ (a\nKorean utensil). Most of these issues stem from the\nlarge training datasets gathered by crawling the In-\nternet without paying attention to the details of the\n*indicates equal contribution.\n†indicates corresponding authors.\nFigure 1: Comparison between Stable Diffusion with\nand without our proposed approach, C-TRIP. (a) shows\nan image of a hangari from Wikipedia. (b) is an image\ngenerated by Stable Diffusion 2, while (c) shows an\nimage generated with our approach. The additional\nknowledge about hangari (highlighted in red) in (c)\nhelps the model generate an image that more closely\nresembles the actual hangari.\ncultural elements (Yun and Kim, 2024). Further-\nmore, Internet access varies significantly across\ncountries (Birhane et al., 2023; Luccioni et al.,\n2024), leading to challenges in appropriately align-\ning culture nouns due to insufficient data, as shown\nin Figure 1 (b).\nRepresentation is important in AI applications.\nAppropriate representation can positively affect\nviewers, while inappropriate ones can negatively\naffect them and can even be harmful (Castañeda,\n2018). Culture nouns are essential elements that\noften represent the identity and the uniqueness of\nthe given culture. The misrepresentation of cul-\nture nouns by existing text-to-image models may\ncause dissatisfaction in the corresponding coun-\ntries. Moreover, the models may reinforce harmful\nstereotypes about particular cultures.\nIn this paper, we introduce a new approach\nthat generates more culturally aligned images for\nthe given culture nouns, called Culturally-Aware\nText-to-Image Generation with Iterative Prompt\narXiv:2502.16902v1  [cs.CV]  24 Feb 2025\n\nRefinement (C-TRIP). C-TRIP focuses on refin-\ning the prompt to ensure that the culture nouns are\nappropriately represented in the generated images,\nas shown in Figure 1 (c). Our goal is to generate\nculturally-aware images by appropriately aligning\nculture nouns with images from underrepresented\ncountries.\nOur research question is, How can we refine the\nprompt so that text-to-image models generate im-\nages that appropriately align with culture nouns?\nThe Culture Capsules (Taylor and Sorensen, 1961)\nis an educational approach designed to help learn-\ners who have not directly experienced a culture\ngain the proper understanding. This approach ex-\nplains cultural contexts and visual details, enabling\nlearners to gain comprehensive understand unfa-\nmiliar cultures. Through this process, learners can\ndevelop a deeper profound awareness of different\ncultures.\nInspired by the Culture Capsules, C-TRIP first\nretrieves cultural contexts and visual details related\nto the culture nouns in the prompt and then iter-\natively refines and evaluates the prompt against\nthe criteria used in culture education. Large Lan-\nguage Models (LLMs) are used for this iterative\nrefinement and evaluation process, guiding the text-\nto-image model in generating images for culture\nnouns.\nWe conducted experiments across eight coun-\ntries, refining a total of 10,000 prompts by using 50\nprompt templates for each of the 25 culture nouns\nper country. To evaluate our results, we recruited\nparticipants who were a native of the correspond-\ning country and had a high familiarity with the\nculture to rank images generated by Stable Diffu-\nsion 2 (Rombach et al., 2022a), with or without\nthe proposed iterative prompt refinement. The 66\nparticipants across eight countries evaluated the\n990 generated images, and C-TRIP received rat-\nings for cultural alignment that were 18.84% on\naverage higher than the baseline’s. In particular,\nour approach demonstrated more improvement for\nrelatively the Unrecognized/Underrepresented Cul-\nture nouns (UC nouns for short) than for the Rec-\nognized/Common Culture nouns (RC nouns for\nshort).\nOur contributions are as follows:\n1. We introduce culturally-aware image genera-\ntion with a prompt that improves the represen-\ntation of ‘culture nouns’—cultural concepts\nor objects often overlooked by existing text-\nto-image models.\n2. We propose a novel approach, C-TRIP\n(Culturally-Aware Text-to-Image GeneRation\nwith Iterative Prompt Refinement), which iter-\natively refines the prompt in order to improve\nthe alignment of culture nouns in the images\ngenerated by text-to-image models.\n3. Human evaluations by representatives across\neight countries demonstrate that our refined\nprompts enhance the alignment between gen-\nerated images and culture nouns. In particular,\nC-TRIP demonstrated more improvement for\nUC nouns than RC nouns.\n2\nRelated Work\n2.1\nCultural Text-to-Image Generation\nPreviously, various methods have been proposed\nto address the cultural bias in text-to-image mod-\nels (Cho et al., 2023; Friedrich et al., 2023; Luc-\ncioni et al., 2024). Liu et al. (2024) collected a\ncultural dataset called CCUB across nine cultural\ncategories for five countries and proposed a train-\ning technique named SCoFT to address cultural\nbias. Similarly, Kannen et al. (2024) collected the\nCUBE across three cultural categories for eight\ncountries. However, these approaches are highly\nresource-intensive, demanding significant time and\ncost for data collection.\nOther works (Basu et al., 2023; Bansal et al.,\n2022) attempted to mitigate cultural bias by modi-\nfying prompt. However, merely adding contextual\ninformation such as country names to prompt is\nproven insufficient in mitigating cultural bias, par-\nticularly for the concepts from underrepresented\ncountries.\nUnlike the previous approaches, our approach\nrefines prompt based on cultural information and\nvisual details to improve the alignment of text-to-\nimage models with culture nouns, which are signif-\nicant for representing unique concepts and objects\nacross cultures.\n2.2\nPrompt Engineering in Text-to-Image\nGeneration\nThe prompt as input to the text-to-image generation\nguides the images created by the models. Many\nstudies\n(Oppenlaender, 2023; Liu and Chilton,\n2022; Brade et al., 2023) on prompt engineering\naimed at optimizing user-desired images by text-to-\nimage models.\n\nFigure 2: C-TRIP Overview. First, retrieve cultural contexts (cultural background, purpose) and visual details\nrelated to the culture nouns as described in Section 3.1. Then, refining the prompt based on the obtained information.\nWe iteratively evaluate and refine the prompt as described in Section 3.2.\nWen et al. (2024) propose a method for learning\nhard prompts that is optimized for text-to-image\ngeneration. This approach demonstrates how to\ngenerate prompt with minimal tokens that effec-\ntively guide the model to produce images in a\nspecific style. Yao et al. (2024) propose a refine-\nment method that aligns input prompt with training\nprompts, ensuring that text-to-image models pro-\nduces high-quality images.\nUnlike the existing approaches, we refine the\nprompt based on cultural information related to cul-\nture nouns, guiding text-to-image models to gen-\nerate images that align appropriately with cultural\nrepresentation.\n2.3\nRefinement\nRefinement is a method designed to improve out-\nput quality through feedback and the application\nof a refiner. Learned Refiners (Schick et al., 2022;\nSaunders et al., 2022) involve providing feedback\nthrough a trained refiner, which requires human-\nannotated data for the training process. In contrast,\nPrompted Refiners (Peng et al., 2023; Yang et al.,\n2022) offer feedback through prompting without\nthe trained refiner. Recently, a method called self-\nrefine (Madaan et al., 2024) has been proposed,\nwhich performs iterative feedback and refinement\nusing a single Large Language Model (LLM) with-\nout external supervision.\nUnlike the self-refine methods designed for LLM\ntasks, we iteratively refine the prompt based on\ncultural contexts and visual details to enhance the\nunderstanding of culture nouns in text-to-image\nmodels.\n3\nMethod\nInspired by the Culture Capsules\n(Taylor and\nSorensen, 1961), an educational method that intro-\nduces unfamiliar cultures through cultural contexts\nand visual details, our method refines the prompt\nfor text-to-image models by incorporating cultural\ncontexts and visual details relevant to the culture\nnoun. In order to include only information essential\nfor cultural expressions in the image, external infor-\nmation is retrieved, and an iterative refinement and\nevaluation process is conducted based on the crite-\nria derived from both cultural contexts and visual\ndetails.\nOur overall architecture is depicted in Figure\n2.\nWe first retrieve cultural information from\nWikipedia and Web content (Section 3.1), then sec-\nond iteratively refine and evaluate the prompt based\non scores (Section 3.2) until the stop condition is\nsatisfied.\n3.1\nCultural Information Retrieval\nIn obtaining raw information related to culture\nnouns, we use two sources. Given a culture noun,\nwe first retrieve the Wikipedia content in order to\nleverage cultural contexts and visual details. Sec-\nond, for certain culture nouns that lack sufficient\ninformation on Wikipedia, we perform additional\nretrieval from the Web. By making use of both\nWikipedia and the Web, we can collect sufficient\nraw data, even for relatively uncommon UC nouns.\n3.2\nIterative Prompt Refinement\nThe iterative refining process consists of 3 key\nsteps: Refine, Scoring, and Feedback. The Refine\nstep refines the raw information using the prompt\n\nAspect\nCriterion\nDescription\nCultural Contexts\nClarity\nThe overall clarity of the information, specifically whether\nthe necessary details to explain the culture noun\nare clearly and easily conveyed.\nBackground\nWhether the prompt provides appropriate historical or\ntemporal context.\nPurpose\nWhether the prompt describes the purpose or usage of the\nculture noun.\nVisual Details\nVisual Elements\nWhether sufficient visual information, such as color and\nshape, is provided.\nComparable Objects\nWhether the prompt offers a well-known or famous ex-\nample by drawing a comparison to the culture nouns.\nTable 1: Criteria for scoring refined information. C-TRIP performs scoring of the refined prompt based on five\ncriteria across the aspects of cultural contexts and visual details. Cultural contexts are a criterion for evaluating\ncultural information, and visual details are criteria for assessing visual information relevant to image generation.\nEach criterion is assigned a score ranging from 0 to 10.\nand feedback from the previous Feedback step. The\nScoring step evaluates the refined prompt based on\nfive cultural criteria. Finally, the Feedback step pro-\nposes revisions in the prompt based on the refined\nprompt and the evaluation score. All three steps\nwere implemented using LLaMA-3-70B (Dubey\net al., 2024), as iterative refinement processes bene-\nfit from larger LLM (Madaan et al., 2024) with the\nlatest open-source model.\nRefine\nThe retrieved raw information I for the\nculture noun K is used to refine the prompts in the\nRefine step. In this step, the refined prompt RP\nis typically generated based on feedback F. For\nthe first step, only the raw information I and the\nprompt P are used. In the equations, ∥denotes\nconcatenation throughout the paper.\nRPi =\n(\nRefine(K||I||P)\nif i = 0,\nRefine(K||I||RPi−1||Fi−1)\nif i > 0.\n(1)\nThrough the Refine step, only the information\nessential for cultural education is extracted from the\nraw data. The final refined prompt guides the text-\nto-image model in generating images for culture\nnouns.\nScoring\nIn the Scoring step, the refined prompts\nare evaluated based on five cultural criteria: Clarity,\nBackground, Purpose, Visual Elements, and Com-\nparable Objects. If the total score does exceed the\nthreshold (thresh.) or a specified maximum itera-\ntion i, the process stops; otherwise, it proceeds to\nthe Feedback step for further refinement.\nscorei = Scoring(K||RPi)\n(2)\nThe five scoring criteria are structured based on\nthe Culture Capsules (Taylor and Sorensen, 1961),\nwhich organize the criteria into two primary as-\npects: cultural contexts and visual details. Specifi-\ncally, Clarity, Background, and Purpose are cate-\ngorized as cultural contexts, while Visual Elements\nand Comparable Objects fall under visual details.\nDetailed descriptions of each evaluation criterion\nare provided in Table 1.\nFeedback\nIn the Feedback step, each score is\nreviewed based on the criteria, and feedback is\nprovided along with suggestions to improve the\nscores.\nFi = Feedback(K||RPi||scorei)\n(3)\nDetails illustrating the evolution of prompts dur-\ning the refinement process, along with templates\nfor each step, can be found in Appendix C\n4\nExperiments\n4.1\nData Preparation\nCulture Nouns\nThe culture nouns are phoneti-\ncally transcribed into English based on the original\npronunciation in their respective languages (e.g.,\nhangari, pronounced /hA:NgA:ri/). However, when\nan English equivalent exists, they are represented in\n\nthe format of ‘Adjective form for the country + En-\nglish expression’ (e.g., Korean pagoda) to signify\nculture nouns.\nSetup\nBased on Basu et al. (2023), which ad-\ndresses cultural bias in text-to-image generation\nby modifying prompts, we selected eight countries\nrepresenting diverse cultural backgrounds: India,\nPakistan, China, Japan, South Korea, Vietnam, the\nUnited States, and Germany. Drawing on research\nby Liu et al. (2024) on culturally-aware text-to-\nimage models, we focused on eight specific cat-\negories that typically represent culture in visual\nexpressions: architecture, city landmarks, clothing,\ndance & music, visual arts, food & drink, religion\n& festivals, and utensils and tools. We generated\n10,000 prompts using 50 prompt templates for each\nof the 25 culture nouns per country. These tem-\nplates, generated by GPT-4o, incorporate culture\nnouns into typical scenarios, enabling consistent\nprompt generation for experimentation without re-\nlying on real-world prompts.\n4.2\nBaselines for Ablation Study\nTo effectively analyze the specific contributions of\ncultural contexts and visual details based on the\nCulture Capsules approach, the baseline and ab-\nlation configurations were established in order to\nsystematically examine the roles of cultural con-\ntexts (Clarity, Background, Purpose) and visual\ndetails (Visual Elements, Comparable Objects).\nIn this study, we evaluated three configurations\nof the C-TRIP, each with different criteria for\nprompt refinement: C-TRIP0, C-TRIP3, and C-\nTRIP5. For C-TRIP3 and C-TRIP5, the refinement\nprocess was performed up to a maximum of 5 itera-\ntions, ensuring that the prompts reached the desired\nlevel of cultural and visual alignment.\nThese configurations were applied to 10,000\nBase Prompts, resulting in 40,000 refined prompts.\nSubsequently, 80,000 images were generated, with\ntwo images created for each prompt using Stable\nDiffusion 2 (Rombach et al., 2022b).\nC-TRIP0\nC-TRIP0 utilizes prompts augmented\nwith raw cultural information without applying the\nIterative Prompt Refinement. This configuration is\nused to evaluate the baseline effect of unrefined cul-\ntural information, enabling an assessment of how\nmuch alignment can be achieved without iterative\nrefinement.\nC-TRIP3\nC-TRIP3 refines the prompts based\nsolely on the cultural context criteria (Clarity, Back-\nground, and Purpose). This setup evaluates the\ncontribution of cultural context alone without in-\ncorporating visual details. This enables assessing\nhow effectively the refined cultural information en-\nhances alignment with the intended culture nouns\nin the generated images.\nC-TRIP5.\nC-TRIP5 incorporates both cultural\ncontext and visual details, refining prompts accord-\ning to all five criteria: Clarity, Background, Pur-\npose, Visual Elements, and Comparable Objects.\nThis configuration assesses whether adding visual\ndetails improves the alignment. By comparing C-\nTRIP3 and C-TRIP5, we can evaluate how much\nvisual details enhance cultural alignment in the gen-\nerated images.\n4.3\nEvaluation\nUser Survey.\nThe alignment of images with cul-\nture nouns is inherently subjective and can only\nbe appropriately evaluated by participants of the\nrespective cultural groups based on country. Ac-\ncordingly, surveys were distributed to individuals\nwho were either native to the respective countries\nor had at least three years of cultural experience\nto evaluate our approach. Participants were pro-\nvided with survey questions based on their chosen\ncountry. Each survey page presented 4 images of a\nrandomly selected culture noun. Each survey page\ncontains 4 evaluation questions to rank images: (a)\nCultural Representation, (b) The Naturalness of the\nKeyword, (c) Offensiveness, and (d) Description\nand Image Alignment. Participants were asked to\nevaluate a randomly ordered set of images for each\nquestion. The image ranked first was considered\nthe most appropriately represented and least offen-\nsive, while the image ranked fourth was deemed\nthe most inappropriate and offensive. Detailed in-\nformation regarding the user survey is provided in\nthe appendix E.\nWe employed the Matrix Mean-Subsequence\nReduced (MMSR) model\n(Ma and Olshevsky,\n2020), an established algorithm (Majdi and Ro-\ndriguez, 2023) for noise label aggregation provided\nby crowd-kit (Ustalov et al., 2021), to quantita-\ntively estimate subjective performance perception.\nUsing MMSR, the labels from all respondents were\naggregated through weighted majority voting based\non the assessment of their reliability. Subsequently,\nthe MMSR+Vote method was applied, in which\n\nFigure 3: Qualitative comparison of C-TRIP ablated configurations compared to Base Prompt. The six columns can\nbe divided into two groups: Relatively UC nouns (left four columns) and RC nouns (right two columns). The left\ngroup needed C-TRIP to introduce culture nouns that were underrepresented in Text-to-Image models, while the\nright group had to recall what they already knew through the additional information provided.\nlabels were further aggregated and ranked using\nsimple majority voting.\nAutomatic Evaluation.\nIn addition to the cul-\ntural survey, we measured the VIEScore (Ku et al.,\n2023) using GPT-4o, demonstrating a strong corre-\nlation with human evaluations of text-guide image\ngeneration. The VIEScore assesses the Semantic\nConsistency (SC) and the Perceptual Quality (PQ)\nand Overall score based on these metrics. To eval-\nuate C-TRIP, 150 Base Prompts were randomly\nsampled from each country. These prompts were\nthen processed through C-TRIP configurations, re-\nsulting in a total of 600 samples per country for\nwhich scores were measured.\n5\nResults\nQualitative Comparison\nFigure 3 compares the\nimages generated from each C-TRIP configuration\nand the Base Prompt described in Section 4.2. The\nrefined prompt generated by C-TRIP provides cul-\ntural knowledge to Stable Diffusion 2, contributing\nto the generation of culturally-aware images. C-\nTRIP5, which includes the visual details criteria,\ndemonstrated higher quality representation. That\nis, Stable Diffusion 2 can produce better images\nwhen the prompts include appropriate cultural con-\ntexts and visual details. With these enhancements,\nC-TRIP effectively improves the model’s ability to\ngenerate culturally relevant images.\n\nEvaluation Criteria\nBase Prompt\nC-TRIP0\nC-TRIP3\nC-TRIP5\nUser Survey (↓)\nCultural Representation\n2.73\n2.53\n2.56\n2.18\nThe Naturalness of the Keyword\n2.76\n2.69\n2.38\n2.18\nOffensiveness\n2.81\n2.60\n2.46\n2.13\nDescription and Image Alignment\n2.53\n2.66\n2.51\n2.30\nVIEScore (↑)\nSemantic Consistency (SC)\n0.37\n0.36\n0.37\n0.38\nPerceptual Quality (PQ)\n7.50\n7.81\n7.80\n7.76\nOverall Score\n0.71\n0.71\n0.73\n0.74\nTable 2: Result of User Survey and VIEScore. The results highlighted in bold indicate the best outcomes. For the\nUser Survey, a lower average rank is better, while for the VIEScore, a higher score is preferred. Except for the\nPerceptual Quality in the VIEScore, C-TRIP5 received the best evaluation in all other evaluations.\nUser Survey Results.\nA total of 66 participants\nfrom eight countries participated in the survey,\nranking the four configurations of the generated\nimages based on the four evaluation questions spec-\nified in the survey. The average ranking for each\nselected configuration is presented in the Table 2.\nWhen applying the MMSR algorithm to all the\nsurvey responses, C-TRIP5 achieved the highest\nranking overall. C-TRIP3 ranked second-highest,\nusing cultural contexts criteria alone is still effec-\ntive in the refinement. However, C-TRIP0 scored\nlower than the Base Prompt, particularly in the De-\nscription and Image Alignment questions. This sug-\ngests that unrefined prompts may introduce irrele-\nvant details, which can degrade description quality.\nFurther analyzing alignment, we converted the\nrankings into binary comparisons between C-\nTRIP5 and the Base Prompt, isolating and com-\nparing their respective rankings. This approach\nrevealed that C-TRIP5 demonstrated higher aver-\nage alignment in 61% of the time.\nIn conclusion, incorporating both cultural con-\ntexts and, importantly, visual details in the scoring\nprocess significantly enhances the alignment of cul-\nture nouns with the generated images.\nAutomatic Evaluation Results.\nC-TRIP5 scored\nthe best in the evaluation of the SC score, evaluat-\ning the semantic similarity between the prompt and\nthe generated image. However, C-TRIP0 scored\nthe best in the PQ score, which assesses the natural-\nness of the generated image. This result suggests\nthat additional iterative refinement can potentially\nreduce the perceived naturalness of the image. It\nappears that the additional refinement process may\nhave overemphasized specific details, thereby devi-\nating from the naturalness in quality as perceived by\nGPT-4o. Nevertheless, C-TRIP5 still outperformed\nthe Base Prompt by 3.4%. Overall, C-TRIP5 main-\ntained the highest score. In conclusion, as in the\nuser survey results, incorporating both cultural and\nvisual refinements consistently enhances the over-\nall performance.\n6\nAblation Study for UC Nouns\nThe Culture Capsule approach is a method that\nteaches learners who have not experienced a par-\nticular culture. With this idea in mind, we aimed\nto apply a similar approach to words that Stable\nDiffusion 2 is not familiar with. In this section,\nwe analyzed and compared the Unrecognized/Un-\nderrepresented Culture nouns (UC nouns) and the\nCommon/Recognized Culture nouns (RC nouns).\nUC and RC noun groups\nWe categorized cul-\nture nouns into UC and RC noun groups according\nto their frequency within the training dataset used\nfor Stable Diffusion 2. To achieve this, we analyzed\nRe-LAION-2B-en-research, a filtered true subset\nof the LAION-2B-en (Schuhmann et al., 2022), us-\ning a punsafe > 0.95 threshold and keyword-based\nfilters to remove potentially suspicious content.1\nOur analysis focused on culture nouns within the\ndataset captions, classifying them based on their\nfrequency of appearance. These nouns were then\ngrouped using a quartile-based approach (Q1 to\nQ4), with Q1 and Q2 representing UC nouns and\nQ3 and Q4 representing RC nouns. This group-\ning provided a structured means to evaluate the\nC-TRIP’s capacity to generate culturally aligned\nimages across varying levels of representation.\nUser Survey.\nWe used the normalized improve-\nment score to evaluate UC nouns. This score is cal-\nculated by normalizing the difference between the\n1https://laion.ai/blog/relaion-5b/\n\nFigure 4: A box plot illustrating the normalized im-\nprovement scores for each group (Q1, Q2, Q3, and\nQ4). A score exceeding 0.45 signifies that the C-TRIP’s\nguidelines enhance the image alignment of the Stable\nDiffusion 2 model. Notably, the Q1 group exhibits\nthe highest performance improvement compared to the\nother groups.\naverage rankings of C-TRIP5 and the Base Prompt\nin the user survey, measuring the improvement of\nC-TRIP5 over the Base Prompt. A normalized im-\nprovement score higher than 0.45 indicates that\nC-TRIP’s guidelines improved image alignment in\nStable Diffusion 2.\nOur approach performed the best with the Q1\ngroup, with the highest median score and a narrow\nIQR, presenting consistent improvement across this\ngroup, as shown in Figure 4. This suggests that\nC-TRIP effectively reinforces the generation of im-\nages for the Q1 group, enhancing alignment for\nUC nouns. The Q2 group demonstrated the highest\nupper range within the IQR and the second-highest\nmedian, suggesting effective but slightly variable\nimprovements. However, the Q3 group showed the\nlowest performance with a wide variance, which\nmay potentially indicate that additional information\ncould decrease alignment for culture nouns.\nOur approach demonstrated an 11.05% higher\nmean normalized improvement score for UC nouns\ncompared to RC nouns. The t-test yielded a t-\nstatistic of 2.951 and a p-value of 0.0033, providing\nstatistical evidence of a significant performance im-\nprovement for the UC noun group. These results\nindicate that C-TRIP’s guidance was more effective\nin improving alignment with UC nouns than with\nRC nouns.\nQ1\nQ2\nQ3\nQ4\nSemantic Consistency (SC)\n0.1304\n-0.0003\n-0.0077\n0.047\nPerceptual Quality (PQ)\n0.4517\n0.2879\n0.3059\n0.1093\nOverall\n0.2158\n0.0165\n0.0489\n0.0541\nTable 3: Score Differences between C-TRIP5 and Base\nPrompt across Groups (Q1, Q2, Q3, and Q4), Assessed\nby GPT-4o. The VIEScore incorporates three key as-\npects: Semantic Consistency, reflecting the alignment\nbetween the image and the prompt; Perceptual Quality,\nmeasuring the naturalness of the generated image; and\nthe Overall Score, which combines these metrics.\nAutomatic Evaluation.\nAs shown in Table 3, C-\nTRIP5 demonstrated improvements in all scores:\nSC, PQ, and Overall score. The table highlights sig-\nnificant gains in Q1, with notable increases across\nall scores. However, C-TRIP5 scored lower in the\nSC score with Q2 and Q3. This discrepancy with\nthe user survey highlights the potential limitations\nof using VIEScore, which relies on LLMs trained\non culturally biased web-based data. It empha-\nsizes the need for surveys conducted by members\nof the respective cultural groups when evaluating\nculture nouns. The consistently low SC scores sug-\ngest that LLMs may struggle to accurately assist\nin recognizing and aligning culture nouns, further\nlimiting VIEScore’s effectiveness in assessing cul-\nturally specific content.\n7\nConclusion\nIn this paper, we introduced C-TRIP (Culturally-\nAware Text-to-Image Generation with Iterative\nPrompt Refinement), a novel approach that iter-\natively refines prompts to improve the alignment\nof culture nouns with images generated by existing\ntext-to-image models without any fine-tuning. Ex-\nperiments across eight countries demonstrated that\nC-TRIP significantly improves the alignment of\nculture nouns in generated images, particularly for\nunderrepresented UC nouns. User surveys and au-\ntomatic evaluations consistently present C-TRIP’s\nsuperior performance in cultural representation and\nthe semantic consistency.\n8\nLimitations\nSources like Wikipedia and general Web content\ncontain cultural biases (Miquel-Ribé and Lani-\nado, 2018; Baeza-Yates, 2018), which can affect\nthe refinement process and C-TRIP’s capacity to\nprovide balanced cultural representation. Future\nwork should focus on enhancing the information\nretrieval process through developing culturally di-\n\nverse datasets, thereby ensuring high-quality, rele-\nvant data for effective prompt refinement.\nThe limited scope of prompts utilized in our ex-\nperiments and human evaluations presents a current\nlimitation and suggests an important avenue for fu-\nture research. Additionally, our work is constrained\nby the perceptual biases of human annotators from\neight countries. To improve the reliability of eval-\nuation outcomes, future work will emphasize the\ninclusion of annotators from a broader range of\ncultural backgrounds.\nAcknowledgements\nThis research was sup-\nported by the MSIT(Ministry of Science and\nICT), Korea, under the ITRC(Information Technol-\nogy Research Center) support program(IITP-2025-\n2020-0-01789), the Artificial Intelligence Con-\nvergence Innovation Human Resources Develop-\nment (IITP-2025-RS-2023-00254592) supervised\nby the IITP(Institute for Information & Communi-\ncations Technology Planning & Evaluation), and\nthe Hyundai Motor Chung Mong-Koo Foundation.\nReferences\nRicardo Baeza-Yates. 2018. Bias on the web. Commu-\nnications of the ACM, 61(6):54–61.\nHritik Bansal, Da Yin, Masoud Monajatipoor, and Kai-\nWei Chang. 2022. How well can text-to-image gen-\nerative models understand ethical natural language\ninterventions? arXiv preprint arXiv:2210.15230.\nAbhipsa Basu, R Venkatesh Babu, and Danish Pruthi.\n2023. Inspecting the geographical representativeness\nof images from text-to-image models. In Proceed-\nings of the IEEE/CVF International Conference on\nComputer Vision, pages 5136–5147.\nAbeba Birhane,\nVinay Prabhu,\nSang Han,\nand\nVishnu Naresh Boddeti. 2023. On hate scaling laws\nfor data-swamps. arXiv preprint arXiv:2306.13141.\nStephen Brade, Bryan Wang, Mauricio Sousa, Sageev\nOore, and Tovi Grossman. 2023. Promptify: Text-to-\nimage generation through interactive prompt explo-\nration with large language models. In Proceedings of\nthe 36th Annual ACM Symposium on User Interface\nSoftware and Technology, pages 1–14.\nMari Castañeda. 2018. The power of (mis) representa-\ntion: Why racial and ethnic stereotypes in the media\nmatter. Challenging inequalities: Readings in race,\nethnicity, and immigration.\nJaemin Cho, Abhay Zala, and Mohit Bansal. 2023. Dall-\neval: Probing the reasoning skills and social biases\nof text-to-image generation models. In Proceedings\nof the IEEE/CVF International Conference on Com-\nputer Vision, pages 3043–3054.\nAbhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,\nAbhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,\nAkhil Mathur, Alan Schelten, Amy Yang, Angela\nFan, et al. 2024. The llama 3 herd of models. arXiv\npreprint arXiv:2407.21783.\nFelix Friedrich, Manuel Brack, Lukas Struppek, Do-\nminik Hintersdorf, Patrick Schramowski, Sasha Luc-\ncioni, and Kristian Kersting. 2023. Fair diffusion:\nInstructing text-to-image generation models on fair-\nness. arXiv preprint arXiv:2302.10893.\nNithish Kannen, Arif Ahmad, Marco Andreetto, Vinod-\nkumar Prabhakaran, Utsav Prabhu, Adji Bousso Di-\neng, Pushpak Bhattacharyya, and Shachi Dave. 2024.\nBeyond aesthetics: Cultural competence in text-to-\nimage models. arXiv preprint arXiv:2407.06863.\nMax Ku, Dongfu Jiang, Cong Wei, Xiang Yue, and\nWenhu Chen. 2023. Viescore: Towards explainable\nmetrics for conditional image synthesis evaluation.\narXiv preprint arXiv:2312.14867.\nVivian Liu and Lydia B Chilton. 2022. Design guide-\nlines for prompt engineering text-to-image generative\nmodels. In Proceedings of the 2022 CHI conference\non human factors in computing systems, pages 1–23.\nZhixuan Liu, Peter Schaldenbrand, Beverley-Claire\nOkogwu, Wenxuan Peng, Youngsik Yun, Andrew\nHundt, Jihie Kim, and Jean Oh. 2024. Scoft: Self-\ncontrastive fine-tuning for equitable image genera-\ntion. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, pages\n10822–10832.\nSasha Luccioni, Christopher Akiki, Margaret Mitchell,\nand Yacine Jernite. 2024. Stable bias: Evaluating so-\ncietal representations in diffusion models. Advances\nin Neural Information Processing Systems, 36.\nQianqian Ma and Alex Olshevsky. 2020. Adversarial\ncrowdsourcing through robust rank-one matrix com-\npletion. Advances in Neural Information Processing\nSystems, 33:21841–21852.\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler\nHallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,\nNouha Dziri, Shrimai Prabhumoye, Yiming Yang,\net al. 2024. Self-refine: Iterative refinement with\nself-feedback. Advances in Neural Information Pro-\ncessing Systems, 36.\nMohammad S Majdi and Jeffrey J Rodriguez. 2023.\nCrowd-certain: Label aggregation in crowdsourced\nand ensemble learning classification. arXiv preprint\narXiv:2310.16293.\nMarc Miquel-Ribé and David Laniado. 2018. Wikipedia\nculture gap: quantifying content imbalances across\n40 language editions. Frontiers in physics, 6:54.\nJonas Oppenlaender. 2023.\nA taxonomy of prompt\nmodifiers for text-to-image generation. Behaviour &\nInformation Technology, pages 1–14.\n\nBaolin Peng, Michel Galley, Pengcheng He, Hao Cheng,\nYujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou\nYu, Weizhu Chen, et al. 2023. Check your facts and\ntry again: Improving large language models with\nexternal knowledge and automated feedback. arXiv\npreprint arXiv:2302.12813.\nAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey\nChu, and Mark Chen. 2022.\nHierarchical text-\nconditional image generation with clip latents. arXiv\npreprint arXiv:2204.06125.\nRobin Rombach, Andreas Blattmann, Dominik Lorenz,\nPatrick Esser, and Björn Ommer. 2022a.\nHigh-\nresolution image synthesis with latent diffusion mod-\nels. In Proceedings of the IEEE/CVF conference\non computer vision and pattern recognition, pages\n10684–10695.\nRobin Rombach, Andreas Blattmann, Dominik Lorenz,\nPatrick Esser, and Björn Ommer. 2022b.\nHigh-\nresolution image synthesis with latent diffusion mod-\nels. In Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition (CVPR),\npages 10684–10695.\nNataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael\nPritch, Michael Rubinstein, and Kfir Aberman. 2023.\nDreambooth: Fine tuning text-to-image diffusion\nmodels for subject-driven generation. In Proceed-\nings of the IEEE/CVF conference on computer vision\nand pattern recognition, pages 22500–22510.\nWilliam Saunders, Catherine Yeh, Jeff Wu, Steven Bills,\nLong Ouyang, Jonathan Ward, and Jan Leike. 2022.\nSelf-critiquing models for assisting human evaluators.\narXiv preprint arXiv:2206.05802.\nTimo Schick, Jane Dwivedi-Yu, Zhengbao Jiang, Fabio\nPetroni, Patrick Lewis, Gautier Izacard, Qingfei You,\nChristoforos Nalmpantis, Edouard Grave, and Sebas-\ntian Riedel. 2022. Peer: A collaborative language\nmodel. arXiv preprint arXiv:2208.11663.\nChristoph Schuhmann, Romain Beaumont, Richard\nVencu, Cade Gordon, Ross Wightman, Mehdi Cherti,\nTheo Coombes, Aarush Katta, Clayton Mullis,\nMitchell Wortsman, et al. 2022. Laion-5b: An open\nlarge-scale dataset for training next generation image-\ntext models. Advances in Neural Information Pro-\ncessing Systems, 35:25278–25294.\nH Darrel Taylor and John L Sorensen. 1961. Culture\ncapsules. The Modern Language Journal, 45(8):350–\n354.\nDmitry Ustalov, Nikita Pavlichenko, and Boris Tseitlin.\n2021. Learning from crowds with crowd-kit. arXiv\npreprint arXiv:2109.08584.\nYuxin Wen, Neel Jain, John Kirchenbauer, Micah Gold-\nblum, Jonas Geiping, and Tom Goldstein. 2024. Hard\nprompts made easy: Gradient-based discrete opti-\nmization for prompt tuning and discovery. Advances\nin Neural Information Processing Systems, 36.\nKevin Yang, Yuandong Tian, Nanyun Peng, and Dan\nKlein. 2022. Re3: Generating longer stories with\nrecursive reprompting and revision. arXiv preprint\narXiv:2210.06774.\nJunyi Yao, Yijiang Liu, Zhen Dong, Mingfei Guo, Helan\nHu, Kurt Keutzer, Li Du, Daquan Zhou, and Shang-\nhang Zhang. 2024. Promptcot: Align prompt distri-\nbution via adapted chain-of-thought. In Proceedings\nof the IEEE/CVF Conference on Computer Vision\nand Pattern Recognition, pages 7027–7037.\nYoungsik Yun and Jihie Kim. 2024. Cic: A framework\nfor culturally-aware image captioning. In Proceed-\nings of the Thirty-Third International Joint Confer-\nence on Artificial Intelligence, IJCAI-24, pages 1625–\n1633. International Joint Conferences on Artificial\nIntelligence Organization. Main Track.\nA\nList of Culture Nouns\nThis part lists culture nouns for the eight countries\nused in the experiment. The culture nouns are di-\nvided into 8 categories: architecture (3), city &\nlandmark (5), clothing (4), dance & music (2), vi-\nsual arts (1), food & drink (5), religion & festival\n(3), and utensils & tools (2). The numbers in paren-\ntheses indicate the quantity of nouns used in each\ncategory. A total of 25 nouns were extracted and\nused for each country as shown in Table 6 to 13.\nB\nRetrieve Cultural Information\nThis part covers the process of retrieving cultural\ninformation.\nAs mentioned in the text, the re-\ntrieval is carried out in two steps.\nFirst, infor-\nmation about the culture noun is retrieved from\nWikipedia. However, for culture nouns categorized\nunder UC nouns, when information is unavailable\nor insufficient on Wikipedia, further information\nis retrieved from the web. Both retrieval processes\nutilized LangChain modules, with WikipediaQue-\nryRun2 used for Wikipedia searches and Google-\nSearchAPIWrapper3 used for web searches. The\ntwo examples below show cases where the retrieval\nwas successful through Wikipedia as shown in Fig-\nure 12 and where the information was not insuf-\nficient through Wikipedia, so additional retrieval\nwas also conducted from the web as shown in 13.\nC\nIterative Prompt Refinement\nFigure 14 visually depicts how the prompt evolves\nthrough the Iterative Prompt Refinement process.\n2https://python.langchain.com/api_reference/\ncommunity/tools/langchain_community.tools.\nwikipedia.tool.WikipediaQueryRun.html\n3https://python.langchain.com/docs/\nintegrations/tools/google_search/\n\nFirst, the prompt is refined, and the score is mea-\nsured based on the five evaluation criteria defined\nin Table 1. Next, the feedback process generates\nan explanation for the given score, based on the re-\nfined prompt and the measured score. Finally, the\nprompt is iteratively refined and scored based on\nthe feedback. The Iterative Prompt Refinement pro-\ncess terminates when the total score of the refined\nprompt exceeds 40 points or after 5 iterations. The\nRefine, Score, and Feedback processes all utilize\nLLaMA-3-70B, and the respective templates can\nbe found in Figure 9, Figure 10, and Figure 11.\nD\nQualitative Comparison Prompts\nThis part includes the prompts used to generate\nthe images in Figure 3 of the main text. Cultural\ncontexts are written in orange, and visual details\nare written in cyan. For culture nouns categorized\nunder the UC nouns (dengchi, jade art, and masala\ndabba), we observe that Stable Diffusion 2 effec-\ntively aligns with the culture nouns using prompt\nrefined through our approach.\nIn contrast, for culture nouns categorized under\nthe RC nouns (Willis Tower and pho), there is no\nsignificant difference in the images generated be-\ntween the refined prompt and the base prompt. For\npho (Vietnamese cuisine), Stable Diffusion 2 gener-\nates images similar to the original reference image,\neven without visual details in the refined prompt.\nE\nUser Survey\nTo evaluate the performance of our approach, we re-\ncruited 66 participants with at least 3 years or older\nof cultural experience in each of the 8 countries.\nEven so, to address the mitigate bias further, we\nrecruited at least 5 participants from each country.\nTable 4 provides detailed information about the par-\nticipants. Each participant responded to 15 survey\npages. A single page of the survey form includes\nculture nouns, a base prompt, and one image gener-\nated from each of the three approaches described in\nSection 4.2, for a total of four images. Each survey\npage has a total of four survey items (see Table\n15) to rank relative to (a) Cultural Representation,\n(b) The naturalness of the keyword, (c) Offensive-\nness, and (d) Description and Image Alignment. A\nsample of a survey page can be viewed in Figure\n15. Survey participants were compensated for their\ntime and contributions in accordance with ethical\nguidelines.\nF\nAdditional Qualitative Samples\nIn Figure 16 to 23, we present additional quali-\ntative examples illustrating how the C_TRIP ap-\nproach improves the alignment of culture nouns in\nUC and RC nouns with the generated images by\nStable Diffusion 2. Results are showcased across\nChina, Germany, India, Japan, Pakistan, South Ko-\nrea, USA, and Vietnam. Additionally, our approach\neffectively enhanced the alignment between prompt\ncontaining culture nouns from the UC nouns and\nthe generated images.\nG\nCulture noun Distribution by Quartile\nGroup for Each Country in the\nRe-LAION Dataset\nTable 16 presents the culture noun counts for each\ncountry, divided into quartiles. Each quartile repre-\nsents 25% of the data, helping to better understand\nand compare the frequency of culture nouns across\ncountries. This allows for an analysis of the char-\nacteristics of cultural expression distribution by\ncountry, making it easier to identify the proportion\nof UC and RC nouns.\nFurthermore, Figures 5 to 8 analyze the distri-\nbution of culture nouns across each quartile group.\nLooking at the top three countries in each group,\nfor Q1, the leading countries were Germany, China,\nand Vietnam. For Q2, Japan, Vietnam, and India\nranked highest. In Q3, China, India, and the USA\nwere the top countries, while in Q4, the USA ac-\ncounted for more than half, showing a dominant\nproportion.\n\nAge\nGender\nTotal\n21-30\n31-40\n41-50\nMale\nFemale\nChina\n6\n1\n0\n6\n1\n7\nGermany\n12\n0\n0\n4\n8\n12\nIndia\n5\n2\n0\n3\n4\n7\nJapan\n6\n0\n0\n2\n4\n6\nPakistan\n9\n3\n0\n9\n3\n12\nSouth Korea\n9\n1\n2\n9\n3\n12\nUSA\n6\n0\n0\n3\n3\n6\nVietnam\n4\n1\n0\n1\n4\n5\nTable 4: This table presents participant information,\nincluding age and gender distribution for each culture\ngroup.\nCountry\nUC nouns\nRC nouns\nQ1(%)\nQ2(%)\nQ3(%)\nQ4(%)\nChina\n12\n24\n40\n24\nGermany\n40\n12\n28\n20\nIndia\n16\n24\n28\n32\nJapan\n12\n40\n28\n20\nPakistan\n40\n20\n16\n24\nSouth Korea\n36\n36\n20\n8\nUSA\n0\n8\n28\n64\nVietnam\n44\n36\n12\n8\nTable 5: Distribution of culture nouns by quartile group\nfor each country. Bold text represents the highest pro-\nportion for each respective country.\nFigure 5: Country Distribution in Q1 group.\nFigure 6: Country Distribution in Q2 group.\nFigure 7: Country Distribution in Q3 group.\nFigure 8: Country Distribution in Q4 group.\n\nCategory\nCulture Nouns\narchitecture\nTulou, Siheyuan, Chinese pagoda\ncity & landmark\nDunhuang (Mogao Caves), Xi’an (Terracotta Army), Beijing (Forbidden\nCity), Beijing (Temple of Heaven), Shanghai (Oriental Pearl Tower)\nclothing\nTangzhuang, Zhongshan suit, Qipao, Hanfu\ndance & music\nLion dance, Yangge\nvisual arts\nJade art\nfood & drink\nMooncake, Peking duck, Wonton, Xiaolongbao, Chinese hot pot\nreligion & festival\nChinese New Year, Chinese Mid-Autumn Festival, Qingming\nutensils & tools\nChinese wok, Chinese bamboo steamer\nTable 6: Categorization of culture nouns associated with Chinese culture.\nCategory\nCulture Nouns\narchitecture\nGerman Romanesque, German Gothic, German Baroque\ncity & landmark\nBerlin (Brandenburger Tor), Munich (Munich’s Marienplatz), Cologne\n(Cologne Cathedral), Bavaria (Neuschwanstein Castle), Heidelberg (Hei-\ndelberg Castle)\nclothing\nLederhosen, Tracht, Dirndl, Schürze\ndance & music\nZwiefacher, Schuhplattler\nvisual arts\nDeutsch Renaissance\nfood & drink\nMulled wine, Currywurst, Knödel, Bratwurst, Sauerkraut\nreligion & festival\nNikolaustag, Weihnachtsmärkte, Oktoberfest\nutensils & tools\nBratpfanne, Rouladenklammer\nTable 7: Categorization of culture nouns associated with German culture.\nCategory\nCulture Nouns\narchitecture\nIndian stupa, Mughal architecture, Gupta architecture\ncity & landmark\nAgra (Taj Mahal), Delhi (Red Fort), Jaipur (Amber Fort), Allahabad (Alla-\nhabad Fort), Delhi (Qutub Minar)\nclothing\nLehenga, Sari, Shalwar kameez, Dhoti\ndance & music\nManipuri dance, Bharatnatyam\nvisual arts\nMughal painting\nfood & drink\nParatha, Biryani, Vada Pav, Aloo Gobi, Saag\nreligion & festival\nDiwali, Holi, Durga Puja\nutensils & tools\nTawa, Masala dabba\nTable 8: Categorization of culture nouns associated with Indian culture.\n\nCategory\nCulture Nouns\narchitecture\nShinto architecture, Torii, Edo architecture\ncity & landmark\nTokyo (Tokyo Tower), Shizuoka (Mount Fuji), Kyoto (Kinkaku-ji), Osaka\n(Osaka Castle), Matsumoto (Matsumoto Castle)\nclothing\nHanten, Haori, Hakama, Yukata\ndance & music\nKabuki, Noh mai\nvisual arts\nOrigami\nfood & drink\nOkonomiyaki, Tempura, Wagashi, Gyudon, Gyoza\nreligion & festival\nSapporo Snow Festival, Gion Matsuri, Sanda Matsuri\nutensils & tools\nSashimi b¯och¯o, Takoyaki Pan\nTable 9: Categorization of culture nouns associated with Japanese culture.\nCategory\nCulture Nouns\narchitecture\nPakistani Buddhist architecture, Pakistani Indo-Islamic architecture, Pakistani\nMughal architecture\ncity & landmark\nLahore (Badshahi Mosque), Karachi (Mazar-e-Quaid), Islamabad (Faisal\nMosque), Multan (Shrine of Bahauddin Zakariya), Hyderabad (Pakka Qila)\nclothing\nSherwani, Gharara, Shalwar Kameez, Lehenga\ndance & music\nKhattak dance, Jhumair\nvisual arts\nTruck art\nfood & drink\nBiryani, Nihari, Gulab Jamun, Kheer, Gol Gappa\nreligion & festival\nVaisakhi, Eid al-Fitr, Eid al-Adha\nutensils & tools\nKarahi, Degchi\nTable 10: Categorization of culture nouns associated with Pakistani culture.\nCategory\nCulture Nouns\narchitecture\nHanok, Korean pagoda, Korean temple\ncity & landmark\nJeonju (Hanok Village), Seoul (Gyeongbokgung), Gyeongju (Bulguksa),\nSuwon (Hwaseong Fortress), Seoul (Jongmyo Shrine)\nclothing\nHanbok, Jeogori, Durumagi, Dangui\ndance & music\nCheoyongmu, Buchaechum\nvisual arts\nMinhwa\nfood & drink\nBingsu, Kimchi, Sundubujjigae, Bibimbap, Tteokbokki\nreligion & festival\nChuseok, Seollal, Korean New Year\nutensils & tools\nGamasot, Hangari\nTable 11: Categorization of culture nouns associated with Korean culture.\n\nCategory\nCulture Nouns\narchitecture\nColonial Revival, Mission Revival, American Craftsman\ncity & landmark\nNew York City (Statue of Liberty), San Francisco (Golden Gate Bridge),\nWashington (The White House), Chicago (Willis Tower), Los Angeles (Hol-\nlywood Sign)\nclothing\nCowboy hat, Denim overalls, Buffalo check shirt, Quilted vest\ndance & music\nBluegrass, Cotton-Eyed joe\nvisual arts\nAmerican folk art\nfood & drink\nApple pie, Buffalo wings, Clam chowder, Barbecue ribs, Cornbread\nreligion & festival\nThanksgiving, Independence Day, Memorial Day\nutensils & tools\nCast iron skillet, Butter dish\nTable 12: Categorization of culture nouns associated with American culture.\nCategory\nCulture Nouns\narchitecture\nVietnamese dynasty architecture, Vietnamese stilt house, Vietnamese pagoda\ncity & landmark\nHanoi (One Pillar Pagoda), Hanoi (Temple of Literature), Hanoi (Old Quar-\nter), Hue (Imperial City of Hue), Quang Nam (My Son Sanctuary)\nclothing\nAo dai, Ao ba ba, Ao tu than, Non la\ndance & music\nMua lan, Quan ho\nvisual arts\nVietnamese silk painting\nfood & drink\nBanh mi, Goi cuon, Pho, Bun cha, Banh xeo\nreligion & festival\nVietnamese Lunar New Year, Vietnamese Mid-Autumn Festival, Hung Kings\nTemple Festival\nutensils & tools\nVietnamese wok, Vietnamese clay pot\nTable 13: Categorization of culture nouns associated with Vietnamese culture.\nFigure 9: Prompt provided to LLaMA-3-70B in the Refine step. There are two key points in the Refine step. The first\nis to effectively refine the INFORMATION and incorporate it into the Base prompt. To address the first key point,\nwe structured the first and second paragraphs. The second is to inject the information while maintaining the structure\nof the Base prompt. At this stage, we also imposed a length limit to prevent exceeding Stable Diffusion’s input limit\nand to ensure that the Base prompt remains the focal point, avoiding distraction from too much information. For the\nsecond key point, we structured the third paragraph.\n\nFigure 10: Prompt provided to LLaMA-3-70B in the Scoring step. We provided LLaMA-3-70B with the criteria\nand definitions set in Table 1 to score each criterion up to 10 points, for a total maximum score of 50 points.\nFigure 11: Prompt provided to LLaMA-3-70B in the Feedback step. We focused on reviewing the scores from the\nScoring step and generating feedback to improve areas with lower scores.\nFigure 12: Example of sufficient information retrieved from Wikipedia: Cowboy hat (USA clothes). This culture\nnoun, classified within the Q4 group and categorized under RC nouns, provided detailed information on its\nappearance and cultural significance, accessible solely through Wikipedia.\nFigure 13: Example of insufficient information retrieved from Wikipedia: Degchi (Pakistan utensil). This culture\nnoun, classified within the Q1 group and categorized under UC nouns, could not be found on Wikipedia. Additional\ncultural information was subsequently obtained through a web search.\n\nFigure 14: The step-by-step results of C-TRIP. The example uses \"hangari\", a Korean conventional utensil. In the\n(t-1)th iteration, a score is assigned based on the criteria, and feedback is generated based on this score. Then, in the\nt-th iteration, the prompt is revised using the feedback.\nCountry\nCulture noun\nConfiguration\nPrompt\nPakistan\nDegchi\nBase prompt\nThe task was made easier with a degchi.\nC-TRIP0\nThe task was made easier with a degchi, a must-have\nutensil for any hardcore foodie, providing a seductive\nand smoked flavor to dishes.\nC-TRIP3\nThe task was made easier with a degchi, which al-\nlowed for efficient cooking and storage of ingredi-\nents.\nC-TRIP5\nThe task was made easier with a degchi, a type of\ntraditional Indian cooking pot known for its rich fla-\nvors and aromas. This utensil was made from heavy-\ngauge brass and resembled a deep cooking vessel\nwith enough space to cook and store milk, tea, veg-\netable curries, curd, and other ingredients. Its versa-\ntility in cooking both vegetarian and non-vegetarian\ndishes made it an essential tool.\nChina\nJade art\nBase prompt\nThe gallery opening was a major event for jade art\nenthusiasts.\nC-TRIP0\nThe gallery opening was a major event for jade art en-\nthusiasts who appreciated the stone’s subtle, translu-\ncent colors and its association with Chinese concep-\ntions of the soul and immortality. The exhibit fea-\ntured a range of jade pieces, from ancient artifacts to\nmodern creations, showcasing the evolution of jade\nart over thousands of years. Attendees were treated to\nan immersive experience, surrounded by the beauty\nand symbolism of this revered stone.\nC-TRIP3\nThe gallery opening was a major event for jade art en-\nthusiasts, who admired the subtle, translucent colors\nand artistic treatment of jade. The exhibit featured\nintricately crafted jade artifacts, created by skilled\nartisans over seven millennia ago. With gold, it rep-\nresented the sky, earth, and four directions.\n\nC-TRIP5\nThe gallery opening was a major event for jade art\nenthusiasts, who gathered to marvel at the exquisite\ncarvings, jewelry, and ornaments on display, crafted\nfrom nephrite and jadeite minerals prized for their\nvibrant colors and high translucency. The exhibit\nfeatured pieces with delicate filigree patterns, ornate\ndesigns, and symbols of good fortune, showcasing\nthe great skill and attention to detail involved in shap-\ning these minerals into beautiful works of art. The\nevent was a testament to the enduring appeal of jade\nart.\nKorea\nHanbok\nBase prompt\nhanbok are scattered on the floor after a long day.\nC-TRIP0\nhanbok are scattered on the floor after a long day,\ntheir delicate fabrics crumpled and disheveled. De-\nspite the chaos, the vibrant colors and intricate pat-\nterns of the garments remain striking, a testament to\nthe beauty and elegance of traditional Korean cloth-\ning.\nC-TRIP3\nhanbok are scattered on the floor after a long day of\nfestivities and celebrations. The hanbok is a tradi-\ntional Korean dress that is worn for formal or semi-\nformal occasions. In modern times, Koreans often\nwear hanbok to cultural events and festivals.\nC-TRIP5\nHanbok are scattered on the floor after a long day,\ntheir vibrant colors and intricate designs reflecting\nKorea’s rich cultural heritage. The traditional cloth-\ning features a unique blend of straight and curved\nlines that are representative of a distinctly Korean\naesthetic. With its roots tracing back to the Three\nKingdoms of Korea period, these elegant dresses are\ntypically worn on special occasions such as weddings\nand festivals.\nIndia\nMasala dabba\nBase prompt\nA simple masala dabba helped achieve the desired\ntexture.\nC-TRIP0\nA simple masala dabba helped achieve the desired\ntexture by providing quick access to the necessary\nspices without having to search through cabinets or\ndrawers. The box’s compact design made it easy\nto store on the countertop, keeping the workspace\nclutter-free and organized. With its small spoon, the\ncook could measure out the perfect amount of each\nspice.\nC-TRIP3\nA simple masala dabba helped achieve the desired\ntexture, by providing quick access to spices like\ncumin, coriander, and turmeric, which are essential\nfor many Indian dishes.\n\nC-TRIP5\nA simple masala dabba helped achieve the desired\ntexture, its carefully arranged cups holding the se-\ncrets to the recipe’s success. The cook knew that\nwith this container, they could confidently combine\nthe various spices and seasonings, resulting in a culi-\nnary masterpiece. It was an indispensable item in\ntheir kitchen, one that had been passed down through\ngenerations.\nUSA\nWillis tower\nBase prompt\nchicago (willis tower) was beautifully lit up at night.\nC-TRIP0\nchicago (willis tower) was beautifully lit up at night,\nmaking it a stunning sight in the city’s skyline. Its\nunique design and impressive height make it a pop-\nular spot for photographers and tourists alike. The\nbuilding’s facade is made of anodized aluminum and\nblack glass, which adds to its visual appeal.\nC-TRIP3\nchicago (Willis Tower) was beautifully lit up at night,\nmaking it one of Chicago’s most popular tourist desti-\nnations, with its facade made of anodized aluminum\nand black glass shining brightly.\nC-TRIP5\nThe Willis Tower was beautifully lit up at night, its\nanodized aluminum and black glass façade shimmer-\ning against the city lights. The building’s unique\ndesign took on a new level of sophistication in the\nevening hours, becoming a beacon of light in the\nChicago skyline. Its nighttime beauty was a sight to\nbehold.\nVietnam\nPho\nBase prompt\npho is a delicious way to start any meal.\nC-TRIP0\nPho is a delicious way to start any meal, with its\nwarm, comforting broth and tender noodles providing\na satisfying and filling experience.\nC-TRIP3\nPho is a delicious way to start any meal, with its\nwarm, comforting broth and soft rice noodles provid-\ning a soothing contrast to the crunch of fresh herbs\nand the savory flavor of meat.\nC-TRIP5\npho is a delicious way to start any meal, providing\ncomfort and sustenance, whether as a light breakfast,\na satisfying lunch, or a nourishing dinner.\n\nItem Title\nItem Text\nCultural Representation\nRank the images from 1 for the best representation of [country]\nculture to 4 for the worst cultural representation. Please ignore\nimage artifacts (such as distorted faces, hands, or glitches) when\nconsidering Cultural Representation. (1=most representative,\n4=least representative)\nThe naturalness of the keyword\nKeyword: [keyword], Rank the images from 1 for the most natural-\nlooking to 4 for the least natural-looking. Please ignore image\nartifacts (such as distorted faces, hands, or glitches) when consid-\nering The naturalness of the keyword. (1=most natural, 4=least\nnatural)\nOffensiveness\nRank the images by their offensiveness to you personally, num-\nbering from 1 as the least offensive to 4 for the most offensive.\nPlease ignore image artifacts (such as distorted faces, hands, or\nglitches) when considering Offensiveness. (1=least offensive,\n4=most offensive)\nDescription and Image Alignment\nImage Description: [prompt], Rank the accuracy of the match\nbetween the image and its description. Number each image from\n1 for the image best described by the description to 4 for the\nworst match between image and description. (1=best described,\n4=worst described)\nTable 15: The four survey items for our human evaluation survey.\n\nFigure 15: A sample page from the survey presents participants with four images, and below, they are asked to enter\na rank between 1 and 4 into designated text fields. Participants provide evaluations based on four criteria: Cultural\nRepresentation, Keyword Naturalness, Offensiveness, and Alignment between Description and Image. For each\nsurvey item, four images are displayed in a randomized but consistent order throughout the page.\n\nCountry\nQuartile\nCulture nouns (Count)\nChina\nQ1\nZhongshan suit (290), Siheyuan (408), Tangzhuang (462)\nQ2\nXiaolongbao (555), Dunhuang (Mogao Caves) (1042), Chinese\nbamboo steamer (1541), Chinese hot pot (2700), Tulou (2830),\nQingming (2901)\nQ3\nYangge (4115), Peking duck (5077), Shanghai (Oriental Pearl\nTower) (5522), Chinese wok (5630), Chinese pagoda (10490),\nChinese Mid-Autumn Festival (10645), Jade art (10856),\nXi’an (Terracotta Army) (12477), Mooncake (15494), Won-\nton (16147)\nQ4\nBeijing (Temple of Heaven) (20108), Lion dance (27302), Qi-\npao (42352), Beijing (Forbidden City) (55328), Hanfu (107289),\nChinese New Year (391554)\nGermany\nQ1\nRouladenklammer (0), Zwiefacher (6), Deutsch Renaissance\n(12), Weihnachtsmärkte (17), Nikolaustag (66), Bratpfanne\n(113), Schuhplattler (129), German Romanesque (138), Knödel\n(409), Schürze (459)\nQ2\nGerman Gothic (2105), German Baroque (2139), Currywurst\n(2831)\nQ3\nTracht (3855), Heidelberg (Heidelberg Castle) (4885), Munich\n(Munich’s Marienplatz) (5646), Bratwurst (7746), Lederhosen\n(8854), Berlin (Brandenburger Tor) (9286), Sauerkraut (17848)\nQ4\nDirndl (19876), Bavaria (Neuschwanstein Castle) (21512),\nCologne (Cologne Cathedral) (29416), Mulled wine (52917),\nOktoberfest (111654)\nIndia\nQ1\nGupta architecture (148), Allahabad (Allahabad Fort) (203),\nIndian stupa (298), Manipuri dance (321)\nQ2\nMasala dabba (825), Bharatnatyam (1280), Vada pav (1355),\nAloo gobi (1797), Mughal architecture (2736), Delhi (Qutub\nMinar) (3833)\nQ3\nMughal Painting (4618), Saag (5053), Shalwar kameez (8824),\nTawa (8949), Jaipur (Amber Fort) (13909), Paratha (14272),\nDurga Puja (14904)\nQ4\nDhoti (26053), Biryani (30699), Delhi (Red Fort) (43940), Agra\n(Taj Mahal) (92631), Holi (124249), Sari (129095), Diwali\n(207137), Lehenga (261160)\nJapan\nQ1\nSashimi b¯och¯o (0), Noh mai (15), Edo architecture (207)\nQ2\nShinto architecture (505), Takoyaki pan (629), Gion Matsuri\n(711), Hanten (756), Gyudon (889), Sanja Matsuri (944), Sap-\nporo Snow Festival (1603), Okonomiyaki (2976), Wagashi\n(3083), Matsumoto (Matsumoto Castle) (3242)\nQ3\nHakama (4957), Gyoza (6092), Haori (6293), Kyoto (Kinkaku-\nji) (6591), Osaka (Osaka Castle) (7576), Yukata (14470), Tem-\npura (15307)\nQ4\nTokyo (Tokyo Tower) (21830), Torii (23570), Kabuki (27924),\nShizuoka (Mount Fuji) (36331), Origami (566794)\nPakistan\nQ1\nPakistani Indo-Islamic architecture (0), Pakistani Buddhist ar-\nchitecture (0), Jhumair (1), Hyderabad (Pakka Qila) (10), Mul-\ntan (Shrine of Bahauddin Zakariya) (19), Pakistani Mughal\narchitecture (29), Khattak dance (32), Degchi (50), Gol gappa\n(175), Karachi (Mazar-e-Quaid) (264)\n\nQ2\nNihari (733), Islamabad (Faisal mosque) (1591), Karahi (2327),\nLahore (Badshahi Mosque) (2607), Vaisakhi (3046)\nQ3\nGulab jamun (4181), Kheer (4285), Gharara (6853), Shalwar\nkameez (8824)\nQ4\nEid al-Fitr (17903), Eid al-Adha (18648), Biryani (30699), Sher-\nwani (34183), Truck art (46479), Lehenga (261160)\nSouth Korea\nQ1\nCheoyongmu (1), Gamasot (23), Durumagi (28), Aundubujjigae\n(29), Hangari (49), Buchaechum (49), Jeogori (200), Minhwa\n(310), Seollal (416)\nQ2\nSeoul (Jongmyo Shrine) (523), Dangui (594), Korean pagoda\n(895), Bingsu (945), Gyeongju (Bulguksa) (1002), Tteokbokki\n(1026), Suwon (Hwaseong Fortress) (1491), Korean temple\n(1846), Jeonju (Hanok Village) (3018)\nQ3\nChuseok (3853), Korean New Year (4840), Hanok (5797), Seoul\n(Gyeongbokgung) (7423), Bibimbap (7718)\nQ4\nHanbok (30133), Kimchi (33340)\nUSA\nQ1\nQ2\nCotton-Eyed Joe (542), Mission Revival (1909)\nQ3\nBuffalo check shirt (4342), American Craftsman (5101), Clam\nchowder (9757), Colonial Revival (11429), American folk\nart (11432), Barbecue ribs (11789), Chicago (Willis Tower)\n(12907)\nQ4\nLos Angeles (Hollywood Sign) (33952), Buffalo wings (34780),\nCast iron skillet (41098), Denim overalls (43346), Butter\ndish (52346), Cornbread (55906), Quilted vest (61705), Blue-\ngrass (96302), Cowboy hat (112205), San Francisco (Golden\nGate Bridge) (120285), Apple pie (137320), New York City\n(Statue of Liberty) (180139), Memorial Day (270410), Indepen-\ndence Day (424057), Washington (The White House) (603026),\nThanksgiving (1375806)\nVietnam\nQ1\nVietnamese dynasty architecture (4), Vietnamese stilt house\n(15), Ao tu than (17), Vietnamese silk painting (21), Mua lan\n(36), Vietnamese wok (38), Ao ba ba (43), Vietnamese clay\npot (68), Hung Kings Temple Festival (151), Vietnamese Mid-\nAutumn Festival (305), Goi cuon (385)\nQ2\nVietnamese pagoda (484), Hnoi (One Pillar Pagoda) (554),\nBanh Xeo (658), Quang Nam (My Son Sanctuary) (998), Quan\nho (1132), Bun Cha (1301), Hue (Imperial City of Hue) (1814),\nVietnamese Lunar New Year (3055), Hanoi (Temple of litera-\nture) (3628)\nQ3\nNon la (5798), Banh mi (8550), Ao dai (12302)\nQ4\nHanoi (Old Quarter) (26451), Pho (66696)\nTable 16: Culture noun counts by Quartile of each country\n\nFigure 16: Additional Qualitative Sample for Chinese culture. The top two images show the results of C-TRIP\nfor culture nouns categorized under UC nouns, while the bottom two images present the result for culture nouns\ncategorized under RC nouns.\n\nFigure 17: Additional Qualitative Sample for German culture. The top two images show the results of C-TRIP\nfor culture nouns categorized under UC nouns, while the bottom two images present the result for culture nouns\ncategorized under RC nouns.\n\nFigure 18: Additional Qualitative Sample for Indian culture. The top two images show the results of C-TRIP\nfor culture nouns categorized under UC nouns, while the bottom two images present the result for culture nouns\ncategorized under RC nouns.\n\nFigure 19: Additional Qualitative Sample for Japanese culture. The top two images show the results of C-TRIP\nfor culture nouns categorized under UC nouns, while the bottom two images present the result for culture nouns\ncategorized under RC nouns.\n\nFigure 20: Additional Qualitative Sample for Pakistani culture. The top two images show the results of C_TRIP\nfor culture nouns categorized under UC nouns, while the bottom two images present the result for culture nouns\ncategorized under RC nouns.\n\nFigure 21: Additional Qualitative Sample for Korean culture. The top two images show the results of C-TRIP\nfor culture nouns categorized under UC nouns, while the bottom two images present the result for culture nouns\ncategorized under RC nouns.\n\nFigure 22: Additional Qualitative Sample for American culture. The top one image show the results of C-TRIP\nfor culture nouns categorized under UC nouns (The United States has no culture nouns categorized under Q1.),\nwhile the bottom two images present the result for culture nouns categorized under RC nouns.\n\nFigure 23: Additional Qualitative Sample for Vietnamese culture. The top two images show the results of\nC-TRIP for culture nouns categorized under UC nouns, while the bottom two images present the result for culture\nnouns categorized under RC nouns.\n",
  "metadata": {
    "source_path": "papers/arxiv/Culture-TRIP_Culturally-Aware_Text-to-Image_Generation_with_Iterative\n__Prompt_Refinment_ed1ffc9925d7389b.pdf",
    "content_hash": "ed1ffc9925d7389b1b46e1049e7ddc5b4c243f11973fdcd8a97e8c75dc3b5914",
    "arxiv_id": null,
    "title": "Culture-TRIP_Culturally-Aware_Text-to-Image_Generation_with_Iterative\n__Prompt_Refinment_ed1ffc9925d7389b",
    "author": "",
    "creation_date": "D:20250225022921Z",
    "published": "2025-02-25T02:29:21",
    "pages": 31,
    "size": 33047186,
    "file_mtime": 1740470211.7928982
  }
}